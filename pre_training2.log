Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
hour2
SimMTM
input_len:336
backbone:vanilla
mask_size:336
mask_rate:0.25
mask_num:3
is_decomp:True
is_norm:True
CI:True
part:s
decomp:fft
st_sep:3.5
topk:50
epoch: 1/20
loss_r:0.3874445855617523
loss_c:2.9317712783813477
tensor(3.0459, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.3191680312156677
loss_c:2.7981796264648438
tensor(2.9425, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.16808608174324036
loss_c:2.910672664642334
tensor(2.9202, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.26538795232772827
loss_c:2.588174343109131
tensor(2.8061, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1461775302886963
loss_c:2.6808853149414062
tensor(2.7898, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.22168560326099396
loss_c:2.8646934032440186
tensor(2.9164, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07696951180696487
loss_c:2.7154593467712402
tensor(2.7669, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07292786240577698
loss_c:2.5749049186706543
tensor(2.6929, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07843942195177078
loss_c:2.7876029014587402
tensor(2.7980, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08160462230443954
loss_c:2.5412378311157227
tensor(2.6759, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.22887954115867615
loss_c:2.465813159942627
tensor(2.7117, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11861824244260788
loss_c:2.5404012203216553
tensor(2.6897, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11080602556467056
loss_c:3.0037200450897217
tensor(2.9097, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10575704276561737
loss_c:2.7312769889831543
tensor(2.7716, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09897392988204956
loss_c:2.372192859649658
tensor(2.5909, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1511896252632141
loss_c:2.321894645690918
tensor(2.5912, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11409684270620346
loss_c:2.5174267292022705
tensor(2.6648, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07956670969724655
loss_c:2.548910617828369
tensor(2.6599, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10541626065969467
loss_c:2.6319475173950195
tensor(2.7112, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0983959510922432
loss_c:2.4183645248413086
tensor(2.6023, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07394666224718094
loss_c:2.3817644119262695
tensor(2.5698, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08018510043621063
loss_c:2.3620405197143555
tensor(2.5615, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06850700825452805
loss_c:2.4906234741210938
tensor(2.6149, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.2145565003156662
loss_c:2.2216389179229736
tensor(2.5606, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05528724938631058
loss_c:2.246124267578125
tensor(2.4869, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07642129808664322
loss_c:2.3191840648651123
tensor(2.5309, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08703934401273727
loss_c:2.6618025302886963
tensor(2.6976, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.12361954152584076
loss_c:2.3451995849609375
tensor(2.5643, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08555654436349869
loss_c:2.2669525146484375
tensor(2.5051, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11197818070650101
loss_c:2.4205596446990967
tensor(2.5899, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.14753757417201996
loss_c:2.2331645488739014
tensor(2.5183, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09867561608552933
loss_c:2.0953919887542725
tensor(2.4255, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.15722236037254333
loss_c:2.2498345375061035
tensor(2.5278, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0726483166217804
loss_c:2.2606115341186523
tensor(2.4859, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07458051294088364
loss_c:2.232273817062378
tensor(2.4718, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08430276066064835
loss_c:2.205803871154785
tensor(2.4628, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07301671802997589
loss_c:2.2281861305236816
tensor(2.4654, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07030951231718063
loss_c:2.0734968185424805
tensor(2.3899, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07790609449148178
loss_c:2.27132248878479
tensor(2.4847, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07568607479333878
loss_c:2.6292738914489746
tensor(2.6484, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08541445434093475
loss_c:2.124366283416748
tensor(2.4168, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.13611552119255066
loss_c:2.1718685626983643
tensor(2.4648, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08357938379049301
loss_c:2.002262830734253
tensor(2.3559, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.14166474342346191
loss_c:2.252199172973633
tensor(2.5018, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07637655735015869
loss_c:2.2187247276306152
tensor(2.4489, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.13385304808616638
loss_c:1.9053189754486084
tensor(2.3342, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.059663958847522736
loss_c:2.423617124557495
tensor(2.5308, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1260441392660141
loss_c:2.0379700660705566
tensor(2.3881, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11369689553976059
loss_c:1.849518060684204
tensor(2.2932, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07117689400911331
loss_c:1.9963245391845703
tensor(2.3357, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09210196137428284
loss_c:1.9935662746429443
tensor(2.3446, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07082710415124893
loss_c:1.943641185760498
tensor(2.3084, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09153660386800766
loss_c:1.966193675994873
tensor(2.3289, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0729752779006958
loss_c:2.0948314666748047
tensor(2.3758, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05338704213500023
loss_c:1.935962200164795
tensor(2.2909, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07468988746404648
loss_c:2.0335652828216553
tensor(2.3459, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10447074472904205
loss_c:1.8016184568405151
tensor(2.2557, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0962447077035904
loss_c:1.7775734663009644
tensor(2.2389, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.060293909162282944
loss_c:1.7531722784042358
tensor(2.2063, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.12155351042747498
loss_c:1.9315284490585327
tensor(2.3205, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.059972185641527176
loss_c:1.6899775266647339
tensor(2.1750, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1759316474199295
loss_c:1.6703178882598877
tensor(2.2308, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.094966821372509
loss_c:1.9507360458374023
tensor(2.3102, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08161280304193497
loss_c:1.78645658493042
tensor(2.2272, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.047914497554302216
loss_c:1.9605293273925781
tensor(2.2851, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.16799338161945343
loss_c:1.9721802473068237
tensor(2.3579, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0559035949409008
loss_c:1.7970250844955444
tensor(2.2136, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08718915283679962
loss_c:1.962957739830017
tensor(2.3048, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06688214093446732
loss_c:1.8931231498718262
tensor(2.2605, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08935901522636414
loss_c:1.864309310913086
tensor(2.2594, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07279790192842484
loss_c:1.9291930198669434
tensor(2.2776, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.13916334509849548
loss_c:1.8064968585968018
tensor(2.2600, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.21178260445594788
loss_c:1.7742637395858765
tensor(2.2868, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05916309729218483
loss_c:1.7737541198730469
tensor(2.1965, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07706482708454132
loss_c:1.7971460819244385
tensor(2.2162, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06905107200145721
loss_c:1.6107311248779297
tensor(2.1274, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11295618116855621
loss_c:1.6836755275726318
tensor(2.1845, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05486827716231346
loss_c:1.8935191631317139
tensor(2.2424, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11087684333324432
loss_c:1.9393658638000488
tensor(2.2946, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09630542248487473
loss_c:1.7557181119918823
tensor(2.2034, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08175762742757797
loss_c:1.8575042486190796
tensor(2.2387, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1226266622543335
loss_c:1.723854422569275
tensor(2.2027, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0645892545580864
loss_c:1.6039923429489136
tensor(2.1141, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1800672709941864
loss_c:1.6587884426116943
tensor(2.2061, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06713277846574783
loss_c:1.946272373199463
tensor(2.2645, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.058820296078920364
loss_c:1.5899739265441895
tensor(2.1013, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1135035902261734
loss_c:1.8443877696990967
tensor(2.2451, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07281412184238434
loss_c:1.6991641521453857
tensor(2.1556, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05341264605522156
loss_c:1.719731330871582
tensor(2.1519, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1276586800813675
loss_c:1.650714635848999
tensor(2.1653, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06271474808454514
loss_c:1.9078330993652344
tensor(2.2378, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05420944467186928
loss_c:1.7746915817260742
tensor(2.1731, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040446776896715164
loss_c:1.93101966381073
tensor(2.2321, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.061350010335445404
loss_c:1.6747965812683105
tensor(2.1314, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05616651847958565
loss_c:1.5901846885681152
tensor(2.0902, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.049371711909770966
loss_c:1.7310419082641602
tensor(2.1465, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05201742425560951
loss_c:1.832486867904663
tensor(2.1912, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.045437462627887726
loss_c:1.6521492004394531
tensor(2.1074, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09277691692113876
loss_c:1.54545259475708
tensor(2.0889, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.15469112992286682
loss_c:1.6058580875396729
tensor(2.1525, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06831979751586914
loss_c:1.606191635131836
tensor(2.0982, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0858936533331871
loss_c:1.8507263660430908
tensor(2.2144, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0657990351319313
loss_c:1.872291922569275
tensor(2.2102, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.050162892788648605
loss_c:1.646890640258789
tensor(2.1015, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.20161880552768707
loss_c:1.7760789394378662
tensor(2.2510, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11386274546384811
loss_c:1.6835830211639404
tensor(2.1551, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10143058001995087
loss_c:1.5963529348373413
tensor(2.1086, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07490570843219757
loss_c:1.4940599203109741
tensor(2.0467, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10847503691911697
loss_c:1.6353321075439453
tensor(2.1279, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1220834031701088
loss_c:1.5634212493896484
tensor(2.1045, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06774593144655228
loss_c:1.5666477680206299
tensor(2.0706, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08184923231601715
loss_c:1.6686532497406006
tensor(2.1226, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06265255808830261
loss_c:1.5584981441497803
tensor(2.0619, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10217619687318802
loss_c:1.4748876094818115
tensor(2.0501, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05989835038781166
loss_c:1.5152000188827515
tensor(2.0395, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.12545698881149292
loss_c:1.710754632949829
tensor(2.1647, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05234132707118988
loss_c:1.718612551689148
tensor(2.1202, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05809303745627403
loss_c:1.6071500778198242
tensor(2.0750, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08719979971647263
loss_c:1.910827875137329
tensor(2.2231, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.052097681909799576
loss_c:1.689401626586914
tensor(2.1044, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.24545781314373016
loss_c:1.7222669124603271
tensor(2.2426, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0606689490377903
loss_c:1.497629165649414
tensor(2.0257, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05719509720802307
loss_c:1.6439036130905151
tensor(2.0851, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.048903822898864746
loss_c:1.8233003616333008
tensor(2.1555, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06129990145564079
loss_c:1.487937331199646
tensor(2.0191, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.056296251714229584
loss_c:1.5344483852386475
tensor(2.0347, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.054528508335351944
loss_c:1.9988353252410889
tensor(2.2309, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05392574518918991
loss_c:1.6447460651397705
tensor(2.0783, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04967806115746498
loss_c:1.6432373523712158
tensor(2.0738, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0467456579208374
loss_c:1.6786617040634155
tensor(2.0859, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06804317235946655
loss_c:1.5811471939086914
tensor(2.0575, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08312654495239258
loss_c:1.5818607807159424
tensor(2.0668, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0864742323756218
loss_c:1.4959825277328491
tensor(2.0315, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.20842956006526947
loss_c:1.5788660049438477
tensor(2.1472, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.050940752029418945
loss_c:1.531628966331482
tensor(2.0211, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.050609976053237915
loss_c:1.543877124786377
tensor(2.0251, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.060752250254154205
loss_c:1.5873537063598633
tensor(2.0494, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0455033965408802
loss_c:1.8284926414489746
tensor(2.1404, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06112755835056305
loss_c:1.5194222927093506
tensor(2.0189, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.060208819806575775
loss_c:1.4934260845184326
tensor(2.0064, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08464284241199493
loss_c:1.5275352001190186
tensor(2.0364, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10166703909635544
loss_c:1.6471503973007202
tensor(2.0976, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05035366117954254
loss_c:1.8181467056274414
tensor(2.1341, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05974951013922691
loss_c:1.6026334762573242
tensor(2.0484, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043078940361738205
loss_c:1.5553185939788818
tensor(2.0160, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04134681075811386
loss_c:1.5225028991699219
tensor(2.0000, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07115790992975235
loss_c:1.4916818141937256
tensor(2.0065, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05329118296504021
loss_c:1.8888871669769287
tensor(2.1607, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09638480097055435
loss_c:1.5155324935913086
tensor(2.0321, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03595982864499092
loss_c:1.624917984008789
tensor(2.0355, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06485619395971298
loss_c:1.4641273021697998
tensor(1.9869, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04777855798602104
loss_c:1.4624695777893066
tensor(1.9734, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05975184589624405
loss_c:1.6701663732528687
tensor(2.0680, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.056360386312007904
loss_c:1.6406705379486084
tensor(2.0523, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0690712034702301
loss_c:1.4936838150024414
tensor(1.9985, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08819480985403061
loss_c:1.4523944854736328
tensor(1.9937, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043195776641368866
loss_c:1.4960815906524658
tensor(1.9795, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.055256426334381104
loss_c:1.4082940816879272
tensor(1.9502, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05545099452137947
loss_c:1.4544651508331299
tensor(1.9688, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09821631014347076
loss_c:1.5235297679901123
tensor(2.0271, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1260174810886383
loss_c:1.592923879623413
tensor(2.0750, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11151935160160065
loss_c:1.4786747694015503
tensor(2.0161, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.13389964401721954
loss_c:1.5598139762878418
tensor(2.0652, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041647616773843765
loss_c:1.8224725723266602
tensor(2.1082, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05011352151632309
loss_c:1.4865777492523193
tensor(1.9729, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06093987822532654
loss_c:1.6447213888168335
tensor(2.0458, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.12001346051692963
loss_c:1.6891368627548218
tensor(2.1060, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07852088660001755
loss_c:1.615332007408142
tensor(2.0444, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06190641224384308
loss_c:1.5569281578063965
tensor(2.0071, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.13283933699131012
loss_c:1.3678288459777832
tensor(1.9789, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06501533836126328
loss_c:1.532412052154541
tensor(1.9974, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06191456690430641
loss_c:1.4698047637939453
tensor(1.9682, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10009804368019104
loss_c:1.3633685111999512
tensor(1.9509, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044095925986766815
loss_c:1.561766505241394
tensor(1.9916, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08209455758333206
loss_c:1.5517055988311768
tensor(2.0144, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05270009487867355
loss_c:1.6213182210922241
tensor(2.0209, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07986050099134445
loss_c:1.4995903968811035
tensor(1.9894, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0552455335855484
loss_c:1.7418632507324219
tensor(2.0710, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03897871822118759
loss_c:1.5856107473373413
tensor(1.9931, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046646129339933395
loss_c:1.7542712688446045
tensor(2.0678, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0485512912273407
loss_c:1.5186126232147217
tensor(1.9706, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0426645465195179
loss_c:1.4958752393722534
tensor(1.9558, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07154329866170883
loss_c:1.501592993736267
tensor(1.9789, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10631345957517624
loss_c:1.4734487533569336
tensor(1.9924, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04568509757518768
loss_c:1.4485429525375366
tensor(1.9357, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06138717010617256
loss_c:1.5174412727355957
tensor(1.9752, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04459642618894577
loss_c:1.458174467086792
tensor(1.9371, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04926272854208946
loss_c:1.420859694480896
tensor(1.9243, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.13037452101707458
loss_c:1.703225016593933
tensor(2.1017, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09324926137924194
loss_c:1.3876426219940186
tensor(1.9423, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07904218882322311
loss_c:1.3603370189666748
tensor(1.9194, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04148217663168907
loss_c:1.557120680809021
tensor(1.9711, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.14480075240135193
loss_c:1.3454980850219727
tensor(1.9621, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05067035183310509
loss_c:1.593437910079956
tensor(1.9913, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05437054857611656
loss_c:1.4946187734603882
tensor(1.9525, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04966362193226814
loss_c:1.3214881420135498
tensor(1.8767, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06416879594326019
loss_c:1.4237499237060547
tensor(1.9292, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05910015106201172
loss_c:1.613717794418335
tensor(2.0026, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04238029196858406
loss_c:1.4994786977767944
tensor(1.9417, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07321753352880478
loss_c:1.471689224243164
tensor(1.9534, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05812665447592735
loss_c:1.49153470993042
tensor(1.9490, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.057052865624427795
loss_c:1.4280208349227905
tensor(1.9211, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06878382712602615
loss_c:1.4905612468719482
tensor(1.9552, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06032371520996094
loss_c:1.6128532886505127
tensor(1.9980, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04416678473353386
loss_c:1.3611021041870117
tensor(1.8809, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05073845759034157
loss_c:1.449900507926941
tensor(1.9217, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.13848264515399933
loss_c:1.3939602375030518
tensor(1.9675, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046147678047418594
loss_c:1.3940141201019287
tensor(1.8934, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07562938332557678
loss_c:1.4804857969284058
tensor(1.9515, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036282796412706375
loss_c:1.3306089639663696
tensor(1.8578, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04493119567632675
loss_c:1.44583261013031
tensor(1.9111, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.045308467000722885
loss_c:1.4227298498153687
tensor(1.9010, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03590095788240433
loss_c:1.3833235502243042
tensor(1.8764, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04879625141620636
loss_c:1.5241577625274658
tensor(1.9437, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0469832643866539
loss_c:1.3555701971054077
tensor(1.8723, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.15469388663768768
loss_c:1.6126317977905273
tensor(2.0641, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06162034720182419
loss_c:1.395536184310913
tensor(1.8988, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033084459602832794
loss_c:1.5110448598861694
tensor(1.9221, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05409698188304901
loss_c:1.4188718795776367
tensor(1.9006, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.048435866832733154
loss_c:1.4691896438598633
tensor(1.9157, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0387859083712101
loss_c:1.336256742477417
tensor(1.8525, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04565814509987831
loss_c:1.346480369567871
tensor(1.8615, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07682083547115326
loss_c:1.4144132137298584
tensor(1.9141, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05143405869603157
loss_c:1.4400074481964111
tensor(1.9028, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04597027227282524
loss_c:1.218503475189209
tensor(1.8068, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.16476091742515564
loss_c:1.382922649383545
tensor(1.9720, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03723614662885666
loss_c:1.4521369934082031
tensor(1.8934, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04669392481446266
loss_c:1.6016687154769897
tensor(1.9616, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041456036269664764
loss_c:1.4459681510925293
tensor(1.8927, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03351624310016632
loss_c:1.4550139904022217
tensor(1.8889, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04707324877381325
loss_c:1.333611249923706
tensor(1.8498, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06407493352890015
loss_c:1.432576060295105
tensor(1.9038, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07565265893936157
loss_c:1.5048997402191162
tensor(1.9423, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08912263810634613
loss_c:1.3239861726760864
tensor(1.8790, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06133563444018364
loss_c:1.3363769054412842
tensor(1.8597, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04090176150202751
loss_c:1.338254451751709
tensor(1.8423, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.045593664050102234
loss_c:1.4134410619735718
tensor(1.8761, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03519962355494499
loss_c:1.4141318798065186
tensor(1.8667, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05341479182243347
loss_c:1.4342041015625
tensor(1.8897, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04691661521792412
loss_c:1.5152086019515991
tensor(1.9163, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03428097069263458
loss_c:1.4170870780944824
tensor(1.8645, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04290115833282471
loss_c:1.4013586044311523
tensor(1.8647, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.050826821476221085
loss_c:1.2973074913024902
tensor(1.8283, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.051171012222766876
loss_c:1.414808750152588
tensor(1.8757, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.053123053163290024
loss_c:1.452202320098877
tensor(1.8918, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05285051092505455
loss_c:1.534468650817871
tensor(1.9242, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10754252225160599
loss_c:1.2964942455291748
tensor(1.8744, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05432279780507088
loss_c:1.244124412536621
tensor(1.8056, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04326566681265831
loss_c:1.3504197597503662
tensor(1.8383, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04638613387942314
loss_c:1.5614604949951172
tensor(1.9263, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04873262718319893
loss_c:1.2276649475097656
tensor(1.7915, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07104028761386871
loss_c:1.7027686834335327
tensor(2.0041, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1182655543088913
loss_c:1.5316286087036133
tensor(1.9756, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04007377848029137
loss_c:1.5355334281921387
tensor(1.9067, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04058300331234932
loss_c:1.3325364589691162
tensor(1.8237, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046391699463129044
loss_c:1.5145974159240723
tensor(1.9022, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04844329506158829
loss_c:1.4675716161727905
tensor(1.8841, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05917546525597572
loss_c:1.213010549545288
tensor(1.7894, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04323874041438103
loss_c:1.4233322143554688
tensor(1.8598, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.13028642535209656
loss_c:1.4847536087036133
tensor(1.9629, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0658426433801651
loss_c:1.555826187133789
tensor(1.9326, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041945669800043106
loss_c:1.421849250793457
tensor(1.8556, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036788083612918854
loss_c:1.3244655132293701
tensor(1.8104, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041644319891929626
loss_c:1.3155229091644287
tensor(1.8104, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10151581466197968
loss_c:1.4436535835266113
tensor(1.9167, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05330153927206993
loss_c:1.408695936203003
tensor(1.8574, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0523962564766407
loss_c:1.4485610723495483
tensor(1.8720, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.056522004306316376
loss_c:1.5614392757415771
tensor(1.9209, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04680294170975685
loss_c:1.269005537033081
tensor(1.7923, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03836613520979881
loss_c:1.3037333488464355
tensor(1.7978, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.14337512850761414
loss_c:1.5167787075042725
tensor(1.9815, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05223517492413521
loss_c:1.327031135559082
tensor(1.8186, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03967243805527687
loss_c:1.4583238363265991
tensor(1.8594, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040624674409627914
loss_c:1.4011973142623901
tensor(1.8363, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040969621390104294
loss_c:1.2899932861328125
tensor(1.7907, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08615100383758545
loss_c:1.4059942960739136
tensor(1.8797, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0646340548992157
loss_c:1.5486371517181396
tensor(1.9165, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1044357493519783
loss_c:1.2962743043899536
tensor(1.8512, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03666865453124046
loss_c:1.2029496431350708
tensor(1.7482, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036899272352457047
loss_c:1.4722989797592163
tensor(1.8569, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.054401546716690063
loss_c:1.2844877243041992
tensor(1.7966, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04102237895131111
loss_c:1.278660774230957
tensor(1.7807, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06319212913513184
loss_c:1.5000760555267334
tensor(1.8911, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0744069367647171
loss_c:1.4362075328826904
tensor(1.8752, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038704968988895416
loss_c:1.1753803491592407
tensor(1.7342, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037581466138362885
loss_c:1.2480390071868896
tensor(1.7618, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07877951115369797
loss_c:1.3968809843063354
tensor(1.8614, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04169481620192528
loss_c:1.2928533554077148
tensor(1.7824, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04338325187563896
loss_c:1.3023817539215088
tensor(1.7872, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04396524652838707
loss_c:1.2854896783828735
tensor(1.7801, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.049169111996889114
loss_c:1.226165533065796
tensor(1.7604, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05068420246243477
loss_c:1.3519601821899414
tensor(1.8121, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.058945052325725555
loss_c:1.318698525428772
tensor(1.8060, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04285285994410515
loss_c:1.1793158054351807
tensor(1.7328, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11167549341917038
loss_c:1.3454021215438843
tensor(1.8677, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.14330735802650452
loss_c:1.3446468114852905
tensor(1.8983, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0464135967195034
loss_c:1.3146295547485352
tensor(1.7890, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06527557969093323
loss_c:1.2085378170013428
tensor(1.7641, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046866752207279205
loss_c:1.7962055206298828
tensor(1.9835, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04752201959490776
loss_c:1.3659204244613647
tensor(1.8087, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03611269220709801
loss_c:1.2990870475769043
tensor(1.7694, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040616657584905624
loss_c:1.282425880432129
tensor(1.7664, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04785755276679993
loss_c:1.1416035890579224
tensor(1.7158, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040827784687280655
loss_c:1.2821729183197021
tensor(1.7650, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04703441262245178
loss_c:1.4350570440292358
tensor(1.8326, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06023665890097618
loss_c:1.6941399574279785
tensor(1.9506, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.096034474670887
loss_c:1.420734167098999
tensor(1.8755, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03878414258360863
loss_c:1.4242080450057983
tensor(1.8175, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08502794057130814
loss_c:1.2962112426757812
tensor(1.8124, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03919651359319687
loss_c:1.4421966075897217
tensor(1.8238, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03517022728919983
loss_c:1.3144795894622803
tensor(1.7670, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04537961259484291
loss_c:1.456512451171875
tensor(1.8345, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05170610547065735
loss_c:1.2675365209579468
tensor(1.7636, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033061422407627106
loss_c:1.3279762268066406
tensor(1.7680, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06392747163772583
loss_c:1.2793830633163452
tensor(1.7798, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.056450966745615005
loss_c:1.1641628742218018
tensor(1.7245, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07272621989250183
loss_c:1.2553701400756836
tensor(1.7779, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04990605637431145
loss_c:1.4155559539794922
tensor(1.8182, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10711416602134705
loss_c:1.1829586029052734
tensor(1.7835, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06080351024866104
loss_c:1.2780038118362427
tensor(1.7725, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07005526125431061
loss_c:1.314676284790039
tensor(1.7966, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0665091946721077
loss_c:1.5945844650268555
tensor(1.9058, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03585227578878403
loss_c:1.3740795850753784
tensor(1.7829, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035740531980991364
loss_c:1.422316551208496
tensor(1.8016, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04289844259619713
loss_c:1.1973285675048828
tensor(1.7172, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07621520757675171
loss_c:1.1519144773483276
tensor(1.7339, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0543547198176384
loss_c:1.3166208267211914
tensor(1.7766, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03680046275258064
loss_c:1.3297052383422852
tensor(1.7622, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05276679992675781
loss_c:1.5341819524765015
tensor(1.8619, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036498330533504486
loss_c:1.321750521659851
tensor(1.7572, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06816914677619934
loss_c:1.3308228254318237
tensor(1.7947, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10163401067256927
loss_c:1.3000415563583374
tensor(1.8181, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03631354123353958
loss_c:1.296873927116394
tensor(1.7447, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03562460467219353
loss_c:1.3299427032470703
tensor(1.7567, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08377379924058914
loss_c:1.3279889822006226
tensor(1.8082, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06340480595827103
loss_c:1.5749953985214233
tensor(1.8855, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08820033818483353
loss_c:1.3093056678771973
tensor(1.8044, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08129021525382996
loss_c:1.307363748550415
tensor(1.7954, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07195000350475311
loss_c:1.1404831409454346
tensor(1.7166, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08921606838703156
loss_c:1.2056126594543457
tensor(1.7617, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.062111444771289825
loss_c:1.1135272979736328
tensor(1.6934, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044151175767183304
loss_c:1.2803001403808594
tensor(1.7404, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04094808176159859
loss_c:1.4966723918914795
tensor(1.8242, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043518610298633575
loss_c:1.258112907409668
tensor(1.7294, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07708552479743958
loss_c:1.2302926778793335
tensor(1.7553, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040722526609897614
loss_c:1.323654055595398
tensor(1.7515, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08142402023077011
loss_c:1.2332855463027954
tensor(1.7603, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03398619592189789
loss_c:1.4168188571929932
tensor(1.7804, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03766391798853874
loss_c:1.154536485671997
tensor(1.6771, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08765292912721634
loss_c:1.2743704319000244
tensor(1.7825, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09748083353042603
loss_c:1.1997631788253784
tensor(1.7629, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0841909870505333
loss_c:1.116043210029602
tensor(1.7130, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.056002967059612274
loss_c:1.2646712064743042
tensor(1.7404, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03723994642496109
loss_c:1.26068913936615
tensor(1.7165, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046753574162721634
loss_c:1.2861624956130981
tensor(1.7372, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0475175566971302
loss_c:1.2920842170715332
tensor(1.7399, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06261470168828964
loss_c:1.121842384338379
tensor(1.6874, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03004555031657219
loss_c:1.2144221067428589
tensor(1.6865, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06732043623924255
loss_c:1.3419342041015625
tensor(1.7815, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05107099562883377
loss_c:1.2228283882141113
tensor(1.7132, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02997623197734356
loss_c:1.338663101196289
tensor(1.7350, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04194753244519234
loss_c:1.2681999206542969
tensor(1.7196, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04070710390806198
loss_c:1.3295068740844727
tensor(1.7425, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05271115154027939
loss_c:1.1167179346084595
tensor(1.6692, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04066118970513344
loss_c:1.2294971942901611
tensor(1.7003, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030526595190167427
loss_c:1.3247244358062744
tensor(1.7264, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03974345326423645
loss_c:1.1818819046020508
tensor(1.6783, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02936817891895771
loss_c:1.239328145980835
tensor(1.6887, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07314042747020721
loss_c:1.1558027267456055
tensor(1.7065, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03154006600379944
loss_c:1.2239556312561035
tensor(1.6835, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05451247841119766
loss_c:1.3876655101776123
tensor(1.7776, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1256168931722641
loss_c:1.4426453113555908
tensor(1.8859, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03926118463277817
loss_c:1.03920316696167
tensor(1.6152, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034603752195835114
loss_c:1.2220746278762817
tensor(1.6837, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05212090164422989
loss_c:1.1050437688827515
tensor(1.6565, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.057466089725494385
loss_c:1.2450387477874756
tensor(1.7198, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06880771368741989
loss_c:1.318741798400879
tensor(1.7634, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03558291122317314
loss_c:1.3694634437561035
tensor(1.7426, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03830202296376228
loss_c:1.214252233505249
tensor(1.6817, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03265569731593132
loss_c:1.419935941696167
tensor(1.7583, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03948833420872688
loss_c:1.3265628814697266
tensor(1.7279, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03589056059718132
loss_c:1.2528080940246582
tensor(1.6925, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09783470630645752
loss_c:1.372096300125122
tensor(1.8183, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05946909263730049
loss_c:1.1178455352783203
tensor(1.6653, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040029119700193405
loss_c:1.2224515676498413
tensor(1.6832, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040212929248809814
loss_c:1.249581217765808
tensor(1.6940, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03232496604323387
loss_c:1.1654982566833496
tensor(1.6488, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.052175186574459076
loss_c:1.2664713859558105
tensor(1.7148, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.052713457494974136
loss_c:1.2383555173873901
tensor(1.7033, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0450606569647789
loss_c:1.1722725629806519
tensor(1.6658, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04760592058300972
loss_c:1.3069970607757568
tensor(1.7238, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03856172785162926
loss_c:1.2973788976669312
tensor(1.7076, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04679489508271217
loss_c:1.287477731704712
tensor(1.7135, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032083965837955475
loss_c:1.1076440811157227
tensor(1.6199, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03159478306770325
loss_c:1.0805115699768066
tensor(1.6074, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03965972363948822
loss_c:1.1463360786437988
tensor(1.6443, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08055347204208374
loss_c:1.2428348064422607
tensor(1.7366, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03836612403392792
loss_c:1.2433969974517822
tensor(1.6813, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07347223907709122
loss_c:1.2265350818634033
tensor(1.7196, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11408033221960068
loss_c:1.2562742233276367
tensor(1.7847, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03742174431681633
loss_c:1.2880295515060425
tensor(1.6966, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04841822013258934
loss_c:1.3998039960861206
tensor(1.7566, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05047681927680969
loss_c:1.2358280420303345
tensor(1.6911, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037838924676179886
loss_c:1.115319013595581
tensor(1.6240, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04199324920773506
loss_c:1.1472009420394897
tensor(1.6421, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05139001086354256
loss_c:1.2905244827270508
tensor(1.7132, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02918003872036934
loss_c:1.324129343032837
tensor(1.6968, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.057634223252534866
loss_c:1.436094045639038
tensor(1.7806, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04332958906888962
loss_c:1.1067359447479248
tensor(1.6247, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028221432119607925
loss_c:1.1777424812316895
tensor(1.6331, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0761057510972023
loss_c:1.2935250997543335
tensor(1.7450, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03710503876209259
loss_c:1.3141400814056396
tensor(1.7002, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034477636218070984
loss_c:1.2828954458236694
tensor(1.6831, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04033391550183296
loss_c:1.2679318189620972
tensor(1.6843, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0342668741941452
loss_c:1.3479059934616089
tensor(1.7085, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04246339574456215
loss_c:1.2333776950836182
tensor(1.6717, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04410163685679436
loss_c:1.3430083990097046
tensor(1.7188, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04274774342775345
loss_c:1.348806381225586
tensor(1.7187, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040811821818351746
loss_c:1.1817247867584229
tensor(1.6463, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04446551948785782
loss_c:1.2357017993927002
tensor(1.6731, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04115373641252518
loss_c:1.3599328994750977
tensor(1.7194, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04958409070968628
loss_c:1.390583872795105
tensor(1.7432, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05424286052584648
loss_c:1.3296717405319214
tensor(1.7240, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036610785871744156
loss_c:1.1028213500976562
tensor(1.6047, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03721945732831955
loss_c:1.2188820838928223
tensor(1.6531, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05384286865592003
loss_c:1.1707149744033813
tensor(1.6559, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04165314510464668
loss_c:1.2100751399993896
tensor(1.6545, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06291254609823227
loss_c:1.5147225856781006
tensor(1.8104, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.093157097697258
loss_c:1.3831710815429688
tensor(1.7984, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03838860243558884
loss_c:1.2481073141098022
tensor(1.6639, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031649816781282425
loss_c:1.3145161867141724
tensor(1.6813, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04276261106133461
loss_c:1.5013024806976318
tensor(1.7741, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1060672253370285
loss_c:1.2720882892608643
tensor(1.7695, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03381049260497093
loss_c:1.2617725133895874
tensor(1.6608, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10977369546890259
loss_c:1.1822075843811035
tensor(1.7370, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06457056850194931
loss_c:1.200082540512085
tensor(1.6787, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06209494546055794
loss_c:1.2244492769241333
tensor(1.6848, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03729371726512909
loss_c:1.3088711500167847
tensor(1.6832, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03601878508925438
loss_c:1.2768274545669556
tensor(1.6676, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04752151668071747
loss_c:1.1519958972930908
tensor(1.6321, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05466672033071518
loss_c:1.2450631856918335
tensor(1.6807, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02917822264134884
loss_c:1.1693414449691772
tensor(1.6113, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036417149007320404
loss_c:1.300214171409607
tensor(1.6757, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04373667761683464
loss_c:1.1386796236038208
tensor(1.6189, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03545273095369339
loss_c:1.2504823207855225
tensor(1.6526, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05261135473847389
loss_c:1.2085669040679932
tensor(1.6601, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026410240679979324
loss_c:1.117737054824829
tensor(1.5828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05492819473147392
loss_c:1.1524927616119385
tensor(1.6393, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.061232324689626694
loss_c:1.1253398656845093
tensor(1.6370, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09154251962900162
loss_c:1.0911298990249634
tensor(1.6679, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03377377241849899
loss_c:1.2905875444412231
tensor(1.6635, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03458508849143982
loss_c:1.1441528797149658
tensor(1.6032, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04745803773403168
loss_c:1.2429304122924805
tensor(1.6633, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04594479873776436
loss_c:1.0866018533706665
tensor(1.5954, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040990639477968216
loss_c:1.2017525434494019
tensor(1.6353, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02971755899488926
loss_c:1.1716196537017822
tensor(1.6050, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0653236135840416
loss_c:1.2199057340621948
tensor(1.6791, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04121045395731926
loss_c:1.2255934476852417
tensor(1.6440, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03154765069484711
loss_c:1.1184813976287842
tensor(1.5839, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05072787031531334
loss_c:1.17746901512146
tensor(1.6376, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06823473423719406
loss_c:1.1830432415008545
tensor(1.6666, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031448204070329666
loss_c:1.226198434829712
tensor(1.6271, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.057970695197582245
loss_c:1.2423514127731323
tensor(1.6746, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03349122405052185
loss_c:1.2111313343048096
tensor(1.6229, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03356700390577316
loss_c:1.1257643699645996
tensor(1.5868, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03257365524768829
loss_c:1.156615972518921
tensor(1.5976, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0676579475402832
loss_c:1.1888253688812256
tensor(1.6658, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022930044680833817
loss_c:1.1309250593185425
tensor(1.5705, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046047769486904144
loss_c:1.2128443717956543
tensor(1.6409, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.107514388859272
loss_c:1.290247917175293
tensor(1.7705, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05279628932476044
loss_c:1.2343966960906982
tensor(1.6597, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030803581699728966
loss_c:1.2258851528167725
tensor(1.6206, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03853559494018555
loss_c:1.203674077987671
tensor(1.6232, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06888769567012787
loss_c:1.2487748861312866
tensor(1.6903, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03658822551369667
loss_c:1.268772840499878
tensor(1.6464, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034251049160957336
loss_c:1.4622564315795898
tensor(1.7234, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06966100633144379
loss_c:1.141412615776062
tensor(1.6455, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08078072220087051
loss_c:1.6524055004119873
tensor(1.8779, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05309981480240822
loss_c:1.1727325916290283
tensor(1.6310, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028220733627676964
loss_c:1.2074034214019775
tensor(1.6046, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03648342564702034
loss_c:1.2301709651947021
tensor(1.6272, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07124795764684677
loss_c:1.1110572814941406
tensor(1.6337, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02883940562605858
loss_c:1.2044198513031006
tensor(1.6029, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0354917086660862
loss_c:1.0946788787841797
tensor(1.5673, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03769794479012489
loss_c:1.2228879928588867
tensor(1.6243, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07667606323957443
loss_c:1.293611764907837
tensor(1.7182, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030703090131282806
loss_c:1.061110258102417
tensor(1.5437, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03215755522251129
loss_c:1.287354588508606
tensor(1.6409, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030058393254876137
loss_c:1.2786660194396973
tensor(1.6332, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046806465834379196
loss_c:1.3129820823669434
tensor(1.6752, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04287600889801979
loss_c:1.2938745021820068
tensor(1.6602, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.054019272327423096
loss_c:1.1753361225128174
tensor(1.6286, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04170888662338257
loss_c:1.125842571258545
tensor(1.5866, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04282226786017418
loss_c:1.1538047790527344
tensor(1.5998, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039556924253702164
loss_c:1.1770106554031372
tensor(1.6036, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044399142265319824
loss_c:1.228379249572754
tensor(1.6330, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026920540258288383
loss_c:1.2046386003494263
tensor(1.5928, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03843337297439575
loss_c:1.3674485683441162
tensor(1.6807, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04649467021226883
loss_c:1.2798948287963867
tensor(1.6571, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.061789996922016144
loss_c:1.1698402166366577
tensor(1.6366, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03946411609649658
loss_c:1.1398814916610718
tensor(1.5851, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03518981486558914
loss_c:1.1426374912261963
tensor(1.5784, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05319371446967125
loss_c:1.2131993770599365
tensor(1.6390, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0488884374499321
loss_c:1.1513278484344482
tensor(1.6050, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.051256563514471054
loss_c:1.2000399827957153
tensor(1.6293, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04799656569957733
loss_c:1.169179081916809
tensor(1.6102, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0686185210943222
loss_c:1.0637497901916504
tensor(1.6014, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03135738521814346
loss_c:1.1725795269012451
tensor(1.5817, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05339238792657852
loss_c:1.0724971294403076
tensor(1.5777, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1085771843791008
loss_c:1.2084441184997559
tensor(1.7324, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03629586845636368
loss_c:1.319981575012207
tensor(1.6515, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.045034222304821014
loss_c:1.1013915538787842
tensor(1.5741, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11397001147270203
loss_c:1.1913304328918457
tensor(1.7346, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041290491819381714
loss_c:1.3607840538024902
tensor(1.6766, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03736629709601402
loss_c:1.1209955215454102
tensor(1.5676, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046182144433259964
loss_c:1.2982121706008911
tensor(1.6582, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04432135075330734
loss_c:1.1074198484420776
tensor(1.5736, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03707071766257286
loss_c:1.3789981603622437
tensor(1.6754, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046443693339824677
loss_c:1.1988950967788696
tensor(1.6156, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034375812858343124
loss_c:1.2923551797866821
tensor(1.6331, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03720169514417648
loss_c:1.1848196983337402
tensor(1.5921, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04227244481444359
loss_c:1.4710023403167725
tensor(1.7225, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03071628510951996
loss_c:1.2103822231292725
tensor(1.5904, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04279287904500961
loss_c:1.1893877983093262
tensor(1.6032, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.048411350697278976
loss_c:1.139590859413147
tensor(1.5919, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04083561152219772
loss_c:1.1046253442764282
tensor(1.5628, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022134356200695038
loss_c:1.0317305326461792
tensor(1.4970, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05404604971408844
loss_c:1.077228307723999
tensor(1.5748, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09906604140996933
loss_c:1.126051902770996
tensor(1.6787, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06689824163913727
loss_c:1.2087626457214355
tensor(1.6540, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03364025801420212
loss_c:1.308788537979126
tensor(1.6345, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03865054249763489
loss_c:1.1546025276184082
tensor(1.5778, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03201833739876747
loss_c:1.1227636337280273
tensor(1.5515, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03894118219614029
loss_c:1.179746150970459
tensor(1.5883, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04480983316898346
loss_c:0.9268113970756531
tensor(1.4912, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03575437143445015
loss_c:1.2822861671447754
tensor(1.6253, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046416688710451126
loss_c:1.0009369850158691
tensor(1.5251, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.054457832127809525
loss_c:1.2652122974395752
tensor(1.6528, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03231284022331238
loss_c:1.401624083518982
tensor(1.6687, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11001939326524734
loss_c:1.2796528339385986
tensor(1.7642, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0316927433013916
loss_c:1.2643647193908691
tensor(1.6082, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.048760347068309784
loss_c:1.3660024404525757
tensor(1.6839, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05827547609806061
loss_c:1.211954951286316
tensor(1.6361, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038181863725185394
loss_c:1.328489065170288
tensor(1.6470, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03601400926709175
loss_c:1.1867187023162842
tensor(1.5819, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04573221132159233
loss_c:1.3375136852264404
tensor(1.6648, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05387352779507637
loss_c:1.2793585062026978
tensor(1.6555, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02780785784125328
loss_c:1.097874641418457
tensor(1.5270, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030283674597740173
loss_c:1.187444806098938
tensor(1.5698, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05136360600590706
loss_c:1.069211721420288
tensor(1.5600, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05281398817896843
loss_c:1.1715295314788818
tensor(1.6063, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06348923593759537
loss_c:1.3457419872283936
tensor(1.7015, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029201358556747437
loss_c:1.233445167541504
tensor(1.5859, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04609772562980652
loss_c:1.2997074127197266
tensor(1.6472, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034742288291454315
loss_c:1.3393338918685913
tensor(1.6414, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06279881298542023
loss_c:1.1168065071105957
tensor(1.6014, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04651733487844467
loss_c:1.1634849309921265
tensor(1.5889, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03318778797984123
loss_c:1.1523483991622925
tensor(1.5573, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04282459616661072
loss_c:1.0556877851486206
tensor(1.5348, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03835579380393028
loss_c:1.2913936376571655
tensor(1.6265, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03677333518862724
loss_c:1.4756550788879395
tensor(1.7020, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02670132741332054
loss_c:1.1762313842773438
tensor(1.5532, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04164211079478264
loss_c:1.1748254299163818
tensor(1.5823, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.051188331097364426
loss_c:1.0428314208984375
tensor(1.5447, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03162604197859764
loss_c:1.2496050596237183
tensor(1.5935, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03759801387786865
loss_c:1.4167253971099854
tensor(1.6769, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04090142250061035
loss_c:1.1690856218338013
tensor(1.5771, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036752332001924515
loss_c:1.0739085674285889
tensor(1.5275, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03719732537865639
loss_c:1.1591079235076904
tensor(1.5647, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041260555386543274
loss_c:1.0935471057891846
tensor(1.5445, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03029058314859867
loss_c:1.137143850326538
tensor(1.5404, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030543722212314606
loss_c:1.2741715908050537
tensor(1.5994, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03856724873185158
loss_c:1.2371575832366943
tensor(1.5997, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040582746267318726
loss_c:1.1845711469650269
tensor(1.5810, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024978570640087128
loss_c:1.1876505613327026
tensor(1.5496, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04384825751185417
loss_c:1.2463488578796387
tensor(1.6138, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02802593819797039
loss_c:1.1161588430404663
tensor(1.5245, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02573605254292488
loss_c:0.9849392771720886
tensor(1.4629, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032409537583589554
loss_c:1.0770609378814697
tensor(1.5161, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03364020958542824
loss_c:1.0056885480880737
tensor(1.4876, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039532992988824844
loss_c:1.0847303867340088
tensor(1.5337, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05783587694168091
loss_c:1.1901887655258179
tensor(1.6176, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028747297823429108
loss_c:1.2337912321090698
tensor(1.5744, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024395540356636047
loss_c:1.1626670360565186
tensor(1.5341, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05771339684724808
loss_c:1.1708793640136719
tensor(1.6084, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.059976350516080856
loss_c:1.3008441925048828
tensor(1.6691, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036526087671518326
loss_c:1.4488487243652344
tensor(1.6824, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03561675176024437
loss_c:1.0934853553771973
tensor(1.5269, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03554973751306534
loss_c:1.2150996923446655
tensor(1.5790, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03804299980401993
loss_c:1.1162877082824707
tensor(1.5414, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029534222558140755
loss_c:1.1374504566192627
tensor(1.5318, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03647614270448685
loss_c:1.1775472164154053
tensor(1.5639, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036124907433986664
loss_c:1.1971566677093506
tensor(1.5713, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046279165893793106
loss_c:1.156191110610962
tensor(1.5755, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04175947234034538
loss_c:1.0878733396530151
tensor(1.5359, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04730284959077835
loss_c:1.4306063652038574
tensor(1.6960, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02679435722529888
loss_c:1.1603124141693115
tensor(1.5337, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026637012138962746
loss_c:1.1555627584457397
tensor(1.5310, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05224401503801346
loss_c:1.132330298423767
tensor(1.5773, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024354498833417892
loss_c:1.1186366081237793
tensor(1.5093, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06436843425035477
loss_c:1.2163137197494507
tensor(1.6403, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04417681321501732
loss_c:1.1374446153640747
tensor(1.5610, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02971797063946724
loss_c:1.2133171558380127
tensor(1.5613, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02748125046491623
loss_c:1.0697053670883179
tensor(1.4938, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028470603749155998
loss_c:0.9970006942749023
tensor(1.4642, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.050980087369680405
loss_c:1.1143656969070435
tensor(1.5654, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044974151998758316
loss_c:1.0783789157867432
tensor(1.5361, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06439219415187836
loss_c:1.1669842004776
tensor(1.6183, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.24359363317489624
loss_c:1.3173558712005615
tensor(2.0900, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05799517780542374
loss_c:1.1243090629577637
tensor(1.5851, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0649554580450058
loss_c:1.2936915159225464
tensor(1.6744, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03233042731881142
loss_c:1.25394606590271
tensor(1.5828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04197783023118973
loss_c:1.182116150856018
tensor(1.5735, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03498995676636696
loss_c:1.1347202062606812
tensor(1.5368, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0805056169629097
loss_c:1.0709350109100342
tensor(1.6130, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030494678765535355
loss_c:1.206233263015747
tensor(1.5573, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026221703737974167
loss_c:1.133780837059021
tensor(1.5159, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021199500188231468
loss_c:0.9405813217163086
tensor(1.4201, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07120849192142487
loss_c:1.1158256530761719
tensor(1.6111, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04184524714946747
loss_c:1.120399832725525
tensor(1.5454, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02849847450852394
loss_c:1.0327301025390625
tensor(1.4762, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031778544187545776
loss_c:1.0652140378952026
tensor(1.4977, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04089539125561714
loss_c:1.118762493133545
tensor(1.5420, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08404231071472168
loss_c:1.1358449459075928
tensor(1.6493, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04209108278155327
loss_c:1.1836057901382446
tensor(1.5727, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035538870841264725
loss_c:1.0776784420013428
tensor(1.5111, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03506598621606827
loss_c:1.1110525131225586
tensor(1.5243, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025714276358485222
loss_c:1.1200535297393799
tensor(1.5062, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033278562128543854
loss_c:1.0620944499969482
tensor(1.4983, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04861241951584816
loss_c:1.1732441186904907
tensor(1.5827, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04092640057206154
loss_c:1.239053726196289
tensor(1.5933, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04355791583657265
loss_c:1.320203423500061
tensor(1.6348, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.16956757009029388
loss_c:1.3866229057312012
tensor(1.9612, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02676931582391262
loss_c:1.1749193668365479
tensor(1.5313, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03799402713775635
loss_c:1.235329508781433
tensor(1.5842, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04009947553277016
loss_c:1.2836025953292847
tensor(1.6102, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03762050345540047
loss_c:1.0282939672470093
tensor(1.4923, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029984058812260628
loss_c:0.9772230982780457
tensor(1.4517, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03032955713570118
loss_c:1.152466058731079
tensor(1.5291, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03617142513394356
loss_c:1.0904481410980225
tensor(1.5156, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04808048903942108
loss_c:1.1895077228546143
tensor(1.5874, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08175290375947952
loss_c:1.171481728553772
tensor(1.6600, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0275663323700428
loss_c:1.31038236618042
tensor(1.5910, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03677766025066376
loss_c:1.1560938358306885
tensor(1.5452, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06104988977313042
loss_c:1.2136828899383545
tensor(1.6288, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026302102953195572
loss_c:1.0643210411071777
tensor(1.4794, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031769927591085434
loss_c:1.2517790794372559
tensor(1.5747, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05477708578109741
loss_c:1.2814884185791016
tensor(1.6433, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03750256821513176
loss_c:1.476104497909546
tensor(1.6868, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09790623933076859
loss_c:1.285752773284912
tensor(1.7498, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0390373095870018
loss_c:1.2202284336090088
tensor(1.5779, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08945862948894501
loss_c:1.284258484840393
tensor(1.7288, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0364275686442852
loss_c:1.2028262615203857
tensor(1.5636, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03919149935245514
loss_c:1.2309386730194092
tensor(1.5826, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030437365174293518
loss_c:1.2656540870666504
tensor(1.5763, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03214085102081299
loss_c:1.1401185989379883
tensor(1.5252, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.051403921097517014
loss_c:1.326134443283081
tensor(1.6541, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03415773808956146
loss_c:1.063119649887085
tensor(1.4961, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0535554476082325
loss_c:1.1117171049118042
tensor(1.5651, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03619791567325592
loss_c:1.295170545578003
tensor(1.6027, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02350546047091484
loss_c:1.1372636556625366
tensor(1.5019, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022769762203097343
loss_c:1.1170549392700195
tensor(1.4910, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027389613911509514
loss_c:1.1369528770446777
tensor(1.5110, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04141363129019737
loss_c:1.2881863117218018
tensor(1.6121, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06534770131111145
loss_c:1.151740312576294
tensor(1.6116, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03687403351068497
loss_c:1.09928560256958
tensor(1.5175, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03051615320146084
loss_c:1.104498267173767
tensor(1.5037, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04018830135464668
loss_c:1.2145322561264038
tensor(1.5761, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07077163457870483
loss_c:1.0718315839767456
tensor(1.5901, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040787406265735626
loss_c:1.2100762128829956
tensor(1.5754, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033691298216581345
loss_c:1.237903118133545
tensor(1.5697, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024709435179829597
loss_c:1.0529634952545166
tensor(1.4656, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06674446165561676
loss_c:1.1952757835388184
tensor(1.6342, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026567492634058
loss_c:1.2469598054885864
tensor(1.5552, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0283175278455019
loss_c:1.1676139831542969
tensor(1.5246, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027338387444615364
loss_c:1.1757566928863525
tensor(1.5255, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029943689703941345
loss_c:1.1078846454620361
tensor(1.5020, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028274191543459892
loss_c:1.100963830947876
tensor(1.4945, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03526364266872406
loss_c:1.1858657598495483
tensor(1.5496, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04883074015378952
loss_c:1.1818751096725464
tensor(1.5825, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05695665255188942
loss_c:1.3833708763122559
tensor(1.6920, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04561205580830574
loss_c:1.0623756647109985
tensor(1.5214, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03427235409617424
loss_c:1.1183912754058838
tensor(1.5167, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03795098885893822
loss_c:1.2941526174545288
tensor(1.6035, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03907215967774391
loss_c:1.024306297302246
tensor(1.4874, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043784599751234055
loss_c:1.0525606870651245
tensor(1.5120, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08860281854867935
loss_c:1.1482458114624023
tensor(1.6705, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02873464860022068
loss_c:1.1711301803588867
tensor(1.5249, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04509955644607544
loss_c:1.0711239576339722
tensor(1.5233, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03985409438610077
loss_c:1.1723072528839111
tensor(1.5542, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03347686305642128
loss_c:1.1254709959030151
tensor(1.5167, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04032416641712189
loss_c:1.2661288976669312
tensor(1.5966, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028037499636411667
loss_c:1.0172417163848877
tensor(1.4544, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029957763850688934
loss_c:1.2061142921447754
tensor(1.5427, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027348019182682037
loss_c:1.0990188121795654
tensor(1.4884, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03080078586935997
loss_c:1.2977498769760132
tensor(1.5851, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06696928292512894
loss_c:1.3408372402191162
tensor(1.6996, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02500751055777073
loss_c:0.9319743514060974
tensor(1.4078, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03445827588438988
loss_c:1.2649335861206055
tensor(1.5799, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022212686017155647
loss_c:1.1385598182678223
tensor(1.4913, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026100346818566322
loss_c:1.0458554029464722
tensor(1.4605, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03594065457582474
loss_c:1.2109073400497437
tensor(1.5596, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029053444042801857
loss_c:1.0130932331085205
tensor(1.4535, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03470974415540695
loss_c:1.1740649938583374
tensor(1.5397, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025658559054136276
loss_c:1.1346368789672852
tensor(1.4978, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0425703190267086
loss_c:1.2001171112060547
tensor(1.5721, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06328219920396805
loss_c:1.0489048957824707
tensor(1.5609, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022658733651041985
loss_c:1.0470046997070312
tensor(1.4503, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029970843344926834
loss_c:1.1101250648498535
tensor(1.4979, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04450203850865364
loss_c:1.1536444425582886
tensor(1.5564, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07544414699077606
loss_c:1.1349416971206665
tensor(1.6322, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029893023893237114
loss_c:1.1967846155166626
tensor(1.5357, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.050668954849243164
loss_c:1.1906373500823975
tensor(1.5895, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04582517594099045
loss_c:1.1475342512130737
tensor(1.5571, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02791585959494114
loss_c:1.1635522842407227
tensor(1.5151, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03236570209264755
loss_c:1.1798166036605835
tensor(1.5344, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025765467435121536
loss_c:1.3047850131988525
tensor(1.5717, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026080911979079247
loss_c:1.156011939048767
tensor(1.5064, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02955424226820469
loss_c:0.9698795080184937
tensor(1.4331, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024088794365525246
loss_c:1.0687205791473389
tensor(1.4617, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03965436667203903
loss_c:1.3646609783172607
tensor(1.6362, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.052777115255594254
loss_c:1.0949281454086304
tensor(1.5525, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026190856471657753
loss_c:1.264267921447754
tensor(1.5540, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040646377950906754
loss_c:0.9447324275970459
tensor(1.4519, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026990512385964394
loss_c:1.2201188802719116
tensor(1.5363, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03578369319438934
loss_c:1.0559041500091553
tensor(1.4876, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03386234864592552
loss_c:1.2014137506484985
tensor(1.5469, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031091131269931793
loss_c:1.1247209310531616
tensor(1.5049, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03679145500063896
loss_c:1.4393177032470703
tensor(1.6609, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03554902598261833
loss_c:1.1550358533859253
tensor(1.5307, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07522660493850708
loss_c:1.4638590812683105
tensor(1.7800, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03084014728665352
loss_c:1.2068203687667847
tensor(1.5403, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029866192489862442
loss_c:1.1253019571304321
tensor(1.5011, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03757457435131073
loss_c:1.0712993144989014
tensor(1.4988, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04137885943055153
loss_c:1.1307728290557861
tensor(1.5360, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029110044240951538
loss_c:1.0781383514404297
tensor(1.4777, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031417444348335266
loss_c:1.0652520656585693
tensor(1.4784, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06165469437837601
loss_c:1.0780408382415771
tensor(1.5702, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029426641762256622
loss_c:1.0436065196990967
tensor(1.4628, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03213885799050331
loss_c:1.1685205698013306
tensor(1.5261, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040372930467128754
loss_c:1.1845932006835938
tensor(1.5568, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027820250019431114
loss_c:0.9993637800216675
tensor(1.4382, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030488859862089157
loss_c:1.0611141920089722
tensor(1.4732, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.048318102955818176
loss_c:1.1537909507751465
tensor(1.5658, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.054392825812101364
loss_c:1.2018088102340698
tensor(1.6047, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024514803662896156
loss_c:1.0681347846984863
tensor(1.4588, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04299751669168472
loss_c:1.1214486360549927
tensor(1.5359, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05711117386817932
loss_c:1.0608363151550293
tensor(1.5496, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027851905673742294
loss_c:1.1285879611968994
tensor(1.4951, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.060495153069496155
loss_c:1.0051119327545166
tensor(1.5346, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08138808608055115
loss_c:1.190773606300354
tensor(1.6783, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.053704049438238144
loss_c:1.184107780456543
tensor(1.5949, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.045551758259534836
loss_c:1.290282964706421
tensor(1.6187, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024533649906516075
loss_c:1.0741318464279175
tensor(1.4608, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02596595324575901
loss_c:1.2124505043029785
tensor(1.5268, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0361604206264019
loss_c:1.1559264659881592
tensor(1.5311, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027622345834970474
loss_c:1.1262301206588745
tensor(1.4929, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027220822870731354
loss_c:1.0025328397750854
tensor(1.4362, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037537481635808945
loss_c:1.1528866291046143
tensor(1.5337, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030673902481794357
loss_c:1.067183494567871
tensor(1.4751, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027400171384215355
loss_c:1.062153697013855
tensor(1.4632, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06544972956180573
loss_c:1.1949269771575928
tensor(1.6343, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05299019441008568
loss_c:1.0366270542144775
tensor(1.5268, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04053327068686485
loss_c:1.199171543121338
tensor(1.5630, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02697114832699299
loss_c:1.2271485328674316
tensor(1.5356, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09401939809322357
loss_c:1.1424791812896729
tensor(1.6953, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05981263518333435
loss_c:1.336926817893982
tensor(1.6817, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02473244071006775
loss_c:1.0963819026947021
tensor(1.4701, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03494439274072647
loss_c:1.1745376586914062
tensor(1.5353, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03007659688591957
loss_c:1.0207152366638184
tensor(1.4519, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03389441594481468
loss_c:1.1690893173217773
tensor(1.5297, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02291538193821907
loss_c:1.0402617454528809
tensor(1.4393, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029805734753608704
loss_c:1.1737399101257324
tensor(1.5196, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.053070344030857086
loss_c:1.2172744274139404
tensor(1.6082, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06566518545150757
loss_c:1.4043660163879395
tensor(1.7297, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05255391448736191
loss_c:1.0432617664337158
tensor(1.5284, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05625120550394058
loss_c:1.241973876953125
tensor(1.6288, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04222904518246651
loss_c:1.2879949808120728
tensor(1.6077, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04037676379084587
loss_c:1.456814169883728
tensor(1.6781, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036008842289447784
loss_c:1.1480669975280762
tensor(1.5263, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03913802653551102
loss_c:1.2812325954437256
tensor(1.5954, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04644503816962242
loss_c:1.1874011754989624
tensor(1.5750, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03274673968553543
loss_c:1.1853222846984863
tensor(1.5332, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027002684772014618
loss_c:1.036583662033081
tensor(1.4492, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0279829278588295
loss_c:1.0569616556167603
tensor(1.4612, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025879960507154465
loss_c:0.9940905570983887
tensor(1.4266, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.12054090201854706
loss_c:1.2227349281311035
tensor(1.8130, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04098540544509888
loss_c:1.1139132976531982
tensor(1.5256, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.14738155901432037
loss_c:1.2950242757797241
tensor(1.9260, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06260371208190918
loss_c:1.076198697090149
tensor(1.5735, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03417336940765381
loss_c:1.159330129623413
tensor(1.5257, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02218434028327465
loss_c:1.0743056535720825
tensor(1.4517, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028724011033773422
loss_c:1.3103034496307373
tensor(1.5773, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02905047871172428
loss_c:1.113907814025879
tensor(1.4900, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03289281204342842
loss_c:0.9350634813308716
tensor(1.4211, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032636675983667374
loss_c:0.9866112470626831
tensor(1.4435, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0351821668446064
loss_c:1.086987018585205
tensor(1.4962, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025246409699320793
loss_c:1.102969765663147
tensor(1.4736, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02793329581618309
loss_c:0.9906644821166992
tensor(1.4311, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03204020857810974
loss_c:1.0718811750411987
tensor(1.4799, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03170549497008324
loss_c:1.1736774444580078
tensor(1.5246, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026007255539298058
loss_c:1.1077160835266113
tensor(1.4777, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03641486540436745
loss_c:1.3381004333496094
tensor(1.6127, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06003997474908829
loss_c:1.108412742614746
tensor(1.5804, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024136213585734367
loss_c:1.047206163406372
tensor(1.4446, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023465771228075027
loss_c:1.035664439201355
tensor(1.4373, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028714444488286972
loss_c:1.1432627439498901
tensor(1.5015, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026173066347837448
loss_c:1.178479552268982
tensor(1.5097, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04077080264687538
loss_c:1.0596987009048462
tensor(1.5002, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025629907846450806
loss_c:1.054802417755127
tensor(1.4520, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09374373406171799
loss_c:1.2347447872161865
tensor(1.7402, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01873346045613289
loss_c:1.0960190296173096
tensor(1.4495, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02276032045483589
loss_c:0.9813170433044434
tensor(1.4099, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020524639636278152
loss_c:1.075954794883728
tensor(1.4457, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.050943080335855484
loss_c:1.1264523267745972
tensor(1.5612, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1364918053150177
loss_c:1.0656417608261108
tensor(1.7953, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042687803506851196
loss_c:1.1761267185211182
tensor(1.5585, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031310465186834335
loss_c:1.2217857837677002
tensor(1.5443, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0398980975151062
loss_c:1.10915207862854
tensor(1.5196, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024582521989941597
loss_c:1.037821650505066
tensor(1.4405, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035851698368787766
loss_c:1.2670238018035889
tensor(1.5787, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025279497727751732
loss_c:1.1886634826660156
tensor(1.5108, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03484237566590309
loss_c:1.1514277458190918
tensor(1.5232, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03975257650017738
loss_c:1.0501176118850708
tensor(1.4924, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02846168540418148
loss_c:1.2902754545211792
tensor(1.5665, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04256822541356087
loss_c:1.2182526588439941
tensor(1.5772, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04510292783379555
loss_c:1.343889594078064
tensor(1.6419, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028789695352315903
loss_c:1.2412176132202148
tensor(1.5451, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03130533918738365
loss_c:1.1487640142440796
tensor(1.5110, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031302310526371
loss_c:1.0335108041763306
tensor(1.4587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024218473583459854
loss_c:1.0588595867156982
tensor(1.4483, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02638893574476242
loss_c:1.1352771520614624
tensor(1.4895, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021827885881066322
loss_c:1.0772202014923096
tensor(1.4490, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.071978859603405
loss_c:1.1607078313827515
tensor(1.6422, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04123856872320175
loss_c:1.1924083232879639
tensor(1.5613, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03373178467154503
loss_c:1.3762376308441162
tensor(1.6212, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04717234522104263
loss_c:1.3515548706054688
tensor(1.6518, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03149019554257393
loss_c:1.0746819972991943
tensor(1.4776, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024472281336784363
loss_c:1.1360058784484863
tensor(1.4835, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05355915054678917
loss_c:1.1170055866241455
tensor(1.5654, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03465406224131584
loss_c:1.5727713108062744
tensor(1.7129, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08509647101163864
loss_c:1.2093017101287842
tensor(1.7058, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05137187987565994
loss_c:0.9805476069450378
tensor(1.4969, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027547407895326614
loss_c:1.000930666923523
tensor(1.4317, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03862261027097702
loss_c:1.1042895317077637
tensor(1.5131, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022038275375962257
loss_c:1.015641212463379
tensor(1.4211, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02141590788960457
loss_c:1.327894926071167
tensor(1.5605, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04030511900782585
loss_c:1.1141654253005981
tensor(1.5228, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07171152532100677
loss_c:1.2003247737884521
tensor(1.6602, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05293417349457741
loss_c:1.2286272048950195
tensor(1.6142, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02565988525748253
loss_c:0.9477152228355408
tensor(1.4015, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028425948694348335
loss_c:0.9624902009963989
tensor(1.4169, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.049317773431539536
loss_c:1.280985713005066
tensor(1.6266, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04112070053815842
loss_c:1.0196610689163208
tensor(1.4826, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032459601759910583
loss_c:1.3277673721313477
tensor(1.5948, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024547826498746872
loss_c:0.9849069118499756
tensor(1.4147, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031317826360464096
loss_c:1.1461235284805298
tensor(1.5089, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033621080219745636
loss_c:1.0265908241271973
tensor(1.4620, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026395218446850777
loss_c:1.1511285305023193
tensor(1.4956, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02389589138329029
loss_c:1.0839885473251343
tensor(1.4573, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03358783945441246
loss_c:1.223137617111206
tensor(1.5509, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02111516147851944
loss_c:0.9818195104598999
tensor(1.4020, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023718610405921936
loss_c:1.0655150413513184
tensor(1.4481, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05098363384604454
loss_c:1.1877739429473877
tensor(1.5899, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022905394434928894
loss_c:0.9577338695526123
tensor(1.3964, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02681601606309414
loss_c:1.057811975479126
tensor(1.4542, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034356825053691864
loss_c:1.169276475906372
tensor(1.5287, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04147687181830406
loss_c:1.1737446784973145
tensor(1.5534, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.049713343381881714
loss_c:1.2370679378509521
tensor(1.6084, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.053861960768699646
loss_c:1.0219769477844238
tensor(1.5240, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03505733981728554
loss_c:1.0149974822998047
tensor(1.4607, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07625561207532883
loss_c:1.2553046941757202
tensor(1.7018, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.056910403072834015
loss_c:1.0534244775772095
tensor(1.5481, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0399048775434494
loss_c:1.081916093826294
tensor(1.5066, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024637052789330482
loss_c:1.093289852142334
tensor(1.4629, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030422350391745567
loss_c:1.1315181255340576
tensor(1.4987, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023642176762223244
loss_c:1.0598541498184204
tensor(1.4444, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042081162333488464
loss_c:1.0969712734222412
tensor(1.5204, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026494216173887253
loss_c:1.1078495979309082
tensor(1.4753, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.052380502223968506
loss_c:1.0319061279296875
tensor(1.5238, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028208959847688675
loss_c:1.0356125831604004
tensor(1.4478, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02188359759747982
loss_c:1.1098517179489136
tensor(1.4613, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020225083455443382
loss_c:0.9011565446853638
tensor(1.3608, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07018043845891953
loss_c:1.4909029006958008
tensor(1.7905, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04103786125779152
loss_c:1.0408542156219482
tensor(1.4914, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034845493733882904
loss_c:1.0404702425003052
tensor(1.4712, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02935350500047207
loss_c:1.177605152130127
tensor(1.5160, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03293479233980179
loss_c:0.8884776830673218
tensor(1.3956, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023874802514910698
loss_c:0.9731796979904175
tensor(1.4050, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021230505779385567
loss_c:1.0167630910873413
tensor(1.4162, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032971810549497604
loss_c:1.258101463317871
tensor(1.5644, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02239277772605419
loss_c:1.0913175344467163
tensor(1.4539, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0329330712556839
loss_c:1.0455424785614014
tensor(1.4671, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07338108867406845
loss_c:1.0447640419006348
tensor(1.5981, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037106093019247055
loss_c:1.2010021209716797
tensor(1.5517, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.057098388671875
loss_c:1.0479382276535034
tensor(1.5467, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028744200244545937
loss_c:1.124109148979187
tensor(1.4893, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02931673265993595
loss_c:0.9601451754570007
tensor(1.4160, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04545798897743225
loss_c:1.1306848526000977
tensor(1.5467, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.049476202577352524
loss_c:1.0497541427612305
tensor(1.5227, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034240785986185074
loss_c:0.954298198223114
tensor(1.4293, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02307961694896221
loss_c:1.0120232105255127
tensor(1.4193, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03661749139428139
loss_c:1.2175943851470947
tensor(1.5578, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027529340237379074
loss_c:1.0634386539459229
tensor(1.4573, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0272308848798275
loss_c:1.2571786642074585
tensor(1.5453, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024463186040520668
loss_c:1.055668592453003
tensor(1.4436, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021174630150198936
loss_c:1.0566906929016113
tensor(1.4332, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02894369699060917
loss_c:1.1129801273345947
tensor(1.4845, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02248568646609783
loss_c:0.9600949287414551
tensor(1.3930, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022693807259202003
loss_c:1.0174518823623657
tensor(1.4199, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027103831991553307
loss_c:1.2011494636535645
tensor(1.5189, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032188329845666885
loss_c:1.040273666381836
tensor(1.4615, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026387106627225876
loss_c:1.0950437784194946
tensor(1.4675, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018796585500240326
loss_c:1.002804160118103
tensor(1.3999, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02277650684118271
loss_c:1.0846734046936035
tensor(1.4506, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026887213811278343
loss_c:1.0216834545135498
tensor(1.4351, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020097849890589714
loss_c:1.053879737854004
tensor(1.4273, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04884488135576248
loss_c:0.9771289825439453
tensor(1.4876, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02231043018400669
loss_c:1.0269684791564941
tensor(1.4220, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028780903667211533
loss_c:1.0747480392456055
tensor(1.4656, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04236297681927681
loss_c:1.0739166736602783
tensor(1.5106, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0275967326015234
loss_c:1.0093772411346436
tensor(1.4313, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02336481213569641
loss_c:1.208033800125122
tensor(1.5088, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02803155593574047
loss_c:1.1740363836288452
tensor(1.5088, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024463726207613945
loss_c:0.9530317783355713
tensor(1.3944, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025487907230854034
loss_c:0.9147639274597168
tensor(1.3801, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04318636283278465
loss_c:1.285184383392334
tensor(1.6113, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041653651744127274
loss_c:0.9526228308677673
tensor(1.4521, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021766606718301773
loss_c:1.018261194229126
tensor(1.4151, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.053553372621536255
loss_c:1.071679949760437
tensor(1.5477, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03571094945073128
loss_c:1.1249980926513672
tensor(1.5118, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0396234467625618
loss_c:1.2492460012435913
tensor(1.5828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03256979212164879
loss_c:0.9647235870361328
tensor(1.4268, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02537822723388672
loss_c:1.1233458518981934
tensor(1.4759, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05006609857082367
loss_c:0.9752929210662842
tensor(1.4912, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030025020241737366
loss_c:1.0882856845855713
tensor(1.4754, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03369304537773132
loss_c:1.0835261344909668
tensor(1.4856, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03066457249224186
loss_c:1.0545587539672852
tensor(1.4618, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022469889372587204
loss_c:1.0960369110107422
tensor(1.4531, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02605501189827919
loss_c:1.0806273221969604
tensor(1.4581, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020627325400710106
loss_c:1.0619912147521973
tensor(1.4308, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02658158913254738
loss_c:1.1769877672195435
tensor(1.5047, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029257789254188538
loss_c:1.2412364482879639
tensor(1.5437, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06582554429769516
loss_c:1.0652798414230347
tensor(1.5875, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02810703217983246
loss_c:1.2228026390075684
tensor(1.5312, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03239566832780838
loss_c:1.0760307312011719
tensor(1.4776, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02968090958893299
loss_c:1.1368224620819092
tensor(1.4965, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02827232889831066
loss_c:1.2350128889083862
tensor(1.5373, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035109519958496094
loss_c:0.8840012550354004
tensor(1.3975, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0346543975174427
loss_c:1.2733538150787354
tensor(1.5772, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023466337472200394
loss_c:0.951854407787323
tensor(1.3888, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05328282713890076
loss_c:1.0777949094772339
tensor(1.5505, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025890802964568138
loss_c:1.050797939300537
tensor(1.4432, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.17722594738006592
loss_c:1.2145938873291016
tensor(2.0434, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.050924163311719894
loss_c:1.2398940324783325
tensor(1.6179, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07100485265254974
loss_c:1.164366602897644
tensor(1.6519, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03150658309459686
loss_c:1.0384933948516846
tensor(1.4570, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041081804782152176
loss_c:1.2254893779754639
tensor(1.5770, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04079902544617653
loss_c:1.1257603168487549
tensor(1.5296, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0497845895588398
loss_c:0.977189302444458
tensor(1.4911, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03299221396446228
loss_c:1.47174072265625
tensor(1.6640, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06466702371835709
loss_c:1.032941460609436
tensor(1.5678, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026565520092844963
loss_c:1.1656607389450073
tensor(1.4996, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03498891368508339
loss_c:1.1239194869995117
tensor(1.5089, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03315189853310585
loss_c:1.024265170097351
tensor(1.4563, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03847041726112366
loss_c:1.2580933570861816
tensor(1.5832, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027312420308589935
loss_c:1.0024323463439941
tensor(1.4263, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03138711303472519
loss_c:1.159589409828186
tensor(1.5133, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02356838993728161
loss_c:1.0918643474578857
tensor(1.4553, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.20104384422302246
loss_c:1.5577201843261719
tensor(2.2730, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03367135673761368
loss_c:0.9999787211418152
tensor(1.4469, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0691271498799324
loss_c:0.9638370871543884
tensor(1.5496, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02713620476424694
loss_c:0.9451493620872498
tensor(1.3995, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03631872683763504
loss_c:1.189494252204895
tensor(1.5440, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06598839908838272
loss_c:1.0611400604248047
tensor(1.5836, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.054329585283994675
loss_c:1.0020602941513062
tensor(1.5170, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04491050913929939
loss_c:1.4580695629119873
tensor(1.6975, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02258933335542679
loss_c:1.0082290172576904
tensor(1.4141, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03819380700588226
loss_c:1.138740062713623
tensor(1.5267, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03879725933074951
loss_c:1.1073507070541382
tensor(1.5141, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036242783069610596
loss_c:1.2209935188293457
tensor(1.5585, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026418816298246384
loss_c:0.9968488216400146
tensor(1.4218, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02582257054746151
loss_c:1.084973931312561
tensor(1.4608, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06279679387807846
loss_c:1.136913776397705
tensor(1.6071, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04980054870247841
loss_c:1.1611343622207642
tensor(1.5754, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03764096647500992
loss_c:1.2671709060668945
tensor(1.5846, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02407708764076233
loss_c:1.0208340883255005
tensor(1.4254, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10231735557317734
loss_c:1.0309290885925293
tensor(1.6878, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05421045422554016
loss_c:1.021701455116272
tensor(1.5251, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05751856043934822
loss_c:1.0349442958831787
tensor(1.5420, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030632145702838898
loss_c:1.069111943244934
tensor(1.4696, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03224635124206543
loss_c:1.1525318622589111
tensor(1.5137, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04212471470236778
loss_c:0.9594014883041382
tensor(1.4563, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02659487910568714
loss_c:1.2382605075836182
tensor(1.5351, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06065787747502327
loss_c:1.120436191558838
tensor(1.5917, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03842878341674805
loss_c:1.116539716720581
tensor(1.5172, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028800418600440025
loss_c:1.132804274559021
tensor(1.4934, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033930741250514984
loss_c:1.1225402355194092
tensor(1.5054, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08529845625162125
loss_c:1.0489747524261475
tensor(1.6386, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0195014588534832
loss_c:1.0079050064086914
tensor(1.4051, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.059358447790145874
loss_c:0.9926385879516602
tensor(1.5278, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04506959021091461
loss_c:1.3369611501693726
tensor(1.6414, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024342678487300873
loss_c:1.091642141342163
tensor(1.4599, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031660955399274826
loss_c:1.044551134109497
tensor(1.4618, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02036106213927269
loss_c:1.0877795219421387
tensor(1.4452, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07901328802108765
loss_c:1.1195317506790161
tensor(1.6505, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02882291190326214
loss_c:1.231966495513916
tensor(1.5398, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.16388356685638428
loss_c:1.1834982633590698
tensor(1.9556, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025525709614157677
loss_c:0.9431514739990234
tensor(1.3949, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043613217771053314
loss_c:1.0992460250854492
tensor(1.5260, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04408466815948486
loss_c:1.1881585121154785
tensor(1.5689, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03113076090812683
loss_c:1.0947262048721313
tensor(1.4837, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03423720598220825
loss_c:1.0869998931884766
tensor(1.4901, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023404786363244057
loss_c:0.9623122215270996
tensor(1.3973, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035530123859643936
loss_c:1.24007248878479
tensor(1.5655, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03614114224910736
loss_c:1.1963162422180176
tensor(1.5471, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03384685143828392
loss_c:1.1631945371627808
tensor(1.5244, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03413739427924156
loss_c:1.1399586200714111
tensor(1.5145, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034171588718891144
loss_c:0.8711206912994385
tensor(1.3895, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031168658286333084
loss_c:1.0018301010131836
tensor(1.4407, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06192630156874657
loss_c:1.0575498342514038
tensor(1.5655, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023598091676831245
loss_c:1.034071445465088
tensor(1.4313, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03388858959078789
loss_c:1.077718734741211
tensor(1.4847, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026689480990171432
loss_c:1.255491852760315
tensor(1.5443, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025638096034526825
loss_c:0.9566688537597656
tensor(1.4017, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02735080197453499
loss_c:1.2247443199157715
tensor(1.5321, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05867832154035568
loss_c:1.1137981414794922
tensor(1.5814, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027409734204411507
loss_c:1.033708930015564
tensor(1.4432, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022118182852864265
loss_c:0.9608551859855652
tensor(1.3922, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02269425056874752
loss_c:0.9553560018539429
tensor(1.3914, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030462125316262245
loss_c:1.0223811864852905
tensor(1.4477, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03321942687034607
loss_c:1.0476514101028442
tensor(1.4683, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035568833351135254
loss_c:1.0088791847229004
tensor(1.4578, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03153785318136215
loss_c:1.1726959943771362
tensor(1.5211, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02162810042500496
loss_c:0.9724764227867126
tensor(1.3955, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05561179667711258
loss_c:1.0197538137435913
tensor(1.5280, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.060452889651060104
loss_c:0.9708037376403809
tensor(1.5209, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01951639913022518
loss_c:0.9261309504508972
tensor(1.3667, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.048140957951545715
loss_c:0.9239555597305298
tensor(1.4589, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038843315094709396
loss_c:1.0892560482025146
tensor(1.5059, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03967496007680893
loss_c:1.1700735092163086
tensor(1.5464, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03401564806699753
loss_c:1.0024861097335815
tensor(1.4494, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02644318901002407
loss_c:1.0899213552474976
tensor(1.4656, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03719522804021835
loss_c:0.9779266119003296
tensor(1.4483, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026696594431996346
loss_c:0.8190571665763855
tensor(1.3394, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03304153308272362
loss_c:1.119842529296875
tensor(1.5012, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036437153816223145
loss_c:1.1733269691467285
tensor(1.5374, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.045094434171915054
loss_c:0.9813050031661987
tensor(1.4756, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04490496590733528
loss_c:1.0421122312545776
tensor(1.5036, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1568518429994583
loss_c:1.1327645778656006
tensor(1.9141, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02438247762620449
loss_c:1.0035409927368164
tensor(1.4180, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02574245259165764
loss_c:1.192131757736206
tensor(1.5112, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041749078780412674
loss_c:1.1345717906951904
tensor(1.5366, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02800825983285904
loss_c:1.255690097808838
tensor(1.5487, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03011585958302021
loss_c:1.0706939697265625
tensor(1.4685, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02483873814344406
loss_c:1.0334835052490234
tensor(1.4337, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027050575241446495
loss_c:0.9734565615653992
tensor(1.4127, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023931851610541344
loss_c:0.9548196792602539
tensor(1.3936, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030592884868383408
loss_c:1.0015987157821655
tensor(1.4375, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026909342035651207
loss_c:1.1519150733947754
tensor(1.4962, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02601046860218048
loss_c:1.0964680910110474
tensor(1.4671, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02321305125951767
loss_c:1.039393663406372
tensor(1.4309, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03028598427772522
loss_c:1.0616188049316406
tensor(1.4646, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025836100801825523
loss_c:1.2282164096832275
tensor(1.5285, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02483382634818554
loss_c:1.0408776998519897
tensor(1.4368, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028808236122131348
loss_c:1.0281853675842285
tensor(1.4438, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02807657979428768
loss_c:1.0965690612792969
tensor(1.4736, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03986377269029617
loss_c:0.9212908744812012
tensor(1.4299, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.048420459032058716
loss_c:0.9817057847976685
tensor(1.4867, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03795052319765091
loss_c:1.0837033987045288
tensor(1.5002, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0328577384352684
loss_c:1.0380275249481201
tensor(1.4617, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02286502718925476
loss_c:0.9269118309020996
tensor(1.3759, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038248028606176376
loss_c:1.1870343685150146
tensor(1.5500, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027179591357707977
loss_c:0.9580387473106384
tensor(1.4048, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04422841593623161
loss_c:1.1702818870544434
tensor(1.5620, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029864907264709473
loss_c:1.0683971643447876
tensor(1.4659, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04186885058879852
loss_c:1.0721564292907715
tensor(1.5078, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026007311418652534
loss_c:1.0168040990829468
tensor(1.4285, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046382319182157516
loss_c:0.9462399482727051
tensor(1.4633, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02337067574262619
loss_c:1.0078190565109253
tensor(1.4153, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044134046882390976
loss_c:1.3247251510620117
tensor(1.6350, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028941001743078232
loss_c:0.9546269178390503
tensor(1.4087, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02460177056491375
loss_c:0.9508034586906433
tensor(1.3923, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025071686133742332
loss_c:1.149969220161438
tensor(1.4882, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024442831054329872
loss_c:1.0460405349731445
tensor(1.4368, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023606272414326668
loss_c:0.9913262724876404
tensor(1.4080, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02128775045275688
loss_c:0.9658052921295166
tensor(1.3880, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02658538892865181
loss_c:1.027514934539795
tensor(1.4350, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023671412840485573
loss_c:1.088047981262207
tensor(1.4538, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03027660958468914
loss_c:1.0897135734558105
tensor(1.4770, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04125066101551056
loss_c:1.2502076625823975
tensor(1.5904, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04389128461480141
loss_c:1.0527210235595703
tensor(1.5056, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0407184474170208
loss_c:1.0827360153198242
tensor(1.5091, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03974521532654762
loss_c:0.9239253997802734
tensor(1.4303, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025038570165634155
loss_c:1.2023990154266357
tensor(1.5125, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019793016836047173
loss_c:1.0068902969360352
tensor(1.4016, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030592594295740128
loss_c:1.016374111175537
tensor(1.4430, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044203732162714005
loss_c:1.251952052116394
tensor(1.6015, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02502807229757309
loss_c:1.029829978942871
tensor(1.4303, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020275531336665154
loss_c:1.166096806526184
tensor(1.4787, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021619020029902458
loss_c:1.1008350849151611
tensor(1.4522, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027060994878411293
loss_c:0.9852237701416016
tensor(1.4159, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06728629022836685
loss_c:1.3637654781341553
tensor(1.7342, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03373999893665314
loss_c:1.0528241395950317
tensor(1.4710, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020784597843885422
loss_c:0.9294580221176147
tensor(1.3677, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02169647440314293
loss_c:1.0263671875
tensor(1.4168, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03113153949379921
loss_c:1.0526056289672852
tensor(1.4618, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023478593677282333
loss_c:1.0397670269012451
tensor(1.4292, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03313574939966202
loss_c:1.094911813735962
tensor(1.4888, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042013294994831085
loss_c:1.2254371643066406
tensor(1.5816, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05208130180835724
loss_c:1.0446275472640991
tensor(1.5306, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04266853630542755
loss_c:1.0578116178512573
tensor(1.5043, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03509974852204323
loss_c:1.159897804260254
tensor(1.5265, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029508771374821663
loss_c:1.18277907371521
tensor(1.5179, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02714996039867401
loss_c:1.063066840171814
tensor(1.4528, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030933625996112823
loss_c:1.1111514568328857
tensor(1.4888, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028114205226302147
loss_c:1.018555998802185
tensor(1.4350, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028832633048295975
loss_c:1.0587626695632935
tensor(1.4566, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031033605337142944
loss_c:1.2276623249053955
tensor(1.5445, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025020519271492958
loss_c:1.1695563793182373
tensor(1.4959, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028595544397830963
loss_c:0.9984426498413086
tensor(1.4271, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035390064120292664
loss_c:0.9953505396842957
tensor(1.4493, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02802615612745285
loss_c:1.28725004196167
tensor(1.5622, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0317111611366272
loss_c:1.1315522193908691
tensor(1.5011, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04474944621324539
loss_c:1.1471295356750488
tensor(1.5542, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04803769662976265
loss_c:0.9807150363922119
tensor(1.4867, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.049665313214063644
loss_c:1.0128505229949951
tensor(1.5077, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0406307615339756
loss_c:1.0093673467636108
tensor(1.4744, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027851980179548264
loss_c:1.142380952835083
tensor(1.4927, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03274552524089813
loss_c:0.9763433337211609
tensor(1.4311, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02770993858575821
loss_c:1.043771505355835
tensor(1.4454, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03769364580512047
loss_c:1.0340962409973145
tensor(1.4758, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11680382490158081
loss_c:1.1806954145431519
tensor(1.8230, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07483632862567902
loss_c:0.9644550085067749
tensor(1.5729, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0221344456076622
loss_c:0.9609293937683105
tensor(1.3867, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02759576588869095
loss_c:1.109573483467102
tensor(1.4763, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030779199674725533
loss_c:1.1738840341567993
tensor(1.5180, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030761685222387314
loss_c:1.4043331146240234
tensor(1.6273, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03620767965912819
loss_c:0.9315009117126465
tensor(1.4219, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030878040939569473
loss_c:1.0339231491088867
tensor(1.4520, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021313659846782684
loss_c:1.1405434608459473
tensor(1.4693, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02521749958395958
loss_c:1.1104309558868408
tensor(1.4686, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030412206426262856
loss_c:1.0092110633850098
tensor(1.4386, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02392367273569107
loss_c:1.184467077255249
tensor(1.4992, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027590502053499222
loss_c:1.0480561256408691
tensor(1.4472, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030728936195373535
loss_c:1.0151546001434326
tensor(1.4425, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034496866166591644
loss_c:0.9715689420700073
tensor(1.4350, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028147317469120026
loss_c:1.057405948638916
tensor(1.4536, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04299679398536682
loss_c:0.9397455453872681
tensor(1.4495, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030139997601509094
loss_c:1.033080816268921
tensor(1.4490, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024852823466062546
loss_c:0.9995779395103455
tensor(1.4146, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03544013202190399
loss_c:1.0374037027359009
tensor(1.4695, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034673742949962616
loss_c:1.0028483867645264
tensor(1.4504, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030008776113390923
loss_c:1.0280909538269043
tensor(1.4461, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030543051660060883
loss_c:1.068396806716919
tensor(1.4671, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02397741936147213
loss_c:1.1344785690307617
tensor(1.4755, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03307187929749489
loss_c:1.1248929500579834
tensor(1.5027, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028393978253006935
loss_c:0.9794051051139832
tensor(1.4172, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03110322169959545
loss_c:0.8999311327934265
tensor(1.3889, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06763516366481781
loss_c:1.0417360067367554
tensor(1.5845, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06190711259841919
loss_c:1.0982582569122314
tensor(1.5913, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026024123653769493
loss_c:0.9995049834251404
tensor(1.4183, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02478230558335781
loss_c:1.1454529762268066
tensor(1.4835, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03394988551735878
loss_c:1.032435655593872
tensor(1.4618, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026246486231684685
loss_c:0.9418907165527344
tensor(1.3917, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03516842797398567
loss_c:1.088607907295227
tensor(1.4928, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0230551790446043
loss_c:0.9886811971664429
tensor(1.4027, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026682285591959953
loss_c:1.1211464405059814
tensor(1.4785, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03199866786599159
loss_c:0.9699497222900391
tensor(1.4251, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027856705710291862
loss_c:0.9244944453239441
tensor(1.3889, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.060580428689718246
loss_c:1.033067226409912
tensor(1.5558, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08112946152687073
loss_c:1.2443716526031494
tensor(1.7290, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038799189031124115
loss_c:1.3013482093811035
tensor(1.6072, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026737993583083153
loss_c:1.0843552350997925
tensor(1.4612, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03015286475419998
loss_c:0.9614865183830261
tensor(1.4146, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05779501795768738
loss_c:1.0345735549926758
tensor(1.5465, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026888422667980194
loss_c:1.0458778142929077
tensor(1.4434, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024067237973213196
loss_c:0.9405962228775024
tensor(1.3833, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08089744299650192
loss_c:1.2046492099761963
tensor(1.7086, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02478613518178463
loss_c:1.0765430927276611
tensor(1.4507, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04587153345346451
loss_c:1.096653699874878
tensor(1.5342, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04139295965433121
loss_c:1.1535307168960571
tensor(1.5456, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027096275240182877
loss_c:1.0175843238830566
tensor(1.4307, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04038538038730621
loss_c:1.2649335861206055
tensor(1.5953, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030323922634124756
loss_c:1.1014827489852905
tensor(1.4821, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039704643189907074
loss_c:1.0129518508911133
tensor(1.4726, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025837339460849762
loss_c:1.0038652420043945
tensor(1.4199, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05454889312386513
loss_c:1.151646375656128
tensor(1.5905, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02737974002957344
loss_c:0.996859073638916
tensor(1.4219, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02667459286749363
loss_c:0.9964486360549927
tensor(1.4193, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03822598233819008
loss_c:1.2211636304855347
tensor(1.5668, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029395122081041336
loss_c:0.9660643339157104
tensor(1.4143, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034450873732566833
loss_c:1.1629135608673096
tensor(1.5259, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.048758815973997116
loss_c:1.0600073337554932
tensor(1.5265, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025635935366153717
loss_c:1.033620834350586
tensor(1.4335, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01609993539750576
loss_c:1.1101595163345337
tensor(1.4368, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02820402942597866
loss_c:1.0434153079986572
tensor(1.4471, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030546871945261955
loss_c:1.2408663034439087
tensor(1.5495, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023142492398619652
loss_c:1.117689609527588
tensor(1.4649, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04186128079891205
loss_c:0.9074182510375977
tensor(1.4297, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04999016225337982
loss_c:1.2004762887954712
tensor(1.5980, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02924278751015663
loss_c:0.9205982089042664
tensor(1.3920, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021915484219789505
loss_c:1.1085344552993774
tensor(1.4561, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021372538059949875
loss_c:0.8639606237411499
tensor(1.3375, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035255562514066696
loss_c:1.0619120597839355
tensor(1.4804, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02794121578335762
loss_c:1.0780560970306396
tensor(1.4626, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04119536280632019
loss_c:1.0402801036834717
tensor(1.4909, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05476495996117592
loss_c:0.9287012815475464
tensor(1.4852, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025779802352190018
loss_c:1.0583691596984863
tensor(1.4455, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024104049429297447
loss_c:1.0677350759506226
tensor(1.4441, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025329403579235077
loss_c:1.0716965198516846
tensor(1.4503, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04872003570199013
loss_c:1.0665785074234009
tensor(1.5299, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028145335614681244
loss_c:1.188360333442688
tensor(1.5159, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02204063907265663
loss_c:1.067328929901123
tensor(1.4366, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02509409561753273
loss_c:0.9835225343704224
tensor(1.4073, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030792949721217155
loss_c:1.0023362636566162
tensor(1.4362, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02140755206346512
loss_c:1.0034868717193604
tensor(1.4038, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07347811013460159
loss_c:0.9902980327606201
tensor(1.5808, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027052389457821846
loss_c:0.9428927302360535
tensor(1.3946, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019710611552000046
loss_c:1.0171501636505127
tensor(1.4042, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033372364938259125
loss_c:1.074321985244751
tensor(1.4797, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.15773090720176697
loss_c:1.2483985424041748
tensor(2.0018, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02040080912411213
loss_c:0.9604665637016296
tensor(1.3795, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.051513779908418655
loss_c:1.0394529104232788
tensor(1.5268, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03748347982764244
loss_c:0.9950985908508301
tensor(1.4562, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02298031374812126
loss_c:0.9882354736328125
tensor(1.4021, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.052120666950941086
loss_c:1.0386321544647217
tensor(1.5283, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04774292930960655
loss_c:0.9754966497421265
tensor(1.4827, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02960982173681259
loss_c:1.1175295114517212
tensor(1.4874, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06926435977220535
loss_c:1.167225956916809
tensor(1.6496, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0276387520134449
loss_c:0.9957632422447205
tensor(1.4222, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022543543949723244
loss_c:1.0539271831512451
tensor(1.4324, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023141637444496155
loss_c:1.0691986083984375
tensor(1.4418, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022990960627794266
loss_c:1.0382747650146484
tensor(1.4265, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04612378776073456
loss_c:1.193178415298462
tensor(1.5812, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030474117025732994
loss_c:0.8684871196746826
tensor(1.3710, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06717947870492935
loss_c:1.006248950958252
tensor(1.5645, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0561223067343235
loss_c:1.1776213645935059
tensor(1.6083, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024665430188179016
loss_c:1.0378715991973877
tensor(1.4322, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029856856912374496
loss_c:0.9455125331878662
tensor(1.4059, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02501564845442772
loss_c:0.9395418167114258
tensor(1.3863, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05514029785990715
loss_c:0.9344608783721924
tensor(1.4880, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02814728207886219
loss_c:0.9598628282546997
tensor(1.4068, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06146591901779175
loss_c:0.9662865996360779
tensor(1.5250, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0198923759162426
loss_c:0.9366585612297058
tensor(1.3672, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03258981928229332
loss_c:0.9989721179008484
tensor(1.4410, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025510549545288086
loss_c:0.9232015609741211
tensor(1.3801, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0427183173596859
loss_c:1.1050561666488647
tensor(1.5270, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027988333255052567
loss_c:0.9467765688896179
tensor(1.3999, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032084010541439056
loss_c:0.9378963708877563
tensor(1.4097, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025358913466334343
loss_c:1.03485107421875
tensor(1.4333, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032524626702070236
loss_c:0.9706400632858276
tensor(1.4270, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020310822874307632
loss_c:0.9619499444961548
tensor(1.3806, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015935983508825302
loss_c:0.9262651205062866
tensor(1.3482, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01913559064269066
loss_c:0.9755752086639404
tensor(1.3830, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030412890017032623
loss_c:0.9639568328857422
tensor(1.4163, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02757689356803894
loss_c:0.9770569801330566
tensor(1.4128, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0289995688945055
loss_c:0.9827120304107666
tensor(1.4204, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03207246586680412
loss_c:1.3287246227264404
tensor(1.5987, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020373135805130005
loss_c:1.0038745403289795
tensor(1.4006, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0184418223798275
loss_c:1.0715571641921997
tensor(1.4266, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04855814948678017
loss_c:1.1382412910461426
tensor(1.5639, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035282012075185776
loss_c:1.084609866142273
tensor(1.4916, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06387873739004135
loss_c:1.0188448429107666
tensor(1.5596, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03027839958667755
loss_c:1.0853828191757202
tensor(1.4744, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04248915985226631
loss_c:0.9818999171257019
tensor(1.4669, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05212394520640373
loss_c:0.9495735168457031
tensor(1.4850, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025362979620695114
loss_c:0.9656044840812683
tensor(1.3991, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02813863381743431
loss_c:1.0148035287857056
tensor(1.4327, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.051906585693359375
loss_c:0.9644107818603516
tensor(1.4914, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028135837987065315
loss_c:0.9750595092773438
tensor(1.4133, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06629791855812073
loss_c:0.8695224523544312
tensor(1.4956, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02829914353787899
loss_c:0.9860541820526123
tensor(1.4192, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02456345222890377
loss_c:1.0615547895431519
tensor(1.4429, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025759179145097733
loss_c:1.0828726291656494
tensor(1.4575, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02068503573536873
loss_c:0.9778620004653931
tensor(1.3886, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02597903087735176
loss_c:0.9794139862060547
tensor(1.4078, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0236542746424675
loss_c:1.060511589050293
tensor(1.4392, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027862519025802612
loss_c:0.956061840057373
tensor(1.4030, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03651627153158188
loss_c:1.0246411561965942
tensor(1.4667, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02415662817656994
loss_c:1.0009387731552124
tensor(1.4118, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04075024276971817
loss_c:1.1216191053390503
tensor(1.5289, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021006455644965172
loss_c:0.9978331923484802
tensor(1.3991, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03101683221757412
loss_c:0.9197816252708435
tensor(1.3962, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040769562125205994
loss_c:1.2451727390289307
tensor(1.5894, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.060289472341537476
loss_c:0.933893084526062
tensor(1.5062, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025496196001768112
loss_c:0.8981020450592041
tensor(1.3661, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03645576536655426
loss_c:0.8500622510910034
tensor(1.3813, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023411395028233528
loss_c:0.9657298922538757
tensor(1.3918, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027138601988554
loss_c:1.1217751502990723
tensor(1.4811, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02329576574265957
loss_c:1.0183453559875488
tensor(1.4170, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04034803807735443
loss_c:0.8581691980361938
tensor(1.3989, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021259557455778122
loss_c:1.0332332849502563
tensor(1.4170, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03626668453216553
loss_c:1.184655785560608
tensor(1.5442, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028048083186149597
loss_c:1.1197785139083862
tensor(1.4834, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022873491048812866
loss_c:1.0425227880477905
tensor(1.4272, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04128018021583557
loss_c:0.9394552111625671
tensor(1.4420, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024554628878831863
loss_c:1.2520461082458496
tensor(1.5357, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03282339870929718
loss_c:1.0611202716827393
tensor(1.4715, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03257136419415474
loss_c:0.9766842722892761
tensor(1.4293, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023481212556362152
loss_c:0.884609580039978
tensor(1.3519, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02601718157529831
loss_c:1.0322377681732178
tensor(1.4331, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02322007156908512
loss_c:1.029525876045227
tensor(1.4218, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01971592754125595
loss_c:0.9761408567428589
tensor(1.3831, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03013247437775135
loss_c:1.0179643630981445
tensor(1.4407, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03560289368033409
loss_c:1.0316495895385742
tensor(1.4670, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020168261602520943
loss_c:1.0142624378204346
tensor(1.4032, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02758106216788292
loss_c:0.9527938365936279
tensor(1.3996, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02634323760867119
loss_c:1.0589239597320557
tensor(1.4471, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037310950458049774
loss_c:1.089671015739441
tensor(1.5016, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03057531639933586
loss_c:0.9654295444488525
tensor(1.4165, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03966493532061577
loss_c:1.1279033422470093
tensor(1.5289, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028174540027976036
loss_c:1.0881705284118652
tensor(1.4680, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11488871276378632
loss_c:1.0030975341796875
tensor(1.7393, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03544873371720314
loss_c:0.9763233065605164
tensor(1.4394, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024227790534496307
loss_c:0.8743709325790405
tensor(1.3489, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02115088701248169
loss_c:0.9482994079589844
tensor(1.3741, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04715792462229729
loss_c:0.9653739929199219
tensor(1.4761, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02832120470702648
loss_c:1.001713514328003
tensor(1.4261, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06135307252407074
loss_c:1.294367790222168
tensor(1.6886, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021170377731323242
loss_c:1.0164631605148315
tensor(1.4077, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.051736846566200256
loss_c:0.9409546852111816
tensor(1.4805, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05872226133942604
loss_c:0.9624099135398865
tensor(1.5160, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01998818852007389
loss_c:1.0821373462677002
tensor(1.4358, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035749420523643494
loss_c:0.9400240182876587
tensor(1.4226, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07154328376054764
loss_c:1.206965446472168
tensor(1.6817, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03388768061995506
loss_c:0.9746682047843933
tensor(1.4329, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03577087074518204
loss_c:1.0802712440490723
tensor(1.4915, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02513573132455349
loss_c:1.0360870361328125
tensor(1.4318, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021759558469057083
loss_c:1.0966503620147705
tensor(1.4496, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0246284082531929
loss_c:0.9986832141876221
tensor(1.4117, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.052438683807849884
loss_c:1.0905966758728027
tensor(1.5558, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028155410662293434
loss_c:0.9738673567771912
tensor(1.4121, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028350166976451874
loss_c:1.0493416786193848
tensor(1.4499, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03558839485049248
loss_c:0.9467611312866211
tensor(1.4253, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02429664321243763
loss_c:0.9542176723480225
tensor(1.3888, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023165497928857803
loss_c:1.013465404510498
tensor(1.4139, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02358178049325943
loss_c:1.0690548419952393
tensor(1.4426, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01967550814151764
loss_c:1.0785068273544312
tensor(1.4333, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026855455711483955
loss_c:1.0345749855041504
tensor(1.4373, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02906561829149723
loss_c:0.9311550855636597
tensor(1.3944, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06034070998430252
loss_c:1.2566765546798706
tensor(1.6656, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02689329721033573
loss_c:0.9690887331962585
tensor(1.4052, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07036367803812027
loss_c:0.9863588213920593
tensor(1.5687, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02643147110939026
loss_c:1.117825984954834
tensor(1.4766, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017774533480405807
loss_c:0.975670337677002
tensor(1.3760, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04872635006904602
loss_c:0.9068414568901062
tensor(1.4525, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036471620202064514
loss_c:0.9023956656455994
tensor(1.4067, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03111596219241619
loss_c:0.9483782649040222
tensor(1.4101, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02653493545949459
loss_c:1.048743724822998
tensor(1.4431, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031436532735824585
loss_c:0.9817843437194824
tensor(1.4277, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01718406192958355
loss_c:0.910148024559021
tensor(1.3417, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04540899768471718
loss_c:0.9130280017852783
tensor(1.4437, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024739569053053856
loss_c:0.8530885577201843
tensor(1.3405, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08966588973999023
loss_c:1.0013535022735596
tensor(1.6449, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030071159824728966
loss_c:1.157320499420166
tensor(1.5091, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024785621091723442
loss_c:0.9495340585708618
tensor(1.3881, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02980976365506649
loss_c:1.1484442949295044
tensor(1.5038, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017784740775823593
loss_c:0.9278788566589355
tensor(1.3525, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02773195691406727
loss_c:1.2370604276657104
tensor(1.5401, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02347962185740471
loss_c:1.0262365341186523
tensor(1.4211, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02529999241232872
loss_c:0.8267640471458435
tensor(1.3294, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023360276594758034
loss_c:0.9228240251541138
tensor(1.3697, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0275189857929945
loss_c:0.9136428833007812
tensor(1.3800, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027420472353696823
loss_c:1.0082297325134277
tensor(1.4262, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02490714192390442
loss_c:0.9886461496353149
tensor(1.4076, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021013401448726654
loss_c:0.9704524874687195
tensor(1.3846, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027952751144766808
loss_c:0.813167929649353
tensor(1.3318, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019520971924066544
loss_c:0.8484662771224976
tensor(1.3189, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04766889661550522
loss_c:0.9692506194114685
tensor(1.4796, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022115632891654968
loss_c:0.9164630770683289
tensor(1.3616, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05165201053023338
loss_c:0.9464549422264099
tensor(1.4827, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03493479639291763
loss_c:1.0772076845169067
tensor(1.4872, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028482329100370407
loss_c:0.9516366720199585
tensor(1.4018, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035079728811979294
loss_c:1.0430634021759033
tensor(1.4709, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030307883396744728
loss_c:1.0575072765350342
tensor(1.4608, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03996814414858818
loss_c:1.021681785583496
tensor(1.4779, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032795801758766174
loss_c:1.0367190837860107
tensor(1.4595, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031842172145843506
loss_c:1.3151640892028809
tensor(1.5941, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027797052636742592
loss_c:0.9942959547042847
tensor(1.4204, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02776068076491356
loss_c:0.9711670279502869
tensor(1.4088, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03658261150121689
loss_c:1.094425916671753
tensor(1.5018, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024426838383078575
loss_c:1.0390253067016602
tensor(1.4303, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018512152135372162
loss_c:0.976059079170227
tensor(1.3777, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04791327938437462
loss_c:1.0952973365783691
tensor(1.5433, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021311556920409203
loss_c:0.9454339742660522
tensor(1.3726, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03380284830927849
loss_c:1.0208265781402588
tensor(1.4552, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02439471147954464
loss_c:0.9083468317985535
tensor(1.3653, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020603718236088753
loss_c:0.9536957740783691
tensor(1.3740, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026314472779631615
loss_c:1.0099635124206543
tensor(1.4226, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036599867045879364
loss_c:1.0243901014328003
tensor(1.4672, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0719226822257042
loss_c:1.0246801376342773
tensor(1.5960, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0695243775844574
loss_c:1.093498706817627
tensor(1.6214, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02299971505999565
loss_c:0.921952486038208
tensor(1.3669, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02307184599339962
loss_c:1.0124011039733887
tensor(1.4121, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024686602875590324
loss_c:1.0277938842773438
tensor(1.4256, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025046493858098984
loss_c:1.1090295314788818
tensor(1.4672, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024539612233638763
loss_c:0.9125036001205444
tensor(1.3679, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03141511231660843
loss_c:1.1533259153366089
tensor(1.5123, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044813912361860275
loss_c:1.01686429977417
tensor(1.4933, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025370130315423012
loss_c:1.0383931398391724
tensor(1.4333, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03022734820842743
loss_c:1.0146565437316895
tensor(1.4392, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02631804533302784
loss_c:1.0467162132263184
tensor(1.4409, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033546049147844315
loss_c:1.0780465602874756
tensor(1.4827, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03693440556526184
loss_c:1.0007089376449585
tensor(1.4567, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024031255394220352
loss_c:0.9349667429924011
tensor(1.3771, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04080624878406525
loss_c:0.9368108510971069
tensor(1.4391, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028541823849081993
loss_c:1.0167988538742065
tensor(1.4341, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023921994492411613
loss_c:0.9634323120117188
tensor(1.3908, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04761418700218201
loss_c:1.0581037998199463
tensor(1.5241, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018993500620126724
loss_c:0.9876631498336792
tensor(1.3848, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025618955492973328
loss_c:1.0755615234375
tensor(1.4525, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05867255851626396
loss_c:1.3089996576309204
tensor(1.6889, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029704589396715164
loss_c:0.9127106070518494
tensor(1.3867, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03177379071712494
loss_c:1.0568727254867554
tensor(1.4657, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03445903956890106
loss_c:1.0716209411621094
tensor(1.4828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0252333153039217
loss_c:0.8963763117790222
tensor(1.3624, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03441936895251274
loss_c:0.9372283816337585
tensor(1.4161, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02635018154978752
loss_c:1.0117239952087402
tensor(1.4235, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030998356640338898
loss_c:1.0325559377670288
tensor(1.4508, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023472873494029045
loss_c:0.909998893737793
tensor(1.3627, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08601449429988861
loss_c:0.9665541648864746
tensor(1.6191, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025610027834773064
loss_c:0.9627549648284912
tensor(1.3966, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03005649521946907
loss_c:1.1385575532913208
tensor(1.4999, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02416471764445305
loss_c:0.9568990468978882
tensor(1.3884, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030083749443292618
loss_c:0.9720230102539062
tensor(1.4175, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027567563578486443
loss_c:1.005810260772705
tensor(1.4251, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03432193398475647
loss_c:1.04924738407135
tensor(1.4712, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029433032497763634
loss_c:1.0763335227966309
tensor(1.4668, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027159545570611954
loss_c:1.1489921808242798
tensor(1.4945, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02881675399839878
loss_c:0.9541494250297546
tensor(1.4040, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02482348307967186
loss_c:0.9913870692253113
tensor(1.4079, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0345095731317997
loss_c:1.0720536708831787
tensor(1.4832, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024170638993382454
loss_c:1.1016595363616943
tensor(1.4601, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02683497592806816
loss_c:0.9202148914337158
tensor(1.3800, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01985420100390911
loss_c:0.8895620703697205
tensor(1.3393, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026751244440674782
loss_c:0.9795607924461365
tensor(1.4090, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023117670789361
loss_c:0.8931309580802917
tensor(1.3529, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030564457178115845
loss_c:0.9669369459152222
tensor(1.4167, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05195770412683487
loss_c:0.9880411028862
tensor(1.5057, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024960961192846298
loss_c:0.92983478307724
tensor(1.3777, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025023164227604866
loss_c:0.9056558012962341
tensor(1.3659, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.045273810625076294
loss_c:1.0402264595031738
tensor(1.5071, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028378097340464592
loss_c:0.963383138179779
tensor(1.4068, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03410762548446655
loss_c:0.9428670406341553
tensor(1.4177, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021517444401979446
loss_c:1.0605264902114868
tensor(1.4298, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018835831433534622
loss_c:0.8931180834770203
tensor(1.3368, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028376856818795204
loss_c:1.0321887731552124
tensor(1.4410, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026582468301057816
loss_c:1.0531377792358398
tensor(1.4447, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029881605878472328
loss_c:0.8869136571884155
tensor(1.3743, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024719370529055595
loss_c:0.9671770930290222
tensor(1.3951, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025452464818954468
loss_c:1.0042498111724854
tensor(1.4162, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02407112903892994
loss_c:1.032849669456482
tensor(1.4253, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022545740008354187
loss_c:1.0687229633331299
tensor(1.4375, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03901214897632599
loss_c:1.1070349216461182
tensor(1.5176, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025887098163366318
loss_c:1.0365599393844604
tensor(1.4338, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016888365149497986
loss_c:1.1912415027618408
tensor(1.4773, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03664260357618332
loss_c:1.0478918552398682
tensor(1.4794, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02978125959634781
loss_c:1.144991159439087
tensor(1.5022, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05452631413936615
loss_c:1.1315850019454956
tensor(1.5877, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023756757378578186
loss_c:0.9575610160827637
tensor(1.3865, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01971542090177536
loss_c:1.0010302066802979
tensor(1.3930, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0245803389698267
loss_c:1.1008658409118652
tensor(1.4607, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025465749204158783
loss_c:1.0780651569366455
tensor(1.4527, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028436925262212753
loss_c:0.9788540601730347
tensor(1.4145, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021660419180989265
loss_c:0.8938261270523071
tensor(1.3469, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031059090048074722
loss_c:1.1832690238952637
tensor(1.5258, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05114664137363434
loss_c:1.0022861957550049
tensor(1.5113, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03410317748785019
loss_c:1.2490005493164062
tensor(1.5697, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03963898494839668
loss_c:0.9915424585342407
tensor(1.4628, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03688583895564079
loss_c:1.2011778354644775
tensor(1.5564, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025116045027971268
loss_c:1.0247795581817627
tensor(1.4248, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05126483738422394
loss_c:1.1286499500274658
tensor(1.5743, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017626414075493813
loss_c:0.9207513332366943
tensor(1.3452, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.053623586893081665
loss_c:0.9834162592887878
tensor(1.5113, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02565346099436283
loss_c:0.9407033324241638
tensor(1.3852, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04886344075202942
loss_c:0.9496179819107056
tensor(1.4766, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025444595143198967
loss_c:1.0782166719436646
tensor(1.4525, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02499094419181347
loss_c:1.0516821146011353
tensor(1.4377, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022086821496486664
loss_c:0.9010798335075378
tensor(1.3524, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020937727764248848
loss_c:0.9382715225219727
tensor(1.3665, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030389636754989624
loss_c:1.0935564041137695
tensor(1.4786, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02252545952796936
loss_c:0.9137686491012573
tensor(1.3603, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03336827829480171
loss_c:0.8895412683486938
tensor(1.3889, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038932301104068756
loss_c:1.146956443786621
tensor(1.5369, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02926298975944519
loss_c:0.9164881706237793
tensor(1.3868, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02027384750545025
loss_c:1.152029275894165
tensor(1.4696, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02209746465086937
loss_c:0.969272792339325
tensor(1.3861, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021486550569534302
loss_c:1.0451202392578125
tensor(1.4212, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023496218025684357
loss_c:0.9845786094665527
tensor(1.3988, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04230279102921486
loss_c:1.215551733970642
tensor(1.5836, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026382524520158768
loss_c:1.0436214208602905
tensor(1.4388, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01691192016005516
loss_c:0.8857325315475464
tensor(1.3252, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02082911506295204
loss_c:0.9878228902816772
tensor(1.3903, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023749154061079025
loss_c:1.0234241485595703
tensor(1.4189, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024143213406205177
loss_c:0.872404932975769
tensor(1.3457, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019170574843883514
loss_c:1.0213650465011597
tensor(1.4005, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028174256905913353
loss_c:0.9398459196090698
tensor(1.3942, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02431747131049633
loss_c:0.9898581504821777
tensor(1.4043, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025192683562636375
loss_c:1.0806316137313843
tensor(1.4524, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02231660857796669
loss_c:0.8937162160873413
tensor(1.3491, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.057875294238328934
loss_c:0.9554378390312195
tensor(1.5147, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035576675087213516
loss_c:0.9874686598777771
tensor(1.4458, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028375715017318726
loss_c:1.0354149341583252
tensor(1.4421, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02604321576654911
loss_c:1.1332392692565918
tensor(1.4817, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030860187485814095
loss_c:1.0170881748199463
tensor(1.4425, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04923306033015251
loss_c:1.1053706407546997
tensor(1.5562, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05162239074707031
loss_c:0.9579285979270935
tensor(1.4924, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02596384845674038
loss_c:0.8434634208679199
tensor(1.3379, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02290050871670246
loss_c:0.8386248350143433
tensor(1.3239, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04111424461007118
loss_c:0.8873519897460938
tensor(1.4173, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.045865342020988464
loss_c:0.8955628275871277
tensor(1.4394, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03469334915280342
loss_c:1.0602236986160278
tensor(1.4785, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0416957251727581
loss_c:0.9746823310852051
tensor(1.4626, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03755434229969978
loss_c:1.0826935768127441
tensor(1.5005, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02729770727455616
loss_c:0.9678220748901367
tensor(1.4046, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02367633581161499
loss_c:1.1094655990600586
tensor(1.4612, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027082348242402077
loss_c:0.921909511089325
tensor(1.3810, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024114718660712242
loss_c:0.9476277828216553
tensor(1.3825, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023928869515657425
loss_c:0.9600973129272461
tensor(1.3880, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019932821393013
loss_c:1.0251330137252808
tensor(1.4052, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027912933379411697
loss_c:1.194994568824768
tensor(1.5198, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04863087087869644
loss_c:0.9400350451469421
tensor(1.4714, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06288750469684601
loss_c:1.0593535900115967
tensor(1.5847, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041394881904125214
loss_c:1.1406491994857788
tensor(1.5438, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037218254059553146
loss_c:1.0835590362548828
tensor(1.4996, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06319183111190796
loss_c:1.0246737003326416
tensor(1.5682, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02590285614132881
loss_c:0.9214878082275391
tensor(1.3764, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06087573617696762
loss_c:1.0545458793640137
tensor(1.5739, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07731855660676956
loss_c:0.9733230471611023
tensor(1.5949, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025286464020609856
loss_c:0.9896599650382996
tensor(1.4081, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023880911991000175
loss_c:1.0555760860443115
tensor(1.4357, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036041129380464554
loss_c:0.9121865034103394
tensor(1.4097, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028946755453944206
loss_c:1.0476713180541992
tensor(1.4507, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024662893265485764
loss_c:1.1444084644317627
tensor(1.4829, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022973468527197838
loss_c:1.0312780141830444
tensor(1.4205, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02493221126496792
loss_c:0.9677473306655884
tensor(1.3962, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02454809844493866
loss_c:0.8753554224967957
tensor(1.3489, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02073727361857891
loss_c:0.9225678443908691
tensor(1.3583, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.050568971782922745
loss_c:0.8912173509597778
tensor(1.4528, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.12838804721832275
loss_c:1.0931472778320312
tensor(1.8401, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0388278104364872
loss_c:1.0454055070877075
tensor(1.4860, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027271157130599022
loss_c:0.9954471588134766
tensor(1.4187, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024476714432239532
loss_c:1.1191198825836182
tensor(1.4700, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04045317694544792
loss_c:0.9415525794029236
tensor(1.4402, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05095244199037552
loss_c:0.9043194651603699
tensor(1.4599, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023910988122224808
loss_c:0.8146846294403076
tensor(1.3168, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021210962906479836
loss_c:0.8932750225067139
tensor(1.3461, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029502835124731064
loss_c:1.0168514251708984
tensor(1.4377, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025443196296691895
loss_c:1.064758539199829
tensor(1.4468, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.12513265013694763
loss_c:1.0702378749847412
tensor(1.8106, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02177063748240471
loss_c:0.8952683210372925
tensor(1.3493, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029093768447637558
loss_c:1.1214689016342163
tensor(1.4884, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0368068665266037
loss_c:0.9874792098999023
tensor(1.4495, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03625768423080444
loss_c:1.0441632270812988
tensor(1.4757, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02383776754140854
loss_c:1.0472517013549805
tensor(1.4327, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03299270570278168
loss_c:0.9074877500534058
tensor(1.3959, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0360998772084713
loss_c:0.993503749370575
tensor(1.4499, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03523288294672966
loss_c:1.0305242538452148
tensor(1.4652, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026104126125574112
loss_c:1.1195544004440308
tensor(1.4770, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026550421491265297
loss_c:1.0047276020050049
tensor(1.4214, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.055324554443359375
loss_c:0.9962944984436035
tensor(1.5198, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029617298394441605
loss_c:0.9164913892745972
tensor(1.3884, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03588879108428955
loss_c:1.0308523178100586
tensor(1.4677, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.059557024389505386
loss_c:0.9567809104919434
tensor(1.5150, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025882132351398468
loss_c:1.125266432762146
tensor(1.4792, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025002213194966316
loss_c:0.9005348086357117
tensor(1.3641, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03630375862121582
loss_c:0.9779386520385742
tensor(1.4428, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02666819654405117
loss_c:1.014840841293335
tensor(1.4270, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02529335953295231
loss_c:0.8998686075210571
tensor(1.3648, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025528758764266968
loss_c:0.9284355640411377
tensor(1.3799, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023445140570402145
loss_c:0.9724464416503906
tensor(1.3944, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030794117599725723
loss_c:1.0617690086364746
tensor(1.4651, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029214374721050262
loss_c:0.9057480096817017
tensor(1.3816, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02716386877000332
loss_c:1.286355972290039
tensor(1.5642, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02831294760107994
loss_c:0.9860328435897827
tensor(1.4184, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02724554017186165
loss_c:0.9567551612854004
tensor(1.4000, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026187334209680557
loss_c:1.065378189086914
tensor(1.4504, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05247269198298454
loss_c:1.0496773719787598
tensor(1.5362, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03240317478775978
loss_c:1.1461222171783447
tensor(1.5128, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026363981887698174
loss_c:1.1139004230499268
tensor(1.4752, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02740856446325779
loss_c:1.0883492231369019
tensor(1.4661, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05302885174751282
loss_c:0.9915356636047363
tensor(1.5094, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022372407838702202
loss_c:1.0866265296936035
tensor(1.4472, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020075762644410133
loss_c:1.0470331907272339
tensor(1.4193, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0222538560628891
loss_c:0.9410163760185242
tensor(1.3742, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032292988151311874
loss_c:1.0649797916412354
tensor(1.4718, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018645992502570152
loss_c:0.9227104187011719
tensor(1.3521, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016595523804426193
loss_c:0.9043740034103394
tensor(1.3356, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04071323201060295
loss_c:0.9486485719680786
tensor(1.4442, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023738795891404152
loss_c:0.9531110525131226
tensor(1.3854, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08633463829755783
loss_c:0.9624559879302979
tensor(1.6154, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03506290540099144
loss_c:0.8552292585372925
tensor(1.3774, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026804335415363312
loss_c:1.291284441947937
tensor(1.5646, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02073422446846962
loss_c:0.8647122383117676
tensor(1.3305, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05101914703845978
loss_c:1.0280226469039917
tensor(1.5209, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04733628034591675
loss_c:0.9638843536376953
tensor(1.4757, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030152514576911926
loss_c:0.8782870769500732
tensor(1.3712, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02459781989455223
loss_c:0.9186933040618896
tensor(1.3713, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06423617899417877
loss_c:0.9077591896057129
tensor(1.5085, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0280226431787014
loss_c:1.0908725261688232
tensor(1.4694, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.047467488795518875
loss_c:1.0769503116607666
tensor(1.5324, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02536103129386902
loss_c:1.21918785572052
tensor(1.5238, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04199106991291046
loss_c:0.9189450144767761
tensor(1.4339, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026470666751265526
loss_c:1.060925006866455
tensor(1.4489, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01969023048877716
loss_c:1.0188946723937988
tensor(1.4037, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032887984067201614
loss_c:1.0071544647216797
tensor(1.4452, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.047962676733732224
loss_c:1.0018954277038574
tensor(1.4966, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01908252015709877
loss_c:0.910923182964325
tensor(1.3477, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02294396422803402
loss_c:0.9556519985198975
tensor(1.3839, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03232860192656517
loss_c:0.9877656698226929
tensor(1.4335, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022356901317834854
loss_c:0.9823824763298035
tensor(1.3950, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026209311559796333
loss_c:1.1354343891143799
tensor(1.4851, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0277791079133749
loss_c:1.0308926105499268
tensor(1.4386, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04833940416574478
loss_c:0.8694834113121033
tensor(1.4321, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018775196745991707
loss_c:0.8129339218139648
tensor(1.2976, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019506672397255898
loss_c:0.9053382873535156
tensor(1.3462, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03190837427973747
loss_c:0.8855659365653992
tensor(1.3810, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04271790757775307
loss_c:0.9585561752319336
tensor(1.4564, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021227696910500526
loss_c:1.1639313697814941
tensor(1.4813, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06395211070775986
loss_c:0.9102810621261597
tensor(1.5090, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05350269749760628
loss_c:0.9846594333648682
tensor(1.5084, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025517132133245468
loss_c:1.0085484981536865
tensor(1.4192, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02528773993253708
loss_c:0.853246808052063
tensor(1.3408, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02662123180925846
loss_c:1.0086143016815186
tensor(1.4233, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02598242461681366
loss_c:0.9155558347702026
tensor(1.3744, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020199937745928764
loss_c:0.9074587821960449
tensor(1.3495, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030930908396840096
loss_c:0.9499847292900085
tensor(1.4095, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05988852679729462
loss_c:1.0426349639892578
tensor(1.5606, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020324019715189934
loss_c:0.8800485134124756
tensor(1.3361, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05679735168814659
loss_c:0.9694685935974121
tensor(1.5128, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.13642017543315887
loss_c:1.109846830368042
tensor(1.8710, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01885213702917099
loss_c:0.9876434803009033
tensor(1.3848, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02237907238304615
loss_c:0.849962592124939
tensor(1.3285, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026087002828717232
loss_c:1.0190694332122803
tensor(1.4267, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04744502529501915
loss_c:1.2239017486572266
tensor(1.6062, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020452061668038368
loss_c:0.8535112738609314
tensor(1.3235, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03667135909199715
loss_c:1.083024501800537
tensor(1.4969, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02409461699426174
loss_c:0.9733450412750244
tensor(1.3968, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02731778658926487
loss_c:1.1074737310409546
tensor(1.4757, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03331119939684868
loss_c:1.0759341716766357
tensor(1.4813, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02243850938975811
loss_c:0.9382034540176392
tensor(1.3733, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02482743188738823
loss_c:1.0081114768981934
tensor(1.4169, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02618660032749176
loss_c:0.8859738111495972
tensor(1.3605, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041278623044490814
loss_c:1.0350626707077026
tensor(1.4892, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031087836250662804
loss_c:0.9892681837081909
tensor(1.4298, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027559146285057068
loss_c:1.1966793537139893
tensor(1.5213, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024621358141303062
loss_c:1.0061067342758179
tensor(1.4151, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024917403236031532
loss_c:1.0027027130126953
tensor(1.4145, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021976962685585022
loss_c:0.9995284080505371
tensor(1.4023, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05210070684552193
loss_c:0.7969614267349243
tensor(1.4086, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04168902710080147
loss_c:1.2610299587249756
tensor(1.6041, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03213059529662132
loss_c:0.8907424807548523
tensor(1.3841, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05985588952898979
loss_c:1.0718952417373657
tensor(1.5744, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04593693092465401
loss_c:1.149038553237915
tensor(1.5631, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02512623369693756
loss_c:1.0579307079315186
tensor(1.4428, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027125004678964615
loss_c:0.8797034025192261
tensor(1.3607, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0236480925232172
loss_c:1.0328292846679688
tensor(1.4250, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0339539535343647
loss_c:1.1485612392425537
tensor(1.5199, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021965794265270233
loss_c:0.8777397871017456
tensor(1.3413, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01785355806350708
loss_c:0.8953132629394531
tensor(1.3353, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.057972587645053864
loss_c:1.0401923656463623
tensor(1.5517, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05258086323738098
loss_c:0.8274110555648804
tensor(1.4259, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02970915287733078
loss_c:0.9700710773468018
tensor(1.4152, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025641953572630882
loss_c:0.9927530288696289
tensor(1.4120, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02326827496290207
loss_c:0.9635583758354187
tensor(1.3889, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017741886898875237
loss_c:0.973868727684021
tensor(1.3742, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025077400729060173
loss_c:0.9767491221427917
tensor(1.4019, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04798005521297455
loss_c:0.9859137535095215
tensor(1.4887, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.162429079413414
loss_c:1.067657232284546
tensor(1.9408, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02619607001543045
loss_c:1.0263727903366089
tensor(1.4309, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02887275442481041
loss_c:1.1099984645843506
tensor(1.4824, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024386301636695862
loss_c:0.8837840557098389
tensor(1.3531, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020148063078522682
loss_c:1.0027345418930054
tensor(1.3976, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025857774540781975
loss_c:1.0707573890686035
tensor(1.4521, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02614733949303627
loss_c:0.9864728450775146
tensor(1.4109, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04053843766450882
loss_c:1.017280101776123
tensor(1.4775, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025543835014104843
loss_c:1.0061087608337402
tensor(1.4186, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018260536715388298
loss_c:1.0009567737579346
tensor(1.3902, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033881571143865585
loss_c:1.1565401554107666
tensor(1.5236, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07179391384124756
loss_c:1.0778541564941406
tensor(1.6189, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044357795268297195
loss_c:1.041682481765747
tensor(1.5033, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05006719380617142
loss_c:0.8761756420135498
tensor(1.4407, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04100683704018593
loss_c:1.0594556331634521
tensor(1.5002, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06755916774272919
loss_c:0.9628415107727051
tensor(1.5459, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02478046342730522
loss_c:1.1577178239822388
tensor(1.4919, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020658642053604126
loss_c:1.0838100910186768
tensor(1.4405, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026836328208446503
loss_c:1.1165239810943604
tensor(1.4786, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04393424093723297
loss_c:1.0357487201690674
tensor(1.4985, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02061675861477852
loss_c:1.0074422359466553
tensor(1.4022, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040062323212623596
loss_c:0.9820936918258667
tensor(1.4581, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025151362642645836
loss_c:1.058606505393982
tensor(1.4438, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038727596402168274
loss_c:1.039179801940918
tensor(1.4818, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016848158091306686
loss_c:0.9570727348327637
tensor(1.3639, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018300505355000496
loss_c:0.9053651690483093
tensor(1.3432, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017945103347301483
loss_c:1.091207504272461
tensor(1.4346, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035665594041347504
loss_c:1.3178632259368896
tensor(1.6099, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04350343719124794
loss_c:1.009779930114746
tensor(1.4840, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019334016367793083
loss_c:0.9429394602775574
tensor(1.3655, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02681323140859604
loss_c:0.9512569904327393
tensor(1.3960, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06587107479572296
loss_c:0.9341750144958496
tensor(1.5256, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03181866183876991
loss_c:1.0810340642929077
tensor(1.4782, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018505694344639778
loss_c:0.8874408006668091
tensor(1.3349, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01938941888511181
loss_c:1.0345137119293213
tensor(1.4111, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037714648991823196
loss_c:1.055305004119873
tensor(1.4863, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04272853583097458
loss_c:0.944121778011322
tensor(1.4488, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025707285851240158
loss_c:0.9685710668563843
tensor(1.4006, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03130728378891945
loss_c:1.0206995010375977
tensor(1.4464, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04240301996469498
loss_c:1.0330209732055664
tensor(1.4919, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023254889994859695
loss_c:1.058502197265625
tensor(1.4365, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03463399037718773
loss_c:1.1676385402679443
tensor(1.5312, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02247326634824276
loss_c:1.1120715141296387
tensor(1.4603, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025738416239619255
loss_c:0.9928051829338074
tensor(1.4126, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02517428621649742
loss_c:0.9730440974235535
tensor(1.4008, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02974589355289936
loss_c:1.1533324718475342
tensor(1.5066, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03220345824956894
loss_c:0.9402405023574829
tensor(1.4096, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02889775112271309
loss_c:0.9856103658676147
tensor(1.4203, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024515599012374878
loss_c:1.0990748405456543
tensor(1.4608, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020857617259025574
loss_c:0.8989951610565186
tensor(1.3485, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02675517648458481
loss_c:1.0204449892044067
tensor(1.4298, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024695545434951782
loss_c:1.0706466436386108
tensor(1.4472, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030968016013503075
loss_c:1.0868093967437744
tensor(1.4778, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.16017049551010132
loss_c:1.1954957246780396
tensor(1.9969, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02447330951690674
loss_c:0.8878495693206787
tensor(1.3558, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02178253047168255
loss_c:1.0441458225250244
tensor(1.4236, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028836149722337723
loss_c:0.9592382311820984
tensor(1.4069, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027766142040491104
loss_c:1.0887738466262817
tensor(1.4672, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019246187061071396
loss_c:0.9391084909439087
tensor(1.3626, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02451208606362343
loss_c:0.9919829368591309
tensor(1.4077, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018569910898804665
loss_c:0.8718565702438354
tensor(1.3269, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018790191039443016
loss_c:0.8423899412155151
tensor(1.3131, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03304877132177353
loss_c:0.9243847727775574
tensor(1.4048, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03908797726035118
loss_c:0.9231159090995789
tensor(1.4258, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02355348691344261
loss_c:0.9479913711547852
tensor(1.3823, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020007571205496788
loss_c:0.9974717497825623
tensor(1.3941, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019029958173632622
loss_c:0.9953286647796631
tensor(1.3894, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018680935725569725
loss_c:0.9305269122123718
tensor(1.3560, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06902952492237091
loss_c:0.9568748474121094
tensor(1.5506, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022746318951249123
loss_c:0.8565716743469238
tensor(1.3338, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02137964405119419
loss_c:1.0103669166564941
tensor(1.4052, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036203376948833466
loss_c:0.9793304204940796
tensor(1.4433, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03178948536515236
loss_c:1.0791020393371582
tensor(1.4770, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024599729105830193
loss_c:0.9275333881378174
tensor(1.3755, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021460512652993202
loss_c:0.9036800265312195
tensor(1.3522, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026752542704343796
loss_c:0.9714290499687195
tensor(1.4051, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03980837017297745
loss_c:0.9586730003356934
tensor(1.4461, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03651011735200882
loss_c:1.0274658203125
tensor(1.4684, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10651814937591553
loss_c:0.932234525680542
tensor(1.6757, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0281513724476099
loss_c:1.2243156433105469
tensor(1.5363, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0281988512724638
loss_c:0.8627545833587646
tensor(1.3561, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021618926897644997
loss_c:1.1256113052368164
tensor(1.4634, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029146842658519745
loss_c:1.0725886821746826
tensor(1.4642, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06821417063474655
loss_c:0.9995178580284119
tensor(1.5695, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04444116726517677
loss_c:0.9214569926261902
tensor(1.4442, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022777095437049866
loss_c:1.1490081548690796
tensor(1.4794, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023719504475593567
loss_c:1.0263408422470093
tensor(1.4216, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03362440690398216
loss_c:1.0481159687042236
tensor(1.4683, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021687474101781845
loss_c:1.114960789680481
tensor(1.4585, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024987487122416496
loss_c:1.0310750007629395
tensor(1.4286, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032813284546136856
loss_c:0.9892102479934692
tensor(1.4359, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04329468682408333
loss_c:1.0097250938415527
tensor(1.4840, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033253397792577744
loss_c:1.0312895774841309
tensor(1.4585, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04910242557525635
loss_c:1.0532647371292114
tensor(1.5267, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03541753068566322
loss_c:1.166039228439331
tensor(1.5335, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039019875228405
loss_c:0.9779154658317566
tensor(1.4527, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028511760756373405
loss_c:1.0648589134216309
tensor(1.4581, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025716211646795273
loss_c:0.9614936709403992
tensor(1.3966, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021368183195590973
loss_c:0.8980675935745239
tensor(1.3493, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023585133254528046
loss_c:0.9921457767486572
tensor(1.4041, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019616317003965378
loss_c:0.9614819884300232
tensor(1.3745, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030315203592181206
loss_c:1.0318610668182373
tensor(1.4482, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019521908834576607
loss_c:0.9372226595878601
tensor(1.3621, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03089981898665428
loss_c:1.0164998769760132
tensor(1.4426, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0496668703854084
loss_c:0.9654929041862488
tensor(1.4851, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019922059029340744
loss_c:0.8853193521499634
tensor(1.3375, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025682097300887108
loss_c:1.0724148750305176
tensor(1.4515, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029241610318422318
loss_c:0.8594445586204529
tensor(1.3584, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02211882546544075
loss_c:1.0474531650543213
tensor(1.4261, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023960469290614128
loss_c:0.9576923251152039
tensor(1.3881, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03037753701210022
loss_c:1.0054272413253784
tensor(1.4351, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022600403055548668
loss_c:1.055574893951416
tensor(1.4318, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0319233313202858
loss_c:1.1217026710510254
tensor(1.4987, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026735462248325348
loss_c:1.130889654159546
tensor(1.4843, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029951000586152077
loss_c:0.9932171106338501
tensor(1.4275, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02200310118496418
loss_c:0.8725433349609375
tensor(1.3382, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02581026963889599
loss_c:0.9345654845237732
tensor(1.3830, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03793157637119293
loss_c:0.8774206638336182
tensor(1.3990, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018260221928358078
loss_c:0.8936516046524048
tensor(1.3348, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04916492477059364
loss_c:1.0338642597198486
tensor(1.5183, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04793022945523262
loss_c:1.1682857275009155
tensor(1.5809, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017034582793712616
loss_c:0.9176008105278015
tensor(1.3421, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.045954685658216476
loss_c:1.1395149230957031
tensor(1.5593, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01754717528820038
loss_c:0.9754034876823425
tensor(1.3728, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04430221766233444
loss_c:1.0760666131973267
tensor(1.5216, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020832303911447525
loss_c:0.9124144911766052
tensor(1.3534, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017107127234339714
loss_c:1.0252413749694824
tensor(1.3959, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01846071146428585
loss_c:0.9436833262443542
tensor(1.3602, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025847645476460457
loss_c:0.9518243074417114
tensor(1.3915, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030245261266827583
loss_c:0.9366795420646667
tensor(1.4002, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022762667387723923
loss_c:0.9198211431503296
tensor(1.3640, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02535034902393818
loss_c:0.8825340270996094
tensor(1.3550, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.051792629063129425
loss_c:0.9654294848442078
tensor(1.4946, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0724000483751297
loss_c:1.0144340991973877
tensor(1.5958, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02322441153228283
loss_c:0.8899211883544922
tensor(1.3507, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02430056594312191
loss_c:0.868273913860321
tensor(1.3438, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04877195507287979
loss_c:1.0599346160888672
tensor(1.5306, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04974335432052612
loss_c:1.0101958513259888
tensor(1.5093, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02366858907043934
loss_c:0.9716916084289551
tensor(1.3932, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025945764034986496
loss_c:0.8847124576568604
tensor(1.3581, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02457391656935215
loss_c:1.100525140762329
tensor(1.4611, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0257820226252079
loss_c:0.9603685736656189
tensor(1.3954, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027139490470290184
loss_c:1.0233652591705322
tensor(1.4320, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01858905330300331
loss_c:0.8185366988182068
tensor(1.2976, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02703196555376053
loss_c:1.0471563339233398
tensor(1.4435, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01734798774123192
loss_c:0.9516960978507996
tensor(1.3597, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10084449499845505
loss_c:1.081642508506775
tensor(1.7352, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02274331822991371
loss_c:0.9690713882446289
tensor(1.3884, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025003572925925255
loss_c:0.9212228655815125
tensor(1.3728, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021543720737099648
loss_c:1.006393313407898
tensor(1.4027, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01635887287557125
loss_c:0.8720093965530396
tensor(1.3160, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017494844272732735
loss_c:0.8551627397537231
tensor(1.3117, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03735378384590149
loss_c:0.9124693274497986
tensor(1.4142, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024511847645044327
loss_c:0.9670107364654541
tensor(1.3939, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022220727056264877
loss_c:1.0691263675689697
tensor(1.4368, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021897127851843834
loss_c:0.826650857925415
tensor(1.3135, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023193057626485825
loss_c:0.8854458332061768
tensor(1.3478, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030535239726305008
loss_c:0.9074145555496216
tensor(1.3862, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06139249727129936
loss_c:1.0784661769866943
tensor(1.5876, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04958430305123329
loss_c:0.9482154250144958
tensor(1.4778, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07025854289531708
loss_c:1.0361344814300537
tensor(1.5993, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020843306556344032
loss_c:1.0286436080932617
tensor(1.4112, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04352835938334465
loss_c:1.0994902849197388
tensor(1.5315, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02315458282828331
loss_c:0.9486347436904907
tensor(1.3795, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.053074054419994354
loss_c:1.2203208208084106
tensor(1.6280, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0342281274497509
loss_c:1.0315282344818115
tensor(1.4625, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05288876220583916
loss_c:1.1238770484924316
tensor(1.5783, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018908843398094177
loss_c:0.9557320475578308
tensor(1.3675, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03819131851196289
loss_c:1.0779204368591309
tensor(1.5006, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04559807479381561
loss_c:1.0776714086532593
tensor(1.5277, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022781213745474815
loss_c:0.8530229926109314
tensor(1.3302, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03062422014772892
loss_c:1.1110670566558838
tensor(1.4893, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06846582144498825
loss_c:0.9795326590538025
tensor(1.5623, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040076859295368195
loss_c:0.8427860140800476
tensor(1.3888, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021391719579696655
loss_c:1.0500273704528809
tensor(1.4246, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034008368849754333
loss_c:1.1177171468734741
tensor(1.5050, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02984478697180748
loss_c:1.1347105503082275
tensor(1.4983, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02432369627058506
loss_c:0.931886613368988
tensor(1.3760, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03127387911081314
loss_c:1.0858709812164307
tensor(1.4789, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02016574516892433
loss_c:0.9087356925010681
tensor(1.3492, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03655579686164856
loss_c:0.9353520274162292
tensor(1.4225, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027965795248746872
loss_c:1.0717394351959229
tensor(1.4597, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019781315699219704
loss_c:0.8655093908309937
tensor(1.3261, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02041221410036087
loss_c:0.9986650347709656
tensor(1.3953, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04456260800361633
loss_c:1.0472018718719482
tensor(1.5080, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05800781771540642
loss_c:0.8621277809143066
tensor(1.4641, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04091750085353851
loss_c:0.9407057762145996
tensor(1.4411, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04484713450074196
loss_c:0.9286763668060303
tensor(1.4494, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03597293794155121
loss_c:0.8970896601676941
tensor(1.4011, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042753685265779495
loss_c:1.0398919582366943
tensor(1.4976, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023754365742206573
loss_c:0.9428970813751221
tensor(1.3796, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023740436881780624
loss_c:1.1835960149765015
tensor(1.5006, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026038529351353645
loss_c:0.9773941040039062
tensor(1.4053, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020472928881645203
loss_c:0.8869253993034363
tensor(1.3396, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020396286621689796
loss_c:0.9722573161125183
tensor(1.3822, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04437039792537689
loss_c:0.9577608108520508
tensor(1.4621, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030216388404369354
loss_c:0.8974878787994385
tensor(1.3803, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.12192903459072113
loss_c:1.1520798206329346
tensor(1.8423, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03233930468559265
loss_c:0.9124626517295837
tensor(1.3955, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06311484426259995
loss_c:1.1534967422485352
tensor(1.6285, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018573472276329994
loss_c:0.9245008230209351
tensor(1.3518, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0334048867225647
loss_c:1.0442726612091064
tensor(1.4658, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026568753644824028
loss_c:0.9530450701713562
tensor(1.3952, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01889340579509735
loss_c:1.0107126235961914
tensor(1.3966, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01718178763985634
loss_c:0.9949070811271667
tensor(1.3825, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025907250121235847
loss_c:0.9158552885055542
tensor(1.3741, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08431706577539444
loss_c:1.0674281120300293
tensor(1.6606, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037052933126688004
loss_c:1.15232515335083
tensor(1.5332, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028577066957950592
loss_c:1.134544849395752
tensor(1.4938, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02892228402197361
loss_c:1.1046696901321411
tensor(1.4800, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02896503172814846
loss_c:0.9573683738708496
tensor(1.4061, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024304836988449097
loss_c:0.9423102140426636
tensor(1.3819, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019088145345449448
loss_c:0.8724563121795654
tensor(1.3281, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02396194450557232
loss_c:0.9858836531639099
tensor(1.4026, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016633527353405952
loss_c:0.9004298448562622
tensor(1.3334, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022190839052200317
loss_c:1.0095386505126953
tensor(1.4081, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04247915744781494
loss_c:1.153872013092041
tensor(1.5533, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05797877162694931
loss_c:1.0828156471252441
tensor(1.5733, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02367769181728363
loss_c:0.959152340888977
tensor(1.3880, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.047041572630405426
loss_c:0.8630425333976746
tensor(1.4237, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036436956375837326
loss_c:1.0147497653961182
tensor(1.4618, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040343210101127625
loss_c:0.9537090063095093
tensor(1.4452, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021832618862390518
loss_c:0.8482362031936646
tensor(1.3258, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01979445107281208
loss_c:0.9970616102218628
tensor(1.3931, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023990023881196976
loss_c:1.0616551637649536
tensor(1.4406, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020165834575891495
loss_c:0.8665446043014526
tensor(1.3289, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022067438811063766
loss_c:0.9430429935455322
tensor(1.3741, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03944821655750275
loss_c:0.8935614824295044
tensor(1.4118, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02708996832370758
loss_c:0.875102698802948
tensor(1.3579, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02679957076907158
loss_c:1.0316568613052368
tensor(1.4355, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04367849603295326
loss_c:1.0307252407073975
tensor(1.4960, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02413417212665081
loss_c:0.8495357036590576
tensor(1.3343, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04185847193002701
loss_c:0.9374774694442749
tensor(1.4426, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019175346940755844
loss_c:1.0150258541107178
tensor(1.3995, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02989664487540722
loss_c:0.9803695678710938
tensor(1.4209, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030058205127716064
loss_c:0.9364973902702332
tensor(1.3993, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03487864509224892
loss_c:0.8558262586593628
tensor(1.3762, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04190398380160332
loss_c:0.9293394088745117
tensor(1.4387, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017700955271720886
loss_c:0.9538615942001343
tensor(1.3632, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026776397600769997
loss_c:0.9423353672027588
tensor(1.3903, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04873051866889
loss_c:0.8790600299835205
tensor(1.4382, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027240175753831863
loss_c:0.9179463386535645
tensor(1.3796, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023771479725837708
loss_c:1.3188531398773193
tensor(1.5696, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017959030345082283
loss_c:0.8930944800376892
tensor(1.3332, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05916650965809822
loss_c:0.9726320505142212
tensor(1.5236, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022770745679736137
loss_c:0.8979277610778809
tensor(1.3531, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021534863859415054
loss_c:1.043563961982727
tensor(1.4222, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02179773338139057
loss_c:0.9885697364807129
tensor(1.3953, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04542383924126625
loss_c:0.8959988951683044
tensor(1.4348, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017564857378602028
loss_c:1.0082557201385498
tensor(1.3897, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04155406728386879
loss_c:0.8772184252738953
tensor(1.4112, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020520206540822983
loss_c:0.9130582809448242
tensor(1.3523, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04229966923594475
loss_c:1.1117355823516846
tensor(1.5328, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02170480415225029
loss_c:0.954816997051239
tensor(1.3777, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034924596548080444
loss_c:1.0989493131637573
tensor(1.4993, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.060613080859184265
loss_c:1.0399218797683716
tensor(1.5637, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03910183534026146
loss_c:0.927559494972229
tensor(1.4277, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030274970456957817
loss_c:0.9075419306755066
tensor(1.3852, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03563845530152321
loss_c:0.9906591176986694
tensor(1.4470, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030082942917943
loss_c:0.8908379077911377
tensor(1.3760, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018461856991052628
loss_c:1.0161525011062622
tensor(1.3969, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07912758737802505
loss_c:0.8777399063110352
tensor(1.5493, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044422660022974014
loss_c:1.0784357786178589
tensor(1.5237, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04041822999715805
loss_c:0.8986589312553406
tensor(1.4178, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026898236945271492
loss_c:1.1404175758361816
tensor(1.4910, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03952593356370926
loss_c:1.337946891784668
tensor(1.6374, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022119609639048576
loss_c:0.9839144945144653
tensor(1.3942, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02285098098218441
loss_c:0.9769136309623718
tensor(1.3933, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0292577613145113
loss_c:1.0949934720993042
tensor(1.4765, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019736848771572113
loss_c:1.0312875509262085
tensor(1.4096, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023183681070804596
loss_c:0.9448832273483276
tensor(1.3784, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016777800396084785
loss_c:0.8987903594970703
tensor(1.3317, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0480085089802742
loss_c:0.9845907092094421
tensor(1.4890, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018702886998653412
loss_c:0.93199223279953
tensor(1.3555, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03844370320439339
loss_c:0.9671844840049744
tensor(1.4453, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04558754339814186
loss_c:0.9580246806144714
tensor(1.4668, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025136025622487068
loss_c:1.0025798082351685
tensor(1.4146, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03316210210323334
loss_c:1.1368446350097656
tensor(1.5118, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04759879782795906
loss_c:1.073755145072937
tensor(1.5327, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026422737166285515
loss_c:1.0691533088684082
tensor(1.4529, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02310149185359478
loss_c:1.060931921005249
tensor(1.4366, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020785953849554062
loss_c:0.9707103967666626
tensor(1.3826, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026965182274580002
loss_c:0.916331946849823
tensor(1.3777, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02424624003469944
loss_c:1.1926013231277466
tensor(1.5071, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02024627849459648
loss_c:1.0125497579574585
tensor(1.4016, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01970692351460457
loss_c:0.940335214138031
tensor(1.3632, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01920749619603157
loss_c:1.0024926662445068
tensor(1.3926, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046312764286994934
loss_c:1.159076452255249
tensor(1.5710, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024547355249524117
loss_c:0.9654281139373779
tensor(1.3935, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021930161863565445
loss_c:0.9942764043807983
tensor(1.3983, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02688741125166416
loss_c:1.0132081508636475
tensor(1.4261, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017718462273478508
loss_c:0.8996221423149109
tensor(1.3351, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03448875993490219
loss_c:0.8975048065185547
tensor(1.3960, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0319671593606472
loss_c:1.017526626586914
tensor(1.4470, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022213200107216835
loss_c:0.9514762759208679
tensor(1.3776, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024984968826174736
loss_c:1.0090162754058838
tensor(1.4168, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02239087224006653
loss_c:0.8503853678703308
tensor(1.3274, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11272892355918884
loss_c:1.1756350994110107
tensor(1.8273, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018635477870702744
loss_c:1.0334948301315308
tensor(1.4054, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02310088835656643
loss_c:1.0331610441207886
tensor(1.4218, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033075690269470215
loss_c:1.0081026554107666
tensor(1.4464, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04175299406051636
loss_c:0.8885077238082886
tensor(1.4186, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038229163736104965
loss_c:0.8784383535385132
tensor(1.4004, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03362942487001419
loss_c:0.8772735595703125
tensor(1.3827, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0346124991774559
loss_c:1.237725019454956
tensor(1.5674, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020037302747368813
loss_c:0.8905249834060669
tensor(1.3389, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06153595820069313
loss_c:1.2229396104812622
tensor(1.6599, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028512177988886833
loss_c:1.0263333320617676
tensor(1.4386, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018660331144928932
loss_c:0.9394461512565613
tensor(1.3585, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02052711509168148
loss_c:0.9277679324150085
tensor(1.3596, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021100735291838646
loss_c:0.8361268043518066
tensor(1.3157, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0685298964381218
loss_c:1.0056967735290527
tensor(1.5765, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03543112799525261
loss_c:0.907233715057373
tensor(1.4045, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0628628209233284
loss_c:0.9231892824172974
tensor(1.5140, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03932696580886841
loss_c:0.9183311462402344
tensor(1.4244, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03902364894747734
loss_c:0.9368988871574402
tensor(1.4325, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.057521138340234756
loss_c:0.9482404589653015
tensor(1.5063, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022156648337841034
loss_c:1.0965924263000488
tensor(1.4507, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04065548628568649
loss_c:0.8209444880485535
tensor(1.3801, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04064154624938965
loss_c:0.9239160418510437
tensor(1.4317, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03794870153069496
loss_c:1.0370644330978394
tensor(1.4788, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035976655781269073
loss_c:1.1028642654418945
tensor(1.5047, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01989421620965004
loss_c:0.9602832794189453
tensor(1.3742, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029658343642950058
loss_c:1.0325820446014404
tensor(1.4462, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025247331708669662
loss_c:1.1180161237716675
tensor(1.4732, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01963837817311287
loss_c:0.7726861834526062
tensor(1.2789, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04191062971949577
loss_c:0.9411713480949402
tensor(1.4448, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023892924189567566
loss_c:0.8197096586227417
tensor(1.3180, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02203887701034546
loss_c:0.9080218076705933
tensor(1.3558, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033119622617959976
loss_c:0.992283821105957
tensor(1.4386, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022753825411200523
loss_c:1.0108864307403564
tensor(1.4102, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030080897733569145
loss_c:0.902751624584198
tensor(1.3823, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11776141822338104
loss_c:1.2053508758544922
tensor(1.8544, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023237626999616623
loss_c:0.9708189368247986
tensor(1.3918, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04478876292705536
loss_c:0.8862099647521973
tensor(1.4273, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02252248488366604
loss_c:0.8194016814231873
tensor(1.3128, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02659205161035061
loss_c:1.108280897140503
tensor(1.4736, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022210804745554924
loss_c:0.8877048492431641
tensor(1.3462, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02486606501042843
loss_c:1.0295906066894531
tensor(1.4276, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025554409250617027
loss_c:0.9503563642501831
tensor(1.3900, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02152658998966217
loss_c:0.8318341970443726
tensor(1.3154, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08395779877901077
loss_c:0.99849534034729
tensor(1.6257, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014051404781639576
loss_c:0.8534278869628906
tensor(1.2993, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0353882759809494
loss_c:1.058440923690796
tensor(1.4803, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02746238186955452
loss_c:1.062842607498169
tensor(1.4539, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02232849970459938
loss_c:0.8715484142303467
tensor(1.3384, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04713571444153786
loss_c:1.0425310134887695
tensor(1.5147, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02303667739033699
loss_c:0.8947843313217163
tensor(1.3527, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024562425911426544
loss_c:0.9159897565841675
tensor(1.3690, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05345398187637329
loss_c:0.9161688089370728
tensor(1.4734, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022826192900538445
loss_c:1.0202375650405884
tensor(1.4156, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03182646632194519
loss_c:1.125157356262207
tensor(1.5014, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027434244751930237
loss_c:1.1124391555786133
tensor(1.4791, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028266754001379013
loss_c:0.9003270864486694
tensor(1.3744, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030158791691064835
loss_c:0.932989776134491
tensor(1.3978, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020092252641916275
loss_c:0.8377017974853516
tensor(1.3130, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01933564618229866
loss_c:0.9198607802391052
tensor(1.3519, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02590748853981495
loss_c:1.138930082321167
tensor(1.4870, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021972570568323135
loss_c:1.0241453647613525
tensor(1.4144, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041924379765987396
loss_c:1.0405690670013428
tensor(1.4951, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01822279952466488
loss_c:0.8348617553710938
tensor(1.3045, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019477132707834244
loss_c:0.9499587416648865
tensor(1.3674, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0384315624833107
loss_c:0.9379705190658569
tensor(1.4304, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02520083077251911
loss_c:0.9308375716209412
tensor(1.3785, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04347210377454758
loss_c:0.9739555716514587
tensor(1.4671, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018942397087812424
loss_c:0.7975756525993347
tensor(1.2878, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0204872265458107
loss_c:0.8120197057723999
tensor(1.3007, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04008952155709267
loss_c:0.8878321647644043
tensor(1.4110, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02953825704753399
loss_c:1.0904749631881714
tensor(1.4755, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01857154630124569
loss_c:0.978588342666626
tensor(1.3782, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038306668400764465
loss_c:1.1670053005218506
tensor(1.5467, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017810210585594177
loss_c:0.850428581237793
tensor(1.3100, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023778684437274933
loss_c:0.8495376110076904
tensor(1.3314, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02328706532716751
loss_c:1.2003401517868042
tensor(1.5084, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03744087368249893
loss_c:0.978625476360321
tensor(1.4477, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01713273860514164
loss_c:0.8253680467605591
tensor(1.2944, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03665509447455406
loss_c:1.0592563152313232
tensor(1.4859, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024020181968808174
loss_c:0.8958143591880798
tensor(1.3557, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020355533808469772
loss_c:0.8849451541900635
tensor(1.3365, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.056897155940532684
loss_c:0.94783616065979
tensor(1.5045, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023128122091293335
loss_c:1.0021989345550537
tensor(1.4065, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024349728599190712
loss_c:0.9995555281639099
tensor(1.4097, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027477089315652847
loss_c:0.976192831993103
tensor(1.4094, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03694375231862068
loss_c:1.1268329620361328
tensor(1.5217, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016476605087518692
loss_c:0.8981673121452332
tensor(1.3285, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02678152360022068
loss_c:1.0037274360656738
tensor(1.4208, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02194850891828537
loss_c:1.0820865631103516
tensor(1.4427, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033192239701747894
loss_c:0.9410640597343445
tensor(1.4129, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020145898684859276
loss_c:0.9035619497299194
tensor(1.3448, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08364219218492508
loss_c:1.0435903072357178
tensor(1.6548, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020641107112169266
loss_c:1.1037178039550781
tensor(1.4487, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016247455030679703
loss_c:0.9133312106132507
tensor(1.3351, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022491341456770897
loss_c:0.9167400598526001
tensor(1.3603, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02830241248011589
loss_c:1.0348700284957886
tensor(1.4423, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03452299162745476
loss_c:1.094305396080017
tensor(1.4960, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033108606934547424
loss_c:1.1172983646392822
tensor(1.5024, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03062395751476288
loss_c:1.0018508434295654
tensor(1.4342, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.15654079616069794
loss_c:1.2174252271652222
tensor(2.0185, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04522111639380455
loss_c:0.9598963260650635
tensor(1.4677, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036323804408311844
loss_c:0.9340950846672058
tensor(1.4211, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01844414509832859
loss_c:0.8035737872123718
tensor(1.2879, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019843237474560738
loss_c:0.9271149635314941
tensor(1.3561, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03152233362197876
loss_c:0.9706306457519531
tensor(1.4217, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04086722806096077
loss_c:0.8895052671432495
tensor(1.4152, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033930957317352295
loss_c:1.006177306175232
tensor(1.4487, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023677101358771324
loss_c:0.9824387431144714
tensor(1.3987, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01834205724298954
loss_c:0.8828197717666626
tensor(1.3284, device='cuda:0', grad_fn=<AddBackward0>)
total_train_loss:1.5935438871383667
loss_r:0.0297233909368515
loss_c:1.8869245052337646
loss_r:0.030492454767227173
loss_c:1.9070689678192139
loss_r:0.03636959567666054
loss_c:1.9423391819000244
loss_r:0.03194832429289818
loss_c:1.9724677801132202
loss_r:0.02472715824842453
loss_c:1.8261096477508545
loss_r:0.025864312425255775
loss_c:1.7009599208831787
loss_r:0.02818194217979908
loss_c:1.9905412197113037
loss_r:0.031379010528326035
loss_c:2.05043888092041
loss_r:0.032047245651483536
loss_c:2.1150009632110596
loss_r:0.030920974910259247
loss_c:2.1582770347595215
loss_r:0.02586294710636139
loss_c:1.9900836944580078
loss_r:0.027162879705429077
loss_c:1.8410062789916992
loss_r:0.024216467514634132
loss_c:1.7750911712646484
loss_r:0.021990204229950905
loss_c:1.7264741659164429
loss_r:0.022391121834516525
loss_c:1.6988162994384766
loss_r:0.025076013058423996
loss_c:1.7312498092651367
loss_r:0.022348273545503616
loss_c:1.7541792392730713
loss_r:0.025387361645698547
loss_c:1.7434260845184326
loss_r:0.02456175535917282
loss_c:1.6893947124481201
loss_r:0.02117646113038063
loss_c:1.6213558912277222
loss_r:0.023683514446020126
loss_c:1.6877778768539429
loss_r:0.02605452947318554
loss_c:1.777536392211914
loss_r:0.02365320920944214
loss_c:1.7221873998641968
loss_r:0.025324782356619835
loss_c:1.662627935409546
loss_r:0.025979258120059967
loss_c:1.6918365955352783
loss_r:0.02213776484131813
loss_c:1.656996488571167
loss_r:0.025120403617620468
loss_c:1.7211790084838867
loss_r:0.026493405923247337
loss_c:1.7726867198944092
loss_r:0.024890348315238953
loss_c:1.7922686338424683
loss_r:0.025054357945919037
loss_c:1.7134332656860352
loss_r:0.027026144787669182
loss_c:1.77396559715271
loss_r:0.020688524469733238
loss_c:1.596278190612793
loss_r:0.02438574656844139
loss_c:1.7585620880126953
loss_r:0.026155073195695877
loss_c:1.8133853673934937
loss_r:0.022387217730283737
loss_c:1.7622148990631104
loss_r:0.023360008373856544
loss_c:1.6220827102661133
loss_r:0.027408543974161148
loss_c:1.76252019405365
loss_r:0.021952372044324875
loss_c:1.728874921798706
loss_r:0.024496622383594513
loss_c:1.7755095958709717
loss_r:0.024737916886806488
loss_c:1.7343261241912842
loss_r:0.023709705099463463
loss_c:1.7849972248077393
loss_r:0.023928793147206306
loss_c:1.716449499130249
loss_r:0.0235611405223608
loss_c:1.758592963218689
loss_r:0.02065858617424965
loss_c:1.7524217367172241
loss_r:0.02283964492380619
loss_c:1.7435519695281982
loss_r:0.022658251225948334
loss_c:1.7327003479003906
loss_r:0.022197015583515167
loss_c:1.7552835941314697
loss_r:0.02254866436123848
loss_c:1.7652795314788818
loss_r:0.02196977473795414
loss_c:1.7315425872802734
loss_r:0.021012114360928535
loss_c:1.814197301864624
loss_r:0.02359590493142605
loss_c:1.9247281551361084
loss_r:0.02298135682940483
loss_c:1.8369054794311523
loss_r:0.0220799520611763
loss_c:1.8165096044540405
loss_r:0.021624593064188957
loss_c:1.707060694694519
loss_r:0.021481163799762726
loss_c:1.7655434608459473
loss_r:0.02286524698138237
loss_c:1.9687284231185913
loss_r:0.022997422143816948
loss_c:1.9504289627075195
loss_r:0.021998200565576553
loss_c:1.8215669393539429
loss_r:0.020720189437270164
loss_c:1.8039649724960327
loss_r:0.021936578676104546
loss_c:1.6896189451217651
loss_r:0.02294921875
loss_c:1.7575448751449585
loss_r:0.02198208123445511
loss_c:1.933103322982788
loss_r:0.022926269099116325
loss_c:1.7293939590454102
loss_r:0.02144841104745865
loss_c:1.6629197597503662
loss_r:0.021695980802178383
loss_c:1.6890342235565186
loss_r:0.022121697664260864
loss_c:1.5891237258911133
loss_r:0.026407791301608086
loss_c:1.7130941152572632
loss_r:0.023429056629538536
loss_c:1.7699604034423828
loss_r:0.02480371668934822
loss_c:1.7506103515625
loss_r:0.02517964132130146
loss_c:1.744280219078064
loss_r:0.024314306676387787
loss_c:1.7115869522094727
loss_r:0.02298288233578205
loss_c:1.5350384712219238
loss_r:0.024132518097758293
loss_c:1.6724618673324585
loss_r:0.023427022621035576
loss_c:1.8199748992919922
loss_r:0.025172820314764977
loss_c:1.843385100364685
loss_r:0.023891160264611244
loss_c:1.7453635931015015
loss_r:0.024822410196065903
loss_c:1.741859793663025
loss_r:0.023918651044368744
loss_c:1.6035326719284058
loss_r:0.02372954599559307
loss_c:1.6964550018310547
loss_r:0.02516873925924301
loss_c:1.853624701499939
loss_r:0.02677418477833271
loss_c:1.9044126272201538
loss_r:0.023799996823072433
loss_c:1.7305902242660522
loss_r:0.023508474230766296
loss_c:1.710693597793579
loss_r:0.023836201056838036
loss_c:1.604357123374939
loss_r:0.025367187336087227
loss_c:1.7210400104522705
loss_r:0.024609318003058434
loss_c:1.8105672597885132
loss_r:0.024425944313406944
loss_c:1.8300905227661133
loss_r:0.0239043440669775
loss_c:1.8400657176971436
loss_r:0.02608598954975605
loss_c:1.840632438659668
loss_r:0.024076098576188087
loss_c:1.5916922092437744
loss_r:0.023935839533805847
loss_c:1.6407893896102905
loss_r:0.024637727066874504
loss_c:1.7992595434188843
loss_r:0.024707818403840065
loss_c:1.7819349765777588
loss_r:0.023247426375746727
loss_c:1.7412561178207397
loss_r:0.024332620203495026
loss_c:1.7819032669067383
loss_r:0.023945337161421776
loss_c:1.5722732543945312
loss_r:0.02545992098748684
loss_c:1.7032684087753296
loss_r:0.026276716962456703
loss_c:1.8434580564498901
loss_r:0.025944631546735764
loss_c:1.8020174503326416
loss_r:0.023375660181045532
loss_c:1.7224881649017334
loss_r:0.027789462357759476
loss_c:1.8695214986801147
loss_r:0.02348492294549942
loss_c:1.5421333312988281
loss_r:0.024462785571813583
loss_c:1.5755714178085327
loss_r:0.025412749499082565
loss_c:1.7513163089752197
loss_r:0.02626526542007923
loss_c:1.7799532413482666
loss_r:0.023237621411681175
loss_c:1.6961345672607422
loss_r:0.025842204689979553
loss_c:1.774531364440918
loss_r:0.02395489253103733
loss_c:1.5184354782104492
loss_r:0.02656683884561062
loss_c:1.6151058673858643
loss_r:0.028260966762900352
loss_c:1.814345121383667
loss_r:0.024755675345659256
loss_c:1.679807186126709
loss_r:0.022724835202097893
loss_c:1.6196473836898804
loss_r:0.0282294824719429
loss_c:1.763343334197998
loss_r:0.025870591402053833
loss_c:1.564428687095642
loss_r:0.02566307969391346
loss_c:1.5654704570770264
loss_r:0.026889337226748466
loss_c:1.7151782512664795
loss_r:0.02446105144917965
loss_c:1.628204584121704
loss_r:0.022435354068875313
loss_c:1.6131219863891602
loss_r:0.030165405943989754
loss_c:1.8512372970581055
loss_r:0.024858590215444565
loss_c:1.4950273036956787
loss_r:0.02957630157470703
loss_c:1.6292893886566162
loss_r:0.02743382379412651
loss_c:1.7466304302215576
loss_r:0.027722863480448723
loss_c:1.8567895889282227
loss_r:0.02417410910129547
loss_c:1.652706503868103
loss_r:0.02877001464366913
loss_c:1.8348174095153809
loss_r:0.02603788487613201
loss_c:1.5429103374481201
loss_r:0.028637347742915154
loss_c:1.6079251766204834
loss_r:0.028498759493231773
loss_c:1.6550410985946655
loss_r:0.02720710076391697
loss_c:1.7898082733154297
loss_r:0.022178877145051956
loss_c:1.6333335638046265
loss_r:0.03034089133143425
loss_c:1.9066613912582397
loss_r:0.0226025078445673
loss_c:1.463343620300293
loss_r:0.028433699160814285
loss_c:1.5674118995666504
loss_r:0.027307074517011642
loss_c:1.5980641841888428
loss_r:0.02528378739953041
loss_c:1.6950373649597168
loss_r:0.02255142107605934
loss_c:1.5852432250976562
loss_r:0.03009035997092724
loss_c:1.8823754787445068
loss_r:0.02421029657125473
loss_c:1.5241286754608154
loss_r:0.02992859296500683
loss_c:1.6162503957748413
loss_r:0.0277047548443079
loss_c:1.6315927505493164
loss_r:0.027206750586628914
loss_c:1.7491763830184937
loss_r:0.024714434519410133
loss_c:1.6629260778427124
loss_r:0.035030242055654526
loss_c:1.9631452560424805
loss_r:0.02652042731642723
loss_c:1.569327712059021
loss_r:0.03266959264874458
loss_c:1.6601512432098389
loss_r:0.03126019984483719
loss_c:1.6746327877044678
loss_r:0.027655497193336487
loss_c:1.7387914657592773
loss_r:0.02490655519068241
loss_c:1.6370139122009277
loss_r:0.03096723183989525
loss_c:1.8503239154815674
loss_r:0.02505689114332199
loss_c:1.5372788906097412
loss_r:0.03363833576440811
loss_c:1.6868226528167725
loss_r:0.030756816267967224
loss_c:1.6846680641174316
loss_r:0.028256097808480263
loss_c:1.7758811712265015
loss_r:0.02461950294673443
loss_c:1.7128980159759521
loss_r:0.03417794033885002
loss_c:1.9878082275390625
loss_r:0.026170996949076653
loss_c:1.628082275390625
loss_r:0.03457183390855789
loss_c:1.7954744100570679
loss_r:0.033977292478084564
loss_c:1.7707476615905762
loss_r:0.03119170106947422
loss_c:1.800142526626587
loss_r:0.026802413165569305
loss_c:1.7206523418426514
loss_r:0.03407224640250206
loss_c:1.9371641874313354
loss_r:0.028762174770236015
loss_c:1.7027963399887085
loss_r:0.035735707730054855
loss_c:1.7492330074310303
loss_r:0.033669330179691315
loss_c:1.7509726285934448
loss_r:0.03434617072343826
loss_c:2.0132927894592285
loss_r:0.027907172217965126
loss_c:1.7746829986572266
loss_r:0.033436477184295654
loss_c:1.9214829206466675
loss_r:0.028128396719694138
loss_c:1.6816257238388062
loss_r:0.031738098710775375
loss_c:1.7285916805267334
loss_r:0.03122580796480179
loss_c:1.6627000570297241
loss_r:0.032441359013319016
loss_c:1.8727210760116577
loss_r:0.027340907603502274
loss_c:1.7667068243026733
loss_r:0.03647929057478905
loss_c:1.987939715385437
loss_r:0.02522462047636509
loss_c:1.605910301208496
loss_r:0.03167101740837097
loss_c:1.7039573192596436
loss_r:0.031085539609193802
loss_c:1.6562480926513672
loss_r:0.03350630775094032
loss_c:1.8906962871551514
loss_r:0.024863559752702713
loss_c:1.6909186840057373
loss_r:0.03238086774945259
loss_c:1.8947210311889648
loss_r:0.02731298841536045
loss_c:1.6448920965194702
loss_r:0.03117063082754612
loss_c:1.692993402481079
loss_r:0.02801155485212803
loss_c:1.587586760520935
loss_r:0.03256051614880562
loss_c:1.9155073165893555
loss_r:0.02630956843495369
loss_c:1.743224859237671
loss_r:0.034117478877305984
loss_c:1.9508130550384521
loss_r:0.026010289788246155
loss_c:1.5958508253097534
loss_r:0.026428038254380226
loss_c:1.6114776134490967
loss_r:0.028112731873989105
loss_c:1.5586955547332764
loss_r:0.03187057003378868
loss_c:1.9158920049667358
loss_r:0.025345459580421448
loss_c:1.7313101291656494
loss_r:0.03300825133919716
loss_c:1.9306843280792236
loss_r:0.02744794264435768
loss_c:1.6253598928451538
loss_r:0.027680769562721252
loss_c:1.634366750717163
loss_r:0.0266217440366745
loss_c:1.5442516803741455
loss_r:0.032304175198078156
loss_c:1.950437307357788
loss_r:0.024994077160954475
loss_c:1.7272710800170898
loss_r:0.0343896709382534
loss_c:1.9730643033981323
loss_r:0.02676556259393692
loss_c:1.6174190044403076
loss_r:0.025481734424829483
loss_c:1.617326259613037
loss_r:0.027954386547207832
loss_c:1.5812759399414062
loss_r:0.030561119318008423
loss_c:1.8476070165634155
loss_r:0.026668144389986992
loss_c:1.7489774227142334
loss_r:0.03459564596414566
loss_c:1.983910322189331
loss_r:0.02843470126390457
loss_c:1.6461814641952515
loss_r:0.030304258689284325
loss_c:1.6755144596099854
loss_r:0.02954084239900112
loss_c:1.557326316833496
loss_r:0.03534913435578346
loss_c:1.9435489177703857
loss_r:0.026413511484861374
loss_c:1.7212920188903809
loss_r:0.035644978284835815
loss_c:1.9304819107055664
loss_r:0.029256301000714302
loss_c:1.6088957786560059
loss_r:0.028345774859189987
loss_c:1.6080818176269531
loss_r:0.031446609646081924
loss_c:1.6349353790283203
loss_r:0.03263057768344879
loss_c:1.8068914413452148
loss_r:0.02515198476612568
loss_c:1.7446508407592773
loss_r:0.03247418254613876
loss_c:1.9406354427337646
loss_r:0.02522134967148304
loss_c:1.5792920589447021
loss_r:0.02657558210194111
loss_c:1.6714844703674316
loss_r:0.026836879551410675
loss_c:1.603371024131775
loss_r:0.03355911001563072
loss_c:1.884016513824463
loss_r:0.022981369867920876
loss_c:1.6602996587753296
loss_r:0.030385581776499748
loss_c:1.8835890293121338
loss_r:0.02803766168653965
loss_c:1.6613845825195312
loss_r:0.02964089810848236
loss_c:1.9204623699188232
loss_r:0.03079908713698387
loss_c:1.8456252813339233
loss_r:0.030693138018250465
loss_c:1.92825448513031
loss_r:0.024437200278043747
loss_c:1.807115912437439
loss_r:0.03102046623826027
loss_c:1.9538476467132568
loss_r:0.026975203305482864
loss_c:1.654892921447754
loss_r:0.0278703011572361
loss_c:1.796939730644226
loss_r:0.02785528264939785
loss_c:1.7279536724090576
loss_r:0.029928063973784447
loss_c:1.8420703411102295
loss_r:0.023921852931380272
loss_c:1.7676982879638672
loss_r:0.029667606577277184
loss_c:1.9141736030578613
loss_r:0.0265517458319664
loss_c:1.672959327697754
loss_r:0.028968453407287598
loss_c:1.8072688579559326
loss_r:0.027385549619793892
loss_c:1.6792106628417969
loss_r:0.029626261442899704
loss_c:1.8470590114593506
loss_r:0.024557316675782204
loss_c:1.8112542629241943
loss_r:0.0315735787153244
loss_c:1.9780243635177612
loss_r:0.027199363335967064
loss_c:1.6701624393463135
loss_r:0.030446857213974
loss_c:1.9019031524658203
loss_r:0.028682559728622437
loss_c:1.7101936340332031
loss_r:0.02997204288840294
loss_c:1.8269680738449097
loss_r:0.024731924757361412
loss_c:1.77731454372406
loss_r:0.03180481120944023
loss_c:1.9601428508758545
loss_r:0.026612209156155586
loss_c:1.6583999395370483
loss_r:0.03204435855150223
loss_c:1.8516130447387695
loss_r:0.0287166740745306
loss_c:1.6883270740509033
loss_r:0.030481474474072456
loss_c:1.8097989559173584
loss_r:0.024152686819434166
loss_c:1.7517517805099487
loss_r:0.033364929258823395
loss_c:1.9254359006881714
loss_r:0.026918776333332062
loss_c:1.5814013481140137
loss_r:0.03357375040650368
loss_c:1.908381462097168
loss_r:0.03080892190337181
loss_c:1.702035903930664
loss_r:0.028290901333093643
loss_c:1.6631584167480469
loss_r:0.025308845564723015
loss_c:1.786995768547058
loss_r:0.034929994493722916
loss_c:1.9401330947875977
loss_r:0.026957450434565544
loss_c:1.5612996816635132
loss_r:0.03436286747455597
loss_c:1.7907823324203491
loss_r:0.030865143984556198
loss_c:1.6602495908737183
loss_r:0.027511781081557274
loss_c:1.6788702011108398
loss_r:0.02621619775891304
loss_c:1.777836561203003
loss_r:0.03457923233509064
loss_c:2.023549795150757
loss_r:0.025602318346500397
loss_c:1.5352122783660889
loss_r:0.033251482993364334
loss_c:1.7850303649902344
loss_r:0.030670782551169395
loss_c:1.6630524396896362
loss_r:0.03119237720966339
loss_c:1.7439851760864258
loss_r:0.025826744735240936
loss_c:1.6703076362609863
loss_r:0.02993890456855297
loss_c:1.73781418800354
loss_r:0.02600771375000477
loss_c:1.5241093635559082
loss_r:0.035057101398706436
loss_c:1.822908878326416
loss_r:0.029727984219789505
loss_c:1.7789644002914429
loss_r:0.02874704636633396
loss_c:1.769894003868103
loss_r:0.025411024689674377
loss_c:1.7114644050598145
loss_r:0.03309512510895729
loss_c:1.8326568603515625
loss_r:0.02662401646375656
loss_c:1.4954818487167358
loss_r:0.036148905754089355
loss_c:1.8164104223251343
loss_r:0.03122568316757679
loss_c:1.7661031484603882
loss_r:0.029156677424907684
loss_c:1.8027286529541016
loss_r:0.025890376418828964
loss_c:1.6949892044067383
loss_r:0.033007025718688965
loss_c:1.8355598449707031
loss_r:0.026847491040825844
loss_c:1.4996702671051025
loss_r:0.03656686469912529
loss_c:1.781604528427124
loss_r:0.03058609366416931
loss_c:1.7477238178253174
loss_r:0.029928168281912804
loss_c:1.734644889831543
loss_r:0.024693844839930534
loss_c:1.6583337783813477
loss_r:0.0310865119099617
loss_c:1.8611929416656494
loss_r:0.025838525965809822
loss_c:1.4884589910507202
loss_r:0.03304372727870941
loss_c:1.7714332342147827
loss_r:0.02742668054997921
loss_c:1.663969874382019
loss_r:0.026330169290304184
loss_c:1.6928393840789795
loss_r:0.024977974593639374
loss_c:1.6997740268707275
loss_r:0.028653228655457497
loss_c:1.8258332014083862
loss_r:0.02836453728377819
loss_c:1.7167142629623413
loss_r:0.03197083622217178
loss_c:1.8888306617736816
loss_r:0.0315120629966259
loss_c:1.8174880743026733
loss_r:0.03326648846268654
loss_c:1.8636120557785034
loss_r:0.0285528264939785
loss_c:1.804420828819275
loss_r:0.03147181123495102
loss_c:1.8478988409042358
loss_r:0.03169587627053261
loss_c:1.6487722396850586
loss_r:0.03447578102350235
loss_c:1.8623607158660889
loss_r:0.03622552007436752
loss_c:1.772743582725525
loss_r:0.0346815399825573
loss_c:1.8506059646606445
loss_r:0.029135463759303093
loss_c:1.7486248016357422
loss_r:0.030375752598047256
loss_c:1.733778715133667
loss_r:0.03041676990687847
loss_c:1.5870730876922607
loss_r:0.032481685280799866
loss_c:1.7878220081329346
loss_r:0.03432139754295349
loss_c:1.7076613903045654
loss_r:0.03564133122563362
loss_c:1.8131959438323975
loss_r:0.0263686366379261
loss_c:1.6864045858383179
loss_r:0.030552953481674194
loss_c:1.8054752349853516
loss_r:0.031159494072198868
loss_c:1.6399900913238525
loss_r:0.03323798254132271
loss_c:1.7793892621994019
loss_r:0.03282734751701355
loss_c:1.7219537496566772
loss_r:0.0341520830988884
loss_c:1.825251817703247
loss_r:0.02749186009168625
loss_c:1.790093183517456
loss_r:0.029170237481594086
loss_c:1.780573844909668
loss_r:0.032429955899715424
loss_c:1.6345436573028564
loss_r:0.033215053379535675
loss_c:1.7953765392303467
loss_r:0.030698969960212708
loss_c:1.6933019161224365
loss_r:0.03144444525241852
loss_c:1.8066614866256714
loss_r:0.026112280786037445
loss_c:1.7541173696517944
loss_r:0.0306687094271183
loss_c:1.8568881750106812
loss_r:0.028563251718878746
loss_c:1.6298696994781494
loss_r:0.03260686248540878
loss_c:1.8056974411010742
loss_r:0.034030284732580185
loss_c:1.7612314224243164
loss_r:0.032257333397865295
loss_c:1.8837742805480957
loss_r:0.024538278579711914
loss_c:1.677206039428711
loss_r:0.02752736024558544
loss_c:1.703539252281189
loss_r:0.026440612971782684
loss_c:1.5236356258392334
loss_r:0.030234096571803093
loss_c:1.7739436626434326
loss_r:0.033615387976169586
loss_c:1.818130373954773
loss_r:0.03205881267786026
loss_c:1.838733434677124
loss_r:0.028313282877206802
loss_c:1.846632957458496
loss_r:0.030843202024698257
loss_c:1.943084478378296
loss_r:0.028149811550974846
loss_c:1.7331727743148804
loss_r:0.031102851033210754
loss_c:1.8312530517578125
loss_r:0.031217554584145546
loss_c:1.8591588735580444
loss_r:0.032386504113674164
loss_c:1.9506739377975464
loss_r:0.028654033318161964
loss_c:1.8341277837753296
loss_r:0.02734755165874958
loss_c:1.9696545600891113
loss_r:0.02754891850054264
loss_c:1.8199477195739746
loss_r:0.030613457784056664
loss_c:1.8712562322616577
loss_r:0.0293258223682642
loss_c:1.896327018737793
loss_r:0.027914270758628845
loss_c:1.922101378440857
loss_r:0.026186078786849976
loss_c:1.894148588180542
loss_r:0.026764031499624252
loss_c:1.9613679647445679
loss_r:0.02736750617623329
loss_c:1.8176487684249878
loss_r:0.029007187113165855
loss_c:1.9211066961288452
loss_r:0.032692693173885345
loss_c:2.0661470890045166
loss_r:0.03449012711644173
loss_c:2.1232857704162598
loss_r:0.028902757912874222
loss_c:1.9792201519012451
loss_r:0.026608848944306374
loss_c:1.9554494619369507
loss_r:0.02551419660449028
loss_c:1.8180831670761108
loss_r:0.026932550594210625
loss_c:1.855049967765808
loss_r:0.03220159932971001
loss_c:1.948993444442749
loss_r:0.029741475358605385
loss_c:2.051539421081543
loss_r:0.0287120770663023
loss_c:1.9964148998260498
loss_r:0.028964892029762268
loss_c:2.1019437313079834
loss_r:0.02547120675444603
loss_c:1.7916042804718018
loss_r:0.028396904468536377
loss_c:1.867967963218689
loss_r:0.030011843889951706
loss_c:1.9089555740356445
loss_r:0.035839080810546875
loss_c:2.097734212875366
loss_r:0.025164950639009476
loss_c:1.9182310104370117
loss_r:0.028166044503450394
loss_c:2.019804000854492
loss_r:0.025852883234620094
loss_c:1.8916904926300049
loss_r:0.02737191505730152
loss_c:1.9481805562973022
loss_r:0.02828078716993332
loss_c:1.9360625743865967
loss_r:0.0273529551923275
loss_c:2.043987989425659
loss_r:0.027053920552134514
loss_c:2.048964023590088
loss_r:0.027378560975193977
loss_c:2.042691707611084
loss_r:0.02314835973083973
loss_c:1.7784662246704102
loss_r:0.024947457015514374
loss_c:1.8487403392791748
loss_r:0.026002416387200356
loss_c:1.9110187292099
loss_r:0.02663252130150795
loss_c:2.0442214012145996
loss_r:0.0218773502856493
loss_c:1.8206310272216797
loss_r:0.02364002913236618
loss_c:1.8944363594055176
loss_r:0.024552209302783012
loss_c:1.808142900466919
loss_r:0.023768479004502296
loss_c:1.8593190908432007
loss_r:0.025019623339176178
loss_c:1.8919410705566406
loss_r:0.02448369562625885
loss_c:1.9914114475250244
loss_r:0.022146299481391907
loss_c:1.899475336074829
loss_r:0.026082897558808327
loss_c:2.1028237342834473
loss_r:0.023066321387887
loss_c:1.861473560333252
loss_r:0.023263730108737946
loss_c:1.8739166259765625
loss_r:0.02567414566874504
loss_c:1.997990369796753
loss_r:0.02522849291563034
loss_c:2.0758626461029053
loss_r:0.02141641266644001
loss_c:1.889872431755066
loss_r:0.02659657411277294
loss_c:2.065268039703369
loss_r:0.022252429276704788
loss_c:1.7797932624816895
loss_r:0.024908093735575676
loss_c:1.8768991231918335
loss_r:0.02628057822585106
loss_c:1.9267511367797852
loss_r:0.026904581114649773
loss_c:1.9969086647033691
loss_r:0.02304631844162941
loss_c:1.8370941877365112
loss_r:0.026514649391174316
loss_c:1.9777015447616577
loss_r:0.024684129282832146
loss_c:1.7844743728637695
loss_r:0.02648569643497467
loss_c:1.8011674880981445
loss_r:0.027720268815755844
loss_c:1.962960958480835
loss_r:0.026849744841456413
loss_c:2.010753870010376
loss_r:0.02145693637430668
loss_c:1.7537429332733154
loss_r:0.025904782116413116
loss_c:1.9796079397201538
loss_r:0.022739049047231674
loss_c:1.8048415184020996
loss_r:0.023474086076021194
loss_c:1.844408392906189
loss_r:0.02515258453786373
loss_c:2.0288846492767334
loss_r:0.023827502503991127
loss_c:1.982560157775879
loss_r:0.02207852713763714
loss_c:1.9506566524505615
loss_r:0.026268575340509415
loss_c:2.1226139068603516
loss_r:0.023223640397191048
loss_c:1.9749854803085327
loss_r:0.02664874494075775
loss_c:2.087334394454956
loss_r:0.024735618382692337
loss_c:2.0937411785125732
loss_r:0.023741377517580986
loss_c:2.0322060585021973
loss_r:0.021156232804059982
loss_c:1.8805993795394897
loss_r:0.024320099502801895
loss_c:2.011843204498291
loss_r:0.02227102592587471
loss_c:1.8545079231262207
loss_r:0.025260794907808304
loss_c:2.013645648956299
loss_r:0.024503547698259354
loss_c:2.0713376998901367
loss_r:0.0230463445186615
loss_c:2.00689697265625
loss_r:0.02146236225962639
loss_c:1.9132444858551025
loss_r:0.02321307174861431
loss_c:1.9276728630065918
loss_r:0.02180866152048111
loss_c:1.8106920719146729
loss_r:0.026663322001695633
loss_c:1.9882835149765015
loss_r:0.024274753406643867
loss_c:2.0270376205444336
loss_r:0.023164164274930954
loss_c:1.966308832168579
loss_r:0.0214547012001276
loss_c:1.9073998928070068
loss_r:0.024191852658987045
loss_c:2.0011720657348633
loss_r:0.022404786199331284
loss_c:1.7811912298202515
loss_r:0.026213262230157852
loss_c:1.936894178390503
loss_r:0.025096185505390167
loss_c:2.0616915225982666
loss_r:0.023372698575258255
loss_c:2.016956329345703
loss_r:0.02297339029610157
loss_c:1.9041473865509033
loss_r:0.024825170636177063
loss_c:1.9549720287322998
loss_r:0.02375630848109722
loss_c:1.8752292394638062
loss_r:0.02443493902683258
loss_c:1.8892724514007568
loss_r:0.02689768373966217
loss_c:2.1197543144226074
loss_r:0.02588510513305664
loss_c:2.008254051208496
loss_r:0.022330937907099724
loss_c:1.8800867795944214
loss_r:0.024672646075487137
loss_c:1.9959653615951538
loss_r:0.024952977895736694
loss_c:1.8886010646820068
loss_r:0.026566432788968086
loss_c:1.9702177047729492
loss_r:0.025650450959801674
loss_c:2.0791690349578857
loss_r:0.023986881598830223
loss_c:1.8859033584594727
loss_r:0.021968744695186615
loss_c:1.8716387748718262
loss_r:0.024956149980425835
loss_c:2.0113399028778076
loss_r:0.02240695059299469
loss_c:1.7670639753341675
loss_r:0.02289688028395176
loss_c:1.8632769584655762
loss_r:0.024652637541294098
loss_c:2.057220458984375
loss_r:0.022464614361524582
loss_c:1.9003562927246094
loss_r:0.022099507972598076
loss_c:1.7439378499984741
loss_r:0.02363491617143154
loss_c:1.9314731359481812
loss_r:0.02387462556362152
loss_c:1.7931069135665894
loss_r:0.023249736055731773
loss_c:1.8446805477142334
loss_r:0.023371824994683266
loss_c:1.9806032180786133
loss_r:0.02053859271109104
loss_c:1.7481565475463867
loss_r:0.023286214098334312
loss_c:1.7236323356628418
loss_r:0.022286290302872658
loss_c:1.8148319721221924
loss_r:0.02356484718620777
loss_c:1.724615454673767
loss_r:0.02349940314888954
loss_c:1.6775178909301758
loss_r:0.024957934394478798
loss_c:1.9025945663452148
loss_r:0.0258957389742136
loss_c:1.8242313861846924
loss_r:0.025039192289114
loss_c:1.7684659957885742
loss_r:0.024066651239991188
loss_c:1.875921607017517
loss_r:0.02324914187192917
loss_c:1.692344069480896
loss_r:0.023150283843278885
loss_c:1.6707029342651367
loss_r:0.027408774942159653
loss_c:1.9172691106796265
loss_r:0.026307830587029457
loss_c:1.7834358215332031
loss_r:0.024256417527794838
loss_c:1.732330560684204
loss_r:0.02366224303841591
loss_c:1.8023618459701538
loss_r:0.02347080409526825
loss_c:1.661041021347046
loss_r:0.022215984761714935
loss_c:1.5963144302368164
loss_r:0.02477450668811798
loss_c:1.7918051481246948
loss_r:0.021539868786931038
loss_c:1.6916422843933105
loss_r:0.025435078889131546
loss_c:1.673112392425537
loss_r:0.026474695652723312
loss_c:1.8443338871002197
loss_r:0.024368025362491608
loss_c:1.7269163131713867
loss_r:0.02433038502931595
loss_c:1.7010282278060913
loss_r:0.02310630865395069
loss_c:1.721258521080017
loss_r:0.022032273933291435
loss_c:1.7098573446273804
loss_r:0.02329111658036709
loss_c:1.6883500814437866
loss_r:0.023887692019343376
loss_c:1.7674064636230469
loss_r:0.024886228144168854
loss_c:1.7609070539474487
loss_r:0.02116464637219906
loss_c:1.5832669734954834
loss_r:0.02523503080010414
loss_c:1.9223999977111816
loss_r:0.024939926341176033
loss_c:1.8141807317733765
loss_r:0.02459855191409588
loss_c:1.611551284790039
loss_r:0.026809269562363625
loss_c:1.8221499919891357
loss_r:0.025053896009922028
loss_c:1.6363486051559448
loss_r:0.021228043362498283
loss_c:1.4604368209838867
loss_r:0.0239859651774168
loss_c:1.6942384243011475
loss_r:0.02569678984582424
loss_c:1.6851048469543457
loss_r:0.024893585592508316
loss_c:1.613909125328064
loss_r:0.02614618092775345
loss_c:1.7438106536865234
loss_r:0.024974267929792404
loss_c:1.6773154735565186
loss_r:0.024185622110962868
loss_c:1.5454022884368896
loss_r:0.02957843616604805
loss_c:1.813001036643982
loss_r:0.027727898210287094
loss_c:1.709716558456421
loss_r:0.02777186408638954
loss_c:1.6465739011764526
loss_r:0.02401614747941494
loss_c:1.69132399559021
loss_r:0.026908688247203827
loss_c:1.6032311916351318
loss_r:0.025700340047478676
loss_c:1.515613317489624
loss_r:0.025070270523428917
loss_c:1.6468791961669922
loss_r:0.025280654430389404
loss_c:1.5960592031478882
loss_r:0.026813745498657227
loss_c:1.5457842350006104
loss_r:0.02724410593509674
loss_c:1.7318110466003418
loss_r:0.02757604978978634
loss_c:1.6038144826889038
loss_r:0.0255555622279644
loss_c:1.5461993217468262
loss_r:0.029492702335119247
loss_c:1.8889894485473633
loss_r:0.026163477450609207
loss_c:1.6555837392807007
loss_r:0.030893314629793167
loss_c:1.6720727682113647
loss_r:0.028027700260281563
loss_c:1.7752140760421753
loss_r:0.030277743935585022
loss_c:1.6733834743499756
loss_r:0.024255799129605293
loss_c:1.4939130544662476
loss_r:0.02382368966937065
loss_c:1.6407192945480347
loss_r:0.026061328127980232
loss_c:1.6069368124008179
loss_r:0.02458031289279461
loss_c:1.6008460521697998
loss_r:0.020825067535042763
loss_c:1.562579870223999
loss_r:0.026117198169231415
loss_c:1.5698018074035645
loss_r:0.02347218245267868
loss_c:1.504927158355713
loss_r:0.0221419595181942
loss_c:1.6380329132080078
loss_r:0.025083791464567184
loss_c:1.5986480712890625
loss_r:0.026410602033138275
loss_c:1.5604636669158936
loss_r:0.025341175496578217
loss_c:1.6957221031188965
loss_r:0.030002934858202934
loss_c:1.7188256978988647
loss_r:0.026228349655866623
loss_c:1.5937678813934326
loss_r:0.0231187641620636
loss_c:1.6027624607086182
loss_r:0.02237173542380333
loss_c:1.5490200519561768
loss_r:0.028111334890127182
loss_c:1.6189954280853271
loss_r:0.02802225388586521
loss_c:1.6820614337921143
loss_r:0.028009504079818726
loss_c:1.584530234336853
loss_r:0.02451326698064804
loss_c:1.472089171409607
loss_r:0.021868783980607986
loss_c:1.6861820220947266
loss_r:0.024171819910407066
loss_c:1.6218876838684082
loss_r:0.026802444830536842
loss_c:1.650791883468628
loss_r:0.023261770606040955
loss_c:1.69028902053833
loss_r:0.028882967308163643
loss_c:1.7846884727478027
loss_r:0.023443249985575676
loss_c:1.6554405689239502
loss_r:0.022646339610219002
loss_c:1.682281255722046
loss_r:0.02782941609621048
loss_c:1.7058794498443604
loss_r:0.02591536194086075
loss_c:1.710850715637207
loss_r:0.02515735663473606
loss_c:1.6804769039154053
loss_r:0.026056867092847824
loss_c:1.572763204574585
loss_r:0.02372637763619423
loss_c:1.5264174938201904
loss_r:0.024067804217338562
loss_c:1.6780223846435547
loss_r:0.02701832540333271
loss_c:1.6553586721420288
loss_r:0.02454199641942978
loss_c:1.6746667623519897
loss_r:0.022690633311867714
loss_c:1.5593540668487549
loss_r:0.02354292944073677
loss_c:1.6224149465560913
loss_r:0.021793942898511887
loss_c:1.628218412399292
loss_r:0.0222594253718853
loss_c:1.7208685874938965
loss_r:0.021439243108034134
loss_c:1.6558336019515991
loss_r:0.02530454471707344
loss_c:1.690730094909668
loss_r:0.02139200083911419
loss_c:1.5444488525390625
loss_r:0.022223560139536858
loss_c:1.5836751461029053
loss_r:0.02005551941692829
loss_c:1.5899443626403809
loss_r:0.021332873031497
loss_c:1.7998756170272827
loss_r:0.020006712526082993
loss_c:1.657301425933838
loss_r:0.023657960817217827
loss_c:1.7172207832336426
loss_r:0.02171909064054489
loss_c:1.6865524053573608
loss_r:0.021654443815350533
loss_c:1.6512349843978882
loss_r:0.01770840771496296
loss_c:1.5260398387908936
loss_r:0.022265342995524406
loss_c:1.7534606456756592
loss_r:0.019172050058841705
loss_c:1.6434814929962158
loss_r:0.028748439624905586
loss_c:1.7082688808441162
loss_r:0.024022821336984634
loss_c:1.706717848777771
loss_r:0.023654531687498093
loss_c:1.643568992614746
loss_r:0.024953525513410568
loss_c:1.6330087184906006
loss_r:0.0311531201004982
loss_c:1.888777256011963
loss_r:0.023420102894306183
loss_c:1.732709288597107
loss_r:0.02771603874862194
loss_c:1.6451966762542725
loss_r:0.026575535535812378
loss_c:1.6479915380477905
loss_r:0.02300005406141281
loss_c:1.6156381368637085
loss_r:0.018970755860209465
loss_c:1.5356072187423706
loss_r:0.023484066128730774
loss_c:1.6756362915039062
loss_r:0.019285980612039566
loss_c:1.6138360500335693
loss_r:0.02248486876487732
loss_c:1.5721015930175781
loss_r:0.02090604230761528
loss_c:1.6201438903808594
loss_r:0.02153441496193409
loss_c:1.7476489543914795
loss_r:0.017923271283507347
loss_c:1.5358998775482178
loss_r:0.02030012756586075
loss_c:1.7707908153533936
loss_r:0.018341204151511192
loss_c:1.6888084411621094
loss_r:0.023625288158655167
loss_c:1.5748224258422852
loss_r:0.020906414836645126
loss_c:1.6753020286560059
loss_r:0.021748634055256844
loss_c:1.725243330001831
loss_r:0.016121182590723038
loss_c:1.4784387350082397
loss_r:0.019797490909695625
loss_c:1.7328097820281982
loss_r:0.015954652801156044
loss_c:1.584499716758728
loss_r:0.02017376571893692
loss_c:1.527785301208496
loss_r:0.0199609212577343
loss_c:1.6790794134140015
loss_r:0.018831176683306694
loss_c:1.687540054321289
loss_r:0.016355833038687706
loss_c:1.5099763870239258
loss_r:0.019589222967624664
loss_c:1.76227605342865
loss_r:0.016240445896983147
loss_c:1.6395835876464844
loss_r:0.019679909572005272
loss_c:1.4681743383407593
loss_r:0.019438913092017174
loss_c:1.644230842590332
loss_r:0.017865443602204323
loss_c:1.6006841659545898
loss_r:0.017262358218431473
loss_c:1.4956083297729492
loss_r:0.01961888186633587
loss_c:1.6571416854858398
loss_r:0.017555639147758484
loss_c:1.6769523620605469
loss_r:0.020582186058163643
loss_c:1.5743751525878906
loss_r:0.021103018894791603
loss_c:1.618746042251587
loss_r:0.021248020231723785
loss_c:1.7457454204559326
loss_r:0.016498617827892303
loss_c:1.443566083908081
loss_r:0.020477302372455597
loss_c:1.6733253002166748
loss_r:0.01708700694143772
loss_c:1.7314996719360352
loss_r:0.02185996249318123
loss_c:1.5653979778289795
loss_r:0.02028258517384529
loss_c:1.6374213695526123
loss_r:0.020593998953700066
loss_c:1.6626644134521484
loss_r:0.01687343791127205
loss_c:1.4961767196655273
loss_r:0.01965438947081566
loss_c:1.6664345264434814
loss_r:0.01918269693851471
loss_c:1.6900184154510498
loss_r:0.021075250580906868
loss_c:1.5671147108078003
loss_r:0.021502075716853142
loss_c:1.676243782043457
loss_r:0.021695252507925034
loss_c:1.6875938177108765
loss_r:0.01890978403389454
loss_c:1.4967992305755615
loss_r:0.02079414203763008
loss_c:1.729820966720581
loss_r:0.01942397654056549
loss_c:1.7599804401397705
loss_r:0.02177060768008232
loss_c:1.5462605953216553
loss_r:0.02150161936879158
loss_c:1.6950170993804932
loss_r:0.02066456899046898
loss_c:1.6651601791381836
loss_r:0.01949634961783886
loss_c:1.4836680889129639
loss_r:0.019819185137748718
loss_c:1.6492774486541748
loss_r:0.019095489755272865
loss_c:1.753829836845398
loss_r:0.022951167076826096
loss_c:1.565784215927124
loss_r:0.023539399728178978
loss_c:1.6975492238998413
loss_r:0.024057870730757713
loss_c:1.753082036972046
loss_r:0.02147611975669861
loss_c:1.4876558780670166
loss_r:0.022795449942350388
loss_c:1.675114631652832
loss_r:0.021219300106167793
loss_c:1.7703980207443237
loss_r:0.02507222630083561
loss_c:1.563772201538086
loss_r:0.025843704119324684
loss_c:1.684563159942627
loss_r:0.026035454124212265
loss_c:1.6814517974853516
loss_r:0.02371346578001976
loss_c:1.4940414428710938
loss_r:0.02640436962246895
loss_c:1.7602304220199585
loss_r:0.02372088097035885
loss_c:1.820591926574707
loss_r:0.02548755519092083
loss_c:1.5211786031723022
loss_r:0.026442991569638252
loss_c:1.6841572523117065
loss_r:0.027423245832324028
loss_c:1.7078760862350464
loss_r:0.02449307218194008
loss_c:1.4365475177764893
loss_r:0.023447133600711823
loss_c:1.7072536945343018
loss_r:0.02475103922188282
loss_c:1.7978832721710205
loss_r:0.026530319824814796
loss_c:1.529181718826294
loss_r:0.02555735595524311
loss_c:1.6498775482177734
loss_r:0.024879377335309982
loss_c:1.6380863189697266
loss_r:0.024455320090055466
loss_c:1.5115554332733154
loss_r:0.023534853011369705
loss_c:1.6597594022750854
loss_r:0.023951716721057892
loss_c:1.6706290245056152
loss_r:0.026932043954730034
loss_c:1.5947883129119873
loss_r:0.02595626935362816
loss_c:1.6503510475158691
loss_r:0.026318995282053947
loss_c:1.67205810546875
loss_r:0.025545362383127213
loss_c:1.5184478759765625
loss_r:0.025792302563786507
loss_c:1.7128801345825195
loss_r:0.024705594405531883
loss_c:1.6966197490692139
loss_r:0.026257602497935295
loss_c:1.5860331058502197
loss_r:0.026343269273638725
loss_c:1.6094732284545898
loss_r:0.02436785027384758
loss_c:1.6765726804733276
loss_r:0.023369289934635162
loss_c:1.5150353908538818
loss_r:0.02765081077814102
loss_c:1.7581981420516968
loss_r:0.023271070793271065
loss_c:1.742950201034546
loss_r:0.027801213786005974
loss_c:1.5973546504974365
loss_r:0.02973656728863716
loss_c:1.6339302062988281
loss_r:0.025709118694067
loss_c:1.624690294265747
loss_r:0.026731355115771294
loss_c:1.540564775466919
loss_r:0.028040681034326553
loss_c:1.7266809940338135
loss_r:0.024183597415685654
loss_c:1.689591884613037
loss_r:0.028214748948812485
loss_c:1.5983604192733765
loss_r:0.02903752774000168
loss_c:1.626474380493164
loss_r:0.026420025154948235
loss_c:1.6213533878326416
loss_r:0.025559471920132637
loss_c:1.5851528644561768
loss_r:0.029150936752557755
loss_c:1.7512166500091553
loss_r:0.02417839504778385
loss_c:1.63802170753479
loss_r:0.026381811127066612
loss_c:1.600459337234497
loss_r:0.028299152851104736
loss_c:1.6349568367004395
loss_r:0.025824692100286484
loss_c:1.661062240600586
loss_r:0.025438997894525528
loss_c:1.5213792324066162
loss_r:0.029564253985881805
loss_c:1.7782914638519287
loss_r:0.02243683487176895
loss_c:1.6367582082748413
loss_r:0.025911835953593254
loss_c:1.7049974203109741
loss_r:0.03043169155716896
loss_c:1.8070653676986694
loss_r:0.02970299683511257
loss_c:1.7553205490112305
loss_r:0.02916884608566761
loss_c:1.8098338842391968
loss_r:0.030177216976881027
loss_c:1.7861080169677734
loss_r:0.0283824373036623
loss_c:1.805688738822937
loss_r:0.02869708463549614
loss_c:1.7284486293792725
loss_r:0.029122857376933098
loss_c:1.7730839252471924
loss_r:0.02885410375893116
loss_c:1.7300734519958496
loss_r:0.028984224423766136
loss_c:1.7374119758605957
loss_r:0.028646981343626976
loss_c:1.8175036907196045
loss_r:0.02635764703154564
loss_c:1.806006669998169
loss_r:0.02863110974431038
loss_c:1.7981008291244507
loss_r:0.02828620746731758
loss_c:1.8761848211288452
loss_r:0.027905801311135292
loss_c:1.7817208766937256
loss_r:0.027515897527337074
loss_c:1.76463782787323
loss_r:0.029073992744088173
loss_c:1.8415515422821045
loss_r:0.026431115344166756
loss_c:1.795153021812439
loss_r:0.027265872806310654
loss_c:1.7935340404510498
loss_r:0.03047483041882515
loss_c:1.9430913925170898
loss_r:0.031661488115787506
loss_c:1.8854150772094727
loss_r:0.030124131590127945
loss_c:1.8432929515838623
loss_r:0.034392379224300385
loss_c:1.9885363578796387
loss_r:0.027510493993759155
loss_c:1.8385642766952515
loss_r:0.02964332140982151
loss_c:1.8290876150131226
loss_r:0.030427828431129456
loss_c:1.85595703125
loss_r:0.032903023064136505
loss_c:1.805149793624878
loss_r:0.029845964163541794
loss_c:1.8079314231872559
loss_r:0.03162786364555359
loss_c:1.8451087474822998
loss_r:0.02891557291150093
loss_c:1.7912306785583496
loss_r:0.02927067130804062
loss_c:1.761210322380066
loss_r:0.02708272822201252
loss_c:1.839634656906128
loss_r:0.0290813185274601
loss_c:1.8198764324188232
loss_r:0.027361895889043808
loss_c:1.8804210424423218
loss_r:0.02730417810380459
loss_c:1.9055047035217285
loss_r:0.028398266062140465
loss_c:1.8794021606445312
loss_r:0.028973644599318504
loss_c:1.8731122016906738
loss_r:0.02714342623949051
loss_c:1.8727989196777344
loss_r:0.027214478701353073
loss_c:1.8154700994491577
loss_r:0.026992911472916603
loss_c:1.8135581016540527
loss_r:0.02776055783033371
loss_c:1.8396148681640625
loss_r:0.026428747922182083
loss_c:1.7885463237762451
loss_r:0.026493502780795097
loss_c:1.8317337036132812
loss_r:0.028933722525835037
loss_c:1.9356238842010498
loss_r:0.03151579946279526
loss_c:1.8666247129440308
total_val_loss:1.8008755445480347
Validation loss decreased (inf --> 1.800876).  Saving model ...
epoch: 2/20
loss_r:0.025420956313610077
loss_c:1.1633164882659912
tensor(1.4970, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03056412562727928
loss_c:0.8741123676300049
tensor(1.3692, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06500792503356934
loss_c:1.1035678386688232
tensor(1.6128, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020543592050671577
loss_c:0.9224240183830261
tensor(1.3568, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025704985484480858
loss_c:0.8603057265281677
tensor(1.3443, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023146960884332657
loss_c:0.9416024088859558
tensor(1.3761, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02756231278181076
loss_c:0.8965750932693481
tensor(1.3695, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04232705384492874
loss_c:0.9422577619552612
tensor(1.4471, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041684817522764206
loss_c:0.8556227087974548
tensor(1.4007, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029899297282099724
loss_c:1.099714994430542
tensor(1.4814, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029133347794413567
loss_c:1.1333588361740112
tensor(1.4956, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04435384273529053
loss_c:1.0274980068206787
tensor(1.4978, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020589614287018776
loss_c:0.9112092852592468
tensor(1.3514, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021518956869840622
loss_c:1.008194923400879
tensor(1.4041, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023626618087291718
loss_c:0.8715343475341797
tensor(1.3424, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018273750320076942
loss_c:0.9846624732017517
tensor(1.3802, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027546362951397896
loss_c:0.9987657070159912
tensor(1.4214, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024704068899154663
loss_c:1.0920522212982178
tensor(1.4583, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018166109919548035
loss_c:0.8631231188774109
tensor(1.3179, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02543855458498001
loss_c:1.011399745941162
tensor(1.4200, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022325370460748672
loss_c:1.0280392169952393
tensor(1.4169, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023207688704133034
loss_c:0.9409950971603394
tensor(1.3759, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018404584378004074
loss_c:1.0051231384277344
tensor(1.3907, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023080870509147644
loss_c:0.9336991310119629
tensor(1.3716, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0275026336312294
loss_c:0.9357673525810242
tensor(1.3890, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016644448041915894
loss_c:0.8064541220664978
tensor(1.2829, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028292078524827957
loss_c:0.9915437698364258
tensor(1.4203, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01656513474881649
loss_c:0.8968889117240906
tensor(1.3283, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03118656948208809
loss_c:0.8776609301567078
tensor(1.3732, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03250681981444359
loss_c:0.960406482219696
tensor(1.4202, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026827795431017876
loss_c:0.904889702796936
tensor(1.3706, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01790667325258255
loss_c:0.8699979782104492
tensor(1.3192, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01786327362060547
loss_c:0.9591972827911377
tensor(1.3644, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04039173200726509
loss_c:1.1372151374816895
tensor(1.5401, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08035826683044434
loss_c:1.119891881942749
tensor(1.6826, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02125471457839012
loss_c:0.9014190435409546
tensor(1.3476, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02524089254438877
loss_c:0.8776904344558716
tensor(1.3505, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026028966531157494
loss_c:0.8558894991874695
tensor(1.3424, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023694517090916634
loss_c:1.2460694313049316
tensor(1.5325, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020856264978647232
loss_c:0.9205241203308105
tensor(1.3557, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024937886744737625
loss_c:0.870564341545105
tensor(1.3457, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020257119089365005
loss_c:0.8932121992111206
tensor(1.3394, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08416344970464706
loss_c:1.040071964263916
tensor(1.6573, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021830685436725616
loss_c:1.028118371963501
tensor(1.4142, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028537020087242126
loss_c:0.8684749007225037
tensor(1.3582, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044472549110651016
loss_c:1.1884135007858276
tensor(1.5821, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02186974324285984
loss_c:0.9574737548828125
tensor(1.3783, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03867410868406296
loss_c:1.1662604808807373
tensor(1.5487, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01659945771098137
loss_c:0.8876907229423523
tensor(1.3228, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02672155387699604
loss_c:0.9906388521194458
tensor(1.4137, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02579798549413681
loss_c:1.0025908946990967
tensor(1.4163, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020625179633498192
loss_c:0.9933323860168457
tensor(1.3919, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036619868129491806
loss_c:0.972639262676239
tensor(1.4421, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018236713483929634
loss_c:0.9720852375030518
tensor(1.3720, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.13712559640407562
loss_c:1.0408499240875244
tensor(1.8590, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025369012728333473
loss_c:1.036820411682129
tensor(1.4321, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03394278883934021
loss_c:0.8557402491569519
tensor(1.3724, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0243763979524374
loss_c:0.9855546355247498
tensor(1.4023, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02669142559170723
loss_c:1.075823187828064
tensor(1.4570, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0195434782654047
loss_c:1.0502361059188843
tensor(1.4171, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024742718786001205
loss_c:1.2208726406097412
tensor(1.5234, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030674034729599953
loss_c:1.1271319389343262
tensor(1.4981, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01979202777147293
loss_c:1.0429599285125732
tensor(1.4143, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02386031113564968
loss_c:0.9364629983901978
tensor(1.3755, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01895660161972046
loss_c:0.9398125410079956
tensor(1.3588, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022698136046528816
loss_c:0.9188374280929565
tensor(1.3623, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019744589924812317
loss_c:0.8997368812561035
tensor(1.3415, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04022925719618797
loss_c:0.8492316007614136
tensor(1.3930, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022043293341994286
loss_c:1.0091814994812012
tensor(1.4055, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024202220141887665
loss_c:1.0558626651763916
tensor(1.4373, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05618653818964958
loss_c:0.9517916440963745
tensor(1.5053, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04817666485905647
loss_c:1.1128697395324707
tensor(1.5566, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017405878752470016
loss_c:0.8718898296356201
tensor(1.3185, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03906061127781868
loss_c:1.1416095495224
tensor(1.5367, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023137984797358513
loss_c:0.9019485712051392
tensor(1.3553, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022199898958206177
loss_c:0.9319804906845093
tensor(1.3670, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021032022312283516
loss_c:0.9349557757377625
tensor(1.3641, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021063746884465218
loss_c:0.863989531993866
tensor(1.3283, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03355518355965614
loss_c:1.1000330448150635
tensor(1.4949, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020042574033141136
loss_c:1.11295485496521
tensor(1.4503, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019659362733364105
loss_c:0.835740327835083
tensor(1.3086, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024685638025403023
loss_c:0.9909431338310242
tensor(1.4061, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02100902609527111
loss_c:0.9867395162582397
tensor(1.3900, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04099898412823677
loss_c:0.8926429152488708
tensor(1.4183, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.055664241313934326
loss_c:0.9380689859390259
tensor(1.4970, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021905675530433655
loss_c:0.9423002004623413
tensor(1.3709, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01829104870557785
loss_c:0.8081008791923523
tensor(1.2892, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02892274782061577
loss_c:1.037287950515747
tensor(1.4456, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03432457521557808
loss_c:0.8514810800552368
tensor(1.3721, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022042976692318916
loss_c:0.9005188941955566
tensor(1.3501, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031182605773210526
loss_c:0.9814056158065796
tensor(1.4259, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02810538560152054
loss_c:1.1130365133285522
tensor(1.4809, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021028956398367882
loss_c:0.938428521156311
tensor(1.3654, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05360379442572594
loss_c:0.9249290227890015
tensor(1.4829, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05875268951058388
loss_c:1.201122760772705
tensor(1.6427, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02287224680185318
loss_c:0.8624998331069946
tensor(1.3339, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03730914741754532
loss_c:1.2170203924179077
tensor(1.5689, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019523611292243004
loss_c:0.932151734828949
tensor(1.3565, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02153029292821884
loss_c:0.9597732424736023
tensor(1.3782, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023948295041918755
loss_c:1.1256695985794067
tensor(1.4715, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02397136017680168
loss_c:0.9285931587219238
tensor(1.3716, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019422851502895355
loss_c:0.934950053691864
tensor(1.3575, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028784839436411858
loss_c:0.9256854057312012
tensor(1.3885, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05375578626990318
loss_c:0.9071602821350098
tensor(1.4744, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03145112842321396
loss_c:0.8667908906936646
tensor(1.3688, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04120780527591705
loss_c:0.9811674952507019
tensor(1.4640, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0324578620493412
loss_c:1.0732959508895874
tensor(1.4774, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02100231684744358
loss_c:0.947500467300415
tensor(1.3699, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02356664463877678
loss_c:1.0300631523132324
tensor(1.4216, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029664570465683937
loss_c:1.024518370628357
tensor(1.4420, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025749946013092995
loss_c:1.1122314929962158
tensor(1.4716, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017544008791446686
loss_c:0.9127378463745117
tensor(1.3391, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02191837690770626
loss_c:0.9810504913330078
tensor(1.3904, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017698034644126892
loss_c:1.04917573928833
tensor(1.4088, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020185042172670364
loss_c:0.8915584087371826
tensor(1.3383, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04632294923067093
loss_c:0.9451557397842407
tensor(1.4655, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022619614377617836
loss_c:1.076688289642334
tensor(1.4414, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023731008172035217
loss_c:0.9964473247528076
tensor(1.4050, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02974979765713215
loss_c:0.9779444932937622
tensor(1.4187, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019207021221518517
loss_c:0.8836416602134705
tensor(1.3304, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025890516117215157
loss_c:1.0059115886688232
tensor(1.4180, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03531016781926155
loss_c:1.0028598308563232
tensor(1.4527, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02288358099758625
loss_c:0.9841005206108093
tensor(1.3954, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01872859336435795
loss_c:0.9776773452758789
tensor(1.3761, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030096858739852905
loss_c:0.936525821685791
tensor(1.3990, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022623369470238686
loss_c:0.9944042563438416
tensor(1.3995, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05396519601345062
loss_c:0.9051496982574463
tensor(1.4754, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04569295421242714
loss_c:0.9530137777328491
tensor(1.4677, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023100079968571663
loss_c:1.1594107151031494
tensor(1.4849, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024351539090275764
loss_c:1.005297064781189
tensor(1.4117, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027208495885133743
loss_c:0.9368739128112793
tensor(1.3880, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024511268362402916
loss_c:1.0151737928390503
tensor(1.4173, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04163870960474014
loss_c:1.0063941478729248
tensor(1.4791, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0205772053450346
loss_c:0.9215240478515625
tensor(1.3546, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022399447858333588
loss_c:0.9989332556724548
tensor(1.4009, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05765192210674286
loss_c:1.1160767078399658
tensor(1.5967, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01844126172363758
loss_c:1.003896713256836
tensor(1.3880, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04472707211971283
loss_c:1.0499730110168457
tensor(1.5131, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015637770295143127
loss_c:0.9788191318511963
tensor(1.3645, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05220729112625122
loss_c:1.0286662578582764
tensor(1.5312, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04111757129430771
loss_c:0.9481393694877625
tensor(1.4475, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020814785733819008
loss_c:1.0026524066925049
tensor(1.3967, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02429037354886532
loss_c:1.0448682308197021
tensor(1.4314, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01702743209898472
loss_c:1.0093669891357422
tensor(1.3855, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02525375224649906
loss_c:1.1412581205368042
tensor(1.4838, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035293594002723694
loss_c:1.0098145008087158
tensor(1.4562, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028488177806138992
loss_c:0.8726055026054382
tensor(1.3607, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026652764528989792
loss_c:0.9268162250518799
tensor(1.3809, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021065425127744675
loss_c:0.9064645171165466
tensor(1.3491, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04076143354177475
loss_c:1.0900496244430542
tensor(1.5177, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029069412499666214
loss_c:1.035789132118225
tensor(1.4452, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0425378642976284
loss_c:0.8419528007507324
tensor(1.3995, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028546299785375595
loss_c:0.9416593909263611
tensor(1.3958, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04132665693759918
loss_c:0.8546096086502075
tensor(1.4011, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0244284775108099
loss_c:0.8534058928489685
tensor(1.3354, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02091614529490471
loss_c:0.8648008108139038
tensor(1.3276, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03672929108142853
loss_c:1.0502830743789673
tensor(1.4821, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036382757127285004
loss_c:1.1093473434448242
tensor(1.5106, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034298498183488846
loss_c:0.8998462557792664
tensor(1.3967, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029249126091599464
loss_c:0.8154584765434265
tensor(1.3347, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03626544401049614
loss_c:1.018807291984558
tensor(1.4644, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038204025477170944
loss_c:0.9845811724662781
tensor(1.4545, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04746821150183678
loss_c:0.977651834487915
tensor(1.4866, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02442602440714836
loss_c:1.0154833793640137
tensor(1.4173, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02810589410364628
loss_c:0.9795860648155212
tensor(1.4132, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01725042797625065
loss_c:0.9937719106674194
tensor(1.3788, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1013650894165039
loss_c:0.938079833984375
tensor(1.6726, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030229954048991203
loss_c:1.0050606727600098
tensor(1.4343, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03277862071990967
loss_c:1.0505180358886719
tensor(1.4670, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03281388431787491
loss_c:0.8666397929191589
tensor(1.3740, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0313812680542469
loss_c:0.8878142237663269
tensor(1.3792, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020835595205426216
loss_c:0.908463716506958
tensor(1.3497, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021387871354818344
loss_c:0.8721911311149597
tensor(1.3334, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024015100672841072
loss_c:1.1582773923873901
tensor(1.4885, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040997736155986786
loss_c:1.2306344509124756
tensor(1.5894, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026250503957271576
loss_c:0.9462383985519409
tensor(1.3894, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017328880727291107
loss_c:0.8955082893371582
tensor(1.3300, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046220239251852036
loss_c:1.0543397665023804
tensor(1.5196, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0551120862364769
loss_c:0.971953272819519
tensor(1.5114, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037513576447963715
loss_c:0.9938380718231201
tensor(1.4560, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01891751028597355
loss_c:0.9178941249847412
tensor(1.3475, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018257085233926773
loss_c:0.8967480063438416
tensor(1.3344, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01922445558011532
loss_c:0.8356477618217468
tensor(1.3070, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.048672161996364594
loss_c:1.118965983390808
tensor(1.5614, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01972016878426075
loss_c:0.8918349146842957
tensor(1.3374, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05165501683950424
loss_c:0.9883432388305664
tensor(1.5063, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021193908527493477
loss_c:0.9307974576950073
tensor(1.3627, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021943828091025352
loss_c:0.8354915380477905
tensor(1.3171, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026566576212644577
loss_c:0.9091941118240356
tensor(1.3719, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02329348586499691
loss_c:0.8679851293563843
tensor(1.3387, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0480303093791008
loss_c:1.1045355796813965
tensor(1.5518, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02734157256782055
loss_c:1.1806588172912598
tensor(1.5128, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022648444399237633
loss_c:0.9291676878929138
tensor(1.3673, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020680027082562447
loss_c:0.9805776476860046
tensor(1.3860, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021800654008984566
loss_c:1.0260584354400635
tensor(1.4134, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.059790901839733124
loss_c:1.0886051654815674
tensor(1.5880, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025225892663002014
loss_c:1.042849063873291
tensor(1.4347, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024229254573583603
loss_c:0.9758755564689636
tensor(1.3969, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05814540386199951
loss_c:0.8880720138549805
tensor(1.4798, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03639928996562958
loss_c:1.126293420791626
tensor(1.5191, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027278397232294083
loss_c:1.238675832748413
tensor(1.5419, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044345736503601074
loss_c:0.9967734217643738
tensor(1.4831, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018065309152007103
loss_c:0.9534026980400085
tensor(1.3625, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03192184865474701
loss_c:0.8602988719940186
tensor(1.3672, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03941188007593155
loss_c:0.8178858757019043
tensor(1.3738, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023031078279018402
loss_c:0.9982357025146484
tensor(1.4039, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04619484767317772
loss_c:0.9202489852905273
tensor(1.4511, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027050305157899857
loss_c:1.2391278743743896
tensor(1.5411, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026627695187926292
loss_c:0.8895124793052673
tensor(1.3623, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03402575105428696
loss_c:0.8655418753623962
tensor(1.3778, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021883487701416016
loss_c:0.8942047953605652
tensor(1.3469, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0258383397012949
loss_c:0.7868954539299011
tensor(1.3073, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020267941057682037
loss_c:1.0045650005340576
tensor(1.3968, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026518605649471283
loss_c:1.0134773254394531
tensor(1.4247, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02680414542555809
loss_c:0.8568632006645203
tensor(1.3463, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01980813965201378
loss_c:0.9798306226730347
tensor(1.3825, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032058149576187134
loss_c:0.9477790594100952
tensor(1.4121, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024709399789571762
loss_c:0.9816926717758179
tensor(1.4017, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03475449979305267
loss_c:1.0655816793441772
tensor(1.4821, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02375730127096176
loss_c:1.1195251941680908
tensor(1.4682, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06749904900789261
loss_c:1.04582679271698
tensor(1.5952, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0372551791369915
loss_c:0.9404057264328003
tensor(1.4279, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020074298605322838
loss_c:0.981724202632904
tensor(1.3843, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013576144352555275
loss_c:0.8618161082267761
tensor(1.2990, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022499458864331245
loss_c:0.8539811372756958
tensor(1.3285, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026630010455846786
loss_c:0.8220254778862
tensor(1.3278, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02353852428495884
loss_c:0.89838045835495
tensor(1.3549, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027579618617892265
loss_c:0.897775411605835
tensor(1.3698, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017221791669726372
loss_c:0.9642714262008667
tensor(1.3645, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02018495462834835
loss_c:0.8168483972549438
tensor(1.3006, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03467768803238869
loss_c:0.9043779373168945
tensor(1.3999, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04782041907310486
loss_c:0.850405216217041
tensor(1.4221, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026027746498584747
loss_c:0.9455253481864929
tensor(1.3881, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019647272303700447
loss_c:0.9295153021812439
tensor(1.3557, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022478943690657616
loss_c:0.8465608358383179
tensor(1.3240, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02392774447798729
loss_c:1.0006005764007568
tensor(1.4082, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02551298588514328
loss_c:0.9528626203536987
tensor(1.3898, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05046018585562706
loss_c:1.0056121349334717
tensor(1.5117, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0210291538387537
loss_c:0.9014872908592224
tensor(1.3463, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06662478297948837
loss_c:1.0341123342514038
tensor(1.5881, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029735013842582703
loss_c:1.0145233869552612
tensor(1.4374, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021761707961559296
loss_c:1.0280343294143677
tensor(1.4140, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019341371953487396
loss_c:1.021705150604248
tensor(1.4016, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03362883999943733
loss_c:0.9719314575195312
tensor(1.4304, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.045212551951408386
loss_c:0.8804140090942383
tensor(1.4276, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02248985506594181
loss_c:0.9429476261138916
tensor(1.3731, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041796281933784485
loss_c:1.0185917615890503
tensor(1.4855, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023906409740447998
loss_c:0.9567462801933289
tensor(1.3856, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01859966479241848
loss_c:0.909172773361206
tensor(1.3410, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029978197067975998
loss_c:0.9155372381210327
tensor(1.3876, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026886405423283577
loss_c:0.8523910045623779
tensor(1.3434, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022467920556664467
loss_c:1.0073254108428955
tensor(1.4061, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021675923839211464
loss_c:0.9248316287994385
tensor(1.3607, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032629724591970444
loss_c:1.0147733688354492
tensor(1.4487, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024496451020240784
loss_c:1.0758898258209229
tensor(1.4491, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022136008366942406
loss_c:0.921556830406189
tensor(1.3607, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025571702048182487
loss_c:0.9869465827941895
tensor(1.4074, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029886702075600624
loss_c:1.0685973167419434
tensor(1.4659, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02861955761909485
loss_c:0.9062139391899109
tensor(1.3775, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07230620831251144
loss_c:1.1098628044128418
tensor(1.6496, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026309315115213394
loss_c:0.9429618716239929
tensor(1.3876, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017158398404717445
loss_c:0.8791003227233887
tensor(1.3198, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02971985749900341
loss_c:1.0469639301300049
tensor(1.4541, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03731491044163704
loss_c:0.9787290096282959
tensor(1.4481, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02288808673620224
loss_c:0.8952068090438843
tensor(1.3500, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03136894851922989
loss_c:1.276767373085022
tensor(1.5783, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026777256280183792
loss_c:1.0349162817001343
tensor(1.4366, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01610291190445423
loss_c:0.9223074913024902
tensor(1.3379, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039844851940870285
loss_c:0.8785485029220581
tensor(1.4065, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021898416802287102
loss_c:0.962687611579895
tensor(1.3808, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025625402107834816
loss_c:0.9716726541519165
tensor(1.3997, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03317365050315857
loss_c:1.2524311542510986
tensor(1.5724, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029220959171652794
loss_c:0.9114648699760437
tensor(1.3827, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018136585131287575
loss_c:0.8063115477561951
tensor(1.2863, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022160286083817482
loss_c:0.8625975847244263
tensor(1.3306, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05118445307016373
loss_c:1.0064690113067627
tensor(1.5157, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02137111686170101
loss_c:0.8588234782218933
tensor(1.3256, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023140588775277138
loss_c:0.8166739344596863
tensor(1.3108, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08070798963308334
loss_c:1.0282528400421143
tensor(1.6405, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03129063919186592
loss_c:0.875705897808075
tensor(1.3723, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024081101641058922
loss_c:1.0320481061935425
tensor(1.4246, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024647707119584084
loss_c:0.9985491633415222
tensor(1.4097, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023920396342873573
loss_c:0.981196403503418
tensor(1.3980, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017967822030186653
loss_c:0.8304097652435303
tensor(1.2980, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01925552822649479
loss_c:0.9243048429489136
tensor(1.3510, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05931776389479637
loss_c:1.0529518127441406
tensor(1.5706, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04589176923036575
loss_c:0.9642170667648315
tensor(1.4736, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04480306804180145
loss_c:1.1061139106750488
tensor(1.5420, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01807422749698162
loss_c:0.9004828929901123
tensor(1.3344, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028320012614130974
loss_c:0.9395017623901367
tensor(1.3936, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02555009536445141
loss_c:0.8340208530426025
tensor(1.3290, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023965345695614815
loss_c:0.9268097281455994
tensor(1.3704, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05158478766679764
loss_c:0.9040130376815796
tensor(1.4642, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04390696436166763
loss_c:0.9251896739006042
tensor(1.4457, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02662399224936962
loss_c:0.8888416290283203
tensor(1.3611, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030341556295752525
loss_c:1.1603405475616455
tensor(1.5146, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022211000323295593
loss_c:0.9845929145812988
tensor(1.3935, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025456147268414497
loss_c:0.8788505792617798
tensor(1.3516, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027932357043027878
loss_c:0.911133885383606
tensor(1.3776, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0267191044986248
loss_c:0.9894752502441406
tensor(1.4131, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023257043212652206
loss_c:0.9237930774688721
tensor(1.3663, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019754542037844658
loss_c:0.9180864691734314
tensor(1.3500, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03633391857147217
loss_c:0.8914998769760132
tensor(1.3994, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03178419545292854
loss_c:0.980888843536377
tensor(1.4280, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038260381668806076
loss_c:1.0225523710250854
tensor(1.4741, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017911022529006004
loss_c:0.8271891474723816
tensor(1.2962, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033264581114053726
loss_c:0.8095666766166687
tensor(1.3456, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02176677994430065
loss_c:0.9354841709136963
tensor(1.3665, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027489976957440376
loss_c:0.9258171319961548
tensor(1.3833, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.047333184629678726
loss_c:0.9910001754760742
tensor(1.4925, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01874432899057865
loss_c:0.916149377822876
tensor(1.3450, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02127906121313572
loss_c:0.9428528547286987
tensor(1.3684, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03218008205294609
loss_c:0.9325995445251465
tensor(1.4047, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02416255511343479
loss_c:0.9089562296867371
tensor(1.3619, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02799178659915924
loss_c:0.9315975904464722
tensor(1.3882, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02221917174756527
loss_c:0.9469919204711914
tensor(1.3740, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020112233236432076
loss_c:0.9761300086975098
tensor(1.3810, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023892471566796303
loss_c:0.8861660957336426
tensor(1.3490, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020637350156903267
loss_c:0.9420897960662842
tensor(1.3654, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02517489530146122
loss_c:0.8428911566734314
tensor(1.3315, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027136335149407387
loss_c:1.0914044380187988
tensor(1.4674, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03684665262699127
loss_c:0.9558018445968628
tensor(1.4347, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018486039713025093
loss_c:1.0509045124053955
tensor(1.4132, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01848532259464264
loss_c:0.9232181310653687
tensor(1.3471, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02718605287373066
loss_c:0.9622259140014648
tensor(1.4008, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05170125141739845
loss_c:0.9265828132629395
tensor(1.4771, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031086992472410202
loss_c:0.8708406686782837
tensor(1.3686, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023742452263832092
loss_c:0.9821486473083496
tensor(1.3978, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019722873345017433
loss_c:0.9126824736595154
tensor(1.3462, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03021991439163685
loss_c:1.130638599395752
tensor(1.4997, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037055157124996185
loss_c:0.8320409655570984
tensor(1.3716, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019994620233774185
loss_c:0.9104598760604858
tensor(1.3461, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024414068087935448
loss_c:1.0009663105010986
tensor(1.4100, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01850445754826069
loss_c:0.9549404978752136
tensor(1.3632, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03947346657514572
loss_c:0.9364173412322998
tensor(1.4351, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028957482427358627
loss_c:0.987602710723877
tensor(1.4207, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03197570517659187
loss_c:0.9408237338066101
tensor(1.4083, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016310373321175575
loss_c:0.8555619120597839
tensor(1.3031, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026887517422437668
loss_c:0.8537298440933228
tensor(1.3434, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018842054530978203
loss_c:0.8771631717681885
tensor(1.3241, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022812025621533394
loss_c:0.8965618014335632
tensor(1.3496, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02312135510146618
loss_c:0.8819581866264343
tensor(1.3432, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025681359693408012
loss_c:0.960838794708252
tensor(1.3941, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01819736137986183
loss_c:0.8873321413993835
tensor(1.3266, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01661449484527111
loss_c:0.9930245280265808
tensor(1.3752, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04207124561071396
loss_c:1.1455254554748535
tensor(1.5543, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0250342208892107
loss_c:0.8931280970573425
tensor(1.3563, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02020505629479885
loss_c:0.9512168169021606
tensor(1.3674, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06016383320093155
loss_c:0.9960066676139832
tensor(1.5483, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02265191078186035
loss_c:0.970786452293396
tensor(1.3872, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02557104453444481
loss_c:1.0688097476959229
tensor(1.4496, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03903849422931671
loss_c:1.090623378753662
tensor(1.5140, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11964395642280579
loss_c:1.1178232431411743
tensor(1.8463, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016754329204559326
loss_c:0.8997625112533569
tensor(1.3272, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03379877656698227
loss_c:0.915973424911499
tensor(1.4027, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03007427416741848
loss_c:0.9364022016525269
tensor(1.3986, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017454054206609726
loss_c:1.054682731628418
tensor(1.4105, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024203971028327942
loss_c:1.0546293258666992
tensor(1.4369, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01850726827979088
loss_c:0.8923851251602173
tensor(1.3307, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02113441377878189
loss_c:1.0518779754638672
tensor(1.4235, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02378867194056511
loss_c:1.0023139715194702
tensor(1.4082, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01834886521100998
loss_c:1.0080578327178955
tensor(1.3899, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01869153045117855
loss_c:1.0127100944519043
tensor(1.3937, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03325656056404114
loss_c:1.0831794738769531
tensor(1.4867, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019248832017183304
loss_c:0.9583427309989929
tensor(1.3677, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017067136242985725
loss_c:0.8987261056900024
tensor(1.3285, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0294475220143795
loss_c:1.006097435951233
tensor(1.4321, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01858232170343399
loss_c:1.0236773490905762
tensor(1.3986, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03741101548075676
loss_c:0.8035053610801697
tensor(1.3591, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04262566566467285
loss_c:0.9419004917144775
tensor(1.4506, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016745170578360558
loss_c:0.8874776363372803
tensor(1.3214, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02392335794866085
loss_c:1.0324265956878662
tensor(1.4239, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04370725899934769
loss_c:0.8416486978530884
tensor(1.4035, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04347306489944458
loss_c:0.8901519775390625
tensor(1.4275, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019689155742526054
loss_c:0.9381438493728638
tensor(1.3589, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05706920102238655
loss_c:1.1377619504928589
tensor(1.6079, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03874489665031433
loss_c:0.9422814249992371
tensor(1.4357, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026714425534009933
loss_c:0.9934487342834473
tensor(1.4148, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016922609880566597
loss_c:0.9406253695487976
tensor(1.3495, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02561035193502903
loss_c:0.9475239515304565
tensor(1.3870, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05487453565001488
loss_c:0.9896933436393738
tensor(1.5228, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022949472069740295
loss_c:1.018267035484314
tensor(1.4129, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019240258261561394
loss_c:0.9804708361625671
tensor(1.3791, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024625113233923912
loss_c:0.9947773814201355
tensor(1.4074, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04291228950023651
loss_c:1.24168860912323
tensor(1.6053, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024556376039981842
loss_c:0.8950330018997192
tensor(1.3560, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018355021253228188
loss_c:0.9611401557922363
tensor(1.3658, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0227068942040205
loss_c:0.998663604259491
tensor(1.4019, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019531097263097763
loss_c:0.9401509165763855
tensor(1.3596, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03615977242588997
loss_c:1.0447721481323242
tensor(1.4779, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0328570120036602
loss_c:0.9349534511566162
tensor(1.4088, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031235869973897934
loss_c:1.0111634731292725
tensor(1.4415, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05445781350135803
loss_c:0.9541052579879761
tensor(1.5027, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028582267463207245
loss_c:0.983012855052948
tensor(1.4168, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040234774351119995
loss_c:0.8791788816452026
tensor(1.4090, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01821386069059372
loss_c:0.9191775321960449
tensor(1.3439, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01781363971531391
loss_c:0.9421933889389038
tensor(1.3541, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02210412360727787
loss_c:0.8583428263664246
tensor(1.3279, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04922926053404808
loss_c:1.1372565031051636
tensor(1.5757, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027040818706154823
loss_c:0.9107804298400879
tensor(1.3739, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021724430844187737
loss_c:0.8009294271469116
tensor(1.2972, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03666120767593384
loss_c:0.8810924291610718
tensor(1.3960, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03730511665344238
loss_c:1.0663645267486572
tensor(1.4932, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023738879710435867
loss_c:0.9863574504852295
tensor(1.3997, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022805843502283096
loss_c:0.9252203702926636
tensor(1.3649, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032264821231365204
loss_c:1.0110090970993042
tensor(1.4453, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024744858965277672
loss_c:1.1414438486099243
tensor(1.4829, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03463698551058769
loss_c:0.930611789226532
tensor(1.4134, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021447306498885155
loss_c:0.9335242509841919
tensor(1.3638, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04852636158466339
loss_c:0.9503836631774902
tensor(1.4773, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029229143634438515
loss_c:0.9863467216491699
tensor(1.4210, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02889256924390793
loss_c:0.8921917676925659
tensor(1.3715, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03298356384038925
loss_c:0.943882167339325
tensor(1.4138, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01731514185667038
loss_c:0.9368432760238647
tensor(1.3496, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02801361493766308
loss_c:1.0221805572509766
tensor(1.4346, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0675254613161087
loss_c:0.9554084539413452
tensor(1.5532, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06775084137916565
loss_c:1.0312039852142334
tensor(1.5927, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021631555631756783
loss_c:0.8925291895866394
tensor(1.3437, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016860688105225563
loss_c:0.955954909324646
tensor(1.3579, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029525456950068474
loss_c:1.0300778150558472
tensor(1.4445, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033787842839956284
loss_c:0.8515805602073669
tensor(1.3696, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.051999133080244064
loss_c:1.00332772731781
tensor(1.5170, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018133768811821938
loss_c:0.9327362775802612
tensor(1.3511, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.13830499351024628
loss_c:1.141575574874878
tensor(1.9174, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01962532475590706
loss_c:0.851628303527832
tensor(1.3156, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024139810353517532
loss_c:0.9584099650382996
tensor(1.3875, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02102603390812874
loss_c:0.8997836112976074
tensor(1.3458, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02361651137471199
loss_c:0.9642033576965332
tensor(1.3886, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023189352825284004
loss_c:1.0240033864974976
tensor(1.4176, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022906847298145294
loss_c:0.8632270693778992
tensor(1.3343, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016548527404665947
loss_c:0.9651637077331543
tensor(1.3626, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023479439318180084
loss_c:0.9525817632675171
tensor(1.3823, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04496083781123161
loss_c:0.9975484609603882
tensor(1.4859, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04913485795259476
loss_c:0.92637699842453
tensor(1.4651, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027217280119657516
loss_c:1.045151710510254
tensor(1.4437, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021890785545110703
loss_c:1.152705192565918
tensor(1.4789, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019058719277381897
loss_c:0.7710860967636108
tensor(1.2729, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04411140829324722
loss_c:0.9241158366203308
tensor(1.4450, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028142191469669342
loss_c:0.9999508857727051
tensor(1.4241, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0192456915974617
loss_c:0.9046013355255127
tensor(1.3420, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025422174483537674
loss_c:0.9816584587097168
tensor(1.4045, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024429626762866974
loss_c:0.883966326713562
tensor(1.3508, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04199134185910225
loss_c:0.9141027331352234
tensor(1.4319, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025607535615563393
loss_c:0.8410385847091675
tensor(1.3332, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021540770307183266
loss_c:1.0913267135620117
tensor(1.4462, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03849828988313675
loss_c:0.9557268023490906
tensor(1.4402, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027706339955329895
loss_c:0.8519477844238281
tensor(1.3465, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05662008374929428
loss_c:0.8870476484298706
tensor(1.4729, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0435829721391201
loss_c:0.8655511736869812
tensor(1.4130, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021126672625541687
loss_c:0.8859907388687134
tensor(1.3393, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021762605756521225
loss_c:0.901368260383606
tensor(1.3496, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05203172191977501
loss_c:0.9662877917289734
tensor(1.4962, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04304894059896469
loss_c:0.9328510761260986
tensor(1.4454, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.051506273448467255
loss_c:1.1554837226867676
tensor(1.5915, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023860204964876175
loss_c:1.0624749660491943
tensor(1.4404, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028974149376153946
loss_c:1.2229769229888916
tensor(1.5421, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0176995936781168
loss_c:0.9631334543228149
tensor(1.3664, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.052675485610961914
loss_c:1.032418966293335
tensor(1.5322, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044581834226846695
loss_c:1.1287702322006226
tensor(1.5516, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021267084404826164
loss_c:0.9505971670150757
tensor(1.3733, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03368432819843292
loss_c:1.0202031135559082
tensor(1.4552, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033356498926877975
loss_c:1.0784887075424194
tensor(1.4839, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01897663064301014
loss_c:0.8814187049865723
tensor(1.3295, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021059060469269753
loss_c:0.8290840983390808
tensor(1.3104, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02219424955546856
loss_c:0.9321681261062622
tensor(1.3674, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03059183992445469
loss_c:1.2173810005187988
tensor(1.5446, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036262430250644684
loss_c:1.0610785484313965
tensor(1.4856, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025257891044020653
loss_c:1.0846269130706787
tensor(1.4568, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03127671033143997
loss_c:1.0154780149459839
tensor(1.4437, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034523870795965195
loss_c:0.8506192564964294
tensor(1.3715, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02384331449866295
loss_c:0.9955958127975464
tensor(1.4059, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026848334819078445
loss_c:0.9870270490646362
tensor(1.4127, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041684556752443314
loss_c:1.137279987335205
tensor(1.5444, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.052496615797281265
loss_c:1.0078251361846924
tensor(1.5186, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043907761573791504
loss_c:0.8781902194023132
tensor(1.4206, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09340976178646088
loss_c:1.2100248336791992
tensor(1.7733, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.047019075602293015
loss_c:0.9644945859909058
tensor(1.4760, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027808228507637978
loss_c:0.8919469714164734
tensor(1.3680, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04041401296854019
loss_c:0.9462751746177673
tensor(1.4421, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02848263457417488
loss_c:0.848203182220459
tensor(1.3484, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02270827628672123
loss_c:0.8990379571914673
tensor(1.3530, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021639667451381683
loss_c:0.9191200733184814
tensor(1.3594, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03600981831550598
loss_c:0.8833813667297363
tensor(1.3939, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027029069140553474
loss_c:1.2337660789489746
tensor(1.5389, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.054902732372283936
loss_c:1.091529369354248
tensor(1.5686, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025324296206235886
loss_c:1.0907783508300781
tensor(1.4601, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05181632190942764
loss_c:1.085381269454956
tensor(1.5540, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026186654344201088
loss_c:1.0199122428894043
tensor(1.4273, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01879797875881195
loss_c:0.8915976881980896
tensor(1.3354, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028569117188453674
loss_c:0.9148272275924683
tensor(1.3828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02113869972527027
loss_c:1.0236155986785889
tensor(1.4109, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018005739897489548
loss_c:0.7569330930709839
tensor(1.2645, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042860791087150574
loss_c:0.8864501714706421
tensor(1.4204, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022434748709201813
loss_c:0.9055096507072449
tensor(1.3557, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025899682193994522
loss_c:0.8680232763290405
tensor(1.3493, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03025415912270546
loss_c:0.9329094886779785
tensor(1.3980, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02952710911631584
loss_c:1.0278539657592773
tensor(1.4435, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013440478593111038
loss_c:1.0346217155456543
tensor(1.3883, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017296554520726204
loss_c:0.8391448259353638
tensor(1.3031, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.050560884177684784
loss_c:1.0073130130767822
tensor(1.5100, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0224106814712286
loss_c:0.9106618762016296
tensor(1.3580, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017962848767638206
loss_c:0.9988260269165039
tensor(1.3864, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031225748360157013
loss_c:1.0624672174453735
tensor(1.4673, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023949751630425453
loss_c:0.9783432483673096
tensor(1.3978, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03550522401928902
loss_c:0.8549860715866089
tensor(1.3776, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03351111710071564
loss_c:0.9888364672660828
tensor(1.4383, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033409617841243744
loss_c:0.9361124038696289
tensor(1.4111, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031047943979501724
loss_c:1.1455414295196533
tensor(1.5089, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019763531163334846
loss_c:0.9837378263473511
tensor(1.3849, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02305971272289753
loss_c:0.8888934850692749
tensor(1.3488, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021931635215878487
loss_c:1.2283034324645996
tensor(1.5173, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02739250287413597
loss_c:1.0224205255508423
tensor(1.4327, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024713188409805298
loss_c:0.8951190710067749
tensor(1.3580, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033061448484659195
loss_c:0.9720481634140015
tensor(1.4281, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030955340713262558
loss_c:1.037657618522644
tensor(1.4536, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031044431030750275
loss_c:1.2820854187011719
tensor(1.5781, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02016063965857029
loss_c:0.8998047709465027
tensor(1.3433, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02135504223406315
loss_c:0.9916284084320068
tensor(1.3944, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06076532229781151
loss_c:1.1065211296081543
tensor(1.6001, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03785492107272148
loss_c:0.9126777648925781
tensor(1.4160, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02934829518198967
loss_c:1.0172232389450073
tensor(1.4372, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018013522028923035
loss_c:0.95048588514328
tensor(1.3609, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.054081737995147705
loss_c:0.99493807554245
tensor(1.5186, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039074573665857315
loss_c:0.8947280645370483
tensor(1.4116, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018267132341861725
loss_c:0.8632625937461853
tensor(1.3177, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04100896418094635
loss_c:0.8631752729415894
tensor(1.4029, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01956193521618843
loss_c:0.9096989631652832
tensor(1.3460, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017066607251763344
loss_c:0.9326084852218628
tensor(1.3483, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021600475534796715
loss_c:1.0752365589141846
tensor(1.4375, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04138520359992981
loss_c:0.8734862208366394
tensor(1.4095, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035289227962493896
loss_c:1.1157162189483643
tensor(1.5094, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019954998046159744
loss_c:1.0373904705047607
tensor(1.4121, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031961310654878616
loss_c:1.1430686712265015
tensor(1.5107, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02148132212460041
loss_c:1.0644996166229248
tensor(1.4315, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018179241567850113
loss_c:0.9042136073112488
tensor(1.3379, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03769829496741295
loss_c:0.9457928538322449
tensor(1.4324, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01879367046058178
loss_c:0.9622361063957214
tensor(1.3695, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0219557024538517
loss_c:0.9304822683334351
tensor(1.3653, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01770584098994732
loss_c:0.8971619606018066
tensor(1.3323, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027012454345822334
loss_c:1.0768758058547974
tensor(1.4584, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03928564488887787
loss_c:1.1074705123901367
tensor(1.5204, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018029728904366493
loss_c:0.8258814811706543
tensor(1.2973, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018582411110401154
loss_c:0.9744687080383301
tensor(1.3745, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0352175198495388
loss_c:1.0319647789001465
tensor(1.4669, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02652936615049839
loss_c:0.9980210661888123
tensor(1.4166, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019314421340823174
loss_c:0.8943526148796082
tensor(1.3366, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01923115737736225
loss_c:0.8620716333389282
tensor(1.3198, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018925417214632034
loss_c:0.9592595100402832
tensor(1.3678, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036501284688711166
loss_c:1.1552454233169556
tensor(1.5344, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024469848722219467
loss_c:0.9011117815971375
tensor(1.3595, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022735899314284325
loss_c:0.9386555552482605
tensor(1.3718, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0410841666162014
loss_c:1.0706801414489746
tensor(1.5093, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019946152344346046
loss_c:1.0074824094772339
tensor(1.3958, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030718917027115822
loss_c:0.8489100337028503
tensor(1.3571, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017780262976884842
loss_c:0.8993067741394043
tensor(1.3326, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01546983327716589
loss_c:0.8523945808410645
tensor(1.2998, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02209831215441227
loss_c:0.9847190380096436
tensor(1.3924, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024710755795240402
loss_c:0.9190081357955933
tensor(1.3692, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017771504819393158
loss_c:0.8443285822868347
tensor(1.3043, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01767629384994507
loss_c:0.9379420280456543
tensor(1.3513, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020617391914129257
loss_c:0.9717656373977661
tensor(1.3799, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04615411162376404
loss_c:1.0413477420806885
tensor(1.5152, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022661494091153145
loss_c:0.8505557775497437
tensor(1.3261, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022712664678692818
loss_c:0.8689552545547485
tensor(1.3356, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030105307698249817
loss_c:1.0651612281799316
tensor(1.4645, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038926318287849426
loss_c:0.7933787107467651
tensor(1.3609, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02628133073449135
loss_c:1.0170941352844238
tensor(1.4250, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020326171070337296
loss_c:0.9557574987411499
tensor(1.3702, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.045307762920856476
loss_c:0.8620076179504395
tensor(1.4211, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02255917899310589
loss_c:1.1769695281982422
tensor(1.4919, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028411608189344406
loss_c:0.8916379809379578
tensor(1.3694, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04361077770590782
loss_c:0.8761881589889526
tensor(1.4216, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022026045247912407
loss_c:0.8841390013694763
tensor(1.3403, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021405557170510292
loss_c:0.8935003280639648
tensor(1.3426, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03887725993990898
loss_c:0.9862209558486938
tensor(1.4591, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03825472295284271
loss_c:0.9151961207389832
tensor(1.4203, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019001366570591927
loss_c:0.97479647397995
tensor(1.3746, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04098358005285263
loss_c:0.9480122327804565
tensor(1.4479, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015398909337818623
loss_c:0.947508692741394
tensor(1.3464, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025450952351093292
loss_c:1.079648494720459
tensor(1.4539, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043878134340047836
loss_c:1.0836302042007446
tensor(1.5289, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03128180280327797
loss_c:0.884626567363739
tensor(1.3770, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023384811356663704
loss_c:0.970152735710144
tensor(1.3896, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026032790541648865
loss_c:1.0198302268981934
tensor(1.4256, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020812897011637688
loss_c:0.8072561025619507
tensor(1.2959, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023014752194285393
loss_c:1.038891315460205
tensor(1.4234, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03878704458475113
loss_c:1.00216805934906
tensor(1.4669, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039856430143117905
loss_c:0.8108043670654297
tensor(1.3730, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02369770035147667
loss_c:0.842218816280365
tensor(1.3252, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028092240914702415
loss_c:1.1264097690582275
tensor(1.4885, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024881141260266304
loss_c:0.7931349277496338
tensor(1.3046, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040007997304201126
loss_c:0.9482728242874146
tensor(1.4441, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02338108792901039
loss_c:0.9393352270126343
tensor(1.3738, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024293269962072372
loss_c:0.9172322154045105
tensor(1.3660, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02607724815607071
loss_c:0.9818836450576782
tensor(1.4063, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024457748979330063
loss_c:0.8682886958122253
tensor(1.3415, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021556243300437927
loss_c:1.0177820920944214
tensor(1.4070, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01657996140420437
loss_c:0.9054245948791504
tensor(1.3295, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021696507930755615
loss_c:0.9667991399765015
tensor(1.3813, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02312636189162731
loss_c:0.9192966818809509
tensor(1.3624, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0318419374525547
loss_c:1.0351357460021973
tensor(1.4566, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044101618230342865
loss_c:1.036293864250183
tensor(1.5058, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04238508269190788
loss_c:1.0634751319885254
tensor(1.5130, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030812352895736694
loss_c:0.9621251821517944
tensor(1.4149, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026158221065998077
loss_c:0.9583799839019775
tensor(1.3945, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03148684650659561
loss_c:0.9810153841972351
tensor(1.4273, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02077479287981987
loss_c:0.8327190279960632
tensor(1.3085, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020186439156532288
loss_c:0.9941422939300537
tensor(1.3893, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02161080203950405
loss_c:1.0014618635177612
tensor(1.3987, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01866202801465988
loss_c:0.8582589626312256
tensor(1.3133, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030734308063983917
loss_c:0.8600387573242188
tensor(1.3620, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02114754356443882
loss_c:0.8976909518241882
tensor(1.3434, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02646367810666561
loss_c:0.9381560683250427
tensor(1.3853, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026842745020985603
loss_c:0.8392364978790283
tensor(1.3358, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023812053725123405
loss_c:0.953889787197113
tensor(1.3829, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01824600249528885
loss_c:0.7818315029144287
tensor(1.2720, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016427738592028618
loss_c:0.9172751903533936
tensor(1.3345, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026315756142139435
loss_c:0.9576104879379272
tensor(1.3947, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03956073522567749
loss_c:0.9787057638168335
tensor(1.4585, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03346285596489906
loss_c:0.9315779209136963
tensor(1.4098, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018596947193145752
loss_c:1.0068720579147339
tensor(1.3894, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01704028993844986
loss_c:0.8340675234794617
tensor(1.2937, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02123873308300972
loss_c:0.8344169855117798
tensor(1.3106, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025636175647377968
loss_c:1.0565837621688843
tensor(1.4433, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029877392575144768
loss_c:0.9220458269119263
tensor(1.3906, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019663522019982338
loss_c:0.8606009483337402
tensor(1.3177, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024880239740014076
loss_c:0.8685654997825623
tensor(1.3427, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038415756076574326
loss_c:0.8985011577606201
tensor(1.4127, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02925129234790802
loss_c:1.0081788301467896
tensor(1.4328, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028521841391921043
loss_c:0.8035086989402771
tensor(1.3235, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04729696363210678
loss_c:1.0628334283828735
tensor(1.5340, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038063328713178635
loss_c:0.9363858103752136
tensor(1.4310, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023817067965865135
loss_c:0.9288579821586609
tensor(1.3697, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017952512949705124
loss_c:0.9015941619873047
tensor(1.3319, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02869795635342598
loss_c:1.0502406358718872
tensor(1.4525, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029585886746644974
loss_c:0.8421521186828613
tensor(1.3478, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031491126865148544
loss_c:1.1508711576461792
tensor(1.5162, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03177178278565407
loss_c:1.1814250946044922
tensor(1.5332, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02995426021516323
loss_c:0.9178330898284912
tensor(1.3886, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04347274452447891
loss_c:0.971367597579956
tensor(1.4708, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039348673075437546
loss_c:0.8984202742576599
tensor(1.4162, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018519945442676544
loss_c:0.9243132472038269
tensor(1.3462, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01855069398880005
loss_c:0.989271342754364
tensor(1.3801, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023565005511045456
loss_c:1.005594253540039
tensor(1.4086, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07967822998762131
loss_c:1.0145035982131958
tensor(1.6378, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019676437601447105
loss_c:1.0552105903625488
tensor(1.4189, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020646311342716217
loss_c:0.9944314360618591
tensor(1.3912, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019759418442845345
loss_c:0.772622287273407
tensor(1.2727, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019506288692355156
loss_c:0.9867498278617859
tensor(1.3828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019848568364977837
loss_c:1.0181866884231567
tensor(1.4004, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021145490929484367
loss_c:0.8171554803848267
tensor(1.3014, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01768762804567814
loss_c:0.9398384094238281
tensor(1.3512, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023059815168380737
loss_c:0.9841692447662354
tensor(1.3955, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01825772225856781
loss_c:0.9229831695556641
tensor(1.3447, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02061045914888382
loss_c:0.9037759304046631
tensor(1.3441, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01655627228319645
loss_c:0.9506485462188721
tensor(1.3522, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03603328764438629
loss_c:0.9651525020599365
tensor(1.4375, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018242552876472473
loss_c:0.9581181406974792
tensor(1.3627, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024949073791503906
loss_c:0.9939426183700562
tensor(1.4080, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04396399110555649
loss_c:0.9152893424034119
tensor(1.4436, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021584605798125267
loss_c:0.815393328666687
tensor(1.3021, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03716449812054634
loss_c:0.8409191966056824
tensor(1.3778, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025259198620915413
loss_c:0.9749693274497986
tensor(1.3994, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038506362587213516
loss_c:1.179688572883606
tensor(1.5587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024277325719594955
loss_c:0.8785016536712646
tensor(1.3455, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029202058911323547
loss_c:0.9431387782096863
tensor(1.3988, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023030906915664673
loss_c:0.9540161490440369
tensor(1.3796, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02917497232556343
loss_c:0.8973748087882996
tensor(1.3750, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025581693276762962
loss_c:0.9846584796905518
tensor(1.4057, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020032057538628578
loss_c:1.1089146137237549
tensor(1.4478, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07126691192388535
loss_c:0.9177294969558716
tensor(1.5547, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03022848442196846
loss_c:0.8910940885543823
tensor(1.3760, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02110702358186245
loss_c:0.9270075559616089
tensor(1.3580, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023810314014554024
loss_c:0.879297137260437
tensor(1.3441, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018179792910814285
loss_c:0.7912911176681519
tensor(1.2760, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023485150188207626
loss_c:0.897469162940979
tensor(1.3522, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014641091227531433
loss_c:0.7977606654167175
tensor(1.2651, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02186751924455166
loss_c:0.9230397939682007
tensor(1.3590, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018643174320459366
loss_c:1.0326405763626099
tensor(1.4029, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02689228765666485
loss_c:0.8486203551292419
tensor(1.3405, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017915800213813782
loss_c:0.9640514254570007
tensor(1.3643, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03995358943939209
loss_c:1.1830499172210693
tensor(1.5666, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02464188076555729
loss_c:0.8035542368888855
tensor(1.3079, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0243140310049057
loss_c:0.9505419731140137
tensor(1.3830, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01815355196595192
loss_c:0.8724576234817505
tensor(1.3176, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0450839065015316
loss_c:1.0161182880401611
tensor(1.5007, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02194450981914997
loss_c:1.0286529064178467
tensor(1.4140, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020489636808633804
loss_c:1.0548489093780518
tensor(1.4218, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022220704704523087
loss_c:0.8188461661338806
tensor(1.3061, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06046956777572632
loss_c:0.9117476344108582
tensor(1.5087, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05484161898493767
loss_c:0.8694150447845459
tensor(1.4639, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021872464567422867
loss_c:0.8851674795150757
tensor(1.3391, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026749329641461372
loss_c:0.9747223258018494
tensor(1.4053, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01885044574737549
loss_c:0.9459819793701172
tensor(1.3587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04152197390794754
loss_c:1.1337580680847168
tensor(1.5474, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019188113510608673
loss_c:0.9323915243148804
tensor(1.3530, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034957826137542725
loss_c:0.8399698734283447
tensor(1.3682, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02398998849093914
loss_c:0.9655925631523132
tensor(1.3896, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024901995435357094
loss_c:1.024498462677002
tensor(1.4239, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044669609516859055
loss_c:0.7806105613708496
tensor(1.3761, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03822014480829239
loss_c:1.136810064315796
tensor(1.5355, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024901719763875008
loss_c:0.8532729148864746
tensor(1.3348, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040658604353666306
loss_c:0.9329864978790283
tensor(1.4391, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02755611017346382
loss_c:1.078202724456787
tensor(1.4624, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037499841302633286
loss_c:0.9507133364677429
tensor(1.4357, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030010933056473732
loss_c:1.1099183559417725
tensor(1.4886, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023426657542586327
loss_c:1.0100750923156738
tensor(1.4106, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08670075982809067
loss_c:1.0511680841445923
tensor(1.6825, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029245268553495407
loss_c:1.0121443271636963
tensor(1.4347, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.055051159113645554
loss_c:0.9425655603408813
tensor(1.5002, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024102389812469482
loss_c:0.9096431732177734
tensor(1.3613, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018589314073324203
loss_c:0.758807361125946
tensor(1.2617, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022327110171318054
loss_c:1.0553596019744873
tensor(1.4300, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02178625389933586
loss_c:1.0199378728866577
tensor(1.4095, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018534567207098007
loss_c:0.8953511118888855
tensor(1.3324, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018204104155302048
loss_c:1.0031330585479736
tensor(1.3870, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04140020161867142
loss_c:1.0098685026168823
tensor(1.4806, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030488818883895874
loss_c:1.2223529815673828
tensor(1.5480, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02480420470237732
loss_c:1.184122920036316
tensor(1.5061, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024964801967144012
loss_c:0.9579514265060425
tensor(1.3899, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05378773808479309
loss_c:1.0974233150482178
tensor(1.5736, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025485809892416
loss_c:1.0420931577682495
tensor(1.4353, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0880974531173706
loss_c:1.0179376602172852
tensor(1.6652, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018980292603373528
loss_c:0.9029600024223328
tensor(1.3386, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03960144892334938
loss_c:0.8751754760742188
tensor(1.4039, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027363186702132225
loss_c:0.9281249046325684
tensor(1.3840, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03969927504658699
loss_c:0.8727139234542847
tensor(1.4030, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021569283679127693
loss_c:0.9031541347503662
tensor(1.3491, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026930155232548714
loss_c:0.9359609484672546
tensor(1.3864, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03897366672754288
loss_c:0.8544819355010986
tensor(1.3907, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022941328585147858
loss_c:0.8393011093139648
tensor(1.3218, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03590017184615135
loss_c:1.0077779293060303
tensor(1.4574, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018572356551885605
loss_c:0.9442585706710815
tensor(1.3589, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031421251595020294
loss_c:0.8846522569656372
tensor(1.3773, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02327890135347843
loss_c:1.0207574367523193
tensor(1.4161, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041445862501859665
loss_c:1.0470154285430908
tensor(1.4986, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016116246581077576
loss_c:0.9478453993797302
tensor(1.3516, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029865244403481483
loss_c:0.7799599170684814
tensor(1.3177, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01864313893020153
loss_c:0.8765628337860107
tensor(1.3246, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02364915981888771
loss_c:0.9582569003105164
tensor(1.3855, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024298282340168953
loss_c:0.7738110423088074
tensor(1.2933, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02544594369828701
loss_c:1.0020320415496826
tensor(1.4148, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022116560488939285
loss_c:0.8906034231185913
tensor(1.3448, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03666647896170616
loss_c:0.8165581226348877
tensor(1.3621, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019600020721554756
loss_c:0.9412474632263184
tensor(1.3612, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019159462302923203
loss_c:0.8862019777297974
tensor(1.3311, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023464618250727654
loss_c:0.9212619662284851
tensor(1.3656, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02296811155974865
loss_c:1.0127899646759033
tensor(1.4108, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016123561188578606
loss_c:0.8787769675254822
tensor(1.3154, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02069287933409214
loss_c:0.9952539801597595
tensor(1.3930, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03088930994272232
loss_c:0.9585098028182983
tensor(1.4131, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03240833804011345
loss_c:0.9165703654289246
tensor(1.3973, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027771813794970512
loss_c:0.9558867812156677
tensor(1.3998, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025351127609610558
loss_c:0.9428853392601013
tensor(1.3837, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024699412286281586
loss_c:0.8995562791824341
tensor(1.3587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02965954877436161
loss_c:1.019553780555725
tensor(1.4400, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03454340621829033
loss_c:1.1648749113082886
tensor(1.5342, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027455098927021027
loss_c:0.9640625715255737
tensor(1.4027, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020569659769535065
loss_c:0.7794482707977295
tensor(1.2804, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020759031176567078
loss_c:0.9070515036582947
tensor(1.3472, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019865795969963074
loss_c:0.853797197341919
tensor(1.3160, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0184517540037632
loss_c:0.896986186504364
tensor(1.3328, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023450708016753197
loss_c:0.8771872520446777
tensor(1.3420, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017526298761367798
loss_c:0.8514422178268433
tensor(1.3054, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01817130111157894
loss_c:0.993750274181366
tensor(1.3817, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0292604211717844
loss_c:1.0438073873519897
tensor(1.4512, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021540213376283646
loss_c:0.880388617515564
tensor(1.3359, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02638310380280018
loss_c:1.0173307657241821
tensor(1.4261, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05374853312969208
loss_c:0.883669376373291
tensor(1.4649, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028075581416487694
loss_c:1.022388219833374
tensor(1.4354, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032195694744586945
loss_c:0.9449304938316345
tensor(1.4115, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0469815656542778
loss_c:0.8955116271972656
tensor(1.4444, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02998395450413227
loss_c:1.285757303237915
tensor(1.5799, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1026092916727066
loss_c:0.9658654928207397
tensor(1.7012, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01651494950056076
loss_c:0.8805677890777588
tensor(1.3161, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023670222610235214
loss_c:0.9146584272384644
tensor(1.3621, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02074877731502056
loss_c:0.8132237195968628
tensor(1.2980, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02509993314743042
loss_c:0.9825358390808105
tensor(1.4030, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03973550349473953
loss_c:0.9469559192657471
tensor(1.4420, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020608600229024887
loss_c:1.0271644592285156
tensor(1.4086, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022958427667617798
loss_c:0.9370772242546082
tensor(1.3711, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016678549349308014
loss_c:0.9715501666069031
tensor(1.3644, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036749910563230515
loss_c:0.8560077548027039
tensor(1.3830, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04105488210916519
loss_c:0.9636937379837036
tensor(1.4557, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030141064897179604
loss_c:0.9039028882980347
tensor(1.3820, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018308795988559723
loss_c:0.7654932737350464
tensor(1.2640, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017244357615709305
loss_c:0.8624131083488464
tensor(1.3101, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0207715705037117
loss_c:0.8142463564872742
tensor(1.2988, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01660042069852352
loss_c:0.9609836339950562
tensor(1.3587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02623129077255726
loss_c:0.9519538879394531
tensor(1.3916, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029293891042470932
loss_c:0.921781063079834
tensor(1.3879, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022150704637169838
loss_c:0.9027074575424194
tensor(1.3500, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017554160207509995
loss_c:0.9893754720687866
tensor(1.3771, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.061543360352516174
loss_c:0.9940482974052429
tensor(1.5521, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01618991605937481
loss_c:0.8462802767753601
tensor(1.2972, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025565341114997864
loss_c:0.7823107242584229
tensor(1.3006, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0355166420340538
loss_c:0.986743152141571
tensor(1.4462, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018577691167593002
loss_c:0.9453551173210144
tensor(1.3581, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023223478347063065
loss_c:0.9357573390007019
tensor(1.3713, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03648338094353676
loss_c:0.8371109962463379
tensor(1.3720, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022539779543876648
loss_c:0.9816583395004272
tensor(1.3926, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02871222421526909
loss_c:1.0996893644332886
tensor(1.4786, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017553145065903664
loss_c:0.8712403178215027
tensor(1.3153, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03626077249646187
loss_c:0.9035582542419434
tensor(1.4058, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023780686780810356
loss_c:1.0156967639923096
tensor(1.4153, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027079300954937935
loss_c:0.9674075841903687
tensor(1.4030, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024778472259640694
loss_c:1.1645160913467407
tensor(1.4970, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02458968199789524
loss_c:0.9926905632019043
tensor(1.4064, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018173737451434135
loss_c:1.0359067916870117
tensor(1.4036, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021465498954057693
loss_c:0.9495062232017517
tensor(1.3714, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016552504152059555
loss_c:0.9929103851318359
tensor(1.3746, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05762471258640289
loss_c:1.0628029108047485
tensor(1.5738, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03676576912403107
loss_c:0.909845769405365
tensor(1.4114, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07961971312761307
loss_c:0.9574551582336426
tensor(1.6062, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03256189078092575
loss_c:0.8697901964187622
tensor(1.3738, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03675807639956474
loss_c:0.9640664458274841
tensor(1.4394, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02752472460269928
loss_c:0.9691604971885681
tensor(1.4056, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04979079216718674
loss_c:0.9321355819702148
tensor(1.4740, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02962837740778923
loss_c:0.9800448417663574
tensor(1.4195, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04491076245903969
loss_c:0.9498955607414246
tensor(1.4638, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02296064980328083
loss_c:0.8987299799919128
tensor(1.3512, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022342680022120476
loss_c:1.034253478050232
tensor(1.4192, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02812231332063675
loss_c:0.9161571860313416
tensor(1.3805, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030039189383387566
loss_c:1.0041618347167969
tensor(1.4336, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024480797350406647
loss_c:1.0197739601135254
tensor(1.4201, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018492184579372406
loss_c:0.9858864545822144
tensor(1.3793, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02224442921578884
loss_c:0.9780076742172241
tensor(1.3897, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06066322326660156
loss_c:1.1425871849060059
tensor(1.6240, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027268623933196068
loss_c:0.8683952689170837
tensor(1.3525, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03791530802845955
loss_c:0.8110365271568298
tensor(1.3641, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021174632012844086
loss_c:0.9339547157287598
tensor(1.3629, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03250560164451599
loss_c:1.1157277822494507
tensor(1.5007, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04404289275407791
loss_c:0.8635448217391968
tensor(1.4149, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018766343593597412
loss_c:1.087315320968628
tensor(1.4329, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018654879182577133
loss_c:0.8946061134338379
tensor(1.3330, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025810595601797104
loss_c:0.8358129858970642
tensor(1.3303, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024456152692437172
loss_c:0.9398152232170105
tensor(1.3787, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020217139273881912
loss_c:1.0741366147994995
tensor(1.4317, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018674472346901894
loss_c:0.8973571062088013
tensor(1.3345, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021074319258332253
loss_c:0.9283918142318726
tensor(1.3598, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018713416531682014
loss_c:0.8887583613395691
tensor(1.3302, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016171544790267944
loss_c:0.9327410459518433
tensor(1.3430, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028538556769490242
loss_c:1.0312718152999878
tensor(1.4416, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04490100219845772
loss_c:1.0800082683563232
tensor(1.5301, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018626533448696136
loss_c:0.887690007686615
tensor(1.3291, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019781777635216713
loss_c:0.9410831332206726
tensor(1.3611, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041402652859687805
loss_c:0.9493823051452637
tensor(1.4494, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01897951401770115
loss_c:0.9918138384819031
tensor(1.3840, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021014779806137085
loss_c:1.0361301898956299
tensor(1.4148, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024213595315814018
loss_c:1.0943869352340698
tensor(1.4572, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03533577173948288
loss_c:1.0603454113006592
tensor(1.4830, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05261502042412758
loss_c:1.1878480911254883
tensor(1.6162, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03776504844427109
loss_c:1.0294685363769531
tensor(1.4766, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017875956371426582
loss_c:0.913693904876709
tensor(1.3393, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01868756301701069
loss_c:0.9042591452598572
tensor(1.3377, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030003197491168976
loss_c:1.0059868097305298
tensor(1.4341, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017181022092700005
loss_c:0.8687803745269775
tensor(1.3136, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043378282338380814
loss_c:0.8792155981063843
tensor(1.4215, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03192121163010597
loss_c:0.9429937601089478
tensor(1.4093, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03092547133564949
loss_c:1.122667670249939
tensor(1.4975, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02154768817126751
loss_c:0.9030067920684814
tensor(1.3482, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05255647748708725
loss_c:1.0620653629302979
tensor(1.5511, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041623346507549286
loss_c:0.9788116812705994
tensor(1.4656, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06583763659000397
loss_c:1.0386028289794922
tensor(1.5908, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028333520516753197
loss_c:1.0274410247802734
tensor(1.4385, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02626846171915531
loss_c:1.197324514389038
tensor(1.5173, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017024004831910133
loss_c:0.8535202741622925
tensor(1.3057, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021073535084724426
loss_c:1.137265682220459
tensor(1.4663, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017886115238070488
loss_c:0.8207566142082214
tensor(1.2925, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038653191179037094
loss_c:1.208667516708374
tensor(1.5708, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01901913806796074
loss_c:0.9322266578674316
tensor(1.3538, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02149788662791252
loss_c:0.9285629987716675
tensor(1.3616, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0303368978202343
loss_c:0.8417813181877136
tensor(1.3517, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026151617988944054
loss_c:0.9156462550163269
tensor(1.3730, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02173285000026226
loss_c:0.9936283826828003
tensor(1.3956, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06089821457862854
loss_c:1.0063073635101318
tensor(1.5540, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030112240463495255
loss_c:0.9505869746208191
tensor(1.4062, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019948318600654602
loss_c:0.8876643180847168
tensor(1.3348, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024535106495022774
loss_c:0.8652310371398926
tensor(1.3412, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021498508751392365
loss_c:0.8175870776176453
tensor(1.3052, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01962433010339737
loss_c:0.8591251373291016
tensor(1.3190, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028253745287656784
loss_c:1.0735085010528564
tensor(1.4615, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04960726946592331
loss_c:0.9713379144668579
tensor(1.4924, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020008690655231476
loss_c:0.9710668325424194
tensor(1.3774, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02515493705868721
loss_c:0.9430878162384033
tensor(1.3831, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03664432466030121
loss_c:1.0641694068908691
tensor(1.4894, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019786523655056953
loss_c:0.8352335691452026
tensor(1.3073, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025438711047172546
loss_c:0.9867441058158875
tensor(1.4064, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04868746176362038
loss_c:0.997302234172821
tensor(1.5021, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04095929116010666
loss_c:1.0008273124694824
tensor(1.4739, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021296031773090363
loss_c:0.9346725344657898
tensor(1.3638, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06207916885614395
loss_c:0.911689043045044
tensor(1.5103, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021234765648841858
loss_c:0.8854517936706543
tensor(1.3385, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023587970063090324
loss_c:1.2292507886886597
tensor(1.5232, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024288274347782135
loss_c:0.9800561666488647
tensor(1.3986, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024535341188311577
loss_c:0.939356803894043
tensor(1.3788, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06188707798719406
loss_c:1.005243182182312
tensor(1.5568, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02416408434510231
loss_c:0.910439670085907
tensor(1.3627, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029071319848299026
loss_c:1.0213879346847534
tensor(1.4383, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02722373604774475
loss_c:0.8392415046691895
tensor(1.3382, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02547115460038185
loss_c:0.8975412249565125
tensor(1.3612, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032734259963035583
loss_c:0.9686304330825806
tensor(1.4254, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04699723422527313
loss_c:1.1141846179962158
tensor(1.5546, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04720761254429817
loss_c:1.0291461944580078
tensor(1.5119, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05268072336912155
loss_c:0.8494259715080261
tensor(1.4410, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027441244572401047
loss_c:0.94712895154953
tensor(1.3941, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017323773354291916
loss_c:0.9281584024429321
tensor(1.3458, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02572363242506981
loss_c:0.8787829279899597
tensor(1.3527, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020257286727428436
loss_c:0.9836171865463257
tensor(1.3854, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021534990519285202
loss_c:0.9400321841239929
tensor(1.3680, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02169661968946457
loss_c:0.9682774543762207
tensor(1.3831, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031246395781636238
loss_c:0.9701189398765564
tensor(1.4204, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021842682734131813
loss_c:0.8307384848594666
tensor(1.3133, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01996307261288166
loss_c:0.882807195186615
tensor(1.3327, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020548522472381592
loss_c:0.9687921404838562
tensor(1.3789, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03165730834007263
loss_c:0.834758460521698
tensor(1.3527, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028850749135017395
loss_c:0.9321746826171875
tensor(1.3918, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03485269472002983
loss_c:0.8848168253898621
tensor(1.3905, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023639218881726265
loss_c:0.8973433375358582
tensor(1.3540, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02164514549076557
loss_c:1.0064634084701538
tensor(1.4023, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019042160362005234
loss_c:1.0358502864837646
tensor(1.4074, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018714338541030884
loss_c:0.856534481048584
tensor(1.3140, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06013099476695061
loss_c:0.9701379537582397
tensor(1.5315, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024227231740951538
loss_c:0.9137877225875854
tensor(1.3645, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04234454035758972
loss_c:0.9438912272453308
tensor(1.4497, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01795344054698944
loss_c:1.0250405073165894
tensor(1.3976, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019293205812573433
loss_c:0.9758827090263367
tensor(1.3775, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019796358421444893
loss_c:0.8340178728103638
tensor(1.3062, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024200931191444397
loss_c:0.965239942073822
tensor(1.3908, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024410726502537727
loss_c:0.9050229787826538
tensor(1.3606, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019286813214421272
loss_c:0.8913286924362183
tensor(1.3337, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022123966366052628
loss_c:0.9383322596549988
tensor(1.3688, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021331626921892166
loss_c:1.123651385307312
tensor(1.4614, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031640466302633286
loss_c:0.9091198444366455
tensor(1.3906, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019184300675988197
loss_c:0.9939695596694946
tensor(1.3860, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02283274382352829
loss_c:1.0000085830688477
tensor(1.4033, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022821398451924324
loss_c:1.030635118484497
tensor(1.4190, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020636260509490967
loss_c:0.8797847628593445
tensor(1.3325, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03043271414935589
loss_c:0.9100428819656372
tensor(1.3864, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02065076120197773
loss_c:0.958852231502533
tensor(1.3733, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023322835564613342
loss_c:0.935505747795105
tensor(1.3717, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03146062418818474
loss_c:1.1065605878829956
tensor(1.4920, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01998990587890148
loss_c:0.9625047445297241
tensor(1.3724, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015808723866939545
loss_c:0.9694365859031677
tensor(1.3594, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03881219029426575
loss_c:0.904755711555481
tensor(1.4169, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025167278945446014
loss_c:1.112571120262146
tensor(1.4702, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01648567244410515
loss_c:0.8783754706382751
tensor(1.3148, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0399436429142952
loss_c:0.8612467050552368
tensor(1.3992, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021992169320583344
loss_c:0.9464390277862549
tensor(1.3718, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026525823399424553
loss_c:1.0697314739227295
tensor(1.4534, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019793927669525146
loss_c:0.8636688590049744
tensor(1.3202, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019557591527700424
loss_c:0.9107858538627625
tensor(1.3436, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02536526694893837
loss_c:0.8928966522216797
tensor(1.3575, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016695890575647354
loss_c:0.9517590999603271
tensor(1.3531, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028723398223519325
loss_c:1.1851482391357422
tensor(1.5218, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0347304530441761
loss_c:0.8447302579879761
tensor(1.3702, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027292458340525627
loss_c:0.9854304194450378
tensor(1.4129, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020781438797712326
loss_c:0.7775566577911377
tensor(1.2795, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01792958937585354
loss_c:0.8683713674545288
tensor(1.3148, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06717930734157562
loss_c:1.0347692966461182
tensor(1.5994, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02458338811993599
loss_c:0.7990231513977051
tensor(1.3058, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03139143064618111
loss_c:1.1703418493270874
tensor(1.5250, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020053785294294357
loss_c:0.9188203811645508
tensor(1.3494, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035915784537792206
loss_c:0.8645276427268982
tensor(1.3853, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01652800291776657
loss_c:0.9371210932731628
tensor(1.3446, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023291578516364098
loss_c:0.8689600825309753
tensor(1.3367, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02865760773420334
loss_c:0.9789963960647583
tensor(1.4152, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02369554713368416
loss_c:0.9305340647697449
tensor(1.3701, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03781905025243759
loss_c:1.0744423866271973
tensor(1.5015, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02463201805949211
loss_c:0.9199808835983276
tensor(1.3684, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03352466598153114
loss_c:0.8530579805374146
tensor(1.3697, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023475611582398415
loss_c:0.8563522696495056
tensor(1.3308, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02875729650259018
loss_c:0.9006222486495972
tensor(1.3750, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016315912827849388
loss_c:0.8922264575958252
tensor(1.3205, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.14333738386631012
loss_c:1.0925252437591553
tensor(1.9368, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042833056300878525
loss_c:0.8945183157920837
tensor(1.4284, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016762850806117058
loss_c:0.9031736254692078
tensor(1.3283, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01811736822128296
loss_c:0.9062614440917969
tensor(1.3354, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02642097882926464
loss_c:0.9634224772453308
tensor(1.3982, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0302607212215662
loss_c:0.9941684007644653
tensor(1.4294, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026545902714133263
loss_c:0.9205910563468933
tensor(1.3765, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020966866984963417
loss_c:1.0393340587615967
tensor(1.4161, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023174768313765526
loss_c:0.9288554191589355
tensor(1.3675, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02375796064734459
loss_c:0.9642047882080078
tensor(1.3882, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03472578153014183
loss_c:0.9189144968986511
tensor(1.4079, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02272697724401951
loss_c:0.7744132876396179
tensor(1.2857, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04233482852578163
loss_c:0.8975663185119629
tensor(1.4267, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02961587905883789
loss_c:0.9155206084251404
tensor(1.3860, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02314772829413414
loss_c:0.8434507250785828
tensor(1.3231, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01987498067319393
loss_c:0.9306511878967285
tensor(1.3556, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01652197539806366
loss_c:0.8781107664108276
tensor(1.3152, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01853981241583824
loss_c:0.8799337148666382
tensor(1.3240, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0400589257478714
loss_c:0.9197955131530762
tensor(1.4291, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037855133414268494
loss_c:1.2521159648895264
tensor(1.5936, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02338680438697338
loss_c:0.9553594589233398
tensor(1.3822, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027544967830181122
loss_c:0.9575949907302856
tensor(1.3997, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019801078364253044
loss_c:0.9502128958702087
tensor(1.3655, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024925773963332176
loss_c:0.9265103340148926
tensor(1.3732, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020709244534373283
loss_c:1.0382951498031616
tensor(1.4149, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030624862760305405
loss_c:0.8338202238082886
tensor(1.3473, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020526248961687088
loss_c:1.0607190132141113
tensor(1.4258, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026429573073983192
loss_c:0.9350991249084473
tensor(1.3836, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023325331509113312
loss_c:0.9276103377342224
tensor(1.3675, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021027646958827972
loss_c:0.8994683623313904
tensor(1.3438, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05848049372434616
loss_c:0.9861253499984741
tensor(1.5365, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021420422941446304
loss_c:0.9355459213256836
tensor(1.3641, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0166338961571455
loss_c:0.9830503463745117
tensor(1.3699, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021656110882759094
loss_c:0.9346612691879272
tensor(1.3645, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022433552891016006
loss_c:0.9463986158370972
tensor(1.3737, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019343655556440353
loss_c:0.9237838983535767
tensor(1.3497, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019716067239642143
loss_c:0.8950197100639343
tensor(1.3361, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024754060432314873
loss_c:1.0692565441131592
tensor(1.4467, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024112919345498085
loss_c:0.8527127504348755
tensor(1.3315, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0329459123313427
loss_c:0.9976581335067749
tensor(1.4419, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02146110124886036
loss_c:0.8861979246139526
tensor(1.3383, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01721484214067459
loss_c:0.9435704946517944
tensor(1.3512, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04607995226979256
loss_c:0.8489294052124023
tensor(1.4171, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02234543487429619
loss_c:1.0746111869812012
tensor(1.4397, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017462631687521935
loss_c:0.8033668398857117
tensor(1.2792, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.049874987453222275
loss_c:0.8748065233230591
tensor(1.4459, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021325115114450455
loss_c:0.9231764674186707
tensor(1.3569, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023848075419664383
loss_c:0.8790163397789001
tensor(1.3440, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02350572496652603
loss_c:0.814996600151062
tensor(1.3093, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018564753234386444
loss_c:0.9122761487960815
tensor(1.3401, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020418358966708183
loss_c:0.877964437007904
tensor(1.3296, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018259814009070396
loss_c:0.8418928980827332
tensor(1.3021, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01866486854851246
loss_c:0.9062210321426392
tensor(1.3372, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022506466135382652
loss_c:0.9605867266654968
tensor(1.3810, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01907205954194069
loss_c:0.9322940707206726
tensor(1.3523, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026703285053372383
loss_c:0.8493669033050537
tensor(1.3397, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023637128993868828
loss_c:1.0975607633590698
tensor(1.4571, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019502980634570122
loss_c:1.0338903665542603
tensor(1.4070, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014024238102138042
loss_c:0.8963636159896851
tensor(1.3128, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.12102744728326797
loss_c:1.0639861822128296
tensor(1.8355, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0159015916287899
loss_c:0.9903144240379333
tensor(1.3696, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031870536506175995
loss_c:1.255016803741455
tensor(1.5728, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02517489530146122
loss_c:0.9360593557357788
tensor(1.3788, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04606245085597038
loss_c:1.0222303867340088
tensor(1.5083, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029475850984454155
loss_c:0.8692418932914734
tensor(1.3614, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.052318282425403595
loss_c:0.9977496862411499
tensor(1.5205, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03613759204745293
loss_c:0.8686496615409851
tensor(1.3879, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04563210904598236
loss_c:0.8771967887878418
tensor(1.4303, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.059165604412555695
loss_c:0.8933155536651611
tensor(1.4927, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024994583800435066
loss_c:0.9073367118835449
tensor(1.3633, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02057231217622757
loss_c:0.9910544157028198
tensor(1.3894, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022040758281946182
loss_c:1.0868654251098633
tensor(1.4452, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0679175853729248
loss_c:0.9238569736480713
tensor(1.5417, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04190171882510185
loss_c:1.1688694953918457
tensor(1.5662, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0234996248036623
loss_c:0.8888953924179077
tensor(1.3481, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03008904680609703
loss_c:0.9768438339233398
tensor(1.4197, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025440802797675133
loss_c:0.8472694158554077
tensor(1.3342, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025251997634768486
loss_c:1.2308306694030762
tensor(1.5326, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03592892736196518
loss_c:0.9401222467422485
tensor(1.4233, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021199984475970268
loss_c:0.8845514059066772
tensor(1.3373, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017845280468463898
loss_c:0.8652183413505554
tensor(1.3143, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022535236552357674
loss_c:0.8104011416435242
tensor(1.3041, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03666573762893677
loss_c:0.9181513786315918
tensor(1.4146, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022272491827607155
loss_c:1.018157720565796
tensor(1.4107, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02818467654287815
loss_c:1.0097192525863647
tensor(1.4292, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0460396446287632
loss_c:0.8980240821838379
tensor(1.4404, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016393814235925674
loss_c:0.8732055425643921
tensor(1.3130, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018306825309991837
loss_c:0.8329862356185913
tensor(1.2996, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02843298204243183
loss_c:0.9046096205711365
tensor(1.3758, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029204225167632103
loss_c:0.8898251056671143
tensor(1.3711, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018576713278889656
loss_c:0.8914851546287537
tensor(1.3309, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05428868904709816
loss_c:1.096997857093811
tensor(1.5753, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024739932268857956
loss_c:1.1264523267745972
tensor(1.4765, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018384672701358795
loss_c:0.804505467414856
tensor(1.2851, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03357129544019699
loss_c:1.0748475790023804
tensor(1.4838, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030903542414307594
loss_c:0.9814122915267944
tensor(1.4251, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030579984188079834
loss_c:0.8804776072502136
tensor(1.3715, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03014824353158474
loss_c:1.0683916807174683
tensor(1.4672, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024462437257170677
loss_c:0.8996989130973816
tensor(1.3579, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03483586013317108
loss_c:0.8536334037780762
tensor(1.3741, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025744551792740822
loss_c:0.8053441047668457
tensor(1.3140, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02251558005809784
loss_c:0.9692785143852234
tensor(1.3864, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09398100525140762
loss_c:0.9426807165145874
tensor(1.6487, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020995311439037323
loss_c:0.8749715685844421
tensor(1.3317, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03063155524432659
loss_c:0.9123455882072449
tensor(1.3882, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018850523978471756
loss_c:1.0354149341583252
tensor(1.4068, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02358390763401985
loss_c:1.0312767028808594
tensor(1.4228, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021351616829633713
loss_c:0.9356307983398438
tensor(1.3647, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02827182039618492
loss_c:1.0012402534484863
tensor(1.4253, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025017252191901207
loss_c:0.9341976642608643
tensor(1.3780, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07073664665222168
loss_c:1.0076265335083008
tensor(1.5916, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028048735111951828
loss_c:0.8367060422897339
tensor(1.3391, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02146182395517826
loss_c:1.0221214294433594
tensor(1.4100, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024341009557247162
loss_c:0.7796216011047363
tensor(1.2953, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028526533395051956
loss_c:0.8897365927696228
tensor(1.3684, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023446738719940186
loss_c:0.8686715364456177
tensor(1.3381, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022540535777807236
loss_c:0.8912588357925415
tensor(1.3463, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01609622687101364
loss_c:0.7804210186004639
tensor(1.2641, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021982474252581596
loss_c:1.0257174968719482
tensor(1.4140, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01974252425134182
loss_c:0.8242896795272827
tensor(1.3007, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027019942179322243
loss_c:1.1297599077224731
tensor(1.4874, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036663807928562164
loss_c:0.9106597900390625
tensor(1.4105, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0226104985922575
loss_c:0.8988277316093445
tensor(1.3503, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024714751169085503
loss_c:1.0428801774978638
tensor(1.4334, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043465789407491684
loss_c:0.8884587287902832
tensor(1.4252, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032849159091711044
loss_c:0.90625
tensor(1.3935, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09940589964389801
loss_c:1.0173981189727783
tensor(1.7079, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024111373350024223
loss_c:0.8307763338088989
tensor(1.3206, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034990571439266205
loss_c:1.1433027982711792
tensor(1.5252, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019594509154558182
loss_c:0.8556640148162842
tensor(1.3163, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021993834525346756
loss_c:0.8740493655204773
tensor(1.3351, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029854988679289818
loss_c:0.8793129920959473
tensor(1.3679, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0171345304697752
loss_c:0.9338191747665405
tensor(1.3477, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0310023482888937
loss_c:0.9802460074424744
tensor(1.4249, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027270641177892685
loss_c:0.7794523239135742
tensor(1.3060, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04478155076503754
loss_c:0.9329898357391357
tensor(1.4530, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021896202117204666
loss_c:0.7375167608261108
tensor(1.2635, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04160834848880768
loss_c:1.0073438882827759
tensor(1.4796, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02233516424894333
loss_c:1.0662269592285156
tensor(1.4368, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046682000160217285
loss_c:0.8268074989318848
tensor(1.4046, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01921246573328972
loss_c:0.8157355189323425
tensor(1.2940, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02549462579190731
loss_c:0.8749634027481079
tensor(1.3489, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03733864054083824
loss_c:0.8886436820030212
tensor(1.4012, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022619476541876793
loss_c:1.0783900022506714
tensor(1.4445, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019792741164565086
loss_c:0.9321913719177246
tensor(1.3572, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09184428304433823
loss_c:0.9059518575668335
tensor(1.6180, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020913464948534966
loss_c:0.8565597534179688
tensor(1.3218, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030376439914107323
loss_c:0.8097047805786133
tensor(1.3333, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019589576870203018
loss_c:0.9397879838943481
tensor(1.3605, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019873104989528656
loss_c:0.8295060992240906
tensor(1.3037, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038931190967559814
loss_c:0.9399862289428711
tensor(1.4340, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022094253450632095
loss_c:0.9418612718582153
tensor(1.3712, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017111826688051224
loss_c:0.9372618198394775
tensor(1.3499, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02312810719013214
loss_c:0.9074652194976807
tensor(1.3570, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021831126883625984
loss_c:0.9682563543319702
tensor(1.3841, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028126517310738564
loss_c:0.9128227233886719
tensor(1.3788, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0361323244869709
loss_c:1.1635832786560059
tensor(1.5412, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017149636521935463
loss_c:0.9463531374931335
tensor(1.3547, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027273306623101234
loss_c:0.9715762138366699
tensor(1.4064, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04018983244895935
loss_c:1.1892752647399902
tensor(1.5702, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04081861674785614
loss_c:0.8911498785018921
tensor(1.4157, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03821231424808502
loss_c:1.0412548780441284
tensor(1.4847, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030057348310947418
loss_c:0.7777261734008789
tensor(1.3152, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035434555262327194
loss_c:0.7735389471054077
tensor(1.3335, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019389940425753593
loss_c:0.9251068830490112
tensor(1.3519, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024395909160375595
loss_c:0.9880036115646362
tensor(1.4040, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02978174388408661
loss_c:0.934177041053772
tensor(1.3963, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0282762348651886
loss_c:1.1734814643859863
tensor(1.5161, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01978633552789688
loss_c:0.9528407454490662
tensor(1.3679, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0184877198189497
loss_c:0.9633207321166992
tensor(1.3685, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01868775300681591
loss_c:0.9180693626403809
tensor(1.3455, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021526111289858818
loss_c:0.8817340731620789
tensor(1.3372, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020130014047026634
loss_c:0.9347587823867798
tensor(1.3596, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020505009219050407
loss_c:1.0173710584640503
tensor(1.4042, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05016014724969864
loss_c:0.9900161623954773
tensor(1.5038, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021196825429797173
loss_c:0.8256758451461792
tensor(1.3065, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02484973333775997
loss_c:0.8653117418289185
tensor(1.3413, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033955223858356476
loss_c:0.9025579690933228
tensor(1.3958, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031164471060037613
loss_c:1.0054043531417847
tensor(1.4388, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019529981538653374
loss_c:0.8961743116378784
tensor(1.3368, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026520244777202606
loss_c:0.9579862356185913
tensor(1.3961, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023370325565338135
loss_c:1.0416443347930908
tensor(1.4276, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.060843512415885925
loss_c:0.9116504192352295
tensor(1.5049, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0921836569905281
loss_c:1.1049976348876953
tensor(1.7273, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021395334973931313
loss_c:0.8688186407089233
tensor(1.3297, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021772727370262146
loss_c:0.9288093447685242
tensor(1.3625, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01931161992251873
loss_c:1.0874371528625488
tensor(1.4358, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0239374041557312
loss_c:0.8903074264526367
tensor(1.3509, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017255660146474838
loss_c:0.8859624862670898
tensor(1.3229, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04463653266429901
loss_c:0.8915368914604187
tensor(1.4312, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028991462662816048
loss_c:0.8898903727531433
tensor(1.3701, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017940988764166832
loss_c:0.827717661857605
tensor(1.2952, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027710692957043648
loss_c:0.9379293322563171
tensor(1.3902, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020496824756264687
loss_c:1.0315272808074951
tensor(1.4113, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022681506350636482
loss_c:0.8289684653282166
tensor(1.3141, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021325698122382164
loss_c:0.8799874186515808
tensor(1.3354, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020117375999689102
loss_c:0.957939088344574
tensor(1.3714, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016844211146235466
loss_c:0.9200652837753296
tensor(1.3390, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019253499805927277
loss_c:0.9518074989318848
tensor(1.3648, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019810620695352554
loss_c:0.9040257334709167
tensor(1.3419, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023233523592352867
loss_c:0.9629222750663757
tensor(1.3859, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025279894471168518
loss_c:0.9322239756584167
tensor(1.3777, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018692148849368095
loss_c:0.958562970161438
tensor(1.3658, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028400132432579994
loss_c:0.9421422481536865
tensor(1.3950, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02240457758307457
loss_c:1.0418531894683838
tensor(1.4237, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022297397255897522
loss_c:0.9357654452323914
tensor(1.3678, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05009055510163307
loss_c:0.9305745959281921
tensor(1.4741, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04547763988375664
loss_c:0.9262291789054871
tensor(1.4538, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020850898697972298
loss_c:0.926235556602478
tensor(1.3571, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02687026374042034
loss_c:0.8831185102462769
tensor(1.3582, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042384710162878036
loss_c:0.9126841425895691
tensor(1.4346, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022067397832870483
loss_c:0.9379655718803406
tensor(1.3679, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042204756289720535
loss_c:1.0243858098983765
tensor(1.4922, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023202108219265938
loss_c:0.8870028257369995
tensor(1.3458, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024497702717781067
loss_c:0.9651827216148376
tensor(1.3917, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020918328315019608
loss_c:0.8873473405838013
tensor(1.3370, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025613537058234215
loss_c:0.8779147863388062
tensor(1.3505, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021543843671679497
loss_c:0.8658837676048279
tensor(1.3282, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020329447463154793
loss_c:0.8403367400169373
tensor(1.3101, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020232398062944412
loss_c:0.8231391310691833
tensor(1.3007, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02269110642373562
loss_c:0.9411510229110718
tensor(1.3720, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018912266939878464
loss_c:0.868518590927124
tensor(1.3190, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01869121752679348
loss_c:0.9872137308120728
tensor(1.3802, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024865806102752686
loss_c:1.0044913291931152
tensor(1.4137, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016398265957832336
loss_c:0.8907884359359741
tensor(1.3205, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024130186066031456
loss_c:0.8697730898857117
tensor(1.3401, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03350549563765526
loss_c:0.8679758906364441
tensor(1.3765, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017337432131171227
loss_c:0.928911566734314
tensor(1.3440, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.13190826773643494
loss_c:1.1019481420516968
tensor(1.8926, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01840941049158573
loss_c:0.863530158996582
tensor(1.3140, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02387990616261959
loss_c:0.9066321849822998
tensor(1.3584, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028771013021469116
loss_c:1.0858685970306396
tensor(1.4720, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02373998984694481
loss_c:0.8856357932090759
tensor(1.3469, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01640496402978897
loss_c:0.9510089159011841
tensor(1.3521, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04541267082095146
loss_c:0.9090774059295654
tensor(1.4451, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019038891419768333
loss_c:1.0426208972930908
tensor(1.4107, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0229165181517601
loss_c:1.0581072568893433
tensor(1.4342, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024400126188993454
loss_c:0.9673360586166382
tensor(1.3924, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02107509970664978
loss_c:0.8629916906356812
tensor(1.3246, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028510741889476776
loss_c:0.9888791441917419
tensor(1.4200, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028346138074994087
loss_c:0.8258709907531738
tensor(1.3339, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024091923609375954
loss_c:0.9769128561019897
tensor(1.3962, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03204149752855301
loss_c:0.9229921102523804
tensor(1.3994, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02210291102528572
loss_c:0.8794635534286499
tensor(1.3373, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021190684288740158
loss_c:0.9025006294250488
tensor(1.3457, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023599831387400627
loss_c:0.8749862909317017
tensor(1.3409, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020352551713585854
loss_c:0.8572161197662354
tensor(1.3187, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022504815831780434
loss_c:0.9081601500511169
tensor(1.3538, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019882168620824814
loss_c:1.0309855937957764
tensor(1.4078, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042920470237731934
loss_c:0.8631582260131836
tensor(1.4114, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05264429375529289
loss_c:0.7808752059936523
tensor(1.4070, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020268745720386505
loss_c:0.8723732829093933
tensor(1.3261, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026541251689195633
loss_c:1.2192472219467163
tensor(1.5330, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02084198035299778
loss_c:0.9830747842788696
tensor(1.3865, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03687802702188492
loss_c:0.9001911878585815
tensor(1.4068, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026928652077913284
loss_c:0.9254297018051147
tensor(1.3804, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023909134790301323
loss_c:0.8620201945304871
tensor(1.3352, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03167615085840225
loss_c:0.8365294337272644
tensor(1.3527, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02701413631439209
loss_c:0.8944944143295288
tensor(1.3645, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031090164557099342
loss_c:0.9326180815696716
tensor(1.4007, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01659722626209259
loss_c:0.8103970289230347
tensor(1.2790, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022095832973718643
loss_c:1.0120775699615479
tensor(1.4067, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024749137461185455
loss_c:0.9503772258758545
tensor(1.3848, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02002745121717453
loss_c:0.9168026447296143
tensor(1.3484, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022494081407785416
loss_c:0.9254252910614014
tensor(1.3627, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04133932292461395
loss_c:0.7757471799850464
tensor(1.3592, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019507767632603645
loss_c:1.1161434650421143
tensor(1.4510, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020220763981342316
loss_c:0.9041092395782471
tensor(1.3424, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029548168182373047
loss_c:0.850348174571991
tensor(1.3514, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022135218605399132
loss_c:0.937532901763916
tensor(1.3676, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021290168166160583
loss_c:0.9176071882247925
tensor(1.3537, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01805456541478634
loss_c:0.8133243322372437
tensor(1.2859, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02459503710269928
loss_c:0.840911328792572
tensor(1.3266, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027433745563030243
loss_c:0.934040904045105
tensor(1.3869, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027779987081885338
loss_c:0.8856098651885986
tensor(1.3628, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03916972875595093
loss_c:1.1336801052093506
tensor(1.5394, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018817979842424393
loss_c:0.8441933393478394
tensor(1.3049, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021077347919344902
loss_c:0.9618959426879883
tensor(1.3760, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020483264699578285
loss_c:0.8884902000427246
tensor(1.3349, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017871158197522163
loss_c:0.9242421984672546
tensor(1.3432, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019673608243465424
loss_c:0.9941743612289429
tensor(1.3873, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.060866523534059525
loss_c:0.9233293533325195
tensor(1.5167, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028436316177248955
loss_c:1.0539960861206055
tensor(1.4543, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038212113082408905
loss_c:0.9453113079071045
tensor(1.4365, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024209139868617058
loss_c:0.9795708060264587
tensor(1.3979, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017848651856184006
loss_c:0.8804904818534851
tensor(1.3200, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023573653772473335
loss_c:1.052298665046692
tensor(1.4336, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021950796246528625
loss_c:0.9485120177268982
tensor(1.3724, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019310418516397476
loss_c:0.9563088417053223
tensor(1.3658, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021384449675679207
loss_c:0.9063295125961304
tensor(1.3479, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03469959273934364
loss_c:0.9006656408309937
tensor(1.3989, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023626791313290596
loss_c:0.961890459060669
tensor(1.3861, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04592127725481987
loss_c:0.9961017370223999
tensor(1.4946, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04233980551362038
loss_c:0.9006315469741821
tensor(1.4299, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016140982508659363
loss_c:0.8314541578292847
tensor(1.2873, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026455918326973915
loss_c:0.923961341381073
tensor(1.3777, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07404301315546036
loss_c:0.9879662394523621
tensor(1.6041, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022549590095877647
loss_c:0.7984318733215332
tensor(1.2960, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03373316675424576
loss_c:0.9846608638763428
tensor(1.4389, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03947283700108528
loss_c:0.8136057257652283
tensor(1.3723, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05117516219615936
loss_c:0.9775238037109375
tensor(1.5053, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029649795964360237
loss_c:1.0580236911773682
tensor(1.4609, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017667600885033607
loss_c:0.8193079829216003
tensor(1.2876, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023378565907478333
loss_c:0.9445816278457642
tensor(1.3763, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025427058339118958
loss_c:1.0427898168563843
tensor(1.4360, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024019328877329826
loss_c:0.7948085069656372
tensor(1.3003, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01839488185942173
loss_c:0.8018584251403809
tensor(1.2816, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03218650072813034
loss_c:0.844054102897644
tensor(1.3586, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06055568531155586
loss_c:1.0672146081924438
tensor(1.5885, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.050792839378118515
loss_c:0.980190634727478
tensor(1.5039, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02189614064991474
loss_c:0.9489877223968506
tensor(1.3729, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025326542556285858
loss_c:0.8714606165885925
tensor(1.3458, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03180979937314987
loss_c:0.9722394943237305
tensor(1.4243, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018297363072633743
loss_c:0.9940738677978516
tensor(1.3825, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01989898458123207
loss_c:0.8918768167495728
tensor(1.3352, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04491948336362839
loss_c:0.8592981100082397
tensor(1.4165, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02203970216214657
loss_c:1.0094079971313477
tensor(1.4054, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020089920610189438
loss_c:0.9866248965263367
tensor(1.3858, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016693437471985817
loss_c:0.7355951070785522
tensor(1.2407, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04115748032927513
loss_c:0.887769877910614
tensor(1.4165, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041865430772304535
loss_c:0.9172492027282715
tensor(1.4348, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016315270215272903
loss_c:0.8332340121269226
tensor(1.2905, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019258761778473854
loss_c:0.8806643486022949
tensor(1.3269, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02515498921275139
loss_c:0.8247101306915283
tensor(1.3206, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032670117914676666
loss_c:0.8848865032196045
tensor(1.3817, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032278116792440414
loss_c:1.015934705734253
tensor(1.4491, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01842006854712963
loss_c:0.8994135856628418
tensor(1.3335, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028318781405687332
loss_c:0.8535283803939819
tensor(1.3481, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02770742028951645
loss_c:0.9165682792663574
tensor(1.3789, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015534968115389347
loss_c:0.9290852546691895
tensor(1.3378, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01702183485031128
loss_c:0.9111014604568481
tensor(1.3341, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04588328301906586
loss_c:0.9282185435295105
tensor(1.4564, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03704965114593506
loss_c:0.8884369730949402
tensor(1.4007, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03241916000843048
loss_c:0.7591790556907654
tensor(1.3142, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018201112747192383
loss_c:0.9219200611114502
tensor(1.3443, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020438900217413902
loss_c:0.888225257396698
tensor(1.3353, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021883483976125717
loss_c:0.9228353500366211
tensor(1.3593, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021752558648586273
loss_c:0.9523156881332397
tensor(1.3744, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028975531458854675
loss_c:1.0118129253387451
tensor(1.4343, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018597479909658432
loss_c:0.8612266778945923
tensor(1.3136, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024409841746091843
loss_c:0.9123454093933105
tensor(1.3636, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01936211809515953
loss_c:0.817300021648407
tensor(1.2932, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01816968247294426
loss_c:0.8591543436050415
tensor(1.3106, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02259843796491623
loss_c:1.1954073905944824
tensor(1.5065, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023516451939940453
loss_c:0.9399983286857605
tensor(1.3746, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04797213897109032
loss_c:1.1956045627593994
tensor(1.6075, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019896194338798523
loss_c:0.910797119140625
tensor(1.3447, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027043884620070457
loss_c:0.7275784015655518
tensor(1.2761, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018410546705126762
loss_c:0.9299928545951843
tensor(1.3489, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019948624074459076
loss_c:0.923161506652832
tensor(1.3513, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.055135779082775116
loss_c:0.987135112285614
tensor(1.5259, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01786748133599758
loss_c:0.8488425612449646
tensor(1.3036, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020355071872472763
loss_c:0.782492995262146
tensor(1.2785, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027097240090370178
loss_c:0.8485506772994995
tensor(1.3404, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02140847034752369
loss_c:0.8301678895950317
tensor(1.3078, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030470704659819603
loss_c:0.8264824151992798
tensor(1.3422, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017453672364354134
loss_c:0.989040732383728
tensor(1.3761, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02032366581261158
loss_c:0.9398848414421082
tensor(1.3615, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020464066416025162
loss_c:0.9297518730163574
tensor(1.3567, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027523456141352654
loss_c:0.9683941602706909
tensor(1.4056, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027643270790576935
loss_c:0.9111700057983398
tensor(1.3757, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021416250616312027
loss_c:0.7580432891845703
tensor(1.2693, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036109767854213715
loss_c:1.0133142471313477
tensor(1.4641, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07407180219888687
loss_c:1.1125205755233765
tensor(1.6704, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024357005953788757
loss_c:0.9488643407821655
tensor(1.3824, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02900899201631546
loss_c:1.1725003719329834
tensor(1.5198, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019268572330474854
loss_c:0.859958291053772
tensor(1.3148, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014569571241736412
loss_c:0.8279203176498413
tensor(1.2789, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021442081779241562
loss_c:0.7818659543991089
tensor(1.2823, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022252600640058517
loss_c:0.829271674156189
tensor(1.3106, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01957838237285614
loss_c:0.789305567741394
tensor(1.2787, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02022610791027546
loss_c:0.9798606634140015
tensor(1.3822, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04212771728634834
loss_c:0.967624843120575
tensor(1.4642, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019650939851999283
loss_c:0.8978564143180847
tensor(1.3364, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017510656267404556
loss_c:0.8827462196350098
tensor(1.3197, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030324211344122887
loss_c:0.8810920715332031
tensor(1.3706, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025301318615674973
loss_c:0.9973921179771423
tensor(1.4120, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04956256225705147
loss_c:0.9800531268119812
tensor(1.5011, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03280162066221237
loss_c:0.8002009391784668
tensor(1.3378, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026793308556079865
loss_c:0.8385014533996582
tensor(1.3338, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029182635247707367
loss_c:0.9811505079269409
tensor(1.4191, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02077013999223709
loss_c:1.1611571311950684
tensor(1.4805, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07053132355213165
loss_c:0.8713831901550293
tensor(1.5281, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01711777225136757
loss_c:0.8705722689628601
tensor(1.3117, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015748539939522743
loss_c:0.9579853415489197
tensor(1.3526, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02141975425183773
loss_c:1.0044983625411987
tensor(1.4001, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02094368077814579
loss_c:0.8086771965026855
tensor(1.2944, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015251033008098602
loss_c:0.8281128406524658
tensor(1.2818, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015553477220237255
loss_c:0.7910348773002625
tensor(1.2634, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03337705507874489
loss_c:0.9040314555168152
tensor(1.3951, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030184008181095123
loss_c:0.8886936902999878
tensor(1.3741, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016788579523563385
loss_c:0.7933577299118042
tensor(1.2695, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025037532672286034
loss_c:0.9197210669517517
tensor(1.3697, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01799093931913376
loss_c:0.9161950945854187
tensor(1.3394, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03422576189041138
loss_c:0.8979452848434448
tensor(1.3953, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03172992169857025
loss_c:0.9019832015037537
tensor(1.3874, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022335678339004517
loss_c:1.0236204862594604
tensor(1.4140, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017859160900115967
loss_c:0.9089273810386658
tensor(1.3349, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03638886287808418
loss_c:0.9190251231193542
tensor(1.4154, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02311144955456257
loss_c:1.0369889736175537
tensor(1.4242, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020926140248775482
loss_c:0.9425580501556396
tensor(1.3651, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019877435639500618
loss_c:0.7867447137832642
tensor(1.2781, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02250475063920021
loss_c:0.9653713703155518
tensor(1.3836, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09925441443920135
loss_c:1.0568976402282715
tensor(1.7446, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017576852813363075
loss_c:0.9536164999008179
tensor(1.3574, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.053739748895168304
loss_c:0.8327822685241699
tensor(1.4399, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04334026202559471
loss_c:0.860658586025238
tensor(1.4124, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02059069648385048
loss_c:0.8765465617179871
tensor(1.3289, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024359511211514473
loss_c:0.9526340365409851
tensor(1.3845, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018919119611382484
loss_c:0.88145512342453
tensor(1.3249, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018484679982066154
loss_c:0.865454375743866
tensor(1.3147, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028696345165371895
loss_c:0.9420899748802185
tensor(1.3963, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019675754010677338
loss_c:0.9687943458557129
tensor(1.3744, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02489546686410904
loss_c:0.9453071355819702
tensor(1.3828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03177233412861824
loss_c:0.8588042259216309
tensor(1.3645, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03881119564175606
loss_c:0.902549684047699
tensor(1.4159, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05796315521001816
loss_c:1.1529587507247925
tensor(1.6254, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019971324130892754
loss_c:0.8578409552574158
tensor(1.3168, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02052619867026806
loss_c:0.9681003093719482
tensor(1.3775, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01745687425136566
loss_c:0.9425141215324402
tensor(1.3517, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025753678753972054
loss_c:0.8952347636222839
tensor(1.3597, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04077953100204468
loss_c:0.9205697774887085
tensor(1.4330, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03448798134922981
loss_c:1.0895192623138428
tensor(1.4974, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021959446370601654
loss_c:0.9264835119247437
tensor(1.3612, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015471870079636574
loss_c:0.7885777354240417
tensor(1.2625, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044991448521614075
loss_c:0.8764505386352539
tensor(1.4263, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015219676308333874
loss_c:0.8821734189987183
tensor(1.3111, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030922356992959976
loss_c:1.250641107559204
tensor(1.5683, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020291456952691078
loss_c:0.9344987869262695
tensor(1.3589, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031757652759552
loss_c:0.8409346342086792
tensor(1.3550, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021703921258449554
loss_c:0.8488940000534058
tensor(1.3193, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023231327533721924
loss_c:0.9742771983146667
tensor(1.3915, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03184937313199043
loss_c:0.8298246264457703
tensor(1.3495, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025877967476844788
loss_c:0.8605202436447144
tensor(1.3420, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04017762839794159
loss_c:1.0726367235183716
tensor(1.5107, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022567018866539
loss_c:0.9100820422172546
tensor(1.3550, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018906651064753532
loss_c:0.7311733961105347
tensor(1.2461, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033520009368658066
loss_c:0.9041306376457214
tensor(1.3954, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025391148403286934
loss_c:0.8989455699920654
tensor(1.3603, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017734475433826447
loss_c:0.8738547563552856
tensor(1.3167, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03815048933029175
loss_c:0.9113008975982666
tensor(1.4176, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015774855390191078
loss_c:0.976036548614502
tensor(1.3628, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0521479956805706
loss_c:0.8611124753952026
tensor(1.4468, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02165134809911251
loss_c:0.861271858215332
tensor(1.3255, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.050857722759246826
loss_c:0.8872808218002319
tensor(1.4554, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024806540459394455
loss_c:0.8781697154045105
tensor(1.3470, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022783057764172554
loss_c:0.8764693140983582
tensor(1.3381, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03141361102461815
loss_c:0.8024901151657104
tensor(1.3332, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022174930199980736
loss_c:1.0681116580963135
tensor(1.4371, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015048644505441189
loss_c:0.9716927409172058
tensor(1.3578, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02551550604403019
loss_c:1.003455400466919
tensor(1.4162, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035952165722846985
loss_c:0.8484629392623901
tensor(1.3755, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01708446443080902
loss_c:0.7600659132003784
tensor(1.2538, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02526995539665222
loss_c:0.9401090145111084
tensor(1.3816, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017098957672715187
loss_c:0.9416688680648804
tensor(1.3500, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023790111765265465
loss_c:0.9253308176994324
tensor(1.3679, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0180625282227993
loss_c:1.0228707790374756
tensor(1.3968, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02330623008310795
loss_c:0.981594443321228
tensor(1.3958, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021212801337242126
loss_c:0.9621466398239136
tensor(1.3771, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04218948259949684
loss_c:0.9218365550041199
tensor(1.4395, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022291172295808792
loss_c:0.9164260625839233
tensor(1.3571, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03300274908542633
loss_c:0.8662471771240234
tensor(1.3734, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021827885881066322
loss_c:0.9005839228630066
tensor(1.3468, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06255719065666199
loss_c:0.948911190032959
tensor(1.5356, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027658751234412193
loss_c:0.8767091631889343
tensor(1.3575, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024588437750935555
loss_c:0.9131919741630554
tensor(1.3646, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0224795900285244
loss_c:0.8650964498519897
tensor(1.3307, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018957266584038734
loss_c:0.9497362971305847
tensor(1.3614, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020917192101478577
loss_c:0.7932577133178711
tensor(1.2864, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02071153186261654
loss_c:0.7944310903549194
tensor(1.2861, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02663789503276348
loss_c:1.0023078918457031
tensor(1.4200, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036661308258771896
loss_c:0.8293792009353638
tensor(1.3685, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018297357484698296
loss_c:0.9098032712936401
tensor(1.3375, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018321098759770393
loss_c:0.79932701587677
tensor(1.2790, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01669435389339924
loss_c:0.8346565961837769
tensor(1.2911, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01812719739973545
loss_c:0.8705568313598633
tensor(1.3159, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02099268138408661
loss_c:0.9488949775695801
tensor(1.3690, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02350013703107834
loss_c:0.938849151134491
tensor(1.3737, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027938907966017723
loss_c:0.8313215970993042
tensor(1.3344, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028053170070052147
loss_c:0.9033489227294922
tensor(1.3732, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02713935077190399
loss_c:0.8619931936264038
tensor(1.3475, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02099834755063057
loss_c:0.9042646884918213
tensor(1.3451, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01966952160000801
loss_c:0.844599723815918
tensor(1.3079, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027582930400967598
loss_c:0.9565329551696777
tensor(1.3997, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024539746344089508
loss_c:1.0593209266662598
tensor(1.4422, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028303392231464386
loss_c:1.0485849380493164
tensor(1.4518, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01797589473426342
loss_c:0.883131742477417
tensor(1.3214, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025991488248109818
loss_c:0.7424956560134888
tensor(1.2790, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01904251240193844
loss_c:0.8480814695358276
tensor(1.3069, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027199864387512207
loss_c:0.9236341714859009
tensor(1.3806, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029117414727807045
loss_c:0.8627352714538574
tensor(1.3559, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022667914628982544
loss_c:0.8320775032043457
tensor(1.3131, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04091053083539009
loss_c:0.9182257056236267
tensor(1.4340, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016553856432437897
loss_c:0.7323881387710571
tensor(1.2347, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02308536320924759
loss_c:0.9915949702262878
tensor(1.4001, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030810855329036713
loss_c:1.0626983642578125
tensor(1.4699, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03128968924283981
loss_c:0.9168701171875
tensor(1.3938, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019378433004021645
loss_c:0.9882349371910095
tensor(1.3830, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021439652889966965
loss_c:0.874267578125
tensor(1.3305, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02331814169883728
loss_c:0.9746860265731812
tensor(1.3920, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043464239686727524
loss_c:0.9748644232749939
tensor(1.4751, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029329773038625717
loss_c:1.094707727432251
tensor(1.4809, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021087946370244026
loss_c:0.9213067889213562
tensor(1.3542, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024643482640385628
loss_c:0.8314945697784424
tensor(1.3209, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018223678693175316
loss_c:1.0232828855514526
tensor(1.3968, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06341050565242767
loss_c:1.0404057502746582
tensor(1.5923, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019398493692278862
loss_c:0.879797637462616
tensor(1.3251, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01895201951265335
loss_c:0.9407942295074463
tensor(1.3558, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02102287858724594
loss_c:0.8038796186447144
tensor(1.2914, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.050789255648851395
loss_c:1.0763696432113647
tensor(1.5589, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02818860113620758
loss_c:0.9473581314086914
tensor(1.3973, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02051977813243866
loss_c:0.9816758632659912
tensor(1.3840, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024642284959554672
loss_c:0.9974716901779175
tensor(1.4093, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03922919183969498
loss_c:1.0012974739074707
tensor(1.4711, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030765170231461525
loss_c:0.988862931728363
tensor(1.4297, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.052468981593847275
loss_c:0.8915349841117859
tensor(1.4670, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04417916014790535
loss_c:0.9551585912704468
tensor(1.4666, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015640411525964737
loss_c:1.0540753602981567
tensor(1.4024, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024527525529265404
loss_c:0.9268109798431396
tensor(1.3713, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018486129119992256
loss_c:0.947335958480835
tensor(1.3576, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019465826451778412
loss_c:0.8888540267944336
tensor(1.3308, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021491458639502525
loss_c:0.8691315650939941
tensor(1.3287, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04180987551808357
loss_c:1.0188863277435303
tensor(1.4898, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02251586504280567
loss_c:0.8856889605522156
tensor(1.3416, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01694129779934883
loss_c:0.8413861989974976
tensor(1.2958, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01995599828660488
loss_c:0.86613929271698
tensor(1.3210, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019128503277897835
loss_c:0.8875808119773865
tensor(1.3289, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015023907646536827
loss_c:0.8818190097808838
tensor(1.3093, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03046194091439247
loss_c:1.0052391290664673
tensor(1.4366, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015379460528492928
loss_c:0.8233246803283691
tensor(1.2799, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020806152373552322
loss_c:0.8721981048583984
tensor(1.3276, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.061634816229343414
loss_c:0.954433798789978
tensor(1.5366, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02080439403653145
loss_c:0.9803868532180786
tensor(1.3844, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019915375858545303
loss_c:0.8973364233970642
tensor(1.3371, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01939503662288189
loss_c:0.9791488647460938
tensor(1.3780, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024201607331633568
loss_c:0.8525816202163696
tensor(1.3310, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020868077874183655
loss_c:0.8964333534240723
tensor(1.3405, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023213228210806847
loss_c:0.9434159994125366
tensor(1.3747, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018643662333488464
loss_c:0.8966280221939087
tensor(1.3315, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024706929922103882
loss_c:1.0137814283370972
tensor(1.4178, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017510192468762398
loss_c:0.9375686645507812
tensor(1.3483, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04079723358154297
loss_c:1.0496916770935059
tensor(1.5024, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02252877876162529
loss_c:0.8630322217941284
tensor(1.3296, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023405177518725395
loss_c:0.8864860534667969
tensor(1.3455, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06817416846752167
loss_c:1.125930666923523
tensor(1.6547, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01814117282629013
loss_c:0.8081068992614746
tensor(1.2828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04110245406627655
loss_c:0.8709739446640015
tensor(1.4097, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03930556774139404
loss_c:0.999934196472168
tensor(1.4701, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025393439456820488
loss_c:0.8277238607406616
tensor(1.3228, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019415926188230515
loss_c:0.9476979970932007
tensor(1.3615, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026908311992883682
loss_c:0.8637515902519226
tensor(1.3479, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020538024604320526
loss_c:0.8482407331466675
tensor(1.3138, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02268734574317932
loss_c:1.0539631843566895
tensor(1.4307, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024383680894970894
loss_c:0.9576975703239441
tensor(1.3870, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021438222378492355
loss_c:0.9822942614555359
tensor(1.3879, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023486316204071045
loss_c:0.9015509486198425
tensor(1.3538, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0337911918759346
loss_c:0.8432178497314453
tensor(1.3651, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029135126620531082
loss_c:0.7959251403808594
tensor(1.3213, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023296451196074486
loss_c:0.7183381915092468
tensor(1.2568, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.047311991453170776
loss_c:0.9595834612846375
tensor(1.4812, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018560856580734253
loss_c:0.9544912576675415
tensor(1.3617, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026356497779488564
loss_c:0.9098377227783203
tensor(1.3698, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03769819438457489
loss_c:0.8289372324943542
tensor(1.3733, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018014337867498398
loss_c:0.8062202334403992
tensor(1.2814, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018214764073491096
loss_c:0.9843738079071045
tensor(1.3761, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022644901648163795
loss_c:1.0194042921066284
tensor(1.4126, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020064156502485275
loss_c:0.9757578372955322
tensor(1.3791, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05355203151702881
loss_c:0.849374532699585
tensor(1.4483, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014031141065061092
loss_c:0.9214181900024414
tensor(1.3259, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01817491464316845
loss_c:0.8643509149551392
tensor(1.3126, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09339714050292969
loss_c:0.9448339343070984
tensor(1.6604, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.047412578016519547
loss_c:0.9458262324333191
tensor(1.4741, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021613337099552155
loss_c:1.1337286233901978
tensor(1.4691, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019287411123514175
loss_c:1.0351523160934448
tensor(1.4076, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021226076409220695
loss_c:0.9479009509086609
tensor(1.3693, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018338514491915703
loss_c:0.8840569257736206
tensor(1.3240, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02074827440083027
loss_c:0.9014860987663269
tensor(1.3430, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01583440601825714
loss_c:0.8383209109306335
tensor(1.2899, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02166348695755005
loss_c:0.8428460955619812
tensor(1.3157, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01653662882745266
loss_c:0.7777328491210938
tensor(1.2608, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0218825563788414
loss_c:0.8468307256698608
tensor(1.3186, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0499957911670208
loss_c:0.9314526319503784
tensor(1.4762, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016895387321710587
loss_c:0.8952757716178894
tensor(1.3242, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017143530771136284
loss_c:0.9696747660636902
tensor(1.3645, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03480406850576401
loss_c:0.8227849006652832
tensor(1.3578, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02511180378496647
loss_c:1.105533480644226
tensor(1.4684, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032783009111881256
loss_c:0.9523112177848816
tensor(1.4182, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02353241667151451
loss_c:1.127212405204773
tensor(1.4735, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02967275120317936
loss_c:0.8848564624786377
tensor(1.3700, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020121941342949867
loss_c:1.066009759902954
tensor(1.4273, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043921779841184616
loss_c:1.037658452987671
tensor(1.5081, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016165846958756447
loss_c:0.7803525924682617
tensor(1.2605, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022814134135842323
loss_c:1.0351217985153198
tensor(1.4217, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031236885115504265
loss_c:0.8731276392936707
tensor(1.3701, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04557370766997337
loss_c:0.9991657137870789
tensor(1.4943, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03599442541599274
loss_c:0.8830751776695251
tensor(1.3946, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025162717327475548
loss_c:0.8261145353317261
tensor(1.3210, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01636296510696411
loss_c:0.9239510297775269
tensor(1.3371, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031900230795145035
loss_c:1.00570547580719
tensor(1.4426, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.13128048181533813
loss_c:1.2864203453063965
tensor(1.9896, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01989404484629631
loss_c:0.8362631797790527
tensor(1.3054, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02114035375416279
loss_c:0.8730904459953308
tensor(1.3298, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02149282395839691
loss_c:0.8789705038070679
tensor(1.3344, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019289450719952583
loss_c:0.8433846831321716
tensor(1.3071, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017497172579169273
loss_c:0.9023431539535522
tensor(1.3310, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019983984529972076
loss_c:0.882326602935791
tensor(1.3304, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017934463918209076
loss_c:1.0173863172531128
tensor(1.3932, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04148529842495918
loss_c:0.8921443223953247
tensor(1.4205, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03482603281736374
loss_c:0.8948656320571899
tensor(1.3956, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026999488472938538
loss_c:0.9955519437789917
tensor(1.4175, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020267849788069725
loss_c:1.074622392654419
tensor(1.4325, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023459093645215034
loss_c:0.9093365669250488
tensor(1.3584, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018116679042577744
loss_c:0.891187846660614
tensor(1.3278, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023773193359375
loss_c:0.8666210174560547
tensor(1.3372, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020638365298509598
loss_c:0.8391546607017517
tensor(1.3105, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029500458389520645
loss_c:1.0603559017181396
tensor(1.4613, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022356625646352768
loss_c:0.8605457544326782
tensor(1.3284, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04308737441897392
loss_c:0.8146916627883911
tensor(1.3862, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03476656600832939
loss_c:0.808851957321167
tensor(1.3503, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02047322876751423
loss_c:0.9021800756454468
tensor(1.3428, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027772340923547745
loss_c:0.929332435131073
tensor(1.3858, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018969930708408356
loss_c:1.04153311252594
tensor(1.4100, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020422643050551414
loss_c:1.0447418689727783
tensor(1.4174, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016433829441666603
loss_c:0.893349826335907
tensor(1.3221, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04090653732419014
loss_c:0.8805269598960876
tensor(1.4122, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04179742559790611
loss_c:0.9256581664085388
tensor(1.4395, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04044036939740181
loss_c:0.879635214805603
tensor(1.4099, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03243077173829079
loss_c:0.7751927375793457
tensor(1.3233, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02308018133044243
loss_c:0.8727573156356812
tensor(1.3375, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01899704337120056
loss_c:0.9081656336784363
tensor(1.3400, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019066976383328438
loss_c:0.8423680067062378
tensor(1.3057, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018470751121640205
loss_c:0.9966573715209961
tensor(1.3845, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018957292661070824
loss_c:0.9628258943557739
tensor(1.3686, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016875948756933212
loss_c:0.7374882698059082
tensor(1.2416, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017578672617673874
loss_c:0.8447777628898621
tensor(1.3008, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017969874665141106
loss_c:1.0063705444335938
tensor(1.3875, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018965626135468483
loss_c:0.7858147025108337
tensor(1.2750, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0270700603723526
loss_c:0.7916740775108337
tensor(1.3103, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029938599094748497
loss_c:0.8313932418823242
tensor(1.3427, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017700055614113808
loss_c:0.934728741645813
tensor(1.3484, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01895519345998764
loss_c:0.8972268104553223
tensor(1.3335, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019113335758447647
loss_c:0.9151002764701843
tensor(1.3435, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025943463668227196
loss_c:1.0545296669006348
tensor(1.4449, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02349458821117878
loss_c:0.9313569068908691
tensor(1.3697, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03214678168296814
loss_c:0.8954237699508667
tensor(1.3856, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019141312688589096
loss_c:0.9099122881889343
tensor(1.3406, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040879424661397934
loss_c:0.8767096996307373
tensor(1.4111, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021465424448251724
loss_c:0.9559058547019958
tensor(1.3744, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026478173211216927
loss_c:0.9862052202224731
tensor(1.4109, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017246996983885765
loss_c:0.883359432220459
tensor(1.3186, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02332938462495804
loss_c:0.9094683527946472
tensor(1.3573, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020304644480347633
loss_c:0.9239737391471863
tensor(1.3526, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03986087068915367
loss_c:0.9286248087882996
tensor(1.4349, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023277971893548965
loss_c:1.0783073902130127
tensor(1.4467, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030896740034222603
loss_c:0.848281741142273
tensor(1.3556, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021324362605810165
loss_c:0.8797796964645386
tensor(1.3332, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02214137837290764
loss_c:0.8841594457626343
tensor(1.3389, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019673671573400497
loss_c:0.841422438621521
tensor(1.3060, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018612345680594444
loss_c:0.8907780051231384
tensor(1.3279, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019265178591012955
loss_c:0.8497521281242371
tensor(1.3087, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024894732981920242
loss_c:0.8883644938468933
tensor(1.3523, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01681407168507576
loss_c:0.9712599515914917
tensor(1.3631, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023147866129875183
loss_c:0.9102839231491089
tensor(1.3568, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019983205944299698
loss_c:0.814049482345581
tensor(1.2925, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04010441154241562
loss_c:0.9313418865203857
tensor(1.4382, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013122018426656723
loss_c:0.7666890025138855
tensor(1.2387, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023803751915693283
loss_c:0.7732595205307007
tensor(1.2865, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024903396144509315
loss_c:0.9854015111923218
tensor(1.4040, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03624244034290314
loss_c:1.03916335105896
tensor(1.4799, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01639600470662117
loss_c:0.7844501733779907
tensor(1.2615, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015865756198763847
loss_c:0.8414188623428345
tensor(1.2896, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02698124572634697
loss_c:0.9148187041282654
tensor(1.3751, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01828802190721035
loss_c:0.91100013256073
tensor(1.3367, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01729116588830948
loss_c:0.8717364072799683
tensor(1.3115, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030713055282831192
loss_c:1.1343395709991455
tensor(1.5080, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017161810770630836
loss_c:0.907146155834198
tensor(1.3298, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017370862886309624
loss_c:1.005075454711914
tensor(1.3830, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03617161512374878
loss_c:0.9496249556541443
tensor(1.4324, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04381883516907692
loss_c:1.0404205322265625
tensor(1.5131, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01950610987842083
loss_c:0.8297426104545593
tensor(1.2982, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030636876821517944
loss_c:0.9936038851737976
tensor(1.4326, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026199400424957275
loss_c:0.9874211549758911
tensor(1.4105, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023258520290255547
loss_c:0.8651309013366699
tensor(1.3330, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016156939789652824
loss_c:0.9219913482666016
tensor(1.3333, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02226831391453743
loss_c:0.8816016912460327
tensor(1.3376, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0355832502245903
loss_c:0.813014030456543
tensor(1.3572, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021438701078295708
loss_c:0.9069619178771973
tensor(1.3476, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024172261357307434
loss_c:0.8183347582817078
tensor(1.3119, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02242358960211277
loss_c:0.8146132230758667
tensor(1.3026, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016248485073447227
loss_c:0.8279239535331726
tensor(1.2836, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04201081395149231
loss_c:0.971361517906189
tensor(1.4687, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02059829793870449
loss_c:0.7997965216636658
tensor(1.2869, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.052714936435222626
loss_c:0.8229180574417114
tensor(1.4348, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015689978376030922
loss_c:0.807693362236023
tensor(1.2704, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023080822080373764
loss_c:0.8622305393218994
tensor(1.3306, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02505427971482277
loss_c:1.1020444631576538
tensor(1.4670, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016261717304587364
loss_c:0.8403298258781433
tensor(1.2902, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017862826585769653
loss_c:0.8272438049316406
tensor(1.2899, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040085021406412125
loss_c:1.0257422924041748
tensor(1.4896, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01749507151544094
loss_c:0.849991500377655
tensor(1.3005, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01890498585999012
loss_c:0.796576201915741
tensor(1.2779, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0395694263279438
loss_c:0.8347441554069519
tensor(1.3853, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04065072908997536
loss_c:0.9536284804344177
tensor(1.4535, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02910124883055687
loss_c:0.8483266234397888
tensor(1.3484, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021382875740528107
loss_c:0.900274932384491
tensor(1.3438, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016689244657754898
loss_c:0.9002897143363953
tensor(1.3241, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039626628160476685
loss_c:0.9363058805465698
tensor(1.4397, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0232565775513649
loss_c:0.8812212944030762
tensor(1.3415, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015446143224835396
loss_c:0.8331036567687988
tensor(1.2829, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026378082111477852
loss_c:1.1578034162521362
tensor(1.5030, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018911534920334816
loss_c:0.8809325098991394
tensor(1.3231, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02481636218726635
loss_c:1.2790647745132446
tensor(1.5615, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01714625023305416
loss_c:0.8728224635124207
tensor(1.3114, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01995321735739708
loss_c:0.8688464164733887
tensor(1.3210, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0215403251349926
loss_c:1.0525434017181396
tensor(1.4260, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02125708945095539
loss_c:0.9473878741264343
tensor(1.3685, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02009047009050846
loss_c:0.9296008944511414
tensor(1.3541, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03007637895643711
loss_c:0.8122965693473816
tensor(1.3334, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025677243247628212
loss_c:0.9294842481613159
tensor(1.3775, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02726900577545166
loss_c:1.0285897254943848
tensor(1.4370, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021879222244024277
loss_c:0.8745688199996948
tensor(1.3322, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018437212333083153
loss_c:0.9131292104721069
tensor(1.3382, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017211731523275375
loss_c:0.8149018287658691
tensor(1.2807, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046191975474357605
loss_c:1.1267762184143066
tensor(1.5691, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024600423872470856
loss_c:0.9186989068984985
tensor(1.3671, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03360633924603462
loss_c:1.0987197160720825
tensor(1.5009, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016341939568519592
loss_c:0.8022710680961609
tensor(1.2705, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0246711578220129
loss_c:0.8734700679779053
tensor(1.3434, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015396750532090664
loss_c:1.0231170654296875
tensor(1.3837, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033203136175870895
loss_c:0.8788917064666748
tensor(1.3824, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02114933729171753
loss_c:1.110213279724121
tensor(1.4540, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04245162755250931
loss_c:1.0106747150421143
tensor(1.4912, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042894233018159866
loss_c:1.0249626636505127
tensor(1.5006, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025481218472123146
loss_c:0.9987658262252808
tensor(1.4131, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021959757432341576
loss_c:0.859472930431366
tensor(1.3248, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029901063069701195
loss_c:0.8710753321647644
tensor(1.3644, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02218437008559704
loss_c:0.824546217918396
tensor(1.3074, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019801832735538483
loss_c:1.016481637954712
tensor(1.3985, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019957872107625008
loss_c:0.8919834494590759
tensor(1.3336, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037499312311410904
loss_c:0.867277979850769
tensor(1.3943, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03232334181666374
loss_c:1.2192578315734863
tensor(1.5576, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018991120159626007
loss_c:0.8603269457817078
tensor(1.3130, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028012540191411972
loss_c:1.0255721807479858
tensor(1.4376, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019689828157424927
loss_c:0.8943799734115601
tensor(1.3339, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01742943562567234
loss_c:0.9022172689437866
tensor(1.3285, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017087765038013458
loss_c:0.8972314596176147
tensor(1.3245, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018516292795538902
loss_c:0.8978748321533203
tensor(1.3308, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031637027859687805
loss_c:0.9840230941772461
tensor(1.4309, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02329472079873085
loss_c:0.9197952747344971
tensor(1.3623, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017654038965702057
loss_c:0.9648718237876892
tensor(1.3622, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03530575707554817
loss_c:0.9072715640068054
tensor(1.4061, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032860174775123596
loss_c:1.0273642539978027
tensor(1.4587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01892944797873497
loss_c:0.9180459976196289
tensor(1.3430, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02930409461259842
loss_c:1.0207369327545166
tensor(1.4403, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014609920792281628
loss_c:0.8139958381652832
tensor(1.2705, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037938591092824936
loss_c:0.8079562187194824
tensor(1.3654, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026996511965990067
loss_c:1.0839786529541016
tensor(1.4636, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03167687729001045
loss_c:0.8471199870109558
tensor(1.3595, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01450550276786089
loss_c:1.0528547763824463
tensor(1.3949, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02373686246573925
loss_c:1.0086274147033691
tensor(1.4106, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04493608698248863
loss_c:1.155592679977417
tensor(1.5762, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02886880375444889
loss_c:0.9481154680252075
tensor(1.4005, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02128254808485508
loss_c:0.9517898559570312
tensor(1.3706, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02024911902844906
loss_c:0.8751765489578247
tensor(1.3263, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016147298738360405
loss_c:0.8944669961929321
tensor(1.3192, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022055242210626602
loss_c:0.9227620959281921
tensor(1.3587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02128451131284237
loss_c:0.8709707260131836
tensor(1.3285, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0216920655220747
loss_c:0.8450608253479004
tensor(1.3167, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02284792810678482
loss_c:0.7617828249931335
tensor(1.2782, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025065286085009575
loss_c:0.9802700281143188
tensor(1.4012, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018527787178754807
loss_c:0.8353409767150879
tensor(1.2983, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022657521069049835
loss_c:0.8912031054496765
tensor(1.3447, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02576013095676899
loss_c:0.9714407324790955
tensor(1.3996, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02621685341000557
loss_c:0.803740382194519
tensor(1.3140, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029080243781208992
loss_c:0.8692934513092041
tensor(1.3603, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0210748128592968
loss_c:0.826574981212616
tensor(1.3042, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019031165167689323
loss_c:0.8111128807067871
tensor(1.2875, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029580939561128616
loss_c:0.8463572263717651
tensor(1.3503, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020231714472174644
loss_c:1.0164132118225098
tensor(1.3999, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038626644760370255
loss_c:0.9297065138816833
tensor(1.4322, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013535162433981895
loss_c:0.8677782416343689
tensor(1.2937, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018618445843458176
loss_c:1.034661054611206
tensor(1.4028, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019236788153648376
loss_c:0.9968024492263794
tensor(1.3855, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02135530114173889
loss_c:0.812658965587616
tensor(1.2977, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04402131959795952
loss_c:0.911712110042572
tensor(1.4457, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021921051666140556
loss_c:0.8095040321350098
tensor(1.2983, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0186606552451849
loss_c:0.8739757537841797
tensor(1.3184, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05876423418521881
loss_c:0.8867596387863159
tensor(1.4951, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020624332129955292
loss_c:1.22969651222229
tensor(1.5143, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027555296197533607
loss_c:1.1210083961486816
tensor(1.4863, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028982503339648247
loss_c:0.8350294828414917
tensor(1.3416, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028538327664136887
loss_c:1.0771088600158691
tensor(1.4672, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02142384834587574
loss_c:0.8686544895172119
tensor(1.3274, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01823650486767292
loss_c:1.0577294826507568
tensor(1.4135, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025037074461579323
loss_c:0.7875816226005554
tensor(1.3000, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01977783627808094
loss_c:1.0129787921905518
tensor(1.3964, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0417056567966938
loss_c:0.9320485591888428
tensor(1.4462, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024302605539560318
loss_c:0.9568547010421753
tensor(1.3860, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030698781833052635
loss_c:0.9295452833175659
tensor(1.3985, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0198777187615633
loss_c:0.8050956726074219
tensor(1.2876, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024045852944254875
loss_c:0.7748300433158875
tensor(1.2892, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014226631261408329
loss_c:0.9765142798423767
tensor(1.3540, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018457571044564247
loss_c:0.8385350108146667
tensor(1.2992, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03151887655258179
loss_c:1.0064871311187744
tensor(1.4424, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0457928366959095
loss_c:1.0104618072509766
tensor(1.5045, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029527533799409866
loss_c:0.9791628122329712
tensor(1.4196, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01672118343412876
loss_c:0.811194896697998
tensor(1.2776, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016280878335237503
loss_c:0.9298490285873413
tensor(1.3381, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023303154855966568
loss_c:0.9088046550750732
tensor(1.3565, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025876762345433235
loss_c:1.1187289953231812
tensor(1.4777, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03163742646574974
loss_c:0.8472141027450562
tensor(1.3591, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018134258687496185
loss_c:0.8395125269889832
tensor(1.2984, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03431101143360138
loss_c:0.9930915832519531
tensor(1.4470, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01966133341193199
loss_c:1.0383683443069458
tensor(1.4094, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0203054491430521
loss_c:0.8260000944137573
tensor(1.3004, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014752620831131935
loss_c:0.8529888987541199
tensor(1.2913, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019739700481295586
loss_c:0.9599453806877136
tensor(1.3684, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02290569245815277
loss_c:0.9179055094718933
tensor(1.3596, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02683098427951336
loss_c:0.9976055026054382
tensor(1.4180, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040309496223926544
loss_c:1.056291937828064
tensor(1.5055, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039150454103946686
loss_c:0.9807299375534058
tensor(1.4609, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017553584650158882
loss_c:0.9495663642883301
tensor(1.3538, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041766081005334854
loss_c:0.984958827495575
tensor(1.4741, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01626668870449066
loss_c:0.8342679738998413
tensor(1.2879, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019133029505610466
loss_c:0.9394286870956421
tensor(1.3551, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01571410708129406
loss_c:0.7922165393829346
tensor(1.2636, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03686529025435448
loss_c:1.0331332683563232
tensor(1.4787, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0227372869849205
loss_c:0.969228982925415
tensor(1.3859, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019935578107833862
loss_c:0.8574222922325134
tensor(1.3155, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018480567261576653
loss_c:0.9665412902832031
tensor(1.3666, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014758434146642685
loss_c:0.8385571837425232
tensor(1.2838, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029995722696185112
loss_c:0.8200327754020691
tensor(1.3381, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01841656304895878
loss_c:0.8528480529785156
tensor(1.3066, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02496255189180374
loss_c:1.052049160003662
tensor(1.4386, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022856760770082474
loss_c:0.9016443490982056
tensor(1.3509, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02209813892841339
loss_c:0.9515914916992188
tensor(1.3739, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017064273357391357
loss_c:0.8847500085830688
tensor(1.3175, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04402663931250572
loss_c:0.8736293315887451
tensor(1.4255, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01668582856655121
loss_c:0.8430536985397339
tensor(1.2940, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03687429055571556
loss_c:0.9841345548629761
tensor(1.4534, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035948917269706726
loss_c:0.8251667022705078
tensor(1.3660, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03850175067782402
loss_c:0.8798116445541382
tensor(1.4054, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022902414202690125
loss_c:0.8264117240905762
tensor(1.3114, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01842389814555645
loss_c:0.8129986524581909
tensor(1.2855, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017112337052822113
loss_c:0.9519772529602051
tensor(1.3531, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043156303465366364
loss_c:0.9478497505187988
tensor(1.4607, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020152945071458817
loss_c:0.875403881072998
tensor(1.3256, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018231086432933807
loss_c:0.9305380582809448
tensor(1.3466, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021000050008296967
loss_c:1.1157978773117065
tensor(1.4561, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03170078992843628
loss_c:0.9563748836517334
tensor(1.4169, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01596168801188469
loss_c:0.8139537572860718
tensor(1.2755, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031050914898514748
loss_c:0.8058201670646667
tensor(1.3346, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022995708510279655
loss_c:0.9858700633049011
tensor(1.3959, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016781117767095566
loss_c:0.7620531916618347
tensor(1.2515, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02541978843510151
loss_c:0.8917887210845947
tensor(1.3564, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015812626108527184
loss_c:0.813002347946167
tensor(1.2742, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022755220532417297
loss_c:0.8970427513122559
tensor(1.3479, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023806743323802948
loss_c:0.9365488886833191
tensor(1.3733, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04743695259094238
loss_c:0.8711892366409302
tensor(1.4383, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021049488335847855
loss_c:0.913485050201416
tensor(1.3494, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022448373958468437
loss_c:0.8589673042297363
tensor(1.3264, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015379645861685276
loss_c:0.8625997304916382
tensor(1.2985, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017618415877223015
loss_c:0.8255304098129272
tensor(1.2882, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02037987671792507
loss_c:0.8683900833129883
tensor(1.3226, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018325356766581535
loss_c:0.7869042754173279
tensor(1.2705, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021666746586561203
loss_c:0.8694808483123779
tensor(1.3285, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024347029626369476
loss_c:0.7896358370780945
tensor(1.2973, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02943110279738903
loss_c:0.9250741004943848
tensor(1.3910, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02884632907807827
loss_c:0.7885856628417969
tensor(1.3156, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03299703821539879
loss_c:0.9268171787261963
tensor(1.4072, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021282939240336418
loss_c:0.9939664602279663
tensor(1.3934, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026078762486577034
loss_c:0.961256206035614
tensor(1.3963, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028967957943677902
loss_c:1.0953130722045898
tensor(1.4804, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02484365925192833
loss_c:0.7955772280693054
tensor(1.3022, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04788026213645935
loss_c:1.022425651550293
tensor(1.5216, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1758125275373459
loss_c:1.1366264820098877
tensor(2.1253, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019197288900613785
loss_c:0.9125393629074097
tensor(1.3412, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032783716917037964
loss_c:1.0145399570465088
tensor(1.4528, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03132329136133194
loss_c:0.8536890745162964
tensor(1.3604, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019293736666440964
loss_c:0.871545672416687
tensor(1.3201, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020421244204044342
loss_c:0.8904110193252563
tensor(1.3350, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018174853175878525
loss_c:0.8784440755844116
tensor(1.3195, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.057250138372182846
loss_c:0.874260663986206
tensor(1.4769, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04266495257616043
loss_c:0.9554955363273621
tensor(1.4605, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03175769001245499
loss_c:0.9953296184539795
tensor(1.4373, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01743231900036335
loss_c:0.9277023077011108
tensor(1.3434, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02481910027563572
loss_c:0.8916439414024353
tensor(1.3539, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.045474257320165634
loss_c:0.8240754008293152
tensor(1.4007, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01728064939379692
loss_c:0.8982070684432983
tensor(1.3274, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03934679180383682
loss_c:1.0753470659255981
tensor(1.5099, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029729388654232025
loss_c:1.0078755617141724
tensor(1.4356, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03371896967291832
loss_c:1.0757341384887695
tensor(1.4875, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07994669675827026
loss_c:0.9717676043510437
tensor(1.6147, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023753175511956215
loss_c:1.136773943901062
tensor(1.4804, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04355182871222496
loss_c:0.8996511697769165
tensor(1.4320, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021151617169380188
loss_c:0.9447569847106934
tensor(1.3682, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03013244830071926
loss_c:0.7651053667068481
tensor(1.3081, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024932336062192917
loss_c:1.0601928234100342
tensor(1.4442, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020545372739434242
loss_c:0.8290631175041199
tensor(1.3049, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03566978499293327
loss_c:0.9796371459960938
tensor(1.4431, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03658538684248924
loss_c:0.8847581744194031
tensor(1.3965, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0180832426995039
loss_c:0.9552558660507202
tensor(1.3623, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0229868795722723
loss_c:0.8154417872428894
tensor(1.3075, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02536933310329914
loss_c:0.8465160131454468
tensor(1.3331, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025499479845166206
loss_c:0.867253303527832
tensor(1.3445, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03519463166594505
loss_c:1.0715783834457397
tensor(1.4896, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018657252192497253
loss_c:0.8293826580047607
tensor(1.2983, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015749193727970123
loss_c:0.755306601524353
tensor(1.2481, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020044967532157898
loss_c:0.7889654040336609
tensor(1.2823, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019281992688775063
loss_c:0.9088597297668457
tensor(1.3426, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018209628760814667
loss_c:0.7912248969078064
tensor(1.2763, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02116633765399456
loss_c:0.86835116147995
tensor(1.3283, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035741522908210754
loss_c:0.9622940421104431
tensor(1.4342, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03304015472531319
loss_c:0.8959571123123169
tensor(1.3887, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.047098610550165176
loss_c:1.0005605220794678
tensor(1.4984, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0281449593603611
loss_c:0.9071404933929443
tensor(1.3757, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017210330814123154
loss_c:0.8760151863098145
tensor(1.3169, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016147861257195473
loss_c:0.8545753359794617
tensor(1.3013, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016407832503318787
loss_c:0.8758620023727417
tensor(1.3136, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016374602913856506
loss_c:0.8192183375358582
tensor(1.2833, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02394394390285015
loss_c:1.20070481300354
tensor(1.5151, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029231823980808258
loss_c:0.8880279064178467
tensor(1.3697, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01780811883509159
loss_c:0.8584341406822205
tensor(1.3094, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029425762593746185
loss_c:0.8866536021232605
tensor(1.3697, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024230774492025375
loss_c:0.9142564535140991
tensor(1.3640, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03192765265703201
loss_c:0.9225718379020691
tensor(1.3986, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030295098200440407
loss_c:0.9185153245925903
tensor(1.3901, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017668526619672775
loss_c:0.731999397277832
tensor(1.2413, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01669967547059059
loss_c:0.865391731262207
tensor(1.3083, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025431031361222267
loss_c:1.1440030336380005
tensor(1.4908, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0167841836810112
loss_c:0.8889419436454773
tensor(1.3210, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02883853018283844
loss_c:0.9112407565116882
tensor(1.3805, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021291660144925117
loss_c:1.0170191526412964
tensor(1.4068, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029187779873609543
loss_c:1.0455777645111084
tensor(1.4533, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030506310984492302
loss_c:1.0403962135314941
tensor(1.4558, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04458235576748848
loss_c:0.8316070437431335
tensor(1.4010, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014611258171498775
loss_c:0.8364719748497009
tensor(1.2841, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035925716161727905
loss_c:1.001955270767212
tensor(1.4570, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08118078857660294
loss_c:1.1656900644302368
tensor(1.7247, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03430454060435295
loss_c:0.9691108465194702
tensor(1.4330, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03142721951007843
loss_c:0.9548120498657227
tensor(1.4139, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0293872132897377
loss_c:0.9968440532684326
tensor(1.4280, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029612969607114792
loss_c:0.8346893191337585
tensor(1.3431, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02059248276054859
loss_c:0.8995465040206909
tensor(1.3416, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015889910981059074
loss_c:0.9527298808097839
tensor(1.3511, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020807938650250435
loss_c:0.9802400469779968
tensor(1.3851, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02109987847507
loss_c:0.9354572296142578
tensor(1.3626, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032105978578329086
loss_c:0.8153976202011108
tensor(1.3430, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024027176201343536
loss_c:0.9621769189834595
tensor(1.3883, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025657055899500847
loss_c:0.8650555610656738
tensor(1.3436, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025388726964592934
loss_c:0.8323979377746582
tensor(1.3253, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018280472606420517
loss_c:0.9552340507507324
tensor(1.3618, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016604097560048103
loss_c:0.7934655547142029
tensor(1.2700, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01858603209257126
loss_c:0.8898584842681885
tensor(1.3285, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041389115154743195
loss_c:0.9343603849411011
tensor(1.4426, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024834798648953438
loss_c:1.0325403213500977
tensor(1.4285, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017788752913475037
loss_c:0.9975357055664062
tensor(1.3820, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022800687700510025
loss_c:1.1179230213165283
tensor(1.4654, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025182120501995087
loss_c:0.8741874694824219
tensor(1.3464, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020785966888070107
loss_c:0.8845896124839783
tensor(1.3343, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021098097786307335
loss_c:0.8734344244003296
tensor(1.3297, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01993395946919918
loss_c:0.8235630989074707
tensor(1.2988, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02046281471848488
loss_c:0.9200136065483093
tensor(1.3516, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016884230077266693
loss_c:0.8530732989311218
tensor(1.3019, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019698359072208405
loss_c:0.7987927198410034
tensor(1.2846, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015750546008348465
loss_c:0.858195960521698
tensor(1.2998, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014866473153233528
loss_c:0.8914146423339844
tensor(1.3136, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013992049731314182
loss_c:0.8362679481506348
tensor(1.2809, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014570146799087524
loss_c:0.6984895467758179
tensor(1.2104, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022579828277230263
loss_c:0.956068217754364
tensor(1.3788, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03298502415418625
loss_c:1.1050477027893066
tensor(1.5001, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.049621954560279846
loss_c:0.9407659769058228
tensor(1.4816, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02197383902966976
loss_c:0.8480287790298462
tensor(1.3191, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02675754390656948
loss_c:1.1780961751937866
tensor(1.5134, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020634524524211884
loss_c:0.9352083206176758
tensor(1.3596, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03701116517186165
loss_c:0.8467742204666138
tensor(1.3804, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03620395436882973
loss_c:0.8809871077537537
tensor(1.3952, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019743824377655983
loss_c:0.8727878332138062
tensor(1.3229, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023005234077572823
loss_c:0.9241912364959717
tensor(1.3635, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016940174624323845
loss_c:0.7865292429924011
tensor(1.2656, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02006959542632103
loss_c:0.8729020953178406
tensor(1.3242, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021933866664767265
loss_c:0.9419829249382019
tensor(1.3685, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022735990583896637
loss_c:1.1218571662902832
tensor(1.4671, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03555908799171448
loss_c:1.0135555267333984
tensor(1.4629, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025751672685146332
loss_c:0.9886078238487244
tensor(1.4090, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036715682595968246
loss_c:0.9305335879325867
tensor(1.4238, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026710575446486473
loss_c:0.9307109713554382
tensor(1.3823, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022349679842591286
loss_c:0.7606691718101501
tensor(1.2742, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0247548408806324
loss_c:1.1471467018127441
tensor(1.4887, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02147253230214119
loss_c:0.8471487760543823
tensor(1.3164, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01712111569941044
loss_c:0.7896550893783569
tensor(1.2679, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07783323526382446
loss_c:1.0239546298980713
tensor(1.6442, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0377347432076931
loss_c:0.9368758201599121
tensor(1.4313, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01881515607237816
loss_c:0.8432905077934265
tensor(1.3034, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02502160705626011
loss_c:0.8103126287460327
tensor(1.3117, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024352528154850006
loss_c:0.90289306640625
tensor(1.3578, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02674834243953228
loss_c:0.9854423403739929
tensor(1.4114, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015430085361003876
loss_c:0.945845365524292
tensor(1.3438, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029041413217782974
loss_c:1.0025484561920166
tensor(1.4299, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018087707459926605
loss_c:0.8004986047744751
tensor(1.2779, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017911093309521675
loss_c:0.9631747007369995
tensor(1.3632, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023985739797353745
loss_c:0.8111583590507507
tensor(1.3079, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035889171063899994
loss_c:1.1765058040618896
tensor(1.5501, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.045069433748722076
loss_c:0.896641194820404
tensor(1.4400, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05406857281923294
loss_c:1.0214401483535767
tensor(1.5429, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03031495027244091
loss_c:1.123016595840454
tensor(1.4987, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03117656335234642
loss_c:0.9950358867645264
tensor(1.4345, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03495572879910469
loss_c:0.943839430809021
tensor(1.4230, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021933220326900482
loss_c:0.9090107679367065
tensor(1.3513, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03346778452396393
loss_c:0.9493276476860046
tensor(1.4196, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021721018478274345
loss_c:0.9307761192321777
tensor(1.3620, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03792674466967583
loss_c:0.8187887072563171
tensor(1.3690, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027295300737023354
loss_c:0.9708041548728943
tensor(1.4057, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021683689206838608
loss_c:0.8962582349777222
tensor(1.3438, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022448763251304626
loss_c:0.8198480606079102
tensor(1.3068, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017021773383021355
loss_c:0.8169536590576172
tensor(1.2833, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019134391099214554
loss_c:1.0852199792861938
tensor(1.4328, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04054734483361244
loss_c:0.9297036528587341
tensor(1.4377, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02022256702184677
loss_c:0.8605594635009766
tensor(1.3192, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034810278564691544
loss_c:0.8532266616821289
tensor(1.3743, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021801989525556564
loss_c:0.7983474135398865
tensor(1.2929, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04794292896986008
loss_c:1.0065629482269287
tensor(1.5079, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022017842158675194
loss_c:1.0082818269729614
tensor(1.4041, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04666066914796829
loss_c:0.8214077353477478
tensor(1.4053, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044984642416238785
loss_c:0.7845098376274109
tensor(1.3790, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02185622602701187
loss_c:0.9764594435691833
tensor(1.3868, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018015598878264427
loss_c:0.9759768843650818
tensor(1.3712, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023363392800092697
loss_c:0.8323627710342407
tensor(1.3171, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10590286552906036
loss_c:1.0542478561401367
tensor(1.7645, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03292496129870415
loss_c:0.900726318359375
tensor(1.3913, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016342371702194214
loss_c:0.8798214793205261
tensor(1.3143, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020350772887468338
loss_c:0.9851862788200378
tensor(1.3858, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02576264552772045
loss_c:0.8133172988891602
tensor(1.3168, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02142493613064289
loss_c:0.7951621413230896
tensor(1.2901, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017996737733483315
loss_c:0.9088543653488159
tensor(1.3365, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022435128688812256
loss_c:0.853323221206665
tensor(1.3247, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027045538648962975
loss_c:0.9180945158004761
tensor(1.3771, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02439136803150177
loss_c:0.8544937372207642
tensor(1.3330, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02111317589879036
loss_c:0.8829282522201538
tensor(1.3351, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022637756541371346
loss_c:0.9797608852386475
tensor(1.3923, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025580953806638718
loss_c:1.0345057249069214
tensor(1.4329, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023965172469615936
loss_c:0.9577096700668335
tensor(1.3859, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021820176392793655
loss_c:0.8789669871330261
tensor(1.3358, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018556760624051094
loss_c:1.096399188041687
tensor(1.4379, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024915870279073715
loss_c:1.0135412216186523
tensor(1.4191, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03953295946121216
loss_c:0.9152213931083679
tensor(1.4249, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04420241340994835
loss_c:1.1547601222991943
tensor(1.5700, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.050336241722106934
loss_c:0.9438810348510742
tensor(1.4828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016987714916467667
loss_c:0.8080732822418213
tensor(1.2793, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017979096621274948
loss_c:0.8876005411148071
tensor(1.3252, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028993034735322
loss_c:0.9419474005699158
tensor(1.3973, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02059180848300457
loss_c:0.9169024229049683
tensor(1.3509, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017974084243178368
loss_c:0.7633955478668213
tensor(1.2597, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01937779225409031
loss_c:0.9118531942367554
tensor(1.3434, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02076352946460247
loss_c:0.8569436073303223
tensor(1.3200, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026045000180602074
loss_c:0.8339651823043823
tensor(1.3287, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018666666001081467
loss_c:0.8649086952209473
tensor(1.3158, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01924820989370346
loss_c:0.9779459238052368
tensor(1.3776, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03608676791191101
loss_c:1.0063107013702393
tensor(1.4595, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07816191017627716
loss_c:0.9557444453239441
tensor(1.6004, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02021174132823944
loss_c:0.9241103529930115
tensor(1.3530, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018849946558475494
loss_c:0.7456464171409607
tensor(1.2534, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02775813639163971
loss_c:0.8912190198898315
tensor(1.3657, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018233653157949448
loss_c:0.8744418621063232
tensor(1.3189, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036907557398080826
loss_c:0.9518355131149292
tensor(1.4341, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01621290110051632
loss_c:0.9418487548828125
tensor(1.3465, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03514961153268814
loss_c:0.7934210300445557
tensor(1.3433, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021135427057743073
loss_c:0.8330206871032715
tensor(1.3085, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020691027864813805
loss_c:0.9135394096374512
tensor(1.3493, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020849285647273064
loss_c:0.9208612442016602
tensor(1.3538, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02356761135160923
loss_c:0.8574910163879395
tensor(1.3310, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016728267073631287
loss_c:0.8646705150604248
tensor(1.3075, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06882131844758987
loss_c:1.0251796245574951
tensor(1.6006, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02160547859966755
loss_c:0.986568808555603
tensor(1.3916, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02957618422806263
loss_c:1.0520739555358887
tensor(1.4582, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019473090767860413
loss_c:0.9177643656730652
tensor(1.3466, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016462519764900208
loss_c:0.8900665044784546
tensor(1.3199, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01709037460386753
loss_c:0.9817723035812378
tensor(1.3710, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023472363129258156
loss_c:0.8395211100578308
tensor(1.3210, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027011170983314514
loss_c:0.8699520826339722
tensor(1.3513, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027706151828169823
loss_c:0.9871640205383301
tensor(1.4163, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0355963408946991
loss_c:0.8341714143753052
tensor(1.3667, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019413916394114494
loss_c:0.7837862968444824
tensor(1.2752, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021068044006824493
loss_c:0.975582480430603
tensor(1.3835, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016470441594719887
loss_c:0.8561129570007324
tensor(1.3016, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01635260321199894
loss_c:0.8039849996566772
tensor(1.2734, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022607680410146713
loss_c:0.8904172778129578
tensor(1.3444, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021513763815164566
loss_c:0.8830757141113281
tensor(1.3361, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018764318898320198
loss_c:0.9514747858047485
tensor(1.3613, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034762538969516754
loss_c:0.9528151750564575
tensor(1.4267, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025321684777736664
loss_c:0.7967161536216736
tensor(1.3054, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029973464086651802
loss_c:1.0149343013763428
tensor(1.4404, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016755886375904083
loss_c:0.8950294852256775
tensor(1.3229, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03389706090092659
loss_c:0.9072203636169434
tensor(1.3991, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042297907173633575
loss_c:1.2402966022491455
tensor(1.6107, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01953129470348358
loss_c:0.980724036693573
tensor(1.3797, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04172360524535179
loss_c:0.8554401397705078
tensor(1.4035, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020629290491342545
loss_c:1.1459660530090332
tensor(1.4720, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018570411950349808
loss_c:0.9414013624191284
tensor(1.3548, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023513605818152428
loss_c:0.9350070953369141
tensor(1.3716, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020113548263907433
loss_c:0.8655282855033875
tensor(1.3208, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016325054690241814
loss_c:0.8902406692504883
tensor(1.3185, device='cuda:0', grad_fn=<AddBackward0>)
total_train_loss:1.3945399522781372
loss_r:0.02434525452554226
loss_c:1.893934965133667
loss_r:0.025780078023672104
loss_c:1.8463214635849
loss_r:0.027739867568016052
loss_c:1.8900903463363647
loss_r:0.025774400681257248
loss_c:1.900747299194336
loss_r:0.02213119901716709
loss_c:1.766813039779663
loss_r:0.025540964677929878
loss_c:1.7437143325805664
loss_r:0.023196859285235405
loss_c:1.8482725620269775
loss_r:0.02550375461578369
loss_c:1.9863579273223877
loss_r:0.026718687266111374
loss_c:2.0852363109588623
loss_r:0.026701200753450394
loss_c:2.044318437576294
loss_r:0.021541399881243706
loss_c:1.9359873533248901
loss_r:0.023086439818143845
loss_c:1.8242480754852295
loss_r:0.02071538195014
loss_c:1.6790962219238281
loss_r:0.018772169947624207
loss_c:1.6634734869003296
loss_r:0.01925811730325222
loss_c:1.687893271446228
loss_r:0.02339373342692852
loss_c:1.7453603744506836
loss_r:0.018890703096985817
loss_c:1.6858699321746826
loss_r:0.021327346563339233
loss_c:1.7421221733093262
loss_r:0.021272260695695877
loss_c:1.673330307006836
loss_r:0.018712079152464867
loss_c:1.6066093444824219
loss_r:0.021290933713316917
loss_c:1.7205127477645874
loss_r:0.021657293662428856
loss_c:1.7088356018066406
loss_r:0.020237082615494728
loss_c:1.683459758758545
loss_r:0.022482264786958694
loss_c:1.7142210006713867
loss_r:0.022836418822407722
loss_c:1.6955461502075195
loss_r:0.018638988956809044
loss_c:1.628408670425415
loss_r:0.022074218839406967
loss_c:1.7644548416137695
loss_r:0.023562077432870865
loss_c:1.790175199508667
loss_r:0.020689211785793304
loss_c:1.6901776790618896
loss_r:0.02171415090560913
loss_c:1.7123082876205444
loss_r:0.024394840002059937
loss_c:1.7845256328582764
loss_r:0.01740053854882717
loss_c:1.5611140727996826
loss_r:0.02145453728735447
loss_c:1.738403081893921
loss_r:0.022877024486660957
loss_c:1.7733373641967773
loss_r:0.020036309957504272
loss_c:1.7205257415771484
loss_r:0.01956624910235405
loss_c:1.6066579818725586
loss_r:0.024862919002771378
loss_c:1.8485316038131714
loss_r:0.01923191174864769
loss_c:1.7408318519592285
loss_r:0.022034883499145508
loss_c:1.7835347652435303
loss_r:0.02271355502307415
loss_c:1.7173579931259155
loss_r:0.020410209894180298
loss_c:1.725412130355835
loss_r:0.02123541384935379
loss_c:1.7388066053390503
loss_r:0.0212988443672657
loss_c:1.7911262512207031
loss_r:0.018408242613077164
loss_c:1.7610485553741455
loss_r:0.020824598148465157
loss_c:1.7575509548187256
loss_r:0.02090209536254406
loss_c:1.7470481395721436
loss_r:0.019885355606675148
loss_c:1.7572015523910522
loss_r:0.020661447197198868
loss_c:1.8246405124664307
loss_r:0.020596908405423164
loss_c:1.8389089107513428
loss_r:0.01936490274965763
loss_c:1.7985153198242188
loss_r:0.022227853536605835
loss_c:1.9021878242492676
loss_r:0.021878914907574654
loss_c:1.8268216848373413
loss_r:0.019387412816286087
loss_c:1.784340262413025
loss_r:0.019733976572752
loss_c:1.6604089736938477
loss_r:0.01953914575278759
loss_c:1.708862066268921
loss_r:0.0195059385150671
loss_c:1.8319933414459229
loss_r:0.0202704519033432
loss_c:1.8301537036895752
loss_r:0.020781105384230614
loss_c:1.8592491149902344
loss_r:0.01976022869348526
loss_c:1.838754653930664
loss_r:0.02018938586115837
loss_c:1.7311558723449707
loss_r:0.022006260231137276
loss_c:1.825598120689392
loss_r:0.019090933725237846
loss_c:1.7875889539718628
loss_r:0.020960122346878052
loss_c:1.7645232677459717
loss_r:0.01964411325752735
loss_c:1.6128771305084229
loss_r:0.01974146068096161
loss_c:1.6939730644226074
loss_r:0.01990589313209057
loss_c:1.6272141933441162
loss_r:0.0229288749396801
loss_c:1.7468780279159546
loss_r:0.019385753199458122
loss_c:1.712660312652588
loss_r:0.0225225742906332
loss_c:1.7569990158081055
loss_r:0.022812625393271446
loss_c:1.69558846950531
loss_r:0.02181580290198326
loss_c:1.7082500457763672
loss_r:0.0202059093862772
loss_c:1.595115065574646
loss_r:0.022312071174383163
loss_c:1.7649005651474
loss_r:0.020272258669137955
loss_c:1.7800887823104858
loss_r:0.021441979333758354
loss_c:1.8047807216644287
loss_r:0.022600514814257622
loss_c:1.7419555187225342
loss_r:0.021407516673207283
loss_c:1.7285854816436768
loss_r:0.020596005022525787
loss_c:1.5906805992126465
loss_r:0.022674264386296272
loss_c:1.7162437438964844
loss_r:0.021427197381854057
loss_c:1.8063291311264038
loss_r:0.02314659394323826
loss_c:1.8396339416503906
loss_r:0.022374674677848816
loss_c:1.6952979564666748
loss_r:0.02121313102543354
loss_c:1.735374927520752
loss_r:0.02102799527347088
loss_c:1.6196998357772827
loss_r:0.021747762337327003
loss_c:1.7672650814056396
loss_r:0.02009911648929119
loss_c:1.7398643493652344
loss_r:0.02281227707862854
loss_c:1.8491370677947998
loss_r:0.021091075614094734
loss_c:1.6761020421981812
loss_r:0.022816648706793785
loss_c:1.8002313375473022
loss_r:0.02195272594690323
loss_c:1.6532940864562988
loss_r:0.02258804254233837
loss_c:1.7525315284729004
loss_r:0.02011989988386631
loss_c:1.7366790771484375
loss_r:0.023300329223275185
loss_c:1.8093866109848022
loss_r:0.02109220065176487
loss_c:1.617322325706482
loss_r:0.022154800593852997
loss_c:1.7807064056396484
loss_r:0.02227863296866417
loss_c:1.6306318044662476
loss_r:0.023167090490460396
loss_c:1.716018557548523
loss_r:0.0237534511834383
loss_c:1.785815954208374
loss_r:0.024922531098127365
loss_c:1.8229683637619019
loss_r:0.02163728140294552
loss_c:1.649347186088562
loss_r:0.025006785988807678
loss_c:1.8576195240020752
loss_r:0.022241318598389626
loss_c:1.6374146938323975
loss_r:0.023292722180485725
loss_c:1.6164124011993408
loss_r:0.02376844733953476
loss_c:1.773101568222046
loss_r:0.02579168975353241
loss_c:1.8292850255966187
loss_r:0.021233264356851578
loss_c:1.6146116256713867
loss_r:0.024714961647987366
loss_c:1.8172696828842163
loss_r:0.023969752714037895
loss_c:1.5894277095794678
loss_r:0.023965446278452873
loss_c:1.6629979610443115
loss_r:0.023427806794643402
loss_c:1.7440080642700195
loss_r:0.024127323180437088
loss_c:1.724613904953003
loss_r:0.020948782563209534
loss_c:1.5169857740402222
loss_r:0.025093810632824898
loss_c:1.7693928480148315
loss_r:0.025526437908411026
loss_c:1.6539173126220703
loss_r:0.02490086294710636
loss_c:1.6509945392608643
loss_r:0.023857126012444496
loss_c:1.6819214820861816
loss_r:0.024098623543977737
loss_c:1.723272681236267
loss_r:0.021045224741101265
loss_c:1.5398626327514648
loss_r:0.02545086108148098
loss_c:1.806480884552002
loss_r:0.022706953808665276
loss_c:1.5263011455535889
loss_r:0.0251508466899395
loss_c:1.6176599264144897
loss_r:0.022589292377233505
loss_c:1.7249298095703125
loss_r:0.02528311312198639
loss_c:1.805875301361084
loss_r:0.02055525965988636
loss_c:1.5900195837020874
loss_r:0.02660285122692585
loss_c:1.8766248226165771
loss_r:0.024950098246335983
loss_c:1.580553412437439
loss_r:0.02600759267807007
loss_c:1.600592017173767
loss_r:0.022257322445511818
loss_c:1.577040672302246
loss_r:0.024867530912160873
loss_c:1.7679152488708496
loss_r:0.02010381780564785
loss_c:1.5754814147949219
loss_r:0.025193851441144943
loss_c:1.8091157674789429
loss_r:0.02284238487482071
loss_c:1.5564689636230469
loss_r:0.026215268298983574
loss_c:1.5934486389160156
loss_r:0.02184944972395897
loss_c:1.5490429401397705
loss_r:0.02358902059495449
loss_c:1.7163448333740234
loss_r:0.020822998136281967
loss_c:1.6024456024169922
loss_r:0.026690034195780754
loss_c:1.8679417371749878
loss_r:0.02201535366475582
loss_c:1.5365266799926758
loss_r:0.02741914801299572
loss_c:1.618234395980835
loss_r:0.0230938158929348
loss_c:1.5841069221496582
loss_r:0.027661005035042763
loss_c:1.7815322875976562
loss_r:0.02242952026426792
loss_c:1.643934726715088
loss_r:0.02842825837433338
loss_c:1.8156945705413818
loss_r:0.02620863728225231
loss_c:1.5771487951278687
loss_r:0.030138401314616203
loss_c:1.6627886295318604
loss_r:0.027097221463918686
loss_c:1.657342791557312
loss_r:0.02673858404159546
loss_c:1.7173852920532227
loss_r:0.023332275450229645
loss_c:1.6071656942367554
loss_r:0.02880791760981083
loss_c:1.811659812927246
loss_r:0.023312963545322418
loss_c:1.5205644369125366
loss_r:0.030244670808315277
loss_c:1.671775221824646
loss_r:0.02624165639281273
loss_c:1.6312386989593506
loss_r:0.028787551447749138
loss_c:1.7535762786865234
loss_r:0.022694330662488937
loss_c:1.6317518949508667
loss_r:0.028766339644789696
loss_c:1.8448207378387451
loss_r:0.024321382865309715
loss_c:1.5642204284667969
loss_r:0.030282773077487946
loss_c:1.7808425426483154
loss_r:0.02672513760626316
loss_c:1.6760762929916382
loss_r:0.029945217072963715
loss_c:1.7979282140731812
loss_r:0.0232319924980402
loss_c:1.6695096492767334
loss_r:0.029900599271059036
loss_c:1.8362096548080444
loss_r:0.024816056713461876
loss_c:1.6007835865020752
loss_r:0.03049318492412567
loss_c:1.7318228483200073
loss_r:0.024500949308276176
loss_c:1.6304023265838623
loss_r:0.032565224915742874
loss_c:1.9582061767578125
loss_r:0.02309403009712696
loss_c:1.6861047744750977
loss_r:0.030478214845061302
loss_c:1.9075506925582886
loss_r:0.02280399017035961
loss_c:1.5425266027450562
loss_r:0.028052257373929024
loss_c:1.6688873767852783
loss_r:0.023457899689674377
loss_c:1.6140588521957397
loss_r:0.029686102643609047
loss_c:1.8582862615585327
loss_r:0.02369333989918232
loss_c:1.6712416410446167
loss_r:0.031252671033144
loss_c:1.9162511825561523
loss_r:0.021666040644049644
loss_c:1.5014493465423584
loss_r:0.025755833834409714
loss_c:1.609318494796753
loss_r:0.02356291376054287
loss_c:1.5755281448364258
loss_r:0.028615886345505714
loss_c:1.7806897163391113
loss_r:0.021549995988607407
loss_c:1.615907073020935
loss_r:0.029823562130331993
loss_c:1.8780735731124878
loss_r:0.021818790584802628
loss_c:1.4845988750457764
loss_r:0.02502569369971752
loss_c:1.6008458137512207
loss_r:0.022686749696731567
loss_c:1.594289779663086
loss_r:0.02841392159461975
loss_c:1.8286406993865967
loss_r:0.02229001373052597
loss_c:1.6472762823104858
loss_r:0.02976272813975811
loss_c:1.8523820638656616
loss_r:0.021884119138121605
loss_c:1.4692211151123047
loss_r:0.02409094199538231
loss_c:1.5862255096435547
loss_r:0.02199164591729641
loss_c:1.564469337463379
loss_r:0.02842504158616066
loss_c:1.8626588582992554
loss_r:0.022382397204637527
loss_c:1.6586170196533203
loss_r:0.030308222398161888
loss_c:1.886289358139038
loss_r:0.02241758070886135
loss_c:1.5062594413757324
loss_r:0.02341952919960022
loss_c:1.5947318077087402
loss_r:0.022334396839141846
loss_c:1.5921400785446167
loss_r:0.02788475528359413
loss_c:1.8503694534301758
loss_r:0.02230258285999298
loss_c:1.683386206626892
loss_r:0.0301497969776392
loss_c:1.943028450012207
loss_r:0.021753601729869843
loss_c:1.5014275312423706
loss_r:0.02396741695702076
loss_c:1.6306610107421875
loss_r:0.021313784644007683
loss_c:1.5900864601135254
loss_r:0.027708662673830986
loss_c:1.838789701461792
loss_r:0.02399648167192936
loss_c:1.7068113088607788
loss_r:0.029739858582615852
loss_c:1.9053504467010498
loss_r:0.023433372378349304
loss_c:1.5544642210006714
loss_r:0.026152094826102257
loss_c:1.6343023777008057
loss_r:0.024247009307146072
loss_c:1.6055362224578857
loss_r:0.03200865536928177
loss_c:1.8571404218673706
loss_r:0.022869456559419632
loss_c:1.6361892223358154
loss_r:0.0320407971739769
loss_c:1.9002103805541992
loss_r:0.022043786942958832
loss_c:1.490156888961792
loss_r:0.026947608217597008
loss_c:1.6376519203186035
loss_r:0.025431543588638306
loss_c:1.6454150676727295
loss_r:0.029777545481920242
loss_c:1.798930048942566
loss_r:0.0214907918125391
loss_c:1.6301047801971436
loss_r:0.02862606570124626
loss_c:1.8578298091888428
loss_r:0.021178385242819786
loss_c:1.5592488050460815
loss_r:0.024780500680208206
loss_c:1.634890079498291
loss_r:0.021930746734142303
loss_c:1.6363627910614014
loss_r:0.030091488733887672
loss_c:1.8719823360443115
loss_r:0.018558941781520844
loss_c:1.5756564140319824
loss_r:0.026875004172325134
loss_c:1.857812762260437
loss_r:0.022601447999477386
loss_c:1.5758366584777832
loss_r:0.026975588873028755
loss_c:1.862188696861267
loss_r:0.025299932807683945
loss_c:1.8102474212646484
loss_r:0.025969916954636574
loss_c:1.848259687423706
loss_r:0.02058151736855507
loss_c:1.7540562152862549
loss_r:0.02639756165444851
loss_c:1.9206011295318604
loss_r:0.022843552753329277
loss_c:1.6636966466903687
loss_r:0.026095591485500336
loss_c:1.7748448848724365
loss_r:0.02335311286151409
loss_c:1.7042646408081055
loss_r:0.026815181598067284
loss_c:1.8376319408416748
loss_r:0.020487889647483826
loss_c:1.6882219314575195
loss_r:0.026522215455770493
loss_c:1.89268159866333
loss_r:0.021404854953289032
loss_c:1.6075177192687988
loss_r:0.026564056053757668
loss_c:1.8213900327682495
loss_r:0.022572429850697517
loss_c:1.6698863506317139
loss_r:0.026886004954576492
loss_c:1.9048599004745483
loss_r:0.02200639434158802
loss_c:1.7940711975097656
loss_r:0.026770228520035744
loss_c:1.9331347942352295
loss_r:0.024564074352383614
loss_c:1.6806896924972534
loss_r:0.02627904713153839
loss_c:1.8153375387191772
loss_r:0.024281879886984825
loss_c:1.734532117843628
loss_r:0.028120098635554314
loss_c:1.88870370388031
loss_r:0.0219936054199934
loss_c:1.771222472190857
loss_r:0.027978114783763885
loss_c:1.9408423900604248
loss_r:0.024176396429538727
loss_c:1.6386590003967285
loss_r:0.027756040915846825
loss_c:1.8040273189544678
loss_r:0.025203155353665352
loss_c:1.6804007291793823
loss_r:0.02982036955654621
loss_c:1.8734235763549805
loss_r:0.02256792038679123
loss_c:1.7400107383728027
loss_r:0.028703060001134872
loss_c:1.89458167552948
loss_r:0.026143480092287064
loss_c:1.6214865446090698
loss_r:0.02915199287235737
loss_c:1.7360610961914062
loss_r:0.027763625606894493
loss_c:1.6964428424835205
loss_r:0.02670569159090519
loss_c:1.758808970451355
loss_r:0.023167353123426437
loss_c:1.7083089351654053
loss_r:0.03198353201150894
loss_c:1.9068329334259033
loss_r:0.025583365932106972
loss_c:1.5557429790496826
loss_r:0.031034501269459724
loss_c:1.7351672649383545
loss_r:0.027414441108703613
loss_c:1.6306546926498413
loss_r:0.031089048832654953
loss_c:1.8708165884017944
loss_r:0.02464449778199196
loss_c:1.761041522026062
loss_r:0.02891005203127861
loss_c:1.859153151512146
loss_r:0.02565341256558895
loss_c:1.6218795776367188
loss_r:0.02809322066605091
loss_c:1.736264944076538
loss_r:0.028437292203307152
loss_c:1.7323516607284546
loss_r:0.028992386534810066
loss_c:1.8024061918258667
loss_r:0.02323540858924389
loss_c:1.6576290130615234
loss_r:0.028967253863811493
loss_c:1.8057187795639038
loss_r:0.027176139876246452
loss_c:1.584273099899292
loss_r:0.032817766070365906
loss_c:1.7878377437591553
loss_r:0.027377042919397354
loss_c:1.7529109716415405
loss_r:0.030649710446596146
loss_c:1.8271387815475464
loss_r:0.022997045889496803
loss_c:1.7139017581939697
loss_r:0.030821066349744797
loss_c:1.8819189071655273
loss_r:0.025875750929117203
loss_c:1.5525867938995361
loss_r:0.03292001038789749
loss_c:1.755774974822998
loss_r:0.028746694326400757
loss_c:1.7323827743530273
loss_r:0.029802678152918816
loss_c:1.8366520404815674
loss_r:0.02281309850513935
loss_c:1.650527000427246
loss_r:0.03079892508685589
loss_c:1.8811439275741577
loss_r:0.026267126202583313
loss_c:1.6086716651916504
loss_r:0.031663212925195694
loss_c:1.7149074077606201
loss_r:0.027501937001943588
loss_c:1.6719698905944824
loss_r:0.03180490806698799
loss_c:1.8328943252563477
loss_r:0.021180298179388046
loss_c:1.556632399559021
loss_r:0.026937637478113174
loss_c:1.7926254272460938
loss_r:0.025620944797992706
loss_c:1.584923267364502
loss_r:0.0303031112998724
loss_c:1.7108687162399292
loss_r:0.025949228554964066
loss_c:1.6333951950073242
loss_r:0.027157235890626907
loss_c:1.731165885925293
loss_r:0.023417163640260696
loss_c:1.664571762084961
loss_r:0.02606094814836979
loss_c:1.7531675100326538
loss_r:0.026875507086515427
loss_c:1.6542072296142578
loss_r:0.030580395832657814
loss_c:1.8061507940292358
loss_r:0.02965828776359558
loss_c:1.731165885925293
loss_r:0.032910242676734924
loss_c:1.8913285732269287
loss_r:0.026482708752155304
loss_c:1.6741670370101929
loss_r:0.028392570093274117
loss_c:1.7763713598251343
loss_r:0.029174858704209328
loss_c:1.6605947017669678
loss_r:0.03312664106488228
loss_c:1.8300275802612305
loss_r:0.029472915455698967
loss_c:1.6765398979187012
loss_r:0.029296185821294785
loss_c:1.7841233015060425
loss_r:0.027720291167497635
loss_c:1.753676176071167
loss_r:0.02801935374736786
loss_c:1.790677547454834
loss_r:0.02746678702533245
loss_c:1.6056674718856812
loss_r:0.0288411732763052
loss_c:1.6900742053985596
loss_r:0.026760350912809372
loss_c:1.6291320323944092
loss_r:0.03202354162931442
loss_c:1.8115653991699219
loss_r:0.023282155394554138
loss_c:1.6484794616699219
loss_r:0.027830956503748894
loss_c:1.7499569654464722
loss_r:0.02861916832625866
loss_c:1.5858612060546875
loss_r:0.029947221279144287
loss_c:1.7579352855682373
loss_r:0.025821173563599586
loss_c:1.628475546836853
loss_r:0.0306429173797369
loss_c:1.7940359115600586
loss_r:0.02300623059272766
loss_c:1.6498651504516602
loss_r:0.026151496917009354
loss_c:1.7409818172454834
loss_r:0.02878851443529129
loss_c:1.604862928390503
loss_r:0.030081624165177345
loss_c:1.7831079959869385
loss_r:0.023811940103769302
loss_c:1.5937575101852417
loss_r:0.029413294047117233
loss_c:1.8555558919906616
loss_r:0.023185066878795624
loss_c:1.7182143926620483
loss_r:0.02579474076628685
loss_c:1.7409824132919312
loss_r:0.027312874794006348
loss_c:1.6208739280700684
loss_r:0.028148306533694267
loss_c:1.7763750553131104
loss_r:0.027891812846064568
loss_c:1.6806929111480713
loss_r:0.025888128206133842
loss_c:1.8045777082443237
loss_r:0.02246398665010929
loss_c:1.6868900060653687
loss_r:0.025016700848937035
loss_c:1.7034199237823486
loss_r:0.024245839565992355
loss_c:1.501250982284546
loss_r:0.02797432243824005
loss_c:1.7568600177764893
loss_r:0.029811151325702667
loss_c:1.7812068462371826
loss_r:0.028004463762044907
loss_c:1.9245342016220093
loss_r:0.021544199436903
loss_c:1.6428289413452148
loss_r:0.026578014716506004
loss_c:1.84482741355896
loss_r:0.02992570959031582
loss_c:1.8090183734893799
loss_r:0.03000444918870926
loss_c:1.8718478679656982
loss_r:0.02826360985636711
loss_c:1.7862203121185303
loss_r:0.0257185660302639
loss_c:1.874861717224121
loss_r:0.022310351952910423
loss_c:1.7014615535736084
loss_r:0.023328205570578575
loss_c:1.8891961574554443
loss_r:0.02564365230500698
loss_c:1.8323400020599365
loss_r:0.028918122872710228
loss_c:1.8945468664169312
loss_r:0.027187587693333626
loss_c:1.9583680629730225
loss_r:0.02734360098838806
loss_c:2.081132411956787
loss_r:0.02239961549639702
loss_c:1.806319236755371
loss_r:0.022836683318018913
loss_c:1.877039909362793
loss_r:0.024976065382361412
loss_c:1.836984395980835
loss_r:0.027331767603754997
loss_c:1.9008886814117432
loss_r:0.02695605531334877
loss_c:1.9928913116455078
loss_r:0.024934865534305573
loss_c:2.0309624671936035
loss_r:0.02431066706776619
loss_c:1.9123162031173706
loss_r:0.024110199883580208
loss_c:1.9806413650512695
loss_r:0.023080455139279366
loss_c:1.816475749015808
loss_r:0.023435253649950027
loss_c:1.8030656576156616
loss_r:0.025640226900577545
loss_c:1.862971305847168
loss_r:0.025511618703603745
loss_c:2.0404133796691895
loss_r:0.02363462559878826
loss_c:1.8765175342559814
loss_r:0.024411898106336594
loss_c:1.9600380659103394
loss_r:0.023064548149704933
loss_c:1.8144197463989258
loss_r:0.025553397834300995
loss_c:1.8150596618652344
loss_r:0.02554936707019806
loss_c:1.864763617515564
loss_r:0.025746852159500122
loss_c:1.9716908931732178
loss_r:0.021445121616125107
loss_c:1.817023515701294
loss_r:0.024951284751296043
loss_c:1.9804222583770752
loss_r:0.021811939775943756
loss_c:1.8156888484954834
loss_r:0.02401353046298027
loss_c:1.898983359336853
loss_r:0.023981889709830284
loss_c:1.9320138692855835
loss_r:0.024080704897642136
loss_c:2.063631057739258
loss_r:0.022596202790737152
loss_c:1.870427131652832
loss_r:0.02445208840072155
loss_c:2.0193135738372803
loss_r:0.020183848217129707
loss_c:1.7699189186096191
loss_r:0.021680312231183052
loss_c:1.8166062831878662
loss_r:0.021596230566501617
loss_c:1.8714078664779663
loss_r:0.02382313273847103
loss_c:2.0384438037872314
loss_r:0.019903143867850304
loss_c:1.8454030752182007
loss_r:0.02323395386338234
loss_c:1.9856815338134766
loss_r:0.019556110724806786
loss_c:1.7563824653625488
loss_r:0.021351603791117668
loss_c:1.8242871761322021
loss_r:0.021584121510386467
loss_c:1.939409613609314
loss_r:0.023954376578330994
loss_c:2.148066759109497
loss_r:0.019774289801716805
loss_c:1.8199490308761597
loss_r:0.02362741529941559
loss_c:2.0479743480682373
loss_r:0.021480053663253784
loss_c:1.8584132194519043
loss_r:0.02136015146970749
loss_c:1.9048233032226562
loss_r:0.022517884150147438
loss_c:1.9701063632965088
loss_r:0.022275200113654137
loss_c:2.0588059425354004
loss_r:0.01877322793006897
loss_c:1.8257086277008057
loss_r:0.023239171132445335
loss_c:2.0529696941375732
loss_r:0.019261078909039497
loss_c:1.7714799642562866
loss_r:0.022407222539186478
loss_c:1.9036765098571777
loss_r:0.022805731743574142
loss_c:1.9406402111053467
loss_r:0.02436351403594017
loss_c:2.044816493988037
loss_r:0.019946439191699028
loss_c:1.7872982025146484
loss_r:0.02428087219595909
loss_c:2.033700942993164
loss_r:0.02062940038740635
loss_c:1.7530138492584229
loss_r:0.02254459820687771
loss_c:1.8341249227523804
loss_r:0.02319864183664322
loss_c:1.9427118301391602
loss_r:0.023888060823082924
loss_c:2.036576747894287
loss_r:0.01890561170876026
loss_c:1.7995851039886475
loss_r:0.022408492863178253
loss_c:1.9623191356658936
loss_r:0.019298072904348373
loss_c:1.8088449239730835
loss_r:0.021060392260551453
loss_c:1.8667097091674805
loss_r:0.02153133414685726
loss_c:1.9718530178070068
loss_r:0.02229560725390911
loss_c:2.054478168487549
loss_r:0.020063253119587898
loss_c:1.9177043437957764
loss_r:0.02388136088848114
loss_c:2.1377081871032715
loss_r:0.022720355540513992
loss_c:2.0129382610321045
loss_r:0.024788450449705124
loss_c:2.0647428035736084
loss_r:0.021884052082896233
loss_c:2.010802745819092
loss_r:0.02192705124616623
loss_c:2.006608009338379
loss_r:0.01878609135746956
loss_c:1.8145169019699097
loss_r:0.02053050324320793
loss_c:1.9201864004135132
loss_r:0.020489059388637543
loss_c:1.8730372190475464
loss_r:0.022017426788806915
loss_c:1.9623397588729858
loss_r:0.02112441696226597
loss_c:2.005960464477539
loss_r:0.02178683690726757
loss_c:2.0209760665893555
loss_r:0.019010066986083984
loss_c:1.8815422058105469
loss_r:0.021708477288484573
loss_c:1.9693431854248047
loss_r:0.020699912682175636
loss_c:1.8549522161483765
loss_r:0.02255106158554554
loss_c:1.9659631252288818
loss_r:0.020750297233462334
loss_c:1.9893620014190674
loss_r:0.021296292543411255
loss_c:1.9766793251037598
loss_r:0.0189012810587883
loss_c:1.8608430624008179
loss_r:0.02155349776148796
loss_c:1.992716670036316
loss_r:0.020704826340079308
loss_c:1.8230293989181519
loss_r:0.02235245518386364
loss_c:1.8996922969818115
loss_r:0.021368399262428284
loss_c:1.962782382965088
loss_r:0.021479496732354164
loss_c:1.9601142406463623
loss_r:0.02126048132777214
loss_c:1.8665785789489746
loss_r:0.023253748193383217
loss_c:1.9661424160003662
loss_r:0.02221851237118244
loss_c:1.8093833923339844
loss_r:0.02177787572145462
loss_c:1.8285300731658936
loss_r:0.023094015195965767
loss_c:1.9867185354232788
loss_r:0.021615969017148018
loss_c:1.9029067754745483
loss_r:0.02045021951198578
loss_c:1.8270823955535889
loss_r:0.021757429465651512
loss_c:1.9133853912353516
loss_r:0.02210811898112297
loss_c:1.7687122821807861
loss_r:0.023261122405529022
loss_c:1.8705508708953857
loss_r:0.022410493344068527
loss_c:1.921870470046997
loss_r:0.02133730612695217
loss_c:1.8438241481781006
loss_r:0.020983705297112465
loss_c:1.8491065502166748
loss_r:0.021500788629055023
loss_c:1.9439222812652588
loss_r:0.020564602687954903
loss_c:1.7628610134124756
loss_r:0.021175464615225792
loss_c:1.8707207441329956
loss_r:0.020724600180983543
loss_c:1.8803409337997437
loss_r:0.020535772666335106
loss_c:1.8781484365463257
loss_r:0.020653055980801582
loss_c:1.787440538406372
loss_r:0.020632289350032806
loss_c:1.8568446636199951
loss_r:0.02149452455341816
loss_c:1.7164890766143799
loss_r:0.02196275070309639
loss_c:1.820314884185791
loss_r:0.02037767693400383
loss_c:1.8835630416870117
loss_r:0.018658673390746117
loss_c:1.7778220176696777
loss_r:0.02092447690665722
loss_c:1.7428081035614014
loss_r:0.02083640731871128
loss_c:1.825535774230957
loss_r:0.021432697772979736
loss_c:1.7491577863693237
loss_r:0.023188188672065735
loss_c:1.8164434432983398
loss_r:0.022406652569770813
loss_c:1.8147433996200562
loss_r:0.023419871926307678
loss_c:1.8107237815856934
loss_r:0.022047612816095352
loss_c:1.6299351453781128
loss_r:0.02209729328751564
loss_c:1.8430213928222656
loss_r:0.02145756408572197
loss_c:1.6654881238937378
loss_r:0.022282147780060768
loss_c:1.7607288360595703
loss_r:0.025851374492049217
loss_c:1.8967573642730713
loss_r:0.024949826300144196
loss_c:1.832067847251892
loss_r:0.023823698982596397
loss_c:1.6801958084106445
loss_r:0.021712107583880424
loss_c:1.7663731575012207
loss_r:0.020082231611013412
loss_c:1.6191052198410034
loss_r:0.02083231508731842
loss_c:1.7463583946228027
loss_r:0.022481322288513184
loss_c:1.7588043212890625
loss_r:0.02058170549571514
loss_c:1.6946237087249756
loss_r:0.02179231122136116
loss_c:1.622218370437622
loss_r:0.02290632762014866
loss_c:1.8174324035644531
loss_r:0.020714171230793
loss_c:1.6741642951965332
loss_r:0.02063927985727787
loss_c:1.7139074802398682
loss_r:0.022605396807193756
loss_c:1.85012948513031
loss_r:0.02243129536509514
loss_c:1.809403896331787
loss_r:0.020145082846283913
loss_c:1.6494169235229492
loss_r:0.022208815440535545
loss_c:1.8756561279296875
loss_r:0.0211534034460783
loss_c:1.750349760055542
loss_r:0.019162015989422798
loss_c:1.7191967964172363
loss_r:0.021758755668997765
loss_c:1.8558257818222046
loss_r:0.02531929314136505
loss_c:1.8934829235076904
loss_r:0.021362800151109695
loss_c:1.605664610862732
loss_r:0.024479767307639122
loss_c:1.8411144018173218
loss_r:0.02265024743974209
loss_c:1.6697849035263062
loss_r:0.020459022372961044
loss_c:1.6310913562774658
loss_r:0.023574668914079666
loss_c:1.6802239418029785
loss_r:0.024275029078125954
loss_c:1.758268117904663
loss_r:0.022151434794068336
loss_c:1.5738601684570312
loss_r:0.02326858974993229
loss_c:1.7169793844223022
loss_r:0.0215337872505188
loss_c:1.750916838645935
loss_r:0.022197362035512924
loss_c:1.6549444198608398
loss_r:0.026885483413934708
loss_c:1.816148281097412
loss_r:0.026885440573096275
loss_c:1.7982325553894043
loss_r:0.022721393033862114
loss_c:1.5123809576034546
loss_r:0.021900150924921036
loss_c:1.6721670627593994
loss_r:0.025339577347040176
loss_c:1.6316609382629395
loss_r:0.022187089547514915
loss_c:1.5073306560516357
loss_r:0.02459799498319626
loss_c:1.7252225875854492
loss_r:0.02313666045665741
loss_c:1.611142873764038
loss_r:0.024999696761369705
loss_c:1.534874439239502
loss_r:0.02535136416554451
loss_c:1.7981929779052734
loss_r:0.027221357449889183
loss_c:1.7255654335021973
loss_r:0.023131733760237694
loss_c:1.5661123991012573
loss_r:0.02346605621278286
loss_c:1.7374776601791382
loss_r:0.02504219301044941
loss_c:1.687620997428894
loss_r:0.02553468756377697
loss_c:1.5506714582443237
loss_r:0.025570331141352654
loss_c:1.7835744619369507
loss_r:0.02573220804333687
loss_c:1.6537625789642334
loss_r:0.022980231791734695
loss_c:1.5377085208892822
loss_r:0.022437701001763344
loss_c:1.6561355590820312
loss_r:0.02467123232781887
loss_c:1.6376852989196777
loss_r:0.021633755415678024
loss_c:1.494410514831543
loss_r:0.021656960248947144
loss_c:1.6204570531845093
loss_r:0.024434268474578857
loss_c:1.6155579090118408
loss_r:0.022010531276464462
loss_c:1.582209825515747
loss_r:0.019976699724793434
loss_c:1.6218475103378296
loss_r:0.02333579771220684
loss_c:1.6484556198120117
loss_r:0.023083869367837906
loss_c:1.5434279441833496
loss_r:0.02616071328520775
loss_c:1.8039865493774414
loss_r:0.026541415601968765
loss_c:1.6881091594696045
loss_r:0.022727077826857567
loss_c:1.6085748672485352
loss_r:0.02363669127225876
loss_c:1.6758439540863037
loss_r:0.01983870379626751
loss_c:1.5808582305908203
loss_r:0.02515811286866665
loss_c:1.5140622854232788
loss_r:0.02764650620520115
loss_c:1.8155670166015625
loss_r:0.024894127622246742
loss_c:1.598197340965271
loss_r:0.02258528210222721
loss_c:1.5833117961883545
loss_r:0.021618032827973366
loss_c:1.6623066663742065
loss_r:0.023604964837431908
loss_c:1.6451687812805176
loss_r:0.025669120252132416
loss_c:1.6153590679168701
loss_r:0.024895764887332916
loss_c:1.7688729763031006
loss_r:0.0271993950009346
loss_c:1.8169262409210205
loss_r:0.022741207852959633
loss_c:1.7685978412628174
loss_r:0.02422538958489895
loss_c:1.7331047058105469
loss_r:0.023980744183063507
loss_c:1.707780122756958
loss_r:0.02273659221827984
loss_c:1.5649021863937378
loss_r:0.02326870709657669
loss_c:1.709824562072754
loss_r:0.022791404277086258
loss_c:1.5850380659103394
loss_r:0.023493286222219467
loss_c:1.6865739822387695
loss_r:0.021401427686214447
loss_c:1.670701265335083
loss_r:0.021987510845065117
loss_c:1.6428626775741577
loss_r:0.02052341401576996
loss_c:1.5617908239364624
loss_r:0.021754110231995583
loss_c:1.694457769393921
loss_r:0.0203322134912014
loss_c:1.6335389614105225
loss_r:0.01978624239563942
loss_c:1.710919737815857
loss_r:0.0206497423350811
loss_c:1.7171962261199951
loss_r:0.018314693123102188
loss_c:1.6437618732452393
loss_r:0.021759143099188805
loss_c:1.6223423480987549
loss_r:0.020031865686178207
loss_c:1.6433346271514893
loss_r:0.018387870863080025
loss_c:1.5501502752304077
loss_r:0.01871315948665142
loss_c:1.664076328277588
loss_r:0.02019917033612728
loss_c:1.662103533744812
loss_r:0.01846027374267578
loss_c:1.6884868144989014
loss_r:0.019613469019532204
loss_c:1.6078532934188843
loss_r:0.021512793377041817
loss_c:1.7295033931732178
loss_r:0.019941013306379318
loss_c:1.654783010482788
loss_r:0.01830972731113434
loss_c:1.6612491607666016
loss_r:0.02127973362803459
loss_c:1.7550172805786133
loss_r:0.0208677239716053
loss_c:1.7462964057922363
loss_r:0.024572670459747314
loss_c:1.6600325107574463
loss_r:0.02311837300658226
loss_c:1.7440756559371948
loss_r:0.020499618723988533
loss_c:1.6429297924041748
loss_r:0.024226097390055656
loss_c:1.7459945678710938
loss_r:0.02709360048174858
loss_c:1.8273357152938843
loss_r:0.02128017507493496
loss_c:1.7540801763534546
loss_r:0.022869491949677467
loss_c:1.6321805715560913
loss_r:0.02414149045944214
loss_c:1.6974338293075562
loss_r:0.021522104740142822
loss_c:1.663543939590454
loss_r:0.018143989145755768
loss_c:1.6167058944702148
loss_r:0.022374194115400314
loss_c:1.6884407997131348
loss_r:0.018043939024209976
loss_c:1.7104473114013672
loss_r:0.01777055114507675
loss_c:1.4844708442687988
loss_r:0.020754294469952583
loss_c:1.745208501815796
loss_r:0.018866831436753273
loss_c:1.7105029821395874
loss_r:0.017206275835633278
loss_c:1.6556785106658936
loss_r:0.019760577008128166
loss_c:1.7383003234863281
loss_r:0.01845313236117363
loss_c:1.744269847869873
loss_r:0.018710916861891747
loss_c:1.6078580617904663
loss_r:0.020930780097842216
loss_c:1.7606844902038574
loss_r:0.01918444223701954
loss_c:1.7364215850830078
loss_r:0.01578189618885517
loss_c:1.624826192855835
loss_r:0.018639128655195236
loss_c:1.7470407485961914
loss_r:0.015464263036847115
loss_c:1.6885122060775757
loss_r:0.01699870079755783
loss_c:1.5469406843185425
loss_r:0.019142869859933853
loss_c:1.7353837490081787
loss_r:0.016748039051890373
loss_c:1.666858434677124
loss_r:0.015143482014536858
loss_c:1.5615580081939697
loss_r:0.018857158720493317
loss_c:1.7365645170211792
loss_r:0.015793439000844955
loss_c:1.6548125743865967
loss_r:0.01627407968044281
loss_c:1.5109374523162842
loss_r:0.019710317254066467
loss_c:1.7291902303695679
loss_r:0.017252901569008827
loss_c:1.641562819480896
loss_r:0.01746462471783161
loss_c:1.6111572980880737
loss_r:0.019402967765927315
loss_c:1.6712350845336914
loss_r:0.017270885407924652
loss_c:1.7364572286605835
loss_r:0.017391471192240715
loss_c:1.4945415258407593
loss_r:0.020755209028720856
loss_c:1.730987310409546
loss_r:0.018459919840097427
loss_c:1.677215337753296
loss_r:0.016930095851421356
loss_c:1.6118552684783936
loss_r:0.019326848909258842
loss_c:1.6752179861068726
loss_r:0.018254946917295456
loss_c:1.7600806951522827
loss_r:0.01714201085269451
loss_c:1.5266289710998535
loss_r:0.019977815449237823
loss_c:1.7314319610595703
loss_r:0.01760031469166279
loss_c:1.6278314590454102
loss_r:0.015759659931063652
loss_c:1.5918464660644531
loss_r:0.019505010917782784
loss_c:1.6878340244293213
loss_r:0.017811739817261696
loss_c:1.7167266607284546
loss_r:0.017377706244587898
loss_c:1.5344772338867188
loss_r:0.021559493616223335
loss_c:1.7581241130828857
loss_r:0.020109040662646294
loss_c:1.7399451732635498
loss_r:0.01906922273337841
loss_c:1.6711056232452393
loss_r:0.01992754638195038
loss_c:1.713212013244629
loss_r:0.018413197249174118
loss_c:1.8082776069641113
loss_r:0.01875157840549946
loss_c:1.5931615829467773
loss_r:0.020456155762076378
loss_c:1.7853686809539795
loss_r:0.019980497658252716
loss_c:1.7224520444869995
loss_r:0.017942171543836594
loss_c:1.6304800510406494
loss_r:0.01974051631987095
loss_c:1.6609266996383667
loss_r:0.01874266192317009
loss_c:1.7921702861785889
loss_r:0.01893029920756817
loss_c:1.5965723991394043
loss_r:0.022654665634036064
loss_c:1.766179084777832
loss_r:0.02136681228876114
loss_c:1.7494205236434937
loss_r:0.020731918513774872
loss_c:1.6631214618682861
loss_r:0.02213965356349945
loss_c:1.7220420837402344
loss_r:0.020828021690249443
loss_c:1.786893606185913
loss_r:0.020669303834438324
loss_c:1.5772614479064941
loss_r:0.024566370993852615
loss_c:1.7487295866012573
loss_r:0.022693097591400146
loss_c:1.7088871002197266
loss_r:0.021982183679938316
loss_c:1.6220030784606934
loss_r:0.0248490609228611
loss_c:1.7498615980148315
loss_r:0.023083766922354698
loss_c:1.8457319736480713
loss_r:0.021634982898831367
loss_c:1.5702918767929077
loss_r:0.02480441890656948
loss_c:1.7441906929016113
loss_r:0.02500864304602146
loss_c:1.7292938232421875
loss_r:0.02223346009850502
loss_c:1.6147617101669312
loss_r:0.022860942408442497
loss_c:1.7216312885284424
loss_r:0.02423892915248871
loss_c:1.8376853466033936
loss_r:0.02179807797074318
loss_c:1.5416463613510132
loss_r:0.025289319455623627
loss_c:1.772831916809082
loss_r:0.02288168855011463
loss_c:1.647790789604187
loss_r:0.022632550448179245
loss_c:1.6151721477508545
loss_r:0.024343149736523628
loss_c:1.7472171783447266
loss_r:0.023009905591607094
loss_c:1.7215989828109741
loss_r:0.020979195833206177
loss_c:1.5513916015625
loss_r:0.02505369298160076
loss_c:1.7395875453948975
loss_r:0.024010123685002327
loss_c:1.6734657287597656
loss_r:0.02372974157333374
loss_c:1.654807448387146
loss_r:0.02392452396452427
loss_c:1.7255033254623413
loss_r:0.021110616624355316
loss_c:1.679968237876892
loss_r:0.022252783179283142
loss_c:1.5485109090805054
loss_r:0.024425256997346878
loss_c:1.7535814046859741
loss_r:0.02295759879052639
loss_c:1.6758813858032227
loss_r:0.022334231063723564
loss_c:1.6102497577667236
loss_r:0.025529000908136368
loss_c:1.7876222133636475
loss_r:0.020445823669433594
loss_c:1.7514123916625977
loss_r:0.02326289564371109
loss_c:1.5614748001098633
loss_r:0.02656213566660881
loss_c:1.7285575866699219
loss_r:0.023264260962605476
loss_c:1.647361159324646
loss_r:0.02423088438808918
loss_c:1.6787112951278687
loss_r:0.026493284851312637
loss_c:1.772291898727417
loss_r:0.022646134719252586
loss_c:1.7739646434783936
loss_r:0.023656750097870827
loss_c:1.5887659788131714
loss_r:0.026595095172524452
loss_c:1.730386734008789
loss_r:0.024933399632573128
loss_c:1.6854524612426758
loss_r:0.023921800777316093
loss_c:1.6878662109375
loss_r:0.026287099346518517
loss_c:1.8044414520263672
loss_r:0.020238259807229042
loss_c:1.7184789180755615
loss_r:0.02236834540963173
loss_c:1.6107118129730225
loss_r:0.02666749432682991
loss_c:1.7485544681549072
loss_r:0.023382315412163734
loss_c:1.6692323684692383
loss_r:0.024417150765657425
loss_c:1.740527868270874
loss_r:0.026544369757175446
loss_c:1.750256061553955
loss_r:0.018506405875086784
loss_c:1.5986003875732422
loss_r:0.024465108290314674
loss_c:1.7084425687789917
loss_r:0.027654802426695824
loss_c:1.8522905111312866
loss_r:0.026920408010482788
loss_c:1.7794749736785889
loss_r:0.025463538244366646
loss_c:1.8352502584457397
loss_r:0.028382599353790283
loss_c:1.87825608253479
loss_r:0.026343073695898056
loss_c:1.8602256774902344
loss_r:0.02454313449561596
loss_c:1.7932045459747314
loss_r:0.02812613919377327
loss_c:1.899209976196289
loss_r:0.027052301913499832
loss_c:1.7736400365829468
loss_r:0.026504743844270706
loss_c:1.8382842540740967
loss_r:0.025119755417108536
loss_c:1.8651299476623535
loss_r:0.024063754826784134
loss_c:1.9007465839385986
loss_r:0.02490968070924282
loss_c:1.8401435613632202
loss_r:0.02626764215528965
loss_c:1.9243578910827637
loss_r:0.0257676113396883
loss_c:1.7812297344207764
loss_r:0.0242777056992054
loss_c:1.8085744380950928
loss_r:0.025669200345873833
loss_c:1.8950603008270264
loss_r:0.024832962080836296
loss_c:1.8435420989990234
loss_r:0.02541329897940159
loss_c:1.8597577810287476
loss_r:0.02848169021308422
loss_c:1.9889825582504272
loss_r:0.027886204421520233
loss_c:1.8823316097259521
loss_r:0.029932275414466858
loss_c:1.92914617061615
loss_r:0.031520359218120575
loss_c:1.9845041036605835
loss_r:0.027919761836528778
loss_c:1.8809093236923218
loss_r:0.0273938849568367
loss_c:1.8378514051437378
loss_r:0.02951427362859249
loss_c:1.917622447013855
loss_r:0.028126196935772896
loss_c:1.7917002439498901
loss_r:0.027167698368430138
loss_c:1.8541278839111328
loss_r:0.027651362121105194
loss_c:1.8666938543319702
loss_r:0.027529165148735046
loss_c:1.8345394134521484
loss_r:0.025126351043581963
loss_c:1.8183584213256836
loss_r:0.026555800810456276
loss_c:1.9269742965698242
loss_r:0.026826929301023483
loss_c:1.8324661254882812
loss_r:0.026247361674904823
loss_c:1.9371061325073242
loss_r:0.025231143459677696
loss_c:1.9114954471588135
loss_r:0.02455328218638897
loss_c:1.8535575866699219
loss_r:0.026559144258499146
loss_c:1.9036636352539062
loss_r:0.024793410673737526
loss_c:1.9239295721054077
loss_r:0.024890150874853134
loss_c:1.793464183807373
loss_r:0.02544088289141655
loss_c:1.8865731954574585
loss_r:0.025195538997650146
loss_c:1.8552488088607788
loss_r:0.023465678095817566
loss_c:1.8065156936645508
loss_r:0.02562892436981201
loss_c:1.8430474996566772
loss_r:0.026373842731118202
loss_c:1.9535675048828125
loss_r:0.027965642511844635
loss_c:1.8128907680511475
total_val_loss:1.8041865825653076
EarlyStopping counter: 1 out of 2
epoch: 3/20
loss_r:0.03179382160305977
loss_c:0.8992903232574463
tensor(1.3864, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022277135401964188
loss_c:1.0272390842437744
tensor(1.4153, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026484861969947815
loss_c:1.0524399280548096
tensor(1.4458, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02517782151699066
loss_c:0.9238141775131226
tensor(1.3724, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019235149025917053
loss_c:0.9666330814361572
tensor(1.3706, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0924026221036911
loss_c:0.9310518503189087
tensor(1.6520, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019401680678129196
loss_c:0.7782992124557495
tensor(1.2719, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01784745417535305
loss_c:0.8812968730926514
tensor(1.3199, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0196796003729105
loss_c:1.0499815940856934
tensor(1.4164, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02113109640777111
loss_c:0.9260342121124268
tensor(1.3570, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018764415755867958
loss_c:0.8824424743652344
tensor(1.3244, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024918144568800926
loss_c:0.7918322086334229
tensor(1.3018, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026152830570936203
loss_c:0.827466607093811
tensor(1.3256, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021304912865161896
loss_c:0.902923583984375
tensor(1.3455, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02765645459294319
loss_c:0.8735498785972595
tensor(1.3560, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01850709691643715
loss_c:0.8709720373153687
tensor(1.3172, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036116693168878555
loss_c:0.8757494688034058
tensor(1.3918, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021618420258164406
loss_c:0.9027986526489258
tensor(1.3467, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017205221578478813
loss_c:0.7622756958007812
tensor(1.2545, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04067468270659447
loss_c:0.9283758997917175
tensor(1.4383, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0241201501339674
loss_c:1.1033201217651367
tensor(1.4629, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024543991312384605
loss_c:0.9215406775474548
tensor(1.3686, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034404486417770386
loss_c:0.9770306348800659
tensor(1.4383, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019534673541784286
loss_c:0.8081297278404236
tensor(1.2881, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03718428313732147
loss_c:0.7578350305557251
tensor(1.3338, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044406142085790634
loss_c:0.9806591868400574
tensor(1.4812, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02072705700993538
loss_c:0.7960473895072937
tensor(1.2865, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10299329459667206
loss_c:0.9407646059989929
tensor(1.6997, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02238464541733265
loss_c:0.8496685028076172
tensor(1.3217, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020968729630112648
loss_c:0.795534610748291
tensor(1.2873, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.060317303985357285
loss_c:0.9917505979537964
tensor(1.5509, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026826348155736923
loss_c:0.9284111261367798
tensor(1.3816, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02189570665359497
loss_c:0.8465191721916199
tensor(1.3182, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030343081802129745
loss_c:0.9110239744186401
tensor(1.3865, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018573865294456482
loss_c:0.9717277884483337
tensor(1.3716, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027915921062231064
loss_c:0.833196759223938
tensor(1.3353, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02197481133043766
loss_c:0.8333553075790405
tensor(1.3117, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03673252463340759
loss_c:0.9677090644836426
tensor(1.4420, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02067619003355503
loss_c:0.8509318232536316
tensor(1.3159, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020656023174524307
loss_c:0.9906246066093445
tensor(1.3903, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03203480318188667
loss_c:0.8606151342391968
tensor(1.3662, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026101432740688324
loss_c:0.8882656097412109
tensor(1.3574, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022135792300105095
loss_c:0.8592416644096375
tensor(1.3262, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04918035492300987
loss_c:0.8369657397270203
tensor(1.4215, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023896722123026848
loss_c:0.9896532893180847
tensor(1.4028, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03796597197651863
loss_c:0.7714263200759888
tensor(1.3420, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0218022633343935
loss_c:1.019083857536316
tensor(1.4103, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0351007916033268
loss_c:0.8377461433410645
tensor(1.3660, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05323292315006256
loss_c:0.910114049911499
tensor(1.4762, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034580159932374954
loss_c:0.9611471891403198
tensor(1.4298, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020928028970956802
loss_c:0.8011609315872192
tensor(1.2905, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01836933009326458
loss_c:0.8968300223350525
tensor(1.3317, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016436349600553513
loss_c:0.8417908549308777
tensor(1.2947, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032119158655405045
loss_c:0.8887215852737427
tensor(1.3813, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02396765723824501
loss_c:0.9327967166900635
tensor(1.3730, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023949110880494118
loss_c:0.9415487051010132
tensor(1.3776, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04432819411158562
loss_c:0.9182577133178711
tensor(1.4450, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019314032047986984
loss_c:0.9157316088676453
tensor(1.3456, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023994507268071175
loss_c:0.9331841468811035
tensor(1.3733, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016694026067852974
loss_c:0.8533865809440613
tensor(1.3019, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02129391022026539
loss_c:0.8665697574615479
tensor(1.3270, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02753921039402485
loss_c:0.8929804563522339
tensor(1.3656, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0217608492821455
loss_c:0.8220610618591309
tensor(1.3049, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030199816450476646
loss_c:1.0277769565582275
tensor(1.4484, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020388025790452957
loss_c:0.809518039226532
tensor(1.2927, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03746913745999336
loss_c:0.8361343145370483
tensor(1.3742, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028641456738114357
loss_c:1.0151909589767456
tensor(1.4355, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023110775277018547
loss_c:0.8776509761810303
tensor(1.3399, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019781962037086487
loss_c:0.9108688235282898
tensor(1.3446, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03734346479177475
loss_c:0.9204747080802917
tensor(1.4191, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023773999884724617
loss_c:0.9015778303146362
tensor(1.3553, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03512868285179138
loss_c:0.8462114334106445
tensor(1.3705, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019026432186365128
loss_c:0.7987948656082153
tensor(1.2814, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015398540534079075
loss_c:0.7839407920837402
tensor(1.2590, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03063664399087429
loss_c:0.833284854888916
tensor(1.3458, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016018206253647804
loss_c:0.9250721335411072
tensor(1.3372, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016099711880087852
loss_c:0.9092134833335876
tensor(1.3289, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0288418997079134
loss_c:0.9160473346710205
tensor(1.3832, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022781474515795708
loss_c:0.9729935526847839
tensor(1.3897, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023717442527413368
loss_c:0.7939481735229492
tensor(1.2970, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021555257961153984
loss_c:1.005402684211731
tensor(1.4022, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024444017559289932
loss_c:0.968248724937439
tensor(1.3937, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020159132778644562
loss_c:0.8615710139274597
tensor(1.3191, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020741553977131844
loss_c:0.9554663896560669
tensor(1.3719, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022377049550414085
loss_c:1.040700912475586
tensor(1.4243, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019910568371415138
loss_c:0.8824931383132935
tensor(1.3292, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02560610882937908
loss_c:1.042049527168274
tensor(1.4379, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02451871894299984
loss_c:1.079341173171997
tensor(1.4535, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0354556180536747
loss_c:1.1400916576385498
tensor(1.5303, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027063308283686638
loss_c:0.8252325057983398
tensor(1.3273, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03502529487013817
loss_c:0.9198927879333496
tensor(1.4104, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03665922209620476
loss_c:0.9996311068534851
tensor(1.4597, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025022923946380615
loss_c:0.9256647825241089
tensor(1.3728, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039852701127529144
loss_c:0.8848018646240234
tensor(1.4113, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017062220722436905
loss_c:0.8273752927780151
tensor(1.2880, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016331469640135765
loss_c:0.8488408923149109
tensor(1.2965, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043877094984054565
loss_c:0.9261037111282349
tensor(1.4497, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026563193649053574
loss_c:0.9280217885971069
tensor(1.3803, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0541023313999176
loss_c:0.9202628135681152
tensor(1.4881, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02867080643773079
loss_c:1.02052903175354
tensor(1.4381, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021416576579213142
loss_c:1.052890419960022
tensor(1.4258, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02244972437620163
loss_c:0.9790182113647461
tensor(1.3907, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02709331177175045
loss_c:0.9287494421005249
tensor(1.3828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03555883467197418
loss_c:1.0632126331329346
tensor(1.4884, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019006894901394844
loss_c:1.0351730585098267
tensor(1.4065, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018772123381495476
loss_c:0.8225022554397583
tensor(1.2929, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02552143856883049
loss_c:0.8060522079467773
tensor(1.3116, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01705891638994217
loss_c:0.8408880233764648
tensor(1.2958, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039133526384830475
loss_c:0.891330897808075
tensor(1.4117, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02373369038105011
loss_c:0.9762555956840515
tensor(1.3943, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022030681371688843
loss_c:0.9370299577713013
tensor(1.3667, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01805678755044937
loss_c:0.8533686399459839
tensor(1.3064, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018048856407403946
loss_c:0.8614165186882019
tensor(1.3106, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02523065358400345
loss_c:0.8417812585830688
tensor(1.3294, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021931391209363937
loss_c:0.8546479940414429
tensor(1.3227, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03054114617407322
loss_c:0.958296000957489
tensor(1.4124, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022267993539571762
loss_c:0.8412913084030151
tensor(1.3170, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041987884789705276
loss_c:0.9119588136672974
tensor(1.4345, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01860417239367962
loss_c:1.0391206741333008
tensor(1.4066, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01597561128437519
loss_c:0.9256102442741394
tensor(1.3359, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020898832008242607
loss_c:0.8708717226982117
tensor(1.3270, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02424527332186699
loss_c:0.9267165064811707
tensor(1.3701, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04425237700343132
loss_c:0.9248301386833191
tensor(1.4508, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06604726612567902
loss_c:0.9172665476799011
tensor(1.5358, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03681418299674988
loss_c:0.8357439041137695
tensor(1.3733, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05775638297200203
loss_c:1.131051778793335
tensor(1.6146, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021324237808585167
loss_c:0.9415273666381836
tensor(1.3661, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019787350669503212
loss_c:0.9019341468811035
tensor(1.3390, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018708162009716034
loss_c:0.8602408766746521
tensor(1.3127, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02767200767993927
loss_c:0.7814666628837585
tensor(1.3073, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02787342481315136
loss_c:1.0939887762069702
tensor(1.4733, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03838071599602699
loss_c:0.9360772967338562
tensor(1.4322, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02058655209839344
loss_c:0.8978607058525085
tensor(1.3403, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016131488606333733
loss_c:0.8293167352676392
tensor(1.2862, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02126776985824108
loss_c:0.9391202926635742
tensor(1.3649, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025263797491788864
loss_c:0.9726608991622925
tensor(1.3986, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018459521234035492
loss_c:0.8543175458908081
tensor(1.3088, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030312933027744293
loss_c:0.9662978649139404
tensor(1.4156, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021460123360157013
loss_c:0.9414981603622437
tensor(1.3669, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02287295088171959
loss_c:0.9101846218109131
tensor(1.3560, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02419837936758995
loss_c:0.7539860606193542
tensor(1.2788, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01675168238580227
loss_c:0.8431033492088318
tensor(1.2959, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01659521646797657
loss_c:0.8692435622215271
tensor(1.3090, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019069746136665344
loss_c:0.8454643487930298
tensor(1.3064, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0375097393989563
loss_c:0.9846171736717224
tensor(1.4545, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04356558993458748
loss_c:0.999863862991333
tensor(1.4871, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017465054988861084
loss_c:0.9034638404846191
tensor(1.3304, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016381578519940376
loss_c:0.833868682384491
tensor(1.2892, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020881254225969315
loss_c:0.8902934789657593
tensor(1.3372, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032213810831308365
loss_c:0.9429730176925659
tensor(1.4111, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0324246920645237
loss_c:0.8674626350402832
tensor(1.3720, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037730034440755844
loss_c:0.8072781562805176
tensor(1.3616, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0444178581237793
loss_c:0.9072487354278564
tensor(1.4418, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019262712448835373
loss_c:0.856564998626709
tensor(1.3127, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019709434360265732
loss_c:0.9014765620231628
tensor(1.3384, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019667252898216248
loss_c:0.9145247340202332
tensor(1.3451, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033132340759038925
loss_c:0.9207302331924438
tensor(1.4031, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03908298537135124
loss_c:1.072688341140747
tensor(1.5081, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037802524864673615
loss_c:1.089124083518982
tensor(1.5116, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027666091918945312
loss_c:0.9162379503250122
tensor(1.3785, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02206159010529518
loss_c:0.8109204173088074
tensor(1.2998, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021711096167564392
loss_c:1.0846126079559326
tensor(1.4439, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03852265328168869
loss_c:0.9236225485801697
tensor(1.4264, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031805217266082764
loss_c:0.757748007774353
tensor(1.3111, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026205701753497124
loss_c:0.934943675994873
tensor(1.3825, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017284836620092392
loss_c:0.8760606646537781
tensor(1.3152, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019891751930117607
loss_c:0.8395811915397644
tensor(1.3064, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02270258590579033
loss_c:0.7362983226776123
tensor(1.2629, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023668888956308365
loss_c:0.9723843336105347
tensor(1.3922, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01436594221740961
loss_c:0.8060760498046875
tensor(1.2662, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020610079169273376
loss_c:1.002075433731079
tensor(1.3956, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021333780139684677
loss_c:0.8514189124107361
tensor(1.3184, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020595351234078407
loss_c:0.9454962611198425
tensor(1.3654, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018372710794210434
loss_c:0.9186064004898071
tensor(1.3420, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05434152111411095
loss_c:0.8577584624290466
tensor(1.4559, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028272712603211403
loss_c:0.8859731554985046
tensor(1.3649, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023539751768112183
loss_c:0.8285164833068848
tensor(1.3150, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022965123876929283
loss_c:0.8727242350578308
tensor(1.3362, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019091567024588585
loss_c:0.777476966381073
tensor(1.2696, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016552379354834557
loss_c:0.8781653642654419
tensor(1.3129, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06333521008491516
loss_c:0.9978975653648376
tensor(1.5677, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06774801015853882
loss_c:1.1004208326339722
tensor(1.6404, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023152824491262436
loss_c:0.8690584897994995
tensor(1.3350, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04107743129134178
loss_c:0.8430179953575134
tensor(1.3939, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017896918579936028
loss_c:0.8152467608451843
tensor(1.2850, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026045650243759155
loss_c:0.9402580261230469
tensor(1.3848, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016917148604989052
loss_c:0.9452645778656006
tensor(1.3506, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017958302050828934
loss_c:0.8340845108032227
tensor(1.2954, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024882597848773003
loss_c:1.0573995113372803
tensor(1.4428, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01931990310549736
loss_c:0.8154740333557129
tensor(1.2910, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03044653870165348
loss_c:0.8904790878295898
tensor(1.3760, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021885523572564125
loss_c:0.8995301723480225
tensor(1.3463, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015120204538106918
loss_c:0.8056182861328125
tensor(1.2687, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0197965856641531
loss_c:0.7854020595550537
tensor(1.2767, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03215918317437172
loss_c:1.025669813156128
tensor(1.4553, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02086816541850567
loss_c:0.9291881918907166
tensor(1.3580, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018940875306725502
loss_c:0.9824573993682861
tensor(1.3787, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035381048917770386
loss_c:0.8795625567436218
tensor(1.3902, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014895918779075146
loss_c:0.8796116709709167
tensor(1.3071, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014122969470918179
loss_c:0.8734568357467651
tensor(1.3007, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034038469195365906
loss_c:0.8851757049560547
tensor(1.3878, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026840316131711006
loss_c:0.918524444103241
tensor(1.3764, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034544769674539566
loss_c:0.9089311957359314
tensor(1.4027, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014693912118673325
loss_c:0.7829083800315857
tensor(1.2542, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017666121944785118
loss_c:0.8450009822845459
tensor(1.2996, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035891856998205185
loss_c:0.9576061964035034
tensor(1.4344, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02591489441692829
loss_c:1.0561572313308716
tensor(1.4465, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018387839198112488
loss_c:0.8860082030296326
tensor(1.3244, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017381949350237846
loss_c:0.7789076566696167
tensor(1.2628, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024951966479420662
loss_c:0.9737788438796997
tensor(1.3983, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025124799460172653
loss_c:0.9811715483665466
tensor(1.4030, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02722739800810814
loss_c:0.8380589485168457
tensor(1.3349, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025047728791832924
loss_c:0.8904781341552734
tensor(1.3540, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030326414853334427
loss_c:0.9087504148483276
tensor(1.3856, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021730264648795128
loss_c:0.9052329063415527
tensor(1.3483, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018562307581305504
loss_c:0.8909906148910522
tensor(1.3275, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018289221450686455
loss_c:0.7867958545684814
tensor(1.2705, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07527246326208115
loss_c:0.9610521197319031
tensor(1.5995, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018353907391428947
loss_c:0.8733072280883789
tensor(1.3172, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020619751885533333
loss_c:0.9495433568954468
tensor(1.3674, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021762285381555557
loss_c:0.9116250872612
tensor(1.3518, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03471340239048004
loss_c:0.8631319999694824
tensor(1.3792, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05396059527993202
loss_c:1.0649363994598389
tensor(1.5669, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026231201365590096
loss_c:1.0095570087432861
tensor(1.4228, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04720500111579895
loss_c:0.8696696162223816
tensor(1.4340, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031223110854625702
loss_c:0.8697533011436462
tensor(1.3683, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01965649425983429
loss_c:0.855146050453186
tensor(1.3131, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05476481840014458
loss_c:0.9828145503997803
tensor(1.5250, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03883066400885582
loss_c:1.0510659217834473
tensor(1.4963, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014488988555967808
loss_c:0.8774418830871582
tensor(1.3042, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01699388585984707
loss_c:0.8814219236373901
tensor(1.3166, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027508819475769997
loss_c:0.9679051637649536
tensor(1.4055, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020668290555477142
loss_c:0.8515459895133972
tensor(1.3156, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026960568502545357
loss_c:0.8927246928215027
tensor(1.3631, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029016928747296333
loss_c:0.906894862651825
tensor(1.3790, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03327888995409012
loss_c:0.8835783004760742
tensor(1.3837, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025393012911081314
loss_c:0.8717114329338074
tensor(1.3456, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028871510177850723
loss_c:0.8491198420524597
tensor(1.3475, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01901078037917614
loss_c:0.8144409656524658
tensor(1.2893, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020792877301573753
loss_c:0.8368731737136841
tensor(1.3085, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033711619675159454
loss_c:0.8627394437789917
tensor(1.3743, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01769186742603779
loss_c:0.9192575812339783
tensor(1.3400, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02680705115199089
loss_c:0.9127189517021179
tensor(1.3732, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01594836823642254
loss_c:0.7133864164352417
tensor(1.2229, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017800500616431236
loss_c:0.8903562426567078
tensor(1.3249, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024211591109633446
loss_c:0.8676750063896179
tensor(1.3386, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028306759893894196
loss_c:0.9940402507781982
tensor(1.4228, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04191761463880539
loss_c:0.9802289009094238
tensor(1.4704, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027317052707076073
loss_c:0.915509819984436
tensor(1.3767, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02194327302277088
loss_c:1.091701865196228
tensor(1.4495, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015059266239404678
loss_c:0.7764015197753906
tensor(1.2527, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015577202662825584
loss_c:0.7933036684989929
tensor(1.2638, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06571895629167557
loss_c:0.9115291833877563
tensor(1.5301, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03627169877290726
loss_c:0.886272132396698
tensor(1.3973, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02825537510216236
loss_c:0.914752721786499
tensor(1.3801, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017092207446694374
loss_c:0.9430770874023438
tensor(1.3502, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023809419944882393
loss_c:1.0057895183563232
tensor(1.4110, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025062229484319687
loss_c:0.9919857382774353
tensor(1.4086, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02128404937684536
loss_c:0.8584482073783875
tensor(1.3218, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015752853825688362
loss_c:0.8068704605102539
tensor(1.2718, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026009341701865196
loss_c:0.8968350291252136
tensor(1.3614, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0254115741699934
loss_c:0.9786881804466248
tensor(1.4029, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030201558023691177
loss_c:1.0373204946517944
tensor(1.4537, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016881948336958885
loss_c:0.8878230452537537
tensor(1.3196, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015209882520139217
loss_c:0.8756018877029419
tensor(1.3063, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01867879182100296
loss_c:0.9045039415359497
tensor(1.3358, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05622468516230583
loss_c:0.9099528789520264
tensor(1.4913, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03822479769587517
loss_c:0.8805934190750122
tensor(1.4024, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03680005297064781
loss_c:0.8489489555358887
tensor(1.3797, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017114583402872086
loss_c:0.8331405520439148
tensor(1.2913, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022090595215559006
loss_c:0.9099119901657104
tensor(1.3525, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02406955324113369
loss_c:0.9026746153831482
tensor(1.3567, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03023970127105713
loss_c:0.8579227924346924
tensor(1.3578, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018767891451716423
loss_c:0.9317960143089294
tensor(1.3507, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021530482918024063
loss_c:0.9401738047599792
tensor(1.3664, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015377817675471306
loss_c:0.7461878657341003
tensor(1.2376, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01882951706647873
loss_c:0.7576543688774109
tensor(1.2577, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022049177438020706
loss_c:0.9297897219657898
tensor(1.3629, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02175939828157425
loss_c:0.8815385699272156
tensor(1.3359, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044729337096214294
loss_c:1.093540072441101
tensor(1.5433, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022217819467186928
loss_c:0.948215663433075
tensor(1.3735, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02458314038813114
loss_c:0.9637314677238464
tensor(1.3914, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037566229701042175
loss_c:0.8739475011825562
tensor(1.3964, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03509709984064102
loss_c:0.9634490013122559
tensor(1.4343, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03893471509218216
loss_c:0.9428521990776062
tensor(1.4389, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026327097788453102
loss_c:0.9592717885971069
tensor(1.3961, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01869637332856655
loss_c:0.9449185132980347
tensor(1.3573, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.053833890706300735
loss_c:0.7990872263908386
tensor(1.4227, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018421942368149757
loss_c:0.7720713019371033
tensor(1.2637, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018039152026176453
loss_c:0.8280782699584961
tensor(1.2922, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02823805995285511
loss_c:0.8188761472702026
tensor(1.3288, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01499321311712265
loss_c:0.83427894115448
tensor(1.2831, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019240546971559525
loss_c:0.8240294456481934
tensor(1.2949, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018084805458784103
loss_c:0.8606614470481873
tensor(1.3098, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016050370410084724
loss_c:0.9557325839996338
tensor(1.3524, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02057957462966442
loss_c:0.9748954772949219
tensor(1.3812, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03837819769978523
loss_c:0.9225497245788574
tensor(1.4257, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020550549030303955
loss_c:0.7656826376914978
tensor(1.2687, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017112111672759056
loss_c:0.7640464305877686
tensor(1.2537, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019659800454974174
loss_c:0.8913337588310242
tensor(1.3324, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03012697398662567
loss_c:0.884842574596405
tensor(1.3718, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020739372819662094
loss_c:0.8260466456413269
tensor(1.3017, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03313572332262993
loss_c:0.8276386260986328
tensor(1.3534, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025646619498729706
loss_c:0.8537453413009644
tensor(1.3367, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021393168717622757
loss_c:1.024451732635498
tensor(1.4112, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018378939479589462
loss_c:0.8806794881820679
tensor(1.3212, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022118089720606804
loss_c:0.8291847109794617
tensor(1.3088, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022686749696731567
loss_c:0.8577274084091187
tensor(1.3266, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03618816286325455
loss_c:0.9707848429679871
tensor(1.4434, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025845089927315712
loss_c:0.864560067653656
tensor(1.3433, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027316277846693993
loss_c:1.090566635131836
tensor(1.4716, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024934768676757812
loss_c:0.8938664197921753
tensor(1.3553, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01420854963362217
loss_c:0.8047975897789001
tensor(1.2627, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020050784572958946
loss_c:0.6933603286743164
tensor(1.2267, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01845608279109001
loss_c:1.0053138732910156
tensor(1.3887, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019771018996834755
loss_c:0.8223904371261597
tensor(1.2952, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01150374487042427
loss_c:0.9284000396728516
tensor(1.3181, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027901597321033478
loss_c:0.9406055808067322
tensor(1.3930, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03153092414140701
loss_c:0.8157617449760437
tensor(1.3406, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014854833483695984
loss_c:0.8715647459030151
tensor(1.3011, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014464040286839008
loss_c:0.8459216356277466
tensor(1.2855, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015382581390440464
loss_c:0.8064508438110352
tensor(1.2679, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026007479056715965
loss_c:0.9758569598197937
tensor(1.4042, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018493954092264175
loss_c:0.911353588104248
tensor(1.3376, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03744451701641083
loss_c:0.8570680618286133
tensor(1.3882, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024568160995841026
loss_c:0.9079992771148682
tensor(1.3614, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02553877979516983
loss_c:1.037791132926941
tensor(1.4359, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030751969665288925
loss_c:0.8282278776168823
tensor(1.3444, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027775870636105537
loss_c:1.0418142080307007
tensor(1.4475, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01942823827266693
loss_c:0.9624568223953247
tensor(1.3691, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03437462076544762
loss_c:0.9736189842224121
tensor(1.4386, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04934777319431305
loss_c:0.9522051811218262
tensor(1.4906, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021827073767781258
loss_c:0.8977761268615723
tensor(1.3442, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03135434165596962
loss_c:0.9266383051872253
tensor(1.4002, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02296479232609272
loss_c:1.0789035558700562
tensor(1.4468, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026061875745654106
loss_c:0.906030535697937
tensor(1.3666, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024083727970719337
loss_c:0.8988239765167236
tensor(1.3544, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020605511963367462
loss_c:1.04020094871521
tensor(1.4157, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024656496942043304
loss_c:1.0161173343658447
tensor(1.4198, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019158529117703438
loss_c:0.9394359588623047
tensor(1.3554, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021884674206376076
loss_c:0.8493673801422119
tensor(1.3186, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015748320147395134
loss_c:0.8471459746360779
tensor(1.2915, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02608655020594597
loss_c:0.9543243646621704
tensor(1.3925, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02212589979171753
loss_c:1.0046476125717163
tensor(1.4027, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018902724608778954
loss_c:0.8360447883605957
tensor(1.2989, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018279144540429115
loss_c:0.8588244318962097
tensor(1.3084, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02107367105782032
loss_c:0.9930331110954285
tensor(1.3919, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020476380363106728
loss_c:0.8482016324996948
tensor(1.3121, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01668766513466835
loss_c:0.7824352979660034
tensor(1.2609, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03597855567932129
loss_c:0.9742274284362793
tensor(1.4451, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04006696119904518
loss_c:0.9597064852714539
tensor(1.4548, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01919408328831196
loss_c:0.9233248233795166
tensor(1.3466, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01918652467429638
loss_c:0.7421940565109253
tensor(1.2501, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027108045294880867
loss_c:0.8447800874710083
tensor(1.3385, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021059229969978333
loss_c:0.9138523936271667
tensor(1.3495, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02464205212891102
loss_c:1.0598223209381104
tensor(1.4425, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022853098809719086
loss_c:0.8322598338127136
tensor(1.3137, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02695099078118801
loss_c:1.002035140991211
tensor(1.4215, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019808383658528328
loss_c:0.8766297698020935
tensor(1.3243, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02017463929951191
loss_c:0.868839681148529
tensor(1.3217, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025151699781417847
loss_c:0.8128044009208679
tensor(1.3131, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04623747244477272
loss_c:1.0543073415756226
tensor(1.5318, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02310003899037838
loss_c:0.890082836151123
tensor(1.3455, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015797166153788567
loss_c:0.7288727164268494
tensor(1.2285, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04297086223959923
loss_c:0.8606151342391968
tensor(1.4147, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025324037298560143
loss_c:0.9295956492424011
tensor(1.3760, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021104656159877777
loss_c:1.0360972881317139
tensor(1.4148, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016444923356175423
loss_c:0.7528085112571716
tensor(1.2440, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04034945368766785
loss_c:0.7967671155929565
tensor(1.3693, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02306143380701542
loss_c:0.8895440101623535
tensor(1.3450, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04309586435556412
loss_c:0.9007880687713623
tensor(1.4363, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04362284019589424
loss_c:0.9478132128715515
tensor(1.4635, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0289470124989748
loss_c:1.1293308734893799
tensor(1.4981, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014904442243278027
loss_c:0.9256934523582458
tensor(1.3299, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.060392506420612335
loss_c:1.0123528242111206
tensor(1.5683, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019729260355234146
loss_c:0.8798338174819946
tensor(1.3259, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018469221889972687
loss_c:0.9081055521965027
tensor(1.3358, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01601015403866768
loss_c:0.8842322826385498
tensor(1.3128, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016402726992964745
loss_c:0.7453362345695496
tensor(1.2404, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027525771409273148
loss_c:1.0977709293365479
tensor(1.4749, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022679341956973076
loss_c:0.8848892450332642
tensor(1.3411, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020228367298841476
loss_c:0.9376503229141235
tensor(1.3590, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029899589717388153
loss_c:0.9235023856163025
tensor(1.3919, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019740434363484383
loss_c:0.7940162420272827
tensor(1.2805, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017436498776078224
loss_c:0.8271071910858154
tensor(1.2885, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021047838032245636
loss_c:0.9583472609519958
tensor(1.3735, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027376167476177216
loss_c:0.9535002708435059
tensor(1.3973, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016568239778280258
loss_c:0.7638220191001892
tensor(1.2511, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023805852979421616
loss_c:0.8353548049926758
tensor(1.3194, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022435147315263748
loss_c:1.0077197551727295
tensor(1.4056, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029070088639855385
loss_c:0.9048075079917908
tensor(1.3785, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02042260952293873
loss_c:0.8700007200241089
tensor(1.3237, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03212999552488327
loss_c:0.8868979215621948
tensor(1.3818, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015342561528086662
loss_c:0.7949962615966797
tensor(1.2623, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016321785748004913
loss_c:0.9228513240814209
tensor(1.3346, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04188540577888489
loss_c:0.9212817549705505
tensor(1.4412, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021594109013676643
loss_c:0.9850410223007202
tensor(1.3900, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019797341898083687
loss_c:0.8491543531417847
tensor(1.3098, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016949506476521492
loss_c:0.8463764190673828
tensor(1.2963, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02924247644841671
loss_c:0.8952007293701172
tensor(1.3742, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02464180439710617
loss_c:0.9356595873832703
tensor(1.3764, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02141915075480938
loss_c:0.8462042808532715
tensor(1.3150, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03726271167397499
loss_c:0.9811199903488159
tensor(1.4540, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023885490372776985
loss_c:0.784809947013855
tensor(1.2925, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0223296657204628
loss_c:1.1873968839645386
tensor(1.5014, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0358823798596859
loss_c:0.8697168827056885
tensor(1.3886, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026727525517344475
loss_c:0.7886971235275269
tensor(1.3066, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036068715155124664
loss_c:0.88849276304245
tensor(1.3994, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02451130747795105
loss_c:0.8214272260665894
tensor(1.3148, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02782413549721241
loss_c:0.9096052050590515
tensor(1.3759, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01964338682591915
loss_c:0.8375169634819031
tensor(1.3029, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017816586419939995
loss_c:0.7863354682922363
tensor(1.2678, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032284948974847794
loss_c:0.8854731917381287
tensor(1.3817, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025100797414779663
loss_c:0.8191924095153809
tensor(1.3160, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016741609200835228
loss_c:0.8966838717460632
tensor(1.3223, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018058806657791138
loss_c:0.9311251044273376
tensor(1.3464, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017771201208233833
loss_c:0.9230308532714844
tensor(1.3408, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024063071236014366
loss_c:0.8527252674102783
tensor(1.3295, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017061619088053703
loss_c:0.8102312088012695
tensor(1.2772, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027888841927051544
loss_c:0.9867562055587769
tensor(1.4177, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02431967295706272
loss_c:0.8250200152397156
tensor(1.3157, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038231175392866135
loss_c:0.869013249874115
tensor(1.3981, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018972523510456085
loss_c:0.8989876508712769
tensor(1.3329, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03769545629620552
loss_c:0.9925066232681274
tensor(1.4624, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01718701422214508
loss_c:0.8518528938293457
tensor(1.2999, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04912945628166199
loss_c:0.8731290698051453
tensor(1.4464, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017975889146327972
loss_c:0.9250307083129883
tensor(1.3427, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025746989995241165
loss_c:0.8801957964897156
tensor(1.3513, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017772307619452477
loss_c:0.9244059920310974
tensor(1.3416, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0188102126121521
loss_c:1.0191175937652588
tensor(1.3970, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017152464017271996
loss_c:0.8340692520141602
tensor(1.2902, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021172190085053444
loss_c:0.9094494581222534
tensor(1.3478, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03874031454324722
loss_c:0.955103874206543
tensor(1.4466, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024340318515896797
loss_c:0.8979518413543701
tensor(1.3550, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018547089770436287
loss_c:0.8804078102111816
tensor(1.3211, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016987774521112442
loss_c:0.8541731238365173
tensor(1.3004, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021196400746703148
loss_c:1.048219084739685
tensor(1.4226, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02019646391272545
loss_c:0.8855255842208862
tensor(1.3308, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017885632812976837
loss_c:0.8976110816001892
tensor(1.3275, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015481601469218731
loss_c:0.8093763589859009
tensor(1.2698, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028254598379135132
loss_c:0.823455274105072
tensor(1.3315, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06384983658790588
loss_c:0.9718184471130371
tensor(1.5626, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07886860519647598
loss_c:0.9769200086593628
tensor(1.6289, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03366353362798691
loss_c:0.9387566447257996
tensor(1.4164, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037086550146341324
loss_c:1.0371150970458984
tensor(1.4836, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022839035838842392
loss_c:0.9648650884628296
tensor(1.3846, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01590433157980442
loss_c:0.8426515460014343
tensor(1.2900, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025727467611432076
loss_c:0.9806979894638062
tensor(1.4052, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.13102945685386658
loss_c:0.9331692457199097
tensor(1.8189, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017736274749040604
loss_c:0.8596351146697998
tensor(1.3072, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022166138514876366
loss_c:0.8340506553649902
tensor(1.3119, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03056209534406662
loss_c:0.9841272234916687
tensor(1.4268, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018545404076576233
loss_c:0.7843946218490601
tensor(1.2707, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01686251163482666
loss_c:1.0235164165496826
tensor(1.3920, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01606372930109501
loss_c:0.8999348878860474
tensor(1.3227, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024331510066986084
loss_c:0.8757857084274292
tensor(1.3434, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020054632797837257
loss_c:0.8785178065299988
tensor(1.3276, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021611278876662254
loss_c:0.8733154535293579
tensor(1.3311, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018943069502711296
loss_c:0.9105533361434937
tensor(1.3403, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016122279688715935
loss_c:0.8915570974349976
tensor(1.3188, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021401066333055496
loss_c:0.9453369975090027
tensor(1.3688, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02146846242249012
loss_c:0.8938872218132019
tensor(1.3416, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01824156753718853
loss_c:0.8710840940475464
tensor(1.3164, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01820230484008789
loss_c:0.8941231966018677
tensor(1.3285, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01745293289422989
loss_c:0.8980230093002319
tensor(1.3275, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0249834842979908
loss_c:0.9121729731559753
tensor(1.3655, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05332609638571739
loss_c:1.0720717906951904
tensor(1.5658, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03846479207277298
loss_c:0.8634259104728699
tensor(1.3941, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0482093021273613
loss_c:0.9634217023849487
tensor(1.4870, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02066473662853241
loss_c:0.920201301574707
tensor(1.3523, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02039649896323681
loss_c:0.8867970705032349
tensor(1.3334, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026560990139842033
loss_c:0.9157621264457703
tensor(1.3738, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035368431359529495
loss_c:0.8678356409072876
tensor(1.3838, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02974814735352993
loss_c:0.9441583156585693
tensor(1.4018, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02185884118080139
loss_c:1.0027989149093628
tensor(1.4012, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023887692019343376
loss_c:0.9662215709686279
tensor(1.3899, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03650813177227974
loss_c:0.8955396413803101
tensor(1.4031, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029725469648838043
loss_c:1.1693845987319946
tensor(1.5216, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022386563941836357
loss_c:1.055442452430725
tensor(1.4313, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02775072120130062
loss_c:0.9134847521781921
tensor(1.3774, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030455809086561203
loss_c:1.0107338428497314
tensor(1.4399, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02537325955927372
loss_c:1.031245470046997
tensor(1.4302, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02998455800116062
loss_c:0.8109495043754578
tensor(1.3321, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017832525074481964
loss_c:0.7919988632202148
tensor(1.2732, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0188099704682827
loss_c:0.8831226229667664
tensor(1.3254, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03673037141561508
loss_c:0.9878982901573181
tensor(1.4528, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03144590184092522
loss_c:0.9755091071128845
tensor(1.4250, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017954615876078606
loss_c:0.9256216883659363
tensor(1.3444, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02019331604242325
loss_c:0.7644144296646118
tensor(1.2683, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026761867105960846
loss_c:0.8613134622573853
tensor(1.3459, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023422610014677048
loss_c:0.896378219127655
tensor(1.3509, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022188786417245865
loss_c:0.8476471900939941
tensor(1.3202, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01860623061656952
loss_c:0.8409201502799988
tensor(1.3022, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05022471770644188
loss_c:0.9293981790542603
tensor(1.4765, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014023404568433762
loss_c:0.7507938146591187
tensor(1.2361, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017484551295638084
loss_c:0.9455327987670898
tensor(1.3529, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028878536075353622
loss_c:0.9975357055664062
tensor(1.4264, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018842067569494247
loss_c:1.126115322113037
tensor(1.4538, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026819156482815742
loss_c:0.8856796026229858
tensor(1.3589, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019079646095633507
loss_c:0.7699942588806152
tensor(1.2664, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023206640034914017
loss_c:1.0259772539138794
tensor(1.4184, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033354341983795166
loss_c:0.7769789695739746
tensor(1.3280, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02280917949974537
loss_c:0.8606793284416199
tensor(1.3294, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020251203328371048
loss_c:0.8394778966903687
tensor(1.3077, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017805416136980057
loss_c:0.8326811790466309
tensor(1.2941, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030104568228125572
loss_c:0.788531482219696
tensor(1.3208, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02303837426006794
loss_c:0.9142152667045593
tensor(1.3585, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023464137688279152
loss_c:0.9117748737335205
tensor(1.3590, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036721423268318176
loss_c:0.9672783613204956
tensor(1.4427, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0421014130115509
loss_c:0.9164222478866577
tensor(1.4378, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030579794198274612
loss_c:1.1475989818572998
tensor(1.5135, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04925568401813507
loss_c:1.067021369934082
tensor(1.5471, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025972560048103333
loss_c:0.8067246675491333
tensor(1.3134, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016514690592885017
loss_c:0.7748706340789795
tensor(1.2579, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01958606019616127
loss_c:0.9759485125541687
tensor(1.3773, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030858539044857025
loss_c:0.9020406603813171
tensor(1.3840, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015864893794059753
loss_c:0.8895168304443359
tensor(1.3162, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01804743893444538
loss_c:0.7999337911605835
tensor(1.2775, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016526691615581512
loss_c:0.9614461660385132
tensor(1.3571, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02990165911614895
loss_c:0.8277177214622498
tensor(1.3406, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018538355827331543
loss_c:0.8198952674865723
tensor(1.2900, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05007069185376167
loss_c:0.8566098213195801
tensor(1.4386, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0232539139688015
loss_c:0.9365576505661011
tensor(1.3713, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03677326440811157
loss_c:1.057698130607605
tensor(1.4912, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015727343037724495
loss_c:0.9609063863754272
tensor(1.3535, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02369503118097782
loss_c:0.9986566305160522
tensor(1.4062, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02429080381989479
loss_c:1.3439124822616577
tensor(1.5925, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01925964653491974
loss_c:0.8950755000114441
tensor(1.3329, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07563617080450058
loss_c:1.0221529006958008
tensor(1.6314, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01514413207769394
loss_c:0.8237477540969849
tensor(1.2782, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02110148034989834
loss_c:1.0485719442367554
tensor(1.4219, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01889236643910408
loss_c:0.877285361289978
tensor(1.3221, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025885891169309616
loss_c:0.8956844806671143
tensor(1.3604, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0316280834376812
loss_c:0.9411711692810059
tensor(1.4079, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06736430525779724
loss_c:0.952438473701477
tensor(1.5597, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033211901783943176
loss_c:0.8921679258346558
tensor(1.3884, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01825317181646824
loss_c:0.8662762641906738
tensor(1.3139, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018607858568429947
loss_c:0.9092289805412292
tensor(1.3381, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02776050567626953
loss_c:0.7928177118301392
tensor(1.3138, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016316842287778854
loss_c:0.7692811489105225
tensor(1.2550, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013066104613244534
loss_c:0.7899948954582214
tensor(1.2528, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03899121284484863
loss_c:0.8467299342155457
tensor(1.3877, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02104930207133293
loss_c:0.9082678556442261
tensor(1.3475, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020278988406062126
loss_c:0.8202600479125977
tensor(1.2979, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031059397384524345
loss_c:0.9135836362838745
tensor(1.3908, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021365340799093246
loss_c:0.9307174682617188
tensor(1.3607, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03667944297194481
loss_c:1.0393810272216797
tensor(1.4803, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03339479863643646
loss_c:1.0544264316558838
tensor(1.4749, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020497910678386688
loss_c:0.952497124671936
tensor(1.3687, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02364301308989525
loss_c:0.8423454165458679
tensor(1.3231, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05525198206305504
loss_c:1.1093755960464478
tensor(1.5926, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019191225990653038
loss_c:0.893497109413147
tensor(1.3322, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035940103232860565
loss_c:0.8406776189804077
tensor(1.3719, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01849421299993992
loss_c:0.8429717421531677
tensor(1.3027, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020791420713067055
loss_c:0.7794196605682373
tensor(1.2783, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04412887245416641
loss_c:0.7573251724243164
tensor(1.3608, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016318244859576225
loss_c:0.8021897077560425
tensor(1.2723, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02082178369164467
loss_c:0.9313011169433594
tensor(1.3589, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026266856119036674
loss_c:1.0283808708190918
tensor(1.4324, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020532261580228806
loss_c:0.8378709554672241
tensor(1.3081, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033782362937927246
loss_c:0.875255286693573
tensor(1.3814, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02389032579958439
loss_c:0.9356021285057068
tensor(1.3736, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020462535321712494
loss_c:0.9879691004753113
tensor(1.3876, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027368346229195595
loss_c:0.8256322741508484
tensor(1.3291, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035632286220788956
loss_c:0.9529144167900085
tensor(1.4302, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02038741298019886
loss_c:0.8431472182273865
tensor(1.3102, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01908881589770317
loss_c:0.8925142288208008
tensor(1.3312, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019843745976686478
loss_c:0.8746199607849121
tensor(1.3247, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02738690748810768
loss_c:0.9560439586639404
tensor(1.3986, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032428715378046036
loss_c:1.0507639646530151
tensor(1.4695, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019091032445430756
loss_c:0.8600516319274902
tensor(1.3138, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027670860290527344
loss_c:0.9972683787345886
tensor(1.4217, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01512526161968708
loss_c:0.846882700920105
tensor(1.2907, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018713565543293953
loss_c:0.8542888164520264
tensor(1.3091, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016295844689011574
loss_c:0.959571361541748
tensor(1.3554, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03389018028974533
loss_c:1.2237772941589355
tensor(1.5679, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01700117439031601
loss_c:0.8844552040100098
tensor(1.3181, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01982501707971096
loss_c:0.8835399150848389
tensor(1.3291, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027960432693362236
loss_c:0.8725970983505249
tensor(1.3565, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03245198726654053
loss_c:1.2508978843688965
tensor(1.5762, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019308285787701607
loss_c:1.0286115407943726
tensor(1.4040, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01966589316725731
loss_c:0.956305205821991
tensor(1.3670, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02873949706554413
loss_c:0.912404477596283
tensor(1.3809, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02262800931930542
loss_c:1.0357589721679688
tensor(1.4211, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031345490366220474
loss_c:0.8636767268180847
tensor(1.3659, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05510057508945465
loss_c:0.9266414642333984
tensor(1.4972, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01900332234799862
loss_c:0.8546657562255859
tensor(1.3103, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018985170871019363
loss_c:0.833605170249939
tensor(1.2992, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0212740246206522
loss_c:0.8937364816665649
tensor(1.3404, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024203041568398476
loss_c:0.8059715032577515
tensor(1.3061, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027974829077720642
loss_c:0.9516026377677917
tensor(1.3985, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022848522290587425
loss_c:0.9604125022888184
tensor(1.3820, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11782070994377136
loss_c:1.0093544721603394
tensor(1.8000, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019218668341636658
loss_c:0.8046621084213257
tensor(1.2850, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029937487095594406
loss_c:0.7572697401046753
tensor(1.3041, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01827358268201351
loss_c:0.9563932418823242
tensor(1.3613, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016530733555555344
loss_c:0.8983546495437622
tensor(1.3236, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02459980547428131
loss_c:1.1608693599700928
tensor(1.4951, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021710269153118134
loss_c:1.0395032167434692
tensor(1.4193, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024053972214460373
loss_c:1.0141197443008423
tensor(1.4154, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021241921931505203
loss_c:0.7486760020256042
tensor(1.2641, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01626565493643284
loss_c:0.8688526153564453
tensor(1.3072, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02620341256260872
loss_c:0.8916940689086914
tensor(1.3597, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02261410467326641
loss_c:0.9245219230651855
tensor(1.3624, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027247408404946327
loss_c:1.021583080291748
tensor(1.4323, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02599567547440529
loss_c:0.8644529581069946
tensor(1.3445, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03325613960623741
loss_c:0.8855891227722168
tensor(1.3851, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04847239702939987
loss_c:0.9535034894943237
tensor(1.4828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015525391325354576
loss_c:0.8601316213607788
tensor(1.2996, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03635288402438164
loss_c:0.9133368730545044
tensor(1.4123, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05255919694900513
loss_c:1.1227413415908813
tensor(1.5883, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019556544721126556
loss_c:0.8567074537277222
tensor(1.3143, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022156529128551483
loss_c:0.9898161888122559
tensor(1.3949, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08136805146932602
loss_c:0.8898317217826843
tensor(1.5818, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027513958513736725
loss_c:1.0403422117233276
tensor(1.4432, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014604104682803154
loss_c:0.8103790283203125
tensor(1.2703, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017444323748350143
loss_c:0.8633097410202026
tensor(1.3097, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018068384379148483
loss_c:0.8431555032730103
tensor(1.3016, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013621669262647629
loss_c:0.8683344125747681
tensor(1.2971, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017884446308016777
loss_c:0.9143087863922119
tensor(1.3383, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05411037057638168
loss_c:0.8975749015808105
tensor(1.4746, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03677058592438698
loss_c:1.0180463790893555
tensor(1.4685, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05921798199415207
loss_c:0.8768420219421387
tensor(1.4839, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026402298361063004
loss_c:0.9096887111663818
tensor(1.3700, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024735460057854652
loss_c:0.9377149939537048
tensor(1.3782, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041360024362802505
loss_c:0.7765259742736816
tensor(1.3593, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01640438660979271
loss_c:0.8434118032455444
tensor(1.2955, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0199794489890337
loss_c:0.8771623969078064
tensor(1.3275, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01634686253964901
loss_c:0.9193936586380005
tensor(1.3354, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020785989239811897
loss_c:1.0824908018112183
tensor(1.4391, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022720355540513992
loss_c:0.8676127791404724
tensor(1.3333, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017467452213168144
loss_c:0.9370492696762085
tensor(1.3492, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015739990398287773
loss_c:0.8671820163726807
tensor(1.3054, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038139909505844116
loss_c:0.8093220591545105
tensor(1.3635, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020932840183377266
loss_c:1.0039933919906616
tensor(1.3982, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023130344226956367
loss_c:0.942193865776062
tensor(1.3742, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023051360622048378
loss_c:0.8929064273834229
tensor(1.3478, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02420533262193203
loss_c:0.8529650568962097
tensor(1.3312, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017195260152220726
loss_c:0.777256190776825
tensor(1.2632, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01647160016000271
loss_c:0.8766152858734131
tensor(1.3129, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020622655749320984
loss_c:0.9685978889465332
tensor(1.3781, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039491452276706696
loss_c:0.8073753714561462
tensor(1.3681, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02235737256705761
loss_c:0.9457265734672546
tensor(1.3729, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04566154256463051
loss_c:0.9609074592590332
tensor(1.4744, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017901353538036346
loss_c:0.873428225517273
tensor(1.3166, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02678820490837097
loss_c:0.7595920562744141
tensor(1.2917, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03153787925839424
loss_c:1.0140665769577026
tensor(1.4461, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05294634401798248
loss_c:0.8457139730453491
tensor(1.4426, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01590321958065033
loss_c:0.8728272914886475
tensor(1.3081, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02610156685113907
loss_c:0.9437164068222046
tensor(1.3868, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03319838270545006
loss_c:0.7281956672668457
tensor(1.3006, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017566433176398277
loss_c:0.8457502126693726
tensor(1.3003, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.045193806290626526
loss_c:0.8083693385124207
tensor(1.3914, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020974062383174896
loss_c:0.8878971934318542
tensor(1.3365, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023208994418382645
loss_c:0.8708168864250183
tensor(1.3363, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03521398827433586
loss_c:0.8689643740653992
tensor(1.3835, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03793172165751457
loss_c:0.9590885043144226
tensor(1.4427, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01906726509332657
loss_c:0.9849719405174255
tensor(1.3809, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018426306545734406
loss_c:0.7721866369247437
tensor(1.2643, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025720208883285522
loss_c:0.8006681799888611
tensor(1.3087, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017178164795041084
loss_c:0.6804510951042175
tensor(1.2099, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04479067027568817
loss_c:0.8288553953170776
tensor(1.4003, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016089970245957375
loss_c:0.8886656165122986
tensor(1.3173, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02668033353984356
loss_c:1.1358766555786133
tensor(1.4930, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017049163579940796
loss_c:0.9108912348747253
tensor(1.3331, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015544310212135315
loss_c:0.8598607778549194
tensor(1.2995, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04210080951452255
loss_c:1.0196056365966797
tensor(1.4925, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026272611692547798
loss_c:0.9011768102645874
tensor(1.3649, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03722354397177696
loss_c:0.909220814704895
tensor(1.4133, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03881364315748215
loss_c:0.8778712153434753
tensor(1.4028, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042755357921123505
loss_c:0.8212040662765503
tensor(1.3881, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018103601410984993
loss_c:0.8073953986167908
tensor(1.2814, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02141890674829483
loss_c:0.8735455274581909
tensor(1.3305, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019053110852837563
loss_c:0.8376927375793457
tensor(1.3016, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0542689748108387
loss_c:0.8929778933525085
tensor(1.4729, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02028975449502468
loss_c:1.040735125541687
tensor(1.4163, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04185566306114197
loss_c:0.9950710535049438
tensor(1.4782, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031857866793870926
loss_c:0.9071073532104492
tensor(1.3905, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018349898979067802
loss_c:0.8477813601493835
tensor(1.3044, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027417901903390884
loss_c:0.7403744459152222
tensor(1.2826, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020055582746863365
loss_c:0.7098612785339355
tensor(1.2367, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0244329571723938
loss_c:1.0433483123779297
tensor(1.4345, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026180816814303398
loss_c:1.1038918495178223
tensor(1.4742, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017160726711153984
loss_c:0.8455492854118347
tensor(1.2984, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015427349135279655
loss_c:0.8759164810180664
tensor(1.3079, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021650521084666252
loss_c:0.9710005521774292
tensor(1.3842, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016932066529989243
loss_c:0.802879273891449
tensor(1.2744, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029633037745952606
loss_c:0.8494402766227722
tensor(1.3504, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025250952690839767
loss_c:0.8473607897758484
tensor(1.3317, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05790533870458603
loss_c:1.1027662754058838
tensor(1.6010, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.060688186436891556
loss_c:0.9683650732040405
tensor(1.5395, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017759108915925026
loss_c:0.8294199705123901
tensor(1.2920, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017600497230887413
loss_c:0.749697208404541
tensor(1.2484, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01740984246134758
loss_c:0.8210908770561218
tensor(1.2862, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017003260552883148
loss_c:0.7387206554412842
tensor(1.2401, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019319597631692886
loss_c:0.8729373812675476
tensor(1.3218, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019406316801905632
loss_c:0.9329975843429565
tensor(1.3545, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019098786637187004
loss_c:0.9028247594833374
tensor(1.3370, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06207006052136421
loss_c:0.9456316232681274
tensor(1.5329, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021247398108243942
loss_c:0.891147255897522
tensor(1.3393, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017937256023287773
loss_c:0.7255458831787109
tensor(1.2364, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017772534862160683
loss_c:0.9724406003952026
tensor(1.3693, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02118842490017414
loss_c:0.8447670936584473
tensor(1.3139, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09130606800317764
loss_c:1.1634901762008667
tensor(1.7688, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03179978206753731
loss_c:0.9926751852035522
tensor(1.4366, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03476680442690849
loss_c:0.8049893379211426
tensor(1.3470, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04564625769853592
loss_c:0.9399544596672058
tensor(1.4635, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02785802073776722
loss_c:0.8886680603027344
tensor(1.3645, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01622573845088482
loss_c:0.9092592000961304
tensor(1.3292, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023020736873149872
loss_c:0.8009239435195923
tensor(1.2979, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025392405688762665
loss_c:1.0183359384536743
tensor(1.4247, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04654252901673317
loss_c:0.8487516641616821
tensor(1.4172, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03025287203490734
loss_c:0.8484935760498047
tensor(1.3523, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02031019516289234
loss_c:0.884650707244873
tensor(1.3324, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037556879222393036
loss_c:0.7706799507141113
tensor(1.3392, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0261167474091053
loss_c:1.17912757396698
tensor(1.5144, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015284940600395203
loss_c:0.8395607471466064
tensor(1.2884, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017809927463531494
loss_c:0.7669140100479126
tensor(1.2592, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029043622314929962
loss_c:0.7993807196617126
tensor(1.3211, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025735633447766304
loss_c:0.9079744219779968
tensor(1.3666, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022171750664711
loss_c:0.8564464449882507
tensor(1.3247, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043375059962272644
loss_c:0.7584351301193237
tensor(1.3555, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023996056988835335
loss_c:0.9320270419120789
tensor(1.3727, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015585806220769882
loss_c:0.8481316566467285
tensor(1.2942, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015841469168663025
loss_c:0.8290436267852783
tensor(1.2849, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03212793171405792
loss_c:1.0491255521774292
tensor(1.4681, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019320402294397354
loss_c:0.8259527087211609
tensor(1.2969, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021243281662464142
loss_c:0.8236832618713379
tensor(1.3032, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029440106824040413
loss_c:0.7383217811584473
tensor(1.2895, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015945173799991608
loss_c:0.8646909594535828
tensor(1.3043, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018470339477062225
loss_c:0.8918518424034119
tensor(1.3289, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02445288375020027
loss_c:0.9767715930938721
tensor(1.3987, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032836418598890305
loss_c:0.8358229398727417
tensor(1.3557, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014109775424003601
loss_c:0.729785680770874
tensor(1.2235, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019881704822182655
loss_c:0.8889392614364624
tensor(1.3328, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021009914577007294
loss_c:0.8270072937011719
tensor(1.3036, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019621333107352257
loss_c:0.867633044719696
tensor(1.3200, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01663663052022457
loss_c:0.7764794230461121
tensor(1.2584, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026650307700037956
loss_c:0.8967175483703613
tensor(1.3640, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02910446561872959
loss_c:1.121464490890503
tensor(1.4963, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016590485349297523
loss_c:0.8277707099914551
tensor(1.2858, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025260932743549347
loss_c:0.936637282371521
tensor(1.3801, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02794937789440155
loss_c:1.0660544633865356
tensor(1.4615, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021714061498641968
loss_c:0.85570228099823
tensor(1.3216, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0348198227584362
loss_c:0.7705706357955933
tensor(1.3287, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025967827066779137
loss_c:1.1110880374908447
tensor(1.4779, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018548576161265373
loss_c:0.7515370845794678
tensor(1.2519, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03422005847096443
loss_c:0.9380068778991699
tensor(1.4174, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03480769693851471
loss_c:1.0827677249908447
tensor(1.4986, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03690832853317261
loss_c:0.9230040311813354
tensor(1.4203, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018039947375655174
loss_c:0.8043932914733887
tensor(1.2786, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018179260194301605
loss_c:0.83724045753479
tensor(1.2970, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026870032772421837
loss_c:1.0657284259796143
tensor(1.4566, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027740107849240303
loss_c:1.0721949338912964
tensor(1.4636, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016645221039652824
loss_c:0.7631230354309082
tensor(1.2506, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041030168533325195
loss_c:0.7300137281417847
tensor(1.3329, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03995851054787636
loss_c:0.8457708358764648
tensor(1.3911, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043369896709918976
loss_c:0.8156210780143738
tensor(1.3888, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017787115648388863
loss_c:0.8896624445915222
tensor(1.3238, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01681661605834961
loss_c:0.7511450052261353
tensor(1.2449, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0550248846411705
loss_c:0.9776467084884644
tensor(1.5241, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05755431577563286
loss_c:1.0355957746505737
tensor(1.5657, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0468350313603878
loss_c:0.9039125442504883
tensor(1.4503, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028809605166316032
loss_c:0.9492208361625671
tensor(1.4012, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018781960010528564
loss_c:0.9241573810577393
tensor(1.3469, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023224210366606712
loss_c:0.7683529853820801
tensor(1.2807, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016325201839208603
loss_c:0.876793384552002
tensor(1.3115, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01743670366704464
loss_c:0.8759721517562866
tensor(1.3156, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019724298268556595
loss_c:0.975663423538208
tensor(1.3787, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01904274709522724
loss_c:0.8397127985954285
tensor(1.3025, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.053742147982120514
loss_c:0.8851594924926758
tensor(1.4670, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02319330908358097
loss_c:1.0445117950439453
tensor(1.4299, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016269521787762642
loss_c:0.7874768972396851
tensor(1.2632, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020368428900837898
loss_c:0.8789644241333008
tensor(1.3291, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01947043463587761
loss_c:0.9480952620506287
tensor(1.3628, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014582805335521698
loss_c:0.7512947916984558
tensor(1.2369, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013676234520971775
loss_c:0.8205744624137878
tensor(1.2706, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022730398923158646
loss_c:0.9340771436691284
tensor(1.3683, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0509473942220211
loss_c:0.9748479723930359
tensor(1.5044, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025093035772442818
loss_c:0.9036307334899902
tensor(1.3614, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022565776482224464
loss_c:0.818405032157898
tensor(1.3052, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026497647166252136
loss_c:0.9489749670028687
tensor(1.3916, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.057333458214998245
loss_c:0.8513695001602173
tensor(1.4637, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07637336850166321
loss_c:1.0729396343231201
tensor(1.6603, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022250473499298096
loss_c:0.8624457120895386
tensor(1.3277, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021511374041438103
loss_c:0.9180192947387695
tensor(1.3548, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01480055134743452
loss_c:0.8697602152824402
tensor(1.3018, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014268256723880768
loss_c:0.748054027557373
tensor(1.2341, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019027408212423325
loss_c:0.9534744024276733
tensor(1.3640, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019074028357863426
loss_c:0.8248745799064636
tensor(1.2949, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0239341389387846
loss_c:0.9067023992538452
tensor(1.3585, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021162590011954308
loss_c:0.9342973232269287
tensor(1.3622, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01520660612732172
loss_c:0.7860115766525269
tensor(1.2583, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02263261377811432
loss_c:1.1194560527801514
tensor(1.4680, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02797938883304596
loss_c:0.8842313289642334
tensor(1.3626, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034571755677461624
loss_c:0.8470537066459656
tensor(1.3691, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01978713646531105
loss_c:0.9217637777328491
tensor(1.3498, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0201045423746109
loss_c:0.8945275545120239
tensor(1.3364, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022100772708654404
loss_c:0.8599861860275269
tensor(1.3258, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024024836719036102
loss_c:0.8978177905082703
tensor(1.3539, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04229707270860672
loss_c:1.0791585445404053
tensor(1.5257, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03314811736345291
loss_c:0.9015299677848816
tensor(1.3929, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01721101813018322
loss_c:0.8686894178390503
tensor(1.3106, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01596103422343731
loss_c:0.8149075508117676
tensor(1.2766, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04307916760444641
loss_c:0.8758951425552368
tensor(1.4195, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019525807350873947
loss_c:0.8325039744377136
tensor(1.3005, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037235286086797714
loss_c:0.9361294507980347
tensor(1.4282, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027293529361486435
loss_c:1.1801588535308838
tensor(1.5191, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01813323050737381
loss_c:0.8762158155441284
tensor(1.3183, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026627277955412865
loss_c:1.005279779434204
tensor(1.4222, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05103949457406998
loss_c:1.0259428024291992
tensor(1.5325, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017729662358760834
loss_c:0.8568317294120789
tensor(1.3063, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028296472504734993
loss_c:0.9806499481201172
tensor(1.4157, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022595960646867752
loss_c:0.8802294731140137
tensor(1.3387, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03334420919418335
loss_c:0.8680013418197632
tensor(1.3758, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028374042361974716
loss_c:0.8458493947982788
tensor(1.3438, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02636515535414219
loss_c:1.1849180459976196
tensor(1.5169, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016178494319319725
loss_c:0.8444585800170898
tensor(1.2936, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022675732150673866
loss_c:0.8099526166915894
tensor(1.3015, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016508156433701515
loss_c:0.804265022277832
tensor(1.2735, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02957819774746895
loss_c:0.9494615793228149
tensor(1.4040, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02351687103509903
loss_c:1.0825906991958618
tensor(1.4504, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021923013031482697
loss_c:0.8247623443603516
tensor(1.3064, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015069837681949139
loss_c:0.8661127090454102
tensor(1.3005, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017329297959804535
loss_c:0.9370514154434204
tensor(1.3475, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0322512723505497
loss_c:0.833030104637146
tensor(1.3529, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023965250700712204
loss_c:0.8608788251876831
tensor(1.3339, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015193064697086811
loss_c:0.9022917747497559
tensor(1.3201, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028072422370314598
loss_c:0.8748515844345093
tensor(1.3582, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02040392905473709
loss_c:0.8160533905029297
tensor(1.2954, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01566694863140583
loss_c:0.8494621515274048
tensor(1.2937, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017678098753094673
loss_c:0.7590184211730957
tensor(1.2537, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01947498321533203
loss_c:0.8748424053192139
tensor(1.3227, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018416019156575203
loss_c:0.844106137752533
tensor(1.3019, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02860441617667675
loss_c:1.0022432804107666
tensor(1.4284, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01978383958339691
loss_c:0.9580055475234985
tensor(1.3683, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05675902217626572
loss_c:1.0124313831329346
tensor(1.5510, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01947902701795101
loss_c:0.8793158531188965
tensor(1.3249, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023639747872948647
loss_c:0.843691349029541
tensor(1.3231, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01891075074672699
loss_c:0.8154802322387695
tensor(1.2883, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015799421817064285
loss_c:0.7722690105438232
tensor(1.2522, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01763642206788063
loss_c:0.8950361013412476
tensor(1.3255, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03529439494013786
loss_c:0.8883095979690552
tensor(1.3956, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016714394092559814
loss_c:1.0180635452270508
tensor(1.3875, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02640397474169731
loss_c:0.8228039741516113
tensor(1.3234, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021954338997602463
loss_c:1.0897611379623413
tensor(1.4478, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03539794310927391
loss_c:1.0159887075424194
tensor(1.4647, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0284873154014349
loss_c:0.718802809715271
tensor(1.2764, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017323087900877
loss_c:0.9033260345458984
tensor(1.3284, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025563323870301247
loss_c:1.1670432090759277
tensor(1.5044, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023126818239688873
loss_c:0.818412184715271
tensor(1.3073, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023240908980369568
loss_c:0.9143039584159851
tensor(1.3591, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.059138230979442596
loss_c:1.0512406826019287
tensor(1.5837, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03630882501602173
loss_c:0.7934116721153259
tensor(1.3494, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03208618983626366
loss_c:0.8666510581970215
tensor(1.3708, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03475969657301903
loss_c:1.1013983488082886
tensor(1.5076, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02545681968331337
loss_c:1.1473387479782104
tensor(1.4930, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03187928721308708
loss_c:1.0265228748321533
tensor(1.4552, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016326049342751503
loss_c:0.9000203609466553
tensor(1.3227, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020775221288204193
loss_c:0.9036015272140503
tensor(1.3432, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01508608739823103
loss_c:0.9233006238937378
tensor(1.3300, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019019359722733498
loss_c:0.7968079447746277
tensor(1.2791, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02677685208618641
loss_c:0.844334065914154
tensor(1.3367, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01807328127324581
loss_c:0.8177134394645691
tensor(1.2863, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018065255135297775
loss_c:0.9394769668579102
tensor(1.3510, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019110657274723053
loss_c:1.0014958381652832
tensor(1.3883, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023085763677954674
loss_c:0.8513235449790955
tensor(1.3251, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01732911728322506
loss_c:0.8194935321807861
tensor(1.2841, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020479289814829826
loss_c:0.8725546598434448
tensor(1.3254, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0440797284245491
loss_c:0.8883384466171265
tensor(1.4326, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016288986429572105
loss_c:0.7211405634880066
tensor(1.2274, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02813274972140789
loss_c:1.03956937789917
tensor(1.4462, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025268344208598137
loss_c:0.9501306414604187
tensor(1.3867, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022834666073322296
loss_c:0.9734634757041931
tensor(1.3889, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016545921564102173
loss_c:0.8843991160392761
tensor(1.3151, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017498645931482315
loss_c:0.9829034209251404
tensor(1.3715, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022284040227532387
loss_c:0.9112998843193054
tensor(1.3535, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05619601532816887
loss_c:1.0414509773254395
tensor(1.5655, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033606067299842834
loss_c:0.9210997819900513
tensor(1.4063, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023733196780085564
loss_c:0.8420495390892029
tensor(1.3228, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05079910159111023
loss_c:0.9119060039520264
tensor(1.4737, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022394198924303055
loss_c:0.8824123740196228
tensor(1.3386, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028389429673552513
loss_c:0.9348315000534058
tensor(1.3916, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039790958166122437
loss_c:0.8321623802185059
tensor(1.3848, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034975048154592514
loss_c:0.8548874855041504
tensor(1.3766, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013779784552752972
loss_c:0.8322448134422302
tensor(1.2761, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01645359955728054
loss_c:0.8160983324050903
tensor(1.2788, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030581675469875336
loss_c:0.8419795036315918
tensor(1.3513, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02082984335720539
loss_c:0.8855298757553101
tensor(1.3339, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018574044108390808
loss_c:0.8925756216049194
tensor(1.3283, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018174467608332634
loss_c:0.8241464495658875
tensor(1.2902, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021996483206748962
loss_c:0.9314008951187134
tensor(1.3632, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02199956215918064
loss_c:0.9680269956588745
tensor(1.3827, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03011917881667614
loss_c:0.9394842982292175
tensor(1.4012, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02227504923939705
loss_c:0.7822756767272949
tensor(1.2848, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04723965376615524
loss_c:0.9335453510284424
tensor(1.4693, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024401485919952393
loss_c:1.0892784595489502
tensor(1.4575, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015236523002386093
loss_c:0.7178459167480469
tensor(1.2211, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037681661546230316
loss_c:0.9422325491905212
tensor(1.4341, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028588999062776566
loss_c:0.8638229370117188
tensor(1.3545, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015092870220541954
loss_c:0.7688166499137878
tensor(1.2477, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04476913437247276
loss_c:1.103162169456482
tensor(1.5496, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030449068173766136
loss_c:0.8603348731994629
tensor(1.3603, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021860985085368156
loss_c:0.8794518709182739
tensor(1.3349, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02105802111327648
loss_c:0.8822795152664185
tensor(1.3331, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02068619430065155
loss_c:0.8027512431144714
tensor(1.2890, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02142280898988247
loss_c:0.8817614316940308
tensor(1.3344, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024870390072464943
loss_c:0.8286632895469666
tensor(1.3202, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03643019497394562
loss_c:0.8906939029693604
tensor(1.4012, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.050451140850782394
loss_c:0.890380322933197
tensor(1.4590, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02355200983583927
loss_c:0.8530623316764832
tensor(1.3278, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01923755556344986
loss_c:0.9236483573913574
tensor(1.3479, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025869546458125114
loss_c:1.0037314891815186
tensor(1.4182, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0177326500415802
loss_c:0.9038161039352417
tensor(1.3311, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020843274891376495
loss_c:0.9517043828964233
tensor(1.3696, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022292405366897583
loss_c:0.8602761030197144
tensor(1.3264, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01810886152088642
loss_c:0.9110590815544128
tensor(1.3365, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018237212672829628
loss_c:0.8295092582702637
tensor(1.2932, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02311842143535614
loss_c:0.8545010089874268
tensor(1.3267, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03539583086967468
loss_c:0.9034227132797241
tensor(1.4037, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02622004598379135
loss_c:1.0110914707183838
tensor(1.4237, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02027789130806923
loss_c:1.0845450162887573
tensor(1.4386, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020837360993027687
loss_c:0.8146311044692993
tensor(1.2958, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03827555105090141
loss_c:0.9667035341262817
tensor(1.4497, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014271054416894913
loss_c:0.8154280185699463
tensor(1.2691, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.060470618307590485
loss_c:0.9535554647445679
tensor(1.5346, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023431019857525826
loss_c:0.8278303146362305
tensor(1.3137, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037030480802059174
loss_c:0.8672478199005127
tensor(1.3911, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02014319598674774
loss_c:0.887203574180603
tensor(1.3320, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01974629797041416
loss_c:0.6990278959274292
tensor(1.2294, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03950437158346176
loss_c:0.8389350175857544
tensor(1.3860, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019708601757884026
loss_c:0.894980788230896
tensor(1.3344, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020691731944680214
loss_c:1.0332261323928833
tensor(1.4128, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02202742174267769
loss_c:0.9700305461883545
tensor(1.3843, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025942575186491013
loss_c:1.0499337911605835
tensor(1.4434, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023039765655994415
loss_c:1.0430506467819214
tensor(1.4277, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02702753245830536
loss_c:0.9875550270080566
tensor(1.4143, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042572904378175735
loss_c:0.8853384852409363
tensor(1.4234, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01729927957057953
loss_c:0.864268958568573
tensor(1.3081, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03523944690823555
loss_c:0.9321944713592529
tensor(1.4183, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018409861251711845
loss_c:0.9468808174133301
tensor(1.3570, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01695970818400383
loss_c:0.9910337328910828
tensor(1.3746, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018091905862092972
loss_c:1.0076467990875244
tensor(1.3881, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017260601744055748
loss_c:0.8599974513053894
tensor(1.3057, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02291920594871044
loss_c:0.885105311870575
tensor(1.3424, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02159120887517929
loss_c:0.8964256048202515
tensor(1.3430, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031050236895680428
loss_c:0.8502218127250671
tensor(1.3573, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041583821177482605
loss_c:0.9172446131706238
tensor(1.4366, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025637278333306313
loss_c:0.8672125339508057
tensor(1.3441, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03320534527301788
loss_c:0.8993064761161804
tensor(1.3925, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02253633178770542
loss_c:0.8246557116508484
tensor(1.3086, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03944123163819313
loss_c:0.8610776662826538
tensor(1.3978, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022504005581140518
loss_c:0.9069057703018188
tensor(1.3523, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02019653096795082
loss_c:0.7682958841323853
tensor(1.2689, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022723793983459473
loss_c:0.9484270811080933
tensor(1.3754, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014806876890361309
loss_c:0.8601352572441101
tensor(1.2956, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021443551406264305
loss_c:0.9498448371887207
tensor(1.3709, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035624437034130096
loss_c:0.9284531474113464
tensor(1.4180, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014209014363586903
loss_c:0.7976021766662598
tensor(1.2597, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022005878388881683
loss_c:0.9193506240844727
tensor(1.3569, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032266609370708466
loss_c:0.9720131158828735
tensor(1.4275, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017733639106154442
loss_c:0.8823761940002441
tensor(1.3194, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02433878742158413
loss_c:0.8798969984054565
tensor(1.3454, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019775763154029846
loss_c:0.9819127917289734
tensor(1.3810, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025967098772525787
loss_c:0.8820776343345642
tensor(1.3533, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032353322952985764
loss_c:0.9405962824821472
tensor(1.4111, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02154393680393696
loss_c:0.8783969879150391
tensor(1.3330, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020078960806131363
loss_c:0.9720454216003418
tensor(1.3769, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027926817536354065
loss_c:1.0191941261291504
tensor(1.4348, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021170226857066154
loss_c:0.8998160362243652
tensor(1.3428, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04048480838537216
loss_c:1.0239123106002808
tensor(1.4896, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03894565626978874
loss_c:1.0167193412780762
tensor(1.4793, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015069117769598961
loss_c:0.7672017812728882
tensor(1.2467, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11144759505987167
loss_c:1.1441237926483154
tensor(1.8493, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02484295330941677
loss_c:0.7795882225036621
tensor(1.2941, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017068741843104362
loss_c:0.9365958571434021
tensor(1.3456, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020622754469513893
loss_c:0.891734778881073
tensor(1.3365, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039699990302324295
loss_c:0.8616703748703003
tensor(1.3991, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020909447222948074
loss_c:0.9553602933883667
tensor(1.3716, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044009942561388016
loss_c:0.934341311454773
tensor(1.4551, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014411264099180698
loss_c:0.8212230205535889
tensor(1.2739, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03550324589014053
loss_c:1.0337307453155518
tensor(1.4730, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023814290761947632
loss_c:0.8275960683822632
tensor(1.3157, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03398068994283676
loss_c:0.8950647115707397
tensor(1.3929, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017708169296383858
loss_c:0.7867411375045776
tensor(1.2693, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02697487361729145
loss_c:0.905592679977417
tensor(1.3700, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020589660853147507
loss_c:0.8206701278686523
tensor(1.2991, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016204286366701126
loss_c:0.8248082995414734
tensor(1.2835, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021840153262019157
loss_c:0.9678915739059448
tensor(1.3824, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025296607986092567
loss_c:0.9443983435630798
tensor(1.3839, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025873657315969467
loss_c:1.0422849655151367
tensor(1.4383, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019634727388620377
loss_c:1.0904805660247803
tensor(1.4388, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023346254602074623
loss_c:0.8675193786621094
tensor(1.3351, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029506810009479523
loss_c:0.9264857172966003
tensor(1.3914, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021670904010534286
loss_c:0.8517165184020996
tensor(1.3199, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04303641989827156
loss_c:0.8867650032043457
tensor(1.4252, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03978235647082329
loss_c:0.7398827075958252
tensor(1.3339, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04816368594765663
loss_c:0.9410690069198608
tensor(1.4748, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021807553246617317
loss_c:0.8850798010826111
tensor(1.3382, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016773153096437454
loss_c:0.8315653204917908
tensor(1.2894, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016768917441368103
loss_c:0.8182085752487183
tensor(1.2823, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017009954899549484
loss_c:0.8875550627708435
tensor(1.3202, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024915924295783043
loss_c:0.8287672400474548
tensor(1.3208, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020150138065218925
loss_c:1.0593178272247314
tensor(1.4244, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021726056933403015
loss_c:1.0093002319335938
tensor(1.4041, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01815774291753769
loss_c:0.7890268564224243
tensor(1.2722, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025240428745746613
loss_c:0.8313379287719727
tensor(1.3234, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018395625054836273
loss_c:0.9049121737480164
tensor(1.3349, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0199282206594944
loss_c:0.8329517841339111
tensor(1.3026, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0239726472645998
loss_c:0.8437725305557251
tensor(1.3248, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019736837595701218
loss_c:0.8533148765563965
tensor(1.3126, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0197455957531929
loss_c:0.9306706190109253
tensor(1.3539, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01845223270356655
loss_c:0.7713537216186523
tensor(1.2634, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026475651189684868
loss_c:0.8735033273696899
tensor(1.3508, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020716117694973946
loss_c:0.7549409866333008
tensor(1.2636, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02930890955030918
loss_c:0.7608041763305664
tensor(1.3020, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03129628673195839
loss_c:0.7950536608695984
tensor(1.3285, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013144858181476593
loss_c:0.8775384426116943
tensor(1.2979, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027093933895230293
loss_c:1.1148346662521362
tensor(1.4832, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019202260300517082
loss_c:0.8803128004074097
tensor(1.3243, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031066028401255608
loss_c:0.8012820482254028
tensor(1.3309, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0210210382938385
loss_c:0.916932225227356
tensor(1.3515, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01741606555879116
loss_c:0.9077927470207214
tensor(1.3316, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01802869699895382
loss_c:0.8140114545822144
tensor(1.2835, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027580607682466507
loss_c:0.8778442740440369
tensor(1.3577, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024365006014704704
loss_c:0.8352095484733582
tensor(1.3212, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022325415164232254
loss_c:0.9803979396820068
tensor(1.3912, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015132427215576172
loss_c:0.7877429723739624
tensor(1.2568, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01907292753458023
loss_c:0.7871131300926208
tensor(1.2729, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01864139549434185
loss_c:0.9094767570495605
tensor(1.3373, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015539251267910004
loss_c:0.9202157855033875
tensor(1.3300, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02248065546154976
loss_c:0.8391687273979187
tensor(1.3153, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0164857879281044
loss_c:0.8255531191825867
tensor(1.2825, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019752664491534233
loss_c:0.9005236625671387
tensor(1.3370, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025632251054048538
loss_c:1.0228818655014038
tensor(1.4284, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02144090086221695
loss_c:0.8788410425186157
tensor(1.3323, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01942811720073223
loss_c:0.8770109415054321
tensor(1.3227, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017435511574149132
loss_c:0.9559530019760132
tensor(1.3570, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01751774549484253
loss_c:0.8441590070724487
tensor(1.2965, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031670406460762024
loss_c:1.003493309020996
tensor(1.4439, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017895594239234924
loss_c:0.7938365936279297
tensor(1.2707, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021495947614312172
loss_c:0.9931691884994507
tensor(1.3945, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020356271415948868
loss_c:1.0191034078598022
tensor(1.4036, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01688331365585327
loss_c:0.8911756277084351
tensor(1.3191, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020450960844755173
loss_c:1.0842499732971191
tensor(1.4392, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019575105980038643
loss_c:0.9018917083740234
tensor(1.3364, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043659791350364685
loss_c:0.8858766555786133
tensor(1.4326, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02182813547551632
loss_c:0.9039437770843506
tensor(1.3473, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04551706463098526
loss_c:0.835693359375
tensor(1.4137, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03451383113861084
loss_c:0.9110118746757507
tensor(1.4064, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029739875346422195
loss_c:0.8464517593383789
tensor(1.3507, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02402438409626484
loss_c:0.8757535815238953
tensor(1.3416, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025950856506824493
loss_c:0.897864580154419
tensor(1.3619, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024158408865332603
loss_c:1.0595028400421143
tensor(1.4414, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020896146073937416
loss_c:1.0321998596191406
tensor(1.4124, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02499966323375702
loss_c:1.2139196395874023
tensor(1.5281, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0370444618165493
loss_c:0.8411769866943359
tensor(1.3794, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02919607050716877
loss_c:0.8939868807792664
tensor(1.3738, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02156468853354454
loss_c:0.9704891443252563
tensor(1.3819, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07262630015611649
loss_c:0.9955689311027527
tensor(1.6156, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027154985815286636
loss_c:0.8080635070800781
tensor(1.3189, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020993048325181007
loss_c:0.8812562823295593
tensor(1.3317, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031536560505628586
loss_c:0.8755204081535339
tensor(1.3737, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018628185614943504
loss_c:0.9023147821426392
tensor(1.3330, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019812729209661484
loss_c:0.9082702398300171
tensor(1.3412, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01953252963721752
loss_c:0.8148263692855835
tensor(1.2902, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016675753518939018
loss_c:0.8604645729064941
tensor(1.3025, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02201414294540882
loss_c:0.8810805082321167
tensor(1.3361, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01984972320497036
loss_c:0.9153541922569275
tensor(1.3453, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026259584352374077
loss_c:0.9587098956108093
tensor(1.3955, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.052218955010175705
loss_c:0.9527961611747742
tensor(1.5022, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01647280715405941
loss_c:0.7898411154747009
tensor(1.2641, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031659964472055435
loss_c:0.9652042388916016
tensor(1.4217, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023330939933657646
loss_c:0.9114801287651062
tensor(1.3580, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021453367546200752
loss_c:0.9019837379455566
tensor(1.3450, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035582348704338074
loss_c:0.8832578659057617
tensor(1.3945, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02955533377826214
loss_c:0.7695964574813843
tensor(1.3085, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021984564140439034
loss_c:0.9067361354827881
tensor(1.3498, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023345686495304108
loss_c:0.90537428855896
tensor(1.3548, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02195822075009346
loss_c:0.7589879035949707
tensor(1.2709, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02574329264461994
loss_c:0.8104426264762878
tensor(1.3142, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021530648693442345
loss_c:0.8670815825462341
tensor(1.3268, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020411204546689987
loss_c:0.7833809852600098
tensor(1.2773, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027761491015553474
loss_c:0.8997020125389099
tensor(1.3703, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036211006343364716
loss_c:0.8627902269363403
tensor(1.3859, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02041301317512989
loss_c:0.8014793395996094
tensor(1.2869, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1685933619737625
loss_c:1.2464513778686523
tensor(2.1450, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0188283771276474
loss_c:0.8849403858184814
tensor(1.3252, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028394289314746857
loss_c:0.8176323771476746
tensor(1.3288, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02665836177766323
loss_c:0.9036602973937988
tensor(1.3677, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02077418565750122
loss_c:0.8921056985855103
tensor(1.3374, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02628590725362301
loss_c:0.8939096331596375
tensor(1.3610, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03768501803278923
loss_c:0.8816630840301514
tensor(1.4007, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018276570364832878
loss_c:0.8521696925163269
tensor(1.3062, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018304528668522835
loss_c:0.8920683860778809
tensor(1.3278, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023212555795907974
loss_c:0.8558235168457031
tensor(1.3282, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021434245631098747
loss_c:0.8351534605026245
tensor(1.3099, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037613291293382645
loss_c:0.8671147227287292
tensor(1.3921, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014123992994427681
loss_c:0.8799549341201782
tensor(1.3048, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01922939531505108
loss_c:0.8364299535751343
tensor(1.3018, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018501615151762962
loss_c:0.802599310874939
tensor(1.2807, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01847449503839016
loss_c:0.7797142267227173
tensor(1.2682, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019158734008669853
loss_c:0.7891343832015991
tensor(1.2760, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0243796706199646
loss_c:0.9748281836509705
tensor(1.3971, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02082742005586624
loss_c:0.9502546787261963
tensor(1.3696, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027614586055278778
loss_c:0.7899684309959412
tensor(1.3102, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02414196915924549
loss_c:1.0353524684906006
tensor(1.4290, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03112334944307804
loss_c:1.067347764968872
tensor(1.4743, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01948685757815838
loss_c:0.7964641451835632
tensor(1.2809, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01869758777320385
loss_c:0.8791027069091797
tensor(1.3225, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03314553573727608
loss_c:0.8433642387390137
tensor(1.3613, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05113831162452698
loss_c:0.8904661536216736
tensor(1.4594, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021655049175024033
loss_c:0.8677167892456055
tensor(1.3282, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018198581412434578
loss_c:0.8005401492118835
tensor(1.2778, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028422698378562927
loss_c:1.1341238021850586
tensor(1.4998, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03039904311299324
loss_c:0.9751242399215698
tensor(1.4216, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035649869590997696
loss_c:0.9560126066207886
tensor(1.4324, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019632358103990555
loss_c:0.7993553876876831
tensor(1.2830, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03937603533267975
loss_c:0.8861159086227417
tensor(1.4096, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02979166992008686
loss_c:0.8689956665039062
tensor(1.3617, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018251826986670494
loss_c:0.845630407333374
tensor(1.3025, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04044507071375847
loss_c:0.9695577621459961
tensor(1.4590, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02119406871497631
loss_c:1.0154286623001099
tensor(1.4062, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016279805451631546
loss_c:0.7613694071769714
tensor(1.2491, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.14151006937026978
loss_c:1.082056999206543
tensor(1.9271, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020869867876172066
loss_c:0.8588694334030151
tensor(1.3204, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016071997582912445
loss_c:0.7579919695854187
tensor(1.2469, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03315684199333191
loss_c:0.9596385955810547
tensor(1.4239, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017428018152713776
loss_c:0.8961338996887207
tensor(1.3271, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02083069272339344
loss_c:0.8101481199264526
tensor(1.2943, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0277189202606678
loss_c:0.9470558166503906
tensor(1.3954, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017314663156867027
loss_c:0.7581298351287842
tensor(1.2524, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041350118815898895
loss_c:0.9281050562858582
tensor(1.4391, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015605634078383446
loss_c:0.964299201965332
tensor(1.3569, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02391444332897663
loss_c:0.7725057005882263
tensor(1.2863, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025720247998833656
loss_c:1.0537267923355103
tensor(1.4451, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01844978891313076
loss_c:0.7971979379653931
tensor(1.2781, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025412529706954956
loss_c:1.0475353002548218
tensor(1.4406, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01677522249519825
loss_c:0.9065510630607605
tensor(1.3304, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02429020032286644
loss_c:0.893516480922699
tensor(1.3530, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0413806214928627
loss_c:0.9709028601646423
tensor(1.4623, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02341790869832039
loss_c:0.9650737643241882
tensor(1.3881, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03163580968976021
loss_c:0.9316410422325134
tensor(1.4026, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028949519619345665
loss_c:0.767424464225769
tensor(1.3036, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02305733971297741
loss_c:0.7788188457489014
tensor(1.2865, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024421662092208862
loss_c:0.9289981126785278
tensor(1.3726, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028670277446508408
loss_c:0.9622807502746582
tensor(1.4073, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02933756448328495
loss_c:0.9020105600357056
tensor(1.3776, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03497126325964928
loss_c:0.8476530909538269
tensor(1.3706, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018272386863827705
loss_c:0.766531229019165
tensor(1.2609, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03545857593417168
loss_c:0.8023127317428589
tensor(1.3482, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019731640815734863
loss_c:0.8808764219284058
tensor(1.3281, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02383420616388321
loss_c:0.8874446153640747
tensor(1.3479, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02598990872502327
loss_c:0.9547693133354187
tensor(1.3927, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028523560613393784
loss_c:0.9111984968185425
tensor(1.3793, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027013123035430908
loss_c:0.8735901713371277
tensor(1.3530, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020043689757585526
loss_c:0.8754178881645203
tensor(1.3263, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028101611882448196
loss_c:0.7902774810791016
tensor(1.3125, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02238604798913002
loss_c:0.9358818531036377
tensor(1.3682, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024853114038705826
loss_c:0.9463413953781128
tensor(1.3836, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01965469866991043
loss_c:0.9700927734375
tensor(1.3757, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018791409209370613
loss_c:0.8721327781677246
tensor(1.3194, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022000929340720177
loss_c:0.9727534055709839
tensor(1.3864, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018560444936156273
loss_c:0.9824437499046326
tensor(1.3778, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01793184131383896
loss_c:0.7483362555503845
tensor(1.2491, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019479935988783836
loss_c:1.034708023071289
tensor(1.4096, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017143385484814644
loss_c:0.970786452293396
tensor(1.3656, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026511339470744133
loss_c:0.909304141998291
tensor(1.3702, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017620110884308815
loss_c:0.8855347633361816
tensor(1.3214, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01982615888118744
loss_c:0.9439587593078613
tensor(1.3617, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05560746416449547
loss_c:0.9848742485046387
tensor(1.5290, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014044307172298431
loss_c:0.760426938533783
tensor(1.2394, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022854657843708992
loss_c:0.8964709043502808
tensor(1.3484, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019527161493897438
loss_c:0.9160658717155457
tensor(1.3453, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020865732803940773
loss_c:0.9262294769287109
tensor(1.3562, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039617497473955154
loss_c:0.8139990568161011
tensor(1.3726, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08405167609453201
loss_c:0.9075969457626343
tensor(1.6048, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02082655020058155
loss_c:0.806309163570404
tensor(1.2916, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.045320890843868256
loss_c:0.8351263403892517
tensor(1.4071, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020938793197274208
loss_c:0.8861401081085205
tensor(1.3350, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03297597914934158
loss_c:0.927376925945282
tensor(1.4062, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02401823364198208
loss_c:0.8510138392448425
tensor(1.3287, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02388092875480652
loss_c:0.9020189046859741
tensor(1.3556, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018568482249975204
loss_c:0.9020481109619141
tensor(1.3341, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02784222550690174
loss_c:0.8690929412841797
tensor(1.3539, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01889677345752716
loss_c:0.8490914106369019
tensor(1.3069, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020671231672167778
loss_c:0.857538640499115
tensor(1.3187, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01754116825759411
loss_c:0.8177425265312195
tensor(1.2846, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02473369613289833
loss_c:1.248053789138794
tensor(1.5454, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018446436151862144
loss_c:0.8037149310112
tensor(1.2806, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03630957752466202
loss_c:0.905389666557312
tensor(1.4078, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02538069151341915
loss_c:0.9166465997695923
tensor(1.3695, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04889307916164398
loss_c:0.9369763731956482
tensor(1.4760, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02171451225876808
loss_c:0.8666608333587646
tensor(1.3278, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016209997236728668
loss_c:0.8619363307952881
tensor(1.3029, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03467829152941704
loss_c:0.773603618144989
tensor(1.3304, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021062646061182022
loss_c:0.8540048003196716
tensor(1.3183, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03500371053814888
loss_c:0.8232349157333374
tensor(1.3583, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02418210171163082
loss_c:0.7540804743766785
tensor(1.2772, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02620716765522957
loss_c:1.0954713821411133
tensor(1.4692, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.052938807755708694
loss_c:0.7842833399772644
tensor(1.4101, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020408757030963898
loss_c:0.913205087184906
tensor(1.3475, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026280544698238373
loss_c:0.9547820091247559
tensor(1.3938, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01549206580966711
loss_c:0.8375474214553833
tensor(1.2869, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02110457792878151
loss_c:0.846453070640564
tensor(1.3144, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014947342686355114
loss_c:0.7592976093292236
tensor(1.2424, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023964082822203636
loss_c:0.9244459867477417
tensor(1.3681, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026383275166153908
loss_c:0.9142729640007019
tensor(1.3724, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01959405280649662
loss_c:0.8373641967773438
tensor(1.3033, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01427538227289915
loss_c:0.7089425921440125
tensor(1.2122, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02381000481545925
loss_c:0.882563591003418
tensor(1.3448, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019819673150777817
loss_c:0.8112322688102722
tensor(1.2899, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019085321575403214
loss_c:0.8297266364097595
tensor(1.2968, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01646793819963932
loss_c:0.8068240880966187
tensor(1.2736, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02513684146106243
loss_c:0.8492567539215088
tensor(1.3320, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0342504158616066
loss_c:0.9056801795959473
tensor(1.4000, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01931913010776043
loss_c:0.8045654296875
tensor(1.2838, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0189422108232975
loss_c:0.8404795527458191
tensor(1.3017, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016180865466594696
loss_c:0.8307134509086609
tensor(1.2849, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02183394879102707
loss_c:0.845099151134491
tensor(1.3160, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028658172115683556
loss_c:0.9733117818832397
tensor(1.4142, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03524265065789223
loss_c:1.103898525238037
tensor(1.5128, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028886519372463226
loss_c:0.8615588545799255
tensor(1.3541, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031108178198337555
loss_c:0.9131932258605957
tensor(1.3916, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018659362569451332
loss_c:0.8134891390800476
tensor(1.2855, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034697674214839935
loss_c:0.9389646053314209
tensor(1.4206, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022662675008177757
loss_c:0.8299329280853271
tensor(1.3110, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018555082380771637
loss_c:0.9017888903617859
tensor(1.3332, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019841082394123077
loss_c:0.8555467128753662
tensor(1.3133, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01677837036550045
loss_c:0.8685974478721619
tensor(1.3076, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05668522045016289
loss_c:0.8109971880912781
tensor(1.4425, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026739660650491714
loss_c:0.9438412189483643
tensor(1.3902, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016898605972528458
loss_c:0.8927070498466492
tensor(1.3213, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02145799808204174
loss_c:0.8650471568107605
tensor(1.3252, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02297034300863743
loss_c:0.9470967054367065
tensor(1.3763, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018656039610505104
loss_c:0.8398181200027466
tensor(1.2997, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018678104504942894
loss_c:0.8880466222763062
tensor(1.3261, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015535399317741394
loss_c:0.9362789392471313
tensor(1.3393, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02343977615237236
loss_c:0.9430440664291382
tensor(1.3760, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014875388704240322
loss_c:0.7917015552520752
tensor(1.2575, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030101435258984566
loss_c:0.860921323299408
tensor(1.3591, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01932050660252571
loss_c:0.8906615972518921
tensor(1.3300, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.045586906373500824
loss_c:0.8364807963371277
tensor(1.4109, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03107338398694992
loss_c:1.0542287826538086
tensor(1.4686, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0484279990196228
loss_c:1.0160821676254272
tensor(1.5208, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02203645184636116
loss_c:0.7949368953704834
tensor(1.2893, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03113115020096302
loss_c:0.8874274492263794
tensor(1.3779, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015472820959985256
loss_c:0.8321226835250854
tensor(1.2820, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023981686681509018
loss_c:0.8731601238250732
tensor(1.3401, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015826668590307236
loss_c:0.9163801670074463
tensor(1.3294, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016625048592686653
loss_c:0.8617050051689148
tensor(1.3030, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03683062270283699
loss_c:0.8816237449645996
tensor(1.3986, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023874759674072266
loss_c:0.8394531011581421
tensor(1.3213, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020056070759892464
loss_c:0.9349109530448914
tensor(1.3572, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05074773356318474
loss_c:0.906897783279419
tensor(1.4707, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03200909122824669
loss_c:0.8189631700515747
tensor(1.3443, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015975428745150566
loss_c:0.9219039678573608
tensor(1.3331, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019019752740859985
loss_c:0.9409584999084473
tensor(1.3562, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02206268720328808
loss_c:0.9756048917770386
tensor(1.3877, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02579360082745552
loss_c:0.9696311950683594
tensor(1.4001, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0183990728110075
loss_c:0.8351879119873047
tensor(1.2961, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02227797545492649
loss_c:0.9326391220092773
tensor(1.3652, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024800848215818405
loss_c:0.8964206576347351
tensor(1.3561, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018191589042544365
loss_c:0.9050054550170898
tensor(1.3331, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021354880183935165
loss_c:0.8294207453727722
tensor(1.3054, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020944397896528244
loss_c:0.919099748134613
tensor(1.3522, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03186158463358879
loss_c:1.001455545425415
tensor(1.4426, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03158453851938248
loss_c:0.8295823931694031
tensor(1.3485, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019703052937984467
loss_c:0.9135866165161133
tensor(1.3440, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018412644043564796
loss_c:0.8612005114555359
tensor(1.3102, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020606830716133118
loss_c:0.8786458969116211
tensor(1.3289, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04422383010387421
loss_c:1.0136990547180176
tensor(1.5012, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018496377393603325
loss_c:0.717503547668457
tensor(1.2330, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028316546231508255
loss_c:0.9692529439926147
tensor(1.4102, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030163340270519257
loss_c:0.8879461288452148
tensor(1.3741, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016518965363502502
loss_c:0.9162095785140991
tensor(1.3319, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02981056459248066
loss_c:0.9561494588851929
tensor(1.4094, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0342145636677742
loss_c:1.0110828876495361
tensor(1.4576, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02354486472904682
loss_c:0.8961504697799683
tensor(1.3507, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018918931484222412
loss_c:0.8966654539108276
tensor(1.3315, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02471783198416233
loss_c:0.9425376653671265
tensor(1.3806, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02459448017179966
loss_c:0.9209184646606445
tensor(1.3684, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0160899106413126
loss_c:0.8334318995475769
tensor(1.2856, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036288872361183167
loss_c:0.8900963664054871
tensor(1.4011, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019692840054631233
loss_c:0.9211232662200928
tensor(1.3479, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019079549238085747
loss_c:0.8306304812431335
tensor(1.2967, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09775268286466599
loss_c:0.9726212024688721
tensor(1.7043, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025281185284256935
loss_c:0.7478622198104858
tensor(1.2783, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0196083877235651
loss_c:1.0285367965698242
tensor(1.4053, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029176652431488037
loss_c:1.0539501905441284
tensor(1.4590, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03536690026521683
loss_c:0.761817455291748
tensor(1.3280, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020622873678803444
loss_c:0.8565030097961426
tensor(1.3173, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027240315452218056
loss_c:0.8620173335075378
tensor(1.3478, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020311947911977768
loss_c:0.8326210379600525
tensor(1.3033, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01681487448513508
loss_c:0.9731222987174988
tensor(1.3642, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021132692694664
loss_c:0.8961004018783569
tensor(1.3408, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015709906816482544
loss_c:0.796872615814209
tensor(1.2651, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028803454712033272
loss_c:0.9527775049209595
tensor(1.4030, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02436566725373268
loss_c:0.9948458075523376
tensor(1.4072, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031709980219602585
loss_c:0.7757997512817383
tensor(1.3200, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015837397426366806
loss_c:0.8407384753227234
tensor(1.2892, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06778938323259354
loss_c:0.9411832690238953
tensor(1.5581, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020445477217435837
loss_c:0.880645751953125
tensor(1.3297, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03167238458991051
loss_c:0.9853717684745789
tensor(1.4323, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019320465624332428
loss_c:0.866919219493866
tensor(1.3178, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02526511810719967
loss_c:0.8489072322845459
tensor(1.3326, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019701143726706505
loss_c:0.9734534025192261
tensor(1.3766, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02913176268339157
loss_c:0.9942287802696228
tensor(1.4265, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031122129410505295
loss_c:0.8815776705741882
tensor(1.3742, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021186746656894684
loss_c:0.9330062866210938
tensor(1.3610, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02686391770839691
loss_c:0.7586538195610046
tensor(1.2907, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01924588344991207
loss_c:0.8538435697555542
tensor(1.3105, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015621957369148731
loss_c:0.888001561164856
tensor(1.3140, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03429922088980675
loss_c:0.78777015209198
tensor(1.3369, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019606556743383408
loss_c:0.8928074240684509
tensor(1.3329, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02488352544605732
loss_c:0.9459190368652344
tensor(1.3831, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014033544808626175
loss_c:0.8129558563232422
tensor(1.2671, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027208851650357246
loss_c:0.9611924886703491
tensor(1.4009, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018902096897363663
loss_c:0.8955442309379578
tensor(1.3314, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025514092296361923
loss_c:0.8464945554733276
tensor(1.3323, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018140146508812904
loss_c:0.8880995512008667
tensor(1.3242, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012913101352751255
loss_c:0.7301021814346313
tensor(1.2176, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03745228052139282
loss_c:1.062936544418335
tensor(1.4982, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0189345795661211
loss_c:0.8503479957580566
tensor(1.3070, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03914773464202881
loss_c:0.8775781393051147
tensor(1.4055, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017714567482471466
loss_c:0.8734849691390991
tensor(1.3144, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02098553068935871
loss_c:0.8796245455741882
tensor(1.3313, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022898320108652115
loss_c:0.8807343244552612
tensor(1.3398, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01760092005133629
loss_c:0.840047299861908
tensor(1.2958, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03779013082385063
loss_c:1.0726056098937988
tensor(1.5053, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034728821367025375
loss_c:0.9146983027458191
tensor(1.4074, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017491964623332024
loss_c:0.8410860896110535
tensor(1.2958, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02000342309474945
loss_c:0.790195643901825
tensor(1.2788, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016208097338676453
loss_c:0.8665304183959961
tensor(1.3041, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022104067727923393
loss_c:0.919512927532196
tensor(1.3573, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02071782946586609
loss_c:0.929341733455658
tensor(1.3568, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023606333881616592
loss_c:0.9381808638572693
tensor(1.3737, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019923174753785133
loss_c:0.8117978572845459
tensor(1.2900, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015899842604994774
loss_c:0.8944683074951172
tensor(1.3177, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01891257055103779
loss_c:0.8906987905502319
tensor(1.3283, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03657780960202217
loss_c:0.9428704977035522
tensor(1.4308, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029260972514748573
loss_c:0.7092432379722595
tensor(1.2738, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.066360242664814
loss_c:0.9239621162414551
tensor(1.5463, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02465970814228058
loss_c:0.7882351875305176
tensor(1.2971, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037109505385160446
loss_c:1.1007616519927979
tensor(1.5184, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022649236023426056
loss_c:0.9313657283782959
tensor(1.3660, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016696084290742874
loss_c:0.8615317344665527
tensor(1.3032, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02987903170287609
loss_c:0.8568922877311707
tensor(1.3561, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031018996611237526
loss_c:0.9437536597251892
tensor(1.4078, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017915965989232063
loss_c:0.9100422859191895
tensor(1.3347, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029310939833521843
loss_c:0.9196814298629761
tensor(1.3876, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020868070423603058
loss_c:0.8262626528739929
tensor(1.3018, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021365465596318245
loss_c:0.9351094961166382
tensor(1.3627, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033546362072229385
loss_c:0.8534332513809204
tensor(1.3695, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021901283413171768
loss_c:0.8011465072631836
tensor(1.2926, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017905941233038902
loss_c:0.760733962059021
tensor(1.2540, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019641853868961334
loss_c:0.882199227809906
tensor(1.3269, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018445884808897972
loss_c:0.8400640487670898
tensor(1.2991, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016813671216368675
loss_c:0.725100040435791
tensor(1.2301, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021781589835882187
loss_c:0.9215878248214722
tensor(1.3571, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10308512300252914
loss_c:0.9342142939567566
tensor(1.7045, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03294297307729721
loss_c:0.8296257853507996
tensor(1.3540, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0417792946100235
loss_c:0.8334518671035767
tensor(1.3928, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016625456511974335
loss_c:0.9044460654258728
tensor(1.3266, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018529558554291725
loss_c:0.7875552177429199
tensor(1.2711, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019899236038327217
loss_c:0.8744301795959473
tensor(1.3240, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025901274755597115
loss_c:1.0103543996810913
tensor(1.4227, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020461367443203926
loss_c:1.072858452796936
tensor(1.4343, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01719401404261589
loss_c:1.0321149826049805
tensor(1.3986, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019634932279586792
loss_c:0.7613827586174011
tensor(1.2616, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0209350548684597
loss_c:0.8326441645622253
tensor(1.3056, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03578551113605499
loss_c:0.8792361617088318
tensor(1.3922, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039399128407239914
loss_c:1.0507919788360596
tensor(1.5003, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023249629884958267
loss_c:0.8714119791984558
tensor(1.3363, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01742975041270256
loss_c:0.8260021209716797
tensor(1.2877, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02740681916475296
loss_c:1.1372020244598389
tensor(1.4976, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02311290241777897
loss_c:0.9874414801597595
tensor(1.3986, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044419944286346436
loss_c:0.9459611773490906
tensor(1.4638, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04093976691365242
loss_c:0.9370280504226685
tensor(1.4446, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017391551285982132
loss_c:0.833806037902832
tensor(1.2919, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0176546648144722
loss_c:0.9721083641052246
tensor(1.3678, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020196368917822838
loss_c:0.9239475727081299
tensor(1.3522, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029088448733091354
loss_c:1.0274571180343628
tensor(1.4445, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02519269846379757
loss_c:0.9424954652786255
tensor(1.3826, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022875038906931877
loss_c:1.1132205724716187
tensor(1.4650, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020962344482541084
loss_c:1.0605289936065674
tensor(1.4287, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019461359828710556
loss_c:0.80955970287323
tensor(1.2877, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013667802326381207
loss_c:0.8666296005249023
tensor(1.2946, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026312943547964096
loss_c:0.93422532081604
tensor(1.3827, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03029595874249935
loss_c:0.9810179471969604
tensor(1.4240, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03837079927325249
loss_c:0.8964166641235352
tensor(1.4121, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021975548937916756
loss_c:1.0074375867843628
tensor(1.4038, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05142609030008316
loss_c:1.0102996826171875
tensor(1.5265, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04604118689894676
loss_c:0.8177001476287842
tensor(1.4017, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020152220502495766
loss_c:0.7961658239364624
tensor(1.2838, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017985032871365547
loss_c:0.7569111585617065
tensor(1.2542, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03836849331855774
loss_c:0.9023785591125488
tensor(1.4151, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024029560387134552
loss_c:0.8958999514579773
tensor(1.3528, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02356288582086563
loss_c:1.0104949474334717
tensor(1.4118, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04938586801290512
loss_c:0.9206889867782593
tensor(1.4697, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01725369691848755
loss_c:0.7929133176803589
tensor(1.2705, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03272947296500206
loss_c:0.7826113700866699
tensor(1.3282, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026253903284668922
loss_c:1.2525103092193604
tensor(1.5514, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02192019671201706
loss_c:0.9392802119255066
tensor(1.3674, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0524812750518322
loss_c:0.8425955176353455
tensor(1.4404, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015698876231908798
loss_c:0.8361915349960327
tensor(1.2875, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031157735735177994
loss_c:0.9455143213272095
tensor(1.4082, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029096875339746475
loss_c:0.9569839239120483
tensor(1.4059, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10155212879180908
loss_c:0.9369451999664307
tensor(1.6885, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026700636371970177
loss_c:0.8983898162841797
tensor(1.3651, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04133002832531929
loss_c:0.9215868711471558
tensor(1.4362, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017539316788315773
loss_c:0.8132802248001099
tensor(1.2834, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043340787291526794
loss_c:0.8877538442611694
tensor(1.4259, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013529165647923946
loss_c:0.8096567988395691
tensor(1.2658, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020303236320614815
loss_c:0.9675276279449463
tensor(1.3765, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04778672009706497
loss_c:0.8581194877624512
tensor(1.4273, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025238238275051117
loss_c:0.7775630950927734
tensor(1.2954, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022767549380660057
loss_c:0.9116873145103455
tensor(1.3568, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014507551677525043
loss_c:0.9381532669067383
tensor(1.3384, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026816682890057564
loss_c:1.063981056213379
tensor(1.4537, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01573432981967926
loss_c:0.889802873134613
tensor(1.3176, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018864193931221962
loss_c:0.7688443064689636
tensor(1.2656, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025516854599118233
loss_c:0.8045069575309753
tensor(1.3107, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018734227865934372
loss_c:0.8762613534927368
tensor(1.3222, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021067315712571144
loss_c:0.7976548671722412
tensor(1.2895, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020614847540855408
loss_c:0.910842776298523
tensor(1.3479, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019344951957464218
loss_c:0.7420355677604675
tensor(1.2529, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025020470842719078
loss_c:0.9814373850822449
tensor(1.4029, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03244577348232269
loss_c:0.8670976161956787
tensor(1.3712, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019212044775485992
loss_c:0.9801360964775085
tensor(1.3792, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02390054427087307
loss_c:1.0349345207214355
tensor(1.4271, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03515373170375824
loss_c:0.9887997508049011
tensor(1.4470, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020358901470899582
loss_c:0.8269443511962891
tensor(1.3018, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02100841887295246
loss_c:0.8436176180839539
tensor(1.3132, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021926918998360634
loss_c:0.8227829933166504
tensor(1.3057, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030169732868671417
loss_c:0.9281706809997559
tensor(1.3949, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01920941472053528
loss_c:0.9157698154449463
tensor(1.3445, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015960626304149628
loss_c:0.8735143542289734
tensor(1.3089, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03083217889070511
loss_c:0.8938273191452026
tensor(1.3792, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01886526122689247
loss_c:0.8825559616088867
tensor(1.3252, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021731091663241386
loss_c:1.0107700824737549
tensor(1.4054, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020406613126397133
loss_c:0.9683253169059753
tensor(1.3772, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02593582309782505
loss_c:0.8977394104003906
tensor(1.3617, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03496300429105759
loss_c:0.8003031611442566
tensor(1.3459, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03711388260126114
loss_c:1.1401723623275757
tensor(1.5367, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02889041043817997
loss_c:0.8245770335197449
tensor(1.3344, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020994896069169044
loss_c:0.809248149394989
tensor(1.2942, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016054745763540268
loss_c:0.9010910987854004
tensor(1.3234, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02115745097398758
loss_c:0.7971872091293335
tensor(1.2884, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017247261479496956
loss_c:0.885432243347168
tensor(1.3197, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02920839749276638
loss_c:0.9107037782669067
tensor(1.3819, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029227713122963905
loss_c:0.8030363321304321
tensor(1.3243, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02966652438044548
loss_c:0.9280456304550171
tensor(1.3931, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020767688751220703
loss_c:0.872452437877655
tensor(1.3269, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01693425141274929
loss_c:0.8093006610870361
tensor(1.2774, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026234963908791542
loss_c:0.9038988351821899
tensor(1.3661, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024487348273396492
loss_c:0.954505443572998
tensor(1.3861, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027292173355817795
loss_c:0.9476761221885681
tensor(1.3940, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016346629709005356
loss_c:0.899287223815918
tensor(1.3230, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02566256746649742
loss_c:0.7601256370544434
tensor(1.2865, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02271123044192791
loss_c:0.8734573125839233
tensor(1.3352, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03968548774719238
loss_c:0.8725181818008423
tensor(1.4047, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028734711930155754
loss_c:1.0070035457611084
tensor(1.4319, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04550088569521904
loss_c:1.0624314546585083
tensor(1.5309, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03050573356449604
loss_c:1.0359007120132446
tensor(1.4547, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022639241069555283
loss_c:1.0459316968917847
tensor(1.4276, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015761099755764008
loss_c:0.6829060912132263
tensor(1.2043, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016338389366865158
loss_c:0.9118451476097107
tensor(1.3296, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025126410648226738
loss_c:0.8989391326904297
tensor(1.3589, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030656125396490097
loss_c:1.1267116069793701
tensor(1.5039, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018391311168670654
loss_c:0.8978675603866577
tensor(1.3305, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03338881582021713
loss_c:0.8738263845443726
tensor(1.3795, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016248559579253197
loss_c:0.8468372225761414
tensor(1.2943, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01811300776898861
loss_c:1.0044307708740234
tensor(1.3864, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01811731792986393
loss_c:0.7657920122146606
tensor(1.2586, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03699431195855141
loss_c:0.8116840124130249
tensor(1.3613, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01818605698645115
loss_c:0.871550440788269
tensor(1.3155, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0375400148332119
loss_c:0.9093002080917358
tensor(1.4159, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02867302857339382
loss_c:0.791545569896698
tensor(1.3161, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04394175112247467
loss_c:1.2041003704071045
tensor(1.6003, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015786180272698402
loss_c:0.9585403203964233
tensor(1.3520, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025332685559988022
loss_c:0.8061884641647339
tensor(1.3101, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021178634837269783
loss_c:0.8648728132247925
tensor(1.3243, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025427279993891716
loss_c:0.8113481998443604
tensor(1.3133, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034478604793548584
loss_c:1.134653091430664
tensor(1.5237, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018711209297180176
loss_c:0.8966967463493347
tensor(1.3311, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030558306723833084
loss_c:0.9601058959960938
tensor(1.4141, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022111592814326286
loss_c:0.9044439196586609
tensor(1.3493, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.047498706728219986
loss_c:0.7732071876525879
tensor(1.3844, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038794904947280884
loss_c:0.929930567741394
tensor(1.4320, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027895187959074974
loss_c:0.7518210411071777
tensor(1.2918, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02055782824754715
loss_c:0.8913835883140564
tensor(1.3360, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012800325639545918
loss_c:0.8019404411315918
tensor(1.2562, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02018732950091362
loss_c:1.0900812149047852
tensor(1.4407, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0158946942538023
loss_c:0.9411858320236206
tensor(1.3434, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022622311487793922
loss_c:0.8004195094108582
tensor(1.2959, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043343108147382736
loss_c:0.8695809841156006
tensor(1.4184, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022314628586173058
loss_c:0.881753146648407
tensor(1.3381, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0216243676841259
loss_c:0.9366397857666016
tensor(1.3646, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022509153932332993
loss_c:0.8992258906364441
tensor(1.3482, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014641569927334785
loss_c:0.9922835230827332
tensor(1.3655, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01741768978536129
loss_c:1.0311496257781982
tensor(1.3977, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01921837218105793
loss_c:0.8659137487411499
tensor(1.3168, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02000335045158863
loss_c:0.8336490392684937
tensor(1.3027, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015415173955261707
loss_c:0.7601026296615601
tensor(1.2444, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039470504969358444
loss_c:0.9132040739059448
tensor(1.4261, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019844433292746544
loss_c:0.9232649803161621
tensor(1.3499, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01790269836783409
loss_c:1.0452237129211426
tensor(1.4070, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020806491374969482
loss_c:0.9158765077590942
tensor(1.3499, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02408185973763466
loss_c:0.9059993624687195
tensor(1.3583, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023866543546319008
loss_c:0.9363037347793579
tensor(1.3735, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05373626947402954
loss_c:1.0079528093338013
tensor(1.5369, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021041521802544594
loss_c:0.979975700378418
tensor(1.3850, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018993066623806953
loss_c:0.8689891695976257
tensor(1.3172, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0312955342233181
loss_c:0.9865419268608093
tensor(1.4314, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03813620284199715
loss_c:0.8628377914428711
tensor(1.3941, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020021993666887283
loss_c:0.8705291748046875
tensor(1.3223, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017861830070614815
loss_c:0.8797698020935059
tensor(1.3182, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03953973576426506
loss_c:0.8298263549804688
tensor(1.3824, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03531487658619881
loss_c:0.9002761840820312
tensor(1.4022, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017897719517350197
loss_c:0.7878806591033936
tensor(1.2694, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019669273868203163
loss_c:0.8043248057365417
tensor(1.2856, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018521863967180252
loss_c:0.8532716035842896
tensor(1.3069, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023511454463005066
loss_c:0.7859807014465332
tensor(1.2918, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017595108598470688
loss_c:0.9303907155990601
tensor(1.3441, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023178035393357277
loss_c:0.9642202258110046
tensor(1.3856, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016935590654611588
loss_c:0.955915629863739
tensor(1.3550, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01517715584486723
loss_c:0.7958835363388062
tensor(1.2620, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019428148865699768
loss_c:0.9213355779647827
tensor(1.3469, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024305930361151695
loss_c:1.0576963424682617
tensor(1.4404, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023944254964590073
loss_c:0.7912330627441406
tensor(1.2962, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01665331982076168
loss_c:0.8748986721038818
tensor(1.3103, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019069060683250427
loss_c:0.931668758392334
tensor(1.3508, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01738741248846054
loss_c:0.8259105682373047
tensor(1.2870, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023164942860603333
loss_c:0.8457741737365723
tensor(1.3220, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029621480032801628
loss_c:1.0112342834472656
tensor(1.4381, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01104763988405466
loss_c:0.7919675707817078
tensor(1.2417, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03026147373020649
loss_c:0.9258543252944946
tensor(1.3951, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014006335288286209
loss_c:0.7033704519271851
tensor(1.2065, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015260102227330208
loss_c:0.8005988001823425
tensor(1.2639, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0336332693696022
loss_c:0.8201264142990112
tensor(1.3529, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01661793701350689
loss_c:0.7374564409255981
tensor(1.2355, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027459412813186646
loss_c:0.918708086013794
tensor(1.3795, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022882528603076935
loss_c:0.8934377431869507
tensor(1.3463, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01762632094323635
loss_c:0.8744611144065857
tensor(1.3134, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03268977999687195
loss_c:1.1042448282241821
tensor(1.5023, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021268924698233604
loss_c:0.9294135570526123
tensor(1.3587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019201219081878662
loss_c:0.8351432085037231
tensor(1.2989, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01702682301402092
loss_c:0.7820029258728027
tensor(1.2607, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019200123846530914
loss_c:0.9537293314933777
tensor(1.3629, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014943606220185757
loss_c:0.803877592086792
tensor(1.2634, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015388942323625088
loss_c:0.7596626281738281
tensor(1.2413, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02146967500448227
loss_c:0.8942587375640869
tensor(1.3405, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02092796377837658
loss_c:0.8608717322349548
tensor(1.3200, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02647649310529232
loss_c:0.97585129737854
tensor(1.4066, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021781262010335922
loss_c:0.8632602095603943
tensor(1.3250, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018164098262786865
loss_c:0.9180712699890137
tensor(1.3389, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01861731708049774
loss_c:0.8439068794250488
tensor(1.3006, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024960173293948174
loss_c:0.9259762763977051
tensor(1.3730, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022756125777959824
loss_c:0.8282687664031982
tensor(1.3103, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03459155187010765
loss_c:0.9094106554985046
tensor(1.4064, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017643898725509644
loss_c:0.8915166258811951
tensor(1.3221, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018362129107117653
loss_c:0.7824459075927734
tensor(1.2660, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0215157363563776
loss_c:0.8330032229423523
tensor(1.3073, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015345517545938492
loss_c:0.877792239189148
tensor(1.3044, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015510041266679764
loss_c:0.889445960521698
tensor(1.3114, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020242417231202126
loss_c:0.8610665202140808
tensor(1.3169, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018381109461188316
loss_c:0.8376860618591309
tensor(1.2959, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014259476214647293
loss_c:0.8103866577148438
tensor(1.2627, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022088082507252693
loss_c:0.798004150390625
tensor(1.2907, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0514545664191246
loss_c:0.897480845451355
tensor(1.4759, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02958942949771881
loss_c:0.8747395277023315
tensor(1.3659, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026246430352330208
loss_c:0.8906235098838806
tensor(1.3597, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019479496404528618
loss_c:0.8233353495597839
tensor(1.2928, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036303602159023285
loss_c:0.8143079280853271
tensor(1.3628, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02403446100652218
loss_c:0.7817083597183228
tensor(1.2903, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01789940521121025
loss_c:0.8429383039474487
tensor(1.2965, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01928393915295601
loss_c:0.766014575958252
tensor(1.2605, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01735796220600605
loss_c:0.8022681474685669
tensor(1.2718, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0271811131387949
loss_c:0.8547183871269226
tensor(1.3441, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018836582079529762
loss_c:0.9215852618217468
tensor(1.3438, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018077678978443146
loss_c:0.8645241260528564
tensor(1.3091, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017839908599853516
loss_c:0.9311122894287109
tensor(1.3446, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02240011841058731
loss_c:0.8688467741012573
tensor(1.3307, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018441185355186462
loss_c:1.0021347999572754
tensor(1.3864, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06081609055399895
loss_c:0.8252465724945068
tensor(1.4776, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018004046753048897
loss_c:0.8907060623168945
tensor(1.3232, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02040802501142025
loss_c:0.8497503995895386
tensor(1.3113, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023485060781240463
loss_c:1.0866247415542603
tensor(1.4553, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019651276990771294
loss_c:1.018904447555542
tensor(1.4010, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014538037590682507
loss_c:0.7114862203598022
tensor(1.2094, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01845243014395237
loss_c:0.8458876609802246
tensor(1.3006, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03552711755037308
loss_c:0.8168805837631226
tensor(1.3603, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01953071728348732
loss_c:0.9306187033653259
tensor(1.3519, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030899975448846817
loss_c:1.0863898992538452
tensor(1.4877, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04636187106370926
loss_c:0.8278816938400269
tensor(1.4142, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08730597794055939
loss_c:0.9933141469955444
tensor(1.6855, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02614370733499527
loss_c:0.9987513422966003
tensor(1.4183, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01896004006266594
loss_c:0.7651118040084839
tensor(1.2589, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027038374915719032
loss_c:1.177127718925476
tensor(1.5196, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022901056334376335
loss_c:0.868310809135437
tensor(1.3326, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02344505488872528
loss_c:0.8218148946762085
tensor(1.3096, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0202033668756485
loss_c:0.8801931142807007
tensor(1.3275, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0192261952906847
loss_c:0.7751870155334473
tensor(1.2661, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022680697962641716
loss_c:0.7599403262138367
tensor(1.2727, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018199237063527107
loss_c:0.7398092746734619
tensor(1.2426, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023241333663463593
loss_c:0.769936740398407
tensor(1.2806, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019795462489128113
loss_c:0.9644834399223328
tensor(1.3718, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0356573611497879
loss_c:0.8229190707206726
tensor(1.3626, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020129680633544922
loss_c:0.8412532210350037
tensor(1.3061, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03712034970521927
loss_c:0.751828134059906
tensor(1.3300, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02205858938395977
loss_c:0.9621049761772156
tensor(1.3803, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04134861379861832
loss_c:0.8501176238059998
tensor(1.4014, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02942761220037937
loss_c:0.9945720434188843
tensor(1.4294, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016042590141296387
loss_c:0.8365671634674072
tensor(1.2863, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032291263341903687
loss_c:0.8664487600326538
tensor(1.3716, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014643840491771698
loss_c:0.8563165664672852
tensor(1.2913, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03244682773947716
loss_c:0.9006060361862183
tensor(1.3908, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03336143493652344
loss_c:0.9611944556236267
tensor(1.4277, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02622060850262642
loss_c:1.0058568716049194
tensor(1.4219, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017268676310777664
loss_c:0.8491358160972595
tensor(1.2986, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018925117328763008
loss_c:1.026000738143921
tensor(1.4021, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01864190213382244
loss_c:0.8141334056854248
tensor(1.2854, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014392266981303692
loss_c:0.81883704662323
tensor(1.2701, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04188448563218117
loss_c:0.8034306764602661
tensor(1.3774, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02635275572538376
loss_c:0.995539665222168
tensor(1.4167, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024575283750891685
loss_c:0.9644209742546082
tensor(1.3923, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01688011921942234
loss_c:0.9102506041526794
tensor(1.3304, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03058803267776966
loss_c:0.9022997617721558
tensor(1.3837, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04253276810050011
loss_c:0.7786340117454529
tensor(1.3667, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03513767570257187
loss_c:0.8171076774597168
tensor(1.3565, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046327847987413406
loss_c:0.8152978420257568
tensor(1.4024, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015574241057038307
loss_c:0.7379161715507507
tensor(1.2313, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017403364181518555
loss_c:0.7749513387680054
tensor(1.2591, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02541147544980049
loss_c:0.8138748407363892
tensor(1.3138, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023791244253516197
loss_c:0.8427263498306274
tensor(1.3227, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01887439750134945
loss_c:0.8163432478904724
tensor(1.2878, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021354954689741135
loss_c:0.860876202583313
tensor(1.3224, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01653122343122959
loss_c:0.762276291847229
tensor(1.2485, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019174398854374886
loss_c:0.9482823610305786
tensor(1.3611, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02320193499326706
loss_c:0.9269046783447266
tensor(1.3662, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015312783420085907
loss_c:0.9213413596153259
tensor(1.3302, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019057417288422585
loss_c:0.8614758253097534
tensor(1.3131, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023917630314826965
loss_c:0.8898296356201172
tensor(1.3489, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02237088233232498
loss_c:1.0020745992660522
tensor(1.4039, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018877044320106506
loss_c:1.2078450918197632
tensor(1.5019, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02004528045654297
loss_c:0.9438412189483643
tensor(1.3622, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02037367783486843
loss_c:0.7824854850769043
tensor(1.2753, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018044279888272285
loss_c:0.7396987676620483
tensor(1.2421, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02051560953259468
loss_c:0.7944010496139526
tensor(1.2824, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03685560077428818
loss_c:0.8402532339096069
tensor(1.3765, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022188374772667885
loss_c:0.9649068713188171
tensor(1.3825, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018096022307872772
loss_c:0.7278863787651062
tensor(1.2357, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01714853011071682
loss_c:0.7830886244773865
tensor(1.2618, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018561823293566704
loss_c:0.8515820503234863
tensor(1.3052, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037041619420051575
loss_c:0.9771568179130554
tensor(1.4525, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022299908101558685
loss_c:0.8729324340820312
tensor(1.3327, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029503731057047844
loss_c:0.9154990911483765
tensor(1.3867, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04267209768295288
loss_c:1.016540288925171
tensor(1.4982, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02058904990553856
loss_c:0.9714173078536987
tensor(1.3792, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07325555384159088
loss_c:1.047389030456543
tensor(1.6455, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02144482359290123
loss_c:0.8656351566314697
tensor(1.3251, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02707458660006523
loss_c:0.9188251495361328
tensor(1.3781, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018333889544010162
loss_c:0.8188073039054871
tensor(1.2864, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026292702183127403
loss_c:0.9242731332778931
tensor(1.3776, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01956651546061039
loss_c:0.8802217245101929
tensor(1.3252, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017018795013427734
loss_c:0.8383915424346924
tensor(1.2917, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023606017231941223
loss_c:0.8574486970901489
tensor(1.3299, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020712601020932198
loss_c:0.8963190913200378
tensor(1.3388, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034298673272132874
loss_c:0.8953551650047302
tensor(1.3957, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021173221990466118
loss_c:1.0739506483078003
tensor(1.4373, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01623273268342018
loss_c:0.8351234197616577
tensor(1.2867, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03278419375419617
loss_c:0.7581174373626709
tensor(1.3148, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019580967724323273
loss_c:0.8836230635643005
tensor(1.3272, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016962090507149696
loss_c:0.8654217720031738
tensor(1.3063, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024274826049804688
loss_c:0.8992938995361328
tensor(1.3555, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02984752133488655
loss_c:0.8877838850021362
tensor(1.3727, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014125881716609001
loss_c:0.724361777305603
tensor(1.2178, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016526727005839348
loss_c:0.9622061252593994
tensor(1.3568, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01938728243112564
loss_c:0.9799512624740601
tensor(1.3785, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018350956961512566
loss_c:0.801881730556488
tensor(1.2776, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013917004689574242
loss_c:0.7762138247489929
tensor(1.2448, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01775548607110977
loss_c:0.8327347636222839
tensor(1.2917, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.15076282620429993
loss_c:1.0977966785430908
tensor(2.0014, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02208731323480606
loss_c:0.8319973945617676
tensor(1.3097, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01932590641081333
loss_c:0.8601452708244324
tensor(1.3133, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015933962538838387
loss_c:0.8294646143913269
tensor(1.2825, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019375208765268326
loss_c:0.7464637756347656
tensor(1.2520, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020910736173391342
loss_c:0.8649048805236816
tensor(1.3227, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02292385883629322
loss_c:0.7480576038360596
tensor(1.2677, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01916530728340149
loss_c:0.899060845375061
tensor(1.3340, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019548818469047546
loss_c:0.9058162569999695
tensor(1.3393, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020546767860651016
loss_c:0.8663782477378845
tensor(1.3221, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018029330298304558
loss_c:0.8283302783966064
tensor(1.2908, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017680618911981583
loss_c:0.8175565600395203
tensor(1.2835, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01908765733242035
loss_c:0.9151686429977417
tensor(1.3425, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024622511118650436
loss_c:0.848759651184082
tensor(1.3295, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0223586093634367
loss_c:0.9676114916801453
tensor(1.3848, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026104049757122993
loss_c:0.8299341201782227
tensor(1.3254, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027385510504245758
loss_c:1.0825127363204956
tensor(1.4686, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020420590415596962
loss_c:1.0255107879638672
tensor(1.4083, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04472726583480835
loss_c:0.880774974822998
tensor(1.4313, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028587697073817253
loss_c:0.7243914604187012
tensor(1.2783, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021447673439979553
loss_c:0.9679670333862305
tensor(1.3811, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019805196672677994
loss_c:0.8906907439231873
tensor(1.3321, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017459146678447723
loss_c:0.8191354274749756
tensor(1.2833, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025631893426179886
loss_c:0.8919687271118164
tensor(1.3572, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02443876303732395
loss_c:0.9798612594604492
tensor(1.4001, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021377695724368095
loss_c:0.872471034526825
tensor(1.3287, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026879748329520226
loss_c:0.9943817853927612
tensor(1.4182, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01333352830260992
loss_c:0.7594764232635498
tensor(1.2334, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016589432954788208
loss_c:1.0137488842010498
tensor(1.3854, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017915816977620125
loss_c:1.0079307556152344
tensor(1.3878, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07765161246061325
loss_c:0.9368433356285095
tensor(1.6012, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013917799107730389
loss_c:0.739048421382904
tensor(1.2248, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015003507025539875
loss_c:0.9453579783439636
tensor(1.3414, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017781784757971764
loss_c:0.8865208625793457
tensor(1.3212, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025275947526097298
loss_c:0.8332616090774536
tensor(1.3239, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018393078818917274
loss_c:0.8591235876083374
tensor(1.3089, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013307621702551842
loss_c:0.8258341550827026
tensor(1.2694, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021508872509002686
loss_c:0.9800853133201599
tensor(1.3876, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02361239306628704
loss_c:0.8687467575073242
tensor(1.3361, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036187201738357544
loss_c:0.8410345911979675
tensor(1.3743, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028621766716241837
loss_c:0.8686355352401733
tensor(1.3572, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015786070376634598
loss_c:0.8157711029052734
tensor(1.2743, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05329027771949768
loss_c:1.0247650146484375
tensor(1.5464, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022232785820961
loss_c:0.9799050092697144
tensor(1.3905, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02173934504389763
loss_c:0.8886353373527527
tensor(1.3389, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023211557418107986
loss_c:0.9368088245391846
tensor(1.3712, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019217969849705696
loss_c:0.8601827621459961
tensor(1.3129, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021121112629771233
loss_c:0.9907999038696289
tensor(1.3916, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017725082114338875
loss_c:0.8613742589950562
tensor(1.3072, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02042190358042717
loss_c:0.9469614028930664
tensor(1.3649, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016440005972981453
loss_c:0.8137625455856323
tensor(1.2760, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013989516533911228
loss_c:0.8904990553855896
tensor(1.3070, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016420681029558182
loss_c:0.7821542620658875
tensor(1.2588, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01942819356918335
loss_c:0.9195124506950378
tensor(1.3457, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06144808977842331
loss_c:0.8263048529624939
tensor(1.4744, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022793855518102646
loss_c:0.8034519553184509
tensor(1.2974, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04100582376122475
loss_c:0.8675874471664429
tensor(1.4096, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01758096180856228
loss_c:0.8197769522666931
tensor(1.2840, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04428817704319954
loss_c:0.964275062084198
tensor(1.4757, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02032032050192356
loss_c:1.0113732814788818
tensor(1.3992, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02565988525748253
loss_c:0.8274361491203308
tensor(1.3225, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01598530448973179
loss_c:0.8819587230682373
tensor(1.3109, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021131116896867752
loss_c:0.8044121265411377
tensor(1.2908, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015314620919525623
loss_c:0.8484725952148438
tensor(1.2900, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027067283168435097
loss_c:0.8543839454650879
tensor(1.3430, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023027056828141212
loss_c:0.8352549076080322
tensor(1.3155, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04671931266784668
loss_c:0.9308507442474365
tensor(1.4678, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017512239515781403
loss_c:0.950476884841919
tensor(1.3545, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025980055332183838
loss_c:0.9401232600212097
tensor(1.3848, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025485312566161156
loss_c:0.69441819190979
tensor(1.2496, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02762608975172043
loss_c:0.8495630025863647
tensor(1.3427, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016624946147203445
loss_c:0.8301048278808594
tensor(1.2856, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024349844083189964
loss_c:0.8606268763542175
tensor(1.3348, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03788883611559868
loss_c:0.8067940473556519
tensor(1.3629, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023348554968833923
loss_c:0.9464057683944702
tensor(1.3771, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017691312357783318
loss_c:0.8524832725524902
tensor(1.3022, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022676007822155952
loss_c:0.9992786645889282
tensor(1.4031, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015038346871733665
loss_c:0.7557680010795593
tensor(1.2384, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016321232542395592
loss_c:0.7558393478393555
tensor(1.2438, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012801251374185085
loss_c:0.7450100183486938
tensor(1.2229, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03124687634408474
loss_c:1.0193803310394287
tensor(1.4505, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02401098608970642
loss_c:0.9018205404281616
tensor(1.3558, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03676876053214073
loss_c:0.8794316053390503
tensor(1.3977, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02641005627810955
loss_c:0.8728655576705933
tensor(1.3502, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014978969469666481
loss_c:0.8407418727874756
tensor(1.2841, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018837565556168556
loss_c:0.7897825241088867
tensor(1.2726, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017384225502610207
loss_c:0.8930964469909668
tensor(1.3228, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028027676045894623
loss_c:0.8824769854545593
tensor(1.3623, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017165036872029305
loss_c:0.9065877795219421
tensor(1.3292, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018309220671653748
loss_c:0.7895807027816772
tensor(1.2701, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025815661996603012
loss_c:0.8869324922561646
tensor(1.3554, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017945995554327965
loss_c:0.8622817397117615
tensor(1.3082, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025577150285243988
loss_c:0.9154812693595886
tensor(1.3700, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03889080882072449
loss_c:0.9510643482208252
tensor(1.4465, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029157502576708794
loss_c:1.011547327041626
tensor(1.4379, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0157612357288599
loss_c:0.7672184705734253
tensor(1.2468, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016353324055671692
loss_c:0.786777675151825
tensor(1.2600, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016238024458289146
loss_c:0.8656712770462036
tensor(1.3026, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02056729421019554
loss_c:0.975745677947998
tensor(1.3815, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037569064646959305
loss_c:1.0243468284606934
tensor(1.4812, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017922570928931236
loss_c:0.8496255278587341
tensor(1.3010, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019613074138760567
loss_c:0.9183003306388855
tensor(1.3459, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028698693960905075
loss_c:0.9179086089134216
tensor(1.3848, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01694592833518982
loss_c:0.9733111262321472
tensor(1.3644, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0213264562189579
loss_c:0.9216897487640381
tensor(1.3550, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02146519348025322
loss_c:0.8854726552963257
tensor(1.3358, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012022015638649464
loss_c:0.838198184967041
tensor(1.2692, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.045638591051101685
loss_c:0.9985553026199341
tensor(1.5021, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03163498640060425
loss_c:0.7979017496109009
tensor(1.3321, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030288735404610634
loss_c:0.852846622467041
tensor(1.3562, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02066090516746044
loss_c:0.9829422235488892
tensor(1.3854, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028058117255568504
loss_c:0.7313093543052673
tensor(1.2805, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016558771952986717
loss_c:0.983299732208252
tensor(1.3678, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020259913057088852
loss_c:0.9263747930526733
tensor(1.3528, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019095132127404213
loss_c:0.7892897129058838
tensor(1.2733, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03116512857377529
loss_c:0.9384281039237976
tensor(1.4065, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02262188121676445
loss_c:0.899838924407959
tensor(1.3486, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01879427768290043
loss_c:0.9334931373596191
tensor(1.3503, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017438679933547974
loss_c:0.9237631559371948
tensor(1.3392, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022739700973033905
loss_c:0.9040203094482422
tensor(1.3514, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016165142878890038
loss_c:0.8687616586685181
tensor(1.3038, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027124417945742607
loss_c:1.0352814197540283
tensor(1.4415, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01648370921611786
loss_c:0.8804895281791687
tensor(1.3115, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04833447188138962
loss_c:0.9227887988090515
tensor(1.4726, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025777358561754227
loss_c:0.8763481974601746
tensor(1.3495, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019540024921298027
loss_c:0.9579402804374695
tensor(1.3666, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021929075941443443
loss_c:1.066978931427002
tensor(1.4359, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01821662113070488
loss_c:0.8435138463973999
tensor(1.2990, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016884105280041695
loss_c:0.7827271223068237
tensor(1.2605, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013333397917449474
loss_c:0.7566978335380554
tensor(1.2310, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013855044730007648
loss_c:0.749796986579895
tensor(1.2295, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0186707004904747
loss_c:0.7621895670890808
tensor(1.2571, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03847361356019974
loss_c:0.9321500062942505
tensor(1.4350, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026009848341345787
loss_c:0.9579707384109497
tensor(1.3947, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018545815721154213
loss_c:0.9583213329315186
tensor(1.3623, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0405617393553257
loss_c:0.9110808372497559
tensor(1.4329, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0411071702837944
loss_c:0.853514552116394
tensor(1.4042, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01782084070146084
loss_c:0.8259801864624023
tensor(1.2877, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017063256353139877
loss_c:0.8104779124259949
tensor(1.2761, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026159444823861122
loss_c:0.8407279849052429
tensor(1.3320, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024630507454276085
loss_c:1.0252184867858887
tensor(1.4250, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024699850007891655
loss_c:0.8975014686584473
tensor(1.3563, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02276638150215149
loss_c:0.8954954147338867
tensor(1.3468, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03660546615719795
loss_c:0.7801057696342468
tensor(1.3446, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01838461309671402
loss_c:0.885472297668457
tensor(1.3224, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04871205613017082
loss_c:0.9528354406356812
tensor(1.4905, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01487286388874054
loss_c:0.9344157576560974
tensor(1.3337, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01628165692090988
loss_c:1.0470647811889648
tensor(1.4007, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03024313412606716
loss_c:0.8693956136703491
tensor(1.3651, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01675153709948063
loss_c:0.8816208839416504
tensor(1.3133, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01665809005498886
loss_c:0.7814764976501465
tensor(1.2589, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02608496882021427
loss_c:1.0318262577056885
tensor(1.4348, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01816205494105816
loss_c:0.8437950611114502
tensor(1.2990, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0763237476348877
loss_c:0.9099146723747253
tensor(1.5860, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01409778743982315
loss_c:0.7254282236099243
tensor(1.2177, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017594901844859123
loss_c:0.8620477914810181
tensor(1.3066, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01788262650370598
loss_c:0.7622160911560059
tensor(1.2539, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07088382542133331
loss_c:0.9186913371086121
tensor(1.5661, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021831445395946503
loss_c:0.8592097163200378
tensor(1.3233, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026300612837076187
loss_c:0.8131949305534363
tensor(1.3175, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030364125967025757
loss_c:0.7795907855033875
tensor(1.3166, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01906154304742813
loss_c:0.8193031549453735
tensor(1.2899, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04509394243359566
loss_c:1.1120637655258179
tensor(1.5591, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017158854752779007
loss_c:0.7880821228027344
tensor(1.2650, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.048480190336704254
loss_c:0.8494771718978882
tensor(1.4307, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02517511323094368
loss_c:0.9360413551330566
tensor(1.3792, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01481635868549347
loss_c:0.795729398727417
tensor(1.2595, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031382735818624496
loss_c:0.8669108748435974
tensor(1.3677, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024664420634508133
loss_c:0.9614421725273132
tensor(1.3909, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020388368517160416
loss_c:0.7424486875534058
tensor(1.2540, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01553193386644125
loss_c:0.7861143946647644
tensor(1.2575, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014295344240963459
loss_c:0.8046166300773621
tensor(1.2624, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020050210878252983
loss_c:0.8513428568840027
tensor(1.3118, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020425811409950256
loss_c:0.9495658874511719
tensor(1.3669, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0366242453455925
loss_c:0.8860213160514832
tensor(1.3999, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030087651684880257
loss_c:0.9333438873291016
tensor(1.3984, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017201855778694153
loss_c:0.8416595458984375
tensor(1.2946, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013739194720983505
loss_c:0.7786256074905396
tensor(1.2458, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014851157553493977
loss_c:0.8988475799560547
tensor(1.3160, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02063782699406147
loss_c:0.9799442291259766
tensor(1.3845, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024022037163376808
loss_c:0.8233898878097534
tensor(1.3131, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024295734241604805
loss_c:1.0630803108215332
tensor(1.4452, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09865694493055344
loss_c:0.8944095373153687
tensor(1.6647, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03492584824562073
loss_c:0.8463155031204224
tensor(1.3712, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03895333781838417
loss_c:0.9855100512504578
tensor(1.4639, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02615193836390972
loss_c:0.7470093965530396
tensor(1.2803, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017757972702383995
loss_c:0.8248910307884216
tensor(1.2880, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019068600609898567
loss_c:0.8246500492095947
tensor(1.2933, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019994400441646576
loss_c:0.8996888995170593
tensor(1.3382, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03668593615293503
loss_c:0.8312896490097046
tensor(1.3698, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023235516622662544
loss_c:0.9986740946769714
tensor(1.4057, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018867921084165573
loss_c:0.8961183428764343
tensor(1.3317, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021408436819911003
loss_c:0.8104812502861023
tensor(1.2954, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032642167061567307
loss_c:0.8297746181488037
tensor(1.3522, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019771896302700043
loss_c:0.8273510336875916
tensor(1.2979, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020352335646748543
loss_c:0.8720848560333252
tensor(1.3247, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03184201195836067
loss_c:0.7804450988769531
tensor(1.3219, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02415442280471325
loss_c:0.8628239035606384
tensor(1.3353, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022958530113101006
loss_c:0.9065912961959839
tensor(1.3543, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020366331562399864
loss_c:0.8704499006271362
tensor(1.3239, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017277151346206665
loss_c:0.8071855902671814
tensor(1.2766, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01846502535045147
loss_c:0.9715344309806824
tensor(1.3714, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014768113382160664
loss_c:0.8688470721244812
tensor(1.2999, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041922677308321
loss_c:0.8541706800460815
tensor(1.4038, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015368330292403698
loss_c:0.8203552961349487
tensor(1.2757, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0390399731695652
loss_c:0.9079791307449341
tensor(1.4214, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03808055818080902
loss_c:0.828347384929657
tensor(1.3739, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01568792574107647
loss_c:0.8094980120658875
tensor(1.2711, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01955961436033249
loss_c:1.0475375652313232
tensor(1.4175, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02512548118829727
loss_c:0.9658025503158569
tensor(1.3957, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021967701613903046
loss_c:1.36602783203125
tensor(1.6018, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019122159108519554
loss_c:0.9781176447868347
tensor(1.3775, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018602875992655754
loss_c:0.9512848854064941
tensor(1.3606, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0319162979722023
loss_c:0.8299764394760132
tensor(1.3495, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0168873630464077
loss_c:0.7707254886627197
tensor(1.2549, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03204146400094032
loss_c:0.8105591535568237
tensor(1.3395, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031831953674554825
loss_c:0.8735724687576294
tensor(1.3730, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02542538195848465
loss_c:0.8662829399108887
tensor(1.3424, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022188395261764526
loss_c:0.9605617523193359
tensor(1.3802, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019649093970656395
loss_c:0.9155058860778809
tensor(1.3451, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02001221477985382
loss_c:0.7919965982437134
tensor(1.2796, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014892718754708767
loss_c:0.8061007261276245
tensor(1.2659, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01903601363301277
loss_c:0.7869313955307007
tensor(1.2727, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020840859040617943
loss_c:0.9735600352287292
tensor(1.3814, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026870135217905045
loss_c:0.9074478149414062
tensor(1.3708, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02127576619386673
loss_c:1.0095038414001465
tensor(1.4027, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014709517359733582
loss_c:0.9827194213867188
tensor(1.3606, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021292701363563538
loss_c:0.9529516100883484
tensor(1.3720, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02068430371582508
loss_c:0.8839873671531677
tensor(1.3321, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029325364157557487
loss_c:0.9735531806945801
tensor(1.4169, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.2114417552947998
loss_c:1.1686840057373047
tensor(2.2913, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01991518773138523
loss_c:1.0111676454544067
tensor(1.3976, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03375033289194107
loss_c:0.9614755511283875
tensor(1.4285, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01982070505619049
loss_c:0.7036382555961609
tensor(1.2317, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026741482317447662
loss_c:0.7938091158866882
tensor(1.3090, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02744094654917717
loss_c:0.8579857349395752
tensor(1.3464, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0238721314817667
loss_c:0.8645057082176208
tensor(1.3353, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03362651914358139
loss_c:0.746092677116394
tensor(1.3116, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019912635907530785
loss_c:0.9054640531539917
tensor(1.3412, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01911352202296257
loss_c:0.783247172832489
tensor(1.2724, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01548129040747881
loss_c:0.8324770331382751
tensor(1.2842, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021155385300517082
loss_c:0.8188471794128418
tensor(1.2999, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0316048227250576
loss_c:1.0564748048782349
tensor(1.4699, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02210254780948162
loss_c:1.0214272737503052
tensor(1.4127, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026296894997358322
loss_c:1.1901006698608398
tensor(1.5203, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024240000173449516
loss_c:0.8848533630371094
tensor(1.3479, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018663065508008003
loss_c:0.7738029360771179
tensor(1.2658, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030280826613307
loss_c:0.850800633430481
tensor(1.3540, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026031935587525368
loss_c:0.928454577922821
tensor(1.3785, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01904773898422718
loss_c:0.7800609469413757
tensor(1.2708, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018822655081748962
loss_c:0.9658135175704956
tensor(1.3695, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021610520780086517
loss_c:0.868657112121582
tensor(1.3286, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014919469133019447
loss_c:0.9410245418548584
tensor(1.3405, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017676031216979027
loss_c:0.962722897529602
tensor(1.3632, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021013163030147552
loss_c:0.9207528829574585
tensor(1.3541, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02369317226111889
loss_c:1.0399113893508911
tensor(1.4288, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020650289952754974
loss_c:0.8559123873710632
tensor(1.3178, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031751688569784164
loss_c:1.1814961433410645
tensor(1.5372, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03419354930520058
loss_c:0.9065718054771423
tensor(1.3999, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04296846315264702
loss_c:0.9788908362388611
tensor(1.4743, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02353321760892868
loss_c:0.8070809245109558
tensor(1.3034, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015777718275785446
loss_c:0.9413653612136841
tensor(1.3436, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.062466587871313095
loss_c:0.8906248807907104
tensor(1.5066, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05755942687392235
loss_c:0.9601743221282959
tensor(1.5236, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023330217227339745
loss_c:0.9010062217712402
tensor(1.3528, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016013525426387787
loss_c:1.0462350845336914
tensor(1.4005, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018025076016783714
loss_c:0.8183557391166687
tensor(1.2874, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026366285979747772
loss_c:1.2249906063079834
tensor(1.5374, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017333338037133217
loss_c:0.8041171431541443
tensor(1.2771, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019336596131324768
loss_c:0.8574585914611816
tensor(1.3136, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025327637791633606
loss_c:0.78760826587677
tensor(1.3008, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017197955399751663
loss_c:0.8055278658866882
tensor(1.2774, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01908005215227604
loss_c:0.990654468536377
tensor(1.3832, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02171938307583332
loss_c:0.9466020464897156
tensor(1.3705, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020718572661280632
loss_c:0.8469074964523315
tensor(1.3136, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03976359963417053
loss_c:0.9468746185302734
tensor(1.4439, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028793437406420708
loss_c:0.8335282802581787
tensor(1.3393, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022079696878790855
loss_c:0.9164265394210815
tensor(1.3559, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017655719071626663
loss_c:0.9295431971549988
tensor(1.3448, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01852092519402504
loss_c:0.8886446952819824
tensor(1.3266, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017577942460775375
loss_c:0.8861227035522461
tensor(1.3214, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02386397309601307
loss_c:0.8808519244194031
tensor(1.3442, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01729675754904747
loss_c:0.8601526021957397
tensor(1.3064, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014497078955173492
loss_c:0.713880717754364
tensor(1.2172, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018345898017287254
loss_c:0.9379216432571411
tensor(1.3518, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04983288794755936
loss_c:0.9154304265975952
tensor(1.4693, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014923636801540852
loss_c:0.8654950857162476
tensor(1.2992, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028914114460349083
loss_c:0.9299435615539551
tensor(1.3910, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032971497625112534
loss_c:1.0047073364257812
tensor(1.4475, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02035626210272312
loss_c:0.7916795015335083
tensor(1.2821, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017027201130986214
loss_c:0.8115455508232117
tensor(1.2789, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06027882173657417
loss_c:0.8396903276443481
tensor(1.4727, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02117009274661541
loss_c:0.8720895648002625
tensor(1.3282, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019129445776343346
loss_c:0.7396674156188965
tensor(1.2491, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03624221682548523
loss_c:0.9016634821891785
tensor(1.4063, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021382763981819153
loss_c:0.9649479389190674
tensor(1.3787, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019423792138695717
loss_c:0.8079557418823242
tensor(1.2866, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03425568342208862
loss_c:0.9730348587036133
tensor(1.4363, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021169790998101234
loss_c:0.8418396711349487
tensor(1.3119, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01762530952692032
loss_c:0.8821743726730347
tensor(1.3189, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027595603838562965
loss_c:0.8823925852775574
tensor(1.3602, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017554234713315964
loss_c:0.8287156820297241
tensor(1.2899, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023370925337076187
loss_c:0.9901136159896851
tensor(1.4006, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01496486272662878
loss_c:0.8552407622337341
tensor(1.2933, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03257891535758972
loss_c:0.809123694896698
tensor(1.3415, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017330504953861237
loss_c:0.9166110754013062
tensor(1.3360, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05233079567551613
loss_c:0.9626142382621765
tensor(1.5061, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019688187167048454
loss_c:0.8970018625259399
tensor(1.3352, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03755413368344307
loss_c:0.8546409606933594
tensor(1.3866, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02254091203212738
loss_c:0.804237961769104
tensor(1.2971, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016910633072257042
loss_c:0.9014319181442261
tensor(1.3261, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1521996706724167
loss_c:1.0466411113739014
tensor(1.9659, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01705949194729328
loss_c:0.9430269002914429
tensor(1.3493, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01853194832801819
loss_c:1.1151642799377441
tensor(1.4484, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019544756039977074
loss_c:0.8969577550888062
tensor(1.3350, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014920693822205067
loss_c:0.8440861105918884
tensor(1.2876, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018237851560115814
loss_c:0.9271740913391113
tensor(1.3460, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01881582848727703
loss_c:0.8365287780761719
tensor(1.2996, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023646419867873192
loss_c:0.9195681810379028
tensor(1.3640, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019166024401783943
loss_c:0.8254507780075073
tensor(1.2952, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038935739547014236
loss_c:1.0073820352554321
tensor(1.4735, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01836608536541462
loss_c:0.964439332485199
tensor(1.3667, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02438546158373356
loss_c:1.0045726299285889
tensor(1.4127, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02419055439531803
loss_c:0.8579561114311218
tensor(1.3332, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0284140482544899
loss_c:0.9169146418571472
tensor(1.3820, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021050896495580673
loss_c:0.7841846942901611
tensor(1.2808, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02218823879957199
loss_c:0.8310131430625916
tensor(1.3106, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030758334323763847
loss_c:0.8923758268356323
tensor(1.3783, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018292417749762535
loss_c:0.9063665270805359
tensor(1.3352, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028396807610988617
loss_c:1.1260814666748047
tensor(1.4941, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01957518607378006
loss_c:0.7831401824951172
tensor(1.2743, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03176383674144745
loss_c:0.9519025683403015
tensor(1.4143, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017503514885902405
loss_c:0.8330017924308777
tensor(1.2926, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021278701722621918
loss_c:0.8360995650291443
tensor(1.3096, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032390791922807693
loss_c:0.9457793235778809
tensor(1.4136, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017665885388851166
loss_c:0.8452438116073608
tensor(1.2998, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015610146336257458
loss_c:0.9613139033317566
tensor(1.3536, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017498401924967766
loss_c:0.8810300827026367
tensor(1.3182, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024165622889995575
loss_c:0.9118466377258301
tensor(1.3619, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015414690598845482
loss_c:0.8221198916435242
tensor(1.2780, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023885631933808327
loss_c:0.9609540700912476
tensor(1.3871, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017813201993703842
loss_c:0.7624168395996094
tensor(1.2557, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01739543303847313
loss_c:0.8109520673751831
tensor(1.2799, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04421594366431236
loss_c:0.9861196875572205
tensor(1.4843, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023636791855096817
loss_c:0.8259776830673218
tensor(1.3136, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017405178397893906
loss_c:0.8747593760490417
tensor(1.3140, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05411428585648537
loss_c:0.9881498217582703
tensor(1.5267, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02125639095902443
loss_c:0.8475689888000488
tensor(1.3153, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021793896332383156
loss_c:0.9014030694961548
tensor(1.3464, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017090240493416786
loss_c:0.833980917930603
tensor(1.2907, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028286147862672806
loss_c:1.0657031536102295
tensor(1.4616, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02711419016122818
loss_c:0.9183251857757568
tensor(1.3775, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028025412932038307
loss_c:0.823464572429657
tensor(1.3303, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03126939386129379
loss_c:0.7605645060539246
tensor(1.3100, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018280912190675735
loss_c:0.911061704158783
tensor(1.3370, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0214791651815176
loss_c:0.9566473960876465
tensor(1.3747, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015285523608326912
loss_c:0.8169398307800293
tensor(1.2739, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023183101788163185
loss_c:0.9309482574462891
tensor(1.3680, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024966774508357048
loss_c:0.8403830528259277
tensor(1.3267, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022689983248710632
loss_c:1.0403916835784912
tensor(1.4248, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01574413850903511
loss_c:0.8213860392570496
tensor(1.2780, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02463868074119091
loss_c:0.8190603256225586
tensor(1.3138, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01944136992096901
loss_c:0.8174721598625183
tensor(1.2913, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046681538224220276
loss_c:0.9251277446746826
tensor(1.4631, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026478907093405724
loss_c:0.7784290313720703
tensor(1.2996, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024622537195682526
loss_c:0.7743744850158691
tensor(1.2896, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013436314649879932
loss_c:0.7771091461181641
tensor(1.2442, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020535830408334732
loss_c:0.8491916656494141
tensor(1.3128, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036198608577251434
loss_c:0.9762317538261414
tensor(1.4470, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01525229774415493
loss_c:0.8035645484924316
tensor(1.2659, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.049910012632608414
loss_c:0.9272271990776062
tensor(1.4781, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02036675438284874
loss_c:0.9915053248405457
tensor(1.3890, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02580900862812996
loss_c:0.9768134951591492
tensor(1.4039, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033392615616321564
loss_c:0.8474329710006714
tensor(1.3656, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03439647704362869
loss_c:0.8628074526786804
tensor(1.3781, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027409955859184265
loss_c:1.0061284303665161
tensor(1.4265, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036859601736068726
loss_c:1.164982795715332
tensor(1.5521, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014694568701088428
loss_c:0.7345797419548035
tensor(1.2263, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020283062011003494
loss_c:0.8779276609420776
tensor(1.3273, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020571792498230934
loss_c:0.856562614440918
tensor(1.3169, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019048940390348434
loss_c:0.8268790245056152
tensor(1.2945, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022141803056001663
loss_c:0.8258872032165527
tensor(1.3069, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018590126186609268
loss_c:0.882842481136322
tensor(1.3229, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04142726585268974
loss_c:0.8423682451248169
tensor(1.3964, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025787947699427605
loss_c:1.076223373413086
tensor(1.4576, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026462720707058907
loss_c:0.8335568308830261
tensor(1.3291, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015438196249306202
loss_c:0.8513085246086121
tensor(1.2926, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020610757172107697
loss_c:0.9200749397277832
tensor(1.3514, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016352076083421707
loss_c:0.8031701445579529
tensor(1.2704, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015893835574388504
loss_c:0.7754982709884644
tensor(1.2534, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024313602596521378
loss_c:0.9182602167129517
tensor(1.3659, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022191854193806648
loss_c:1.019172191619873
tensor(1.4117, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022191083058714867
loss_c:1.0598869323730469
tensor(1.4337, device='cuda:0', grad_fn=<AddBackward0>)
total_train_loss:1.3620703220367432
loss_r:0.02523244358599186
loss_c:1.8620262145996094
loss_r:0.02495396137237549
loss_c:1.8016974925994873
loss_r:0.025137560442090034
loss_c:1.7753856182098389
loss_r:0.024828193709254265
loss_c:1.8156211376190186
loss_r:0.02383548952639103
loss_c:1.7478301525115967
loss_r:0.024221552535891533
loss_c:1.685494303703308
loss_r:0.02313978038728237
loss_c:1.8861138820648193
loss_r:0.023331329226493835
loss_c:1.8812302350997925
loss_r:0.02591809444129467
loss_c:1.9869351387023926
loss_r:0.023906199261546135
loss_c:1.942854642868042
loss_r:0.02087550237774849
loss_c:1.8120524883270264
loss_r:0.019811535254120827
loss_c:1.6799571514129639
loss_r:0.020918579772114754
loss_c:1.6813950538635254
loss_r:0.01713901199400425
loss_c:1.5718368291854858
loss_r:0.018985284492373466
loss_c:1.608568549156189
loss_r:0.022232649847865105
loss_c:1.6042687892913818
loss_r:0.018874088302254677
loss_c:1.6093335151672363
loss_r:0.020069053396582603
loss_c:1.6085313558578491
loss_r:0.021889403462409973
loss_c:1.6631401777267456
loss_r:0.018109958618879318
loss_c:1.518512487411499
loss_r:0.021220142021775246
loss_c:1.6285877227783203
loss_r:0.022528041154146194
loss_c:1.6445515155792236
loss_r:0.01980614848434925
loss_c:1.5852270126342773
loss_r:0.022757582366466522
loss_c:1.6458566188812256
loss_r:0.022958558052778244
loss_c:1.623928427696228
loss_r:0.017945541068911552
loss_c:1.4825105667114258
loss_r:0.02248837612569332
loss_c:1.67386794090271
loss_r:0.024170201271772385
loss_c:1.6644220352172852
loss_r:0.022756824269890785
loss_c:1.6319383382797241
loss_r:0.021929943934082985
loss_c:1.5859920978546143
loss_r:0.02341347001492977
loss_c:1.6943310499191284
loss_r:0.018740329891443253
loss_c:1.522193431854248
loss_r:0.02269946038722992
loss_c:1.7099506855010986
loss_r:0.024954399093985558
loss_c:1.738781213760376
loss_r:0.019808031618595123
loss_c:1.598242163658142
loss_r:0.02143491432070732
loss_c:1.5297975540161133
loss_r:0.025592342019081116
loss_c:1.7397937774658203
loss_r:0.019225185737013817
loss_c:1.6067638397216797
loss_r:0.021994464099407196
loss_c:1.7228425741195679
loss_r:0.023557163774967194
loss_c:1.6581138372421265
loss_r:0.020409541204571724
loss_c:1.664290189743042
loss_r:0.021874167025089264
loss_c:1.650486707687378
loss_r:0.0218861885368824
loss_c:1.7248811721801758
loss_r:0.016936032101511955
loss_c:1.6795105934143066
loss_r:0.02093486115336418
loss_c:1.7458703517913818
loss_r:0.021050749346613884
loss_c:1.6629894971847534
loss_r:0.01915689744055271
loss_c:1.6309490203857422
loss_r:0.020475780591368675
loss_c:1.6472091674804688
loss_r:0.019944550469517708
loss_c:1.718300223350525
loss_r:0.018508726730942726
loss_c:1.7573163509368896
loss_r:0.02187155932188034
loss_c:1.8143796920776367
loss_r:0.021252155303955078
loss_c:1.7266252040863037
loss_r:0.020547540858387947
loss_c:1.712401270866394
loss_r:0.02016286738216877
loss_c:1.6427191495895386
loss_r:0.019188156351447105
loss_c:1.7064435482025146
loss_r:0.019694538787007332
loss_c:1.8504972457885742
loss_r:0.02136545069515705
loss_c:1.8561605215072632
loss_r:0.02170080877840519
loss_c:1.6968190670013428
loss_r:0.019822778180241585
loss_c:1.732706069946289
loss_r:0.01965801604092121
loss_c:1.5721988677978516
loss_r:0.02145456150174141
loss_c:1.7306709289550781
loss_r:0.018914122134447098
loss_c:1.7397449016571045
loss_r:0.020603734999895096
loss_c:1.707721471786499
loss_r:0.019992295652627945
loss_c:1.5775868892669678
loss_r:0.01964571885764599
loss_c:1.6101570129394531
loss_r:0.021082386374473572
loss_c:1.507138729095459
loss_r:0.023375263437628746
loss_c:1.6999529600143433
loss_r:0.02040286920964718
loss_c:1.6911805868148804
loss_r:0.02263028174638748
loss_c:1.6917126178741455
loss_r:0.023082146421074867
loss_c:1.595736026763916
loss_r:0.021703505888581276
loss_c:1.634434461593628
loss_r:0.02062198333442211
loss_c:1.5350478887557983
loss_r:0.02220129407942295
loss_c:1.6799705028533936
loss_r:0.019934847950935364
loss_c:1.6977260112762451
loss_r:0.021258337423205376
loss_c:1.682509422302246
loss_r:0.023299843072891235
loss_c:1.5431044101715088
loss_r:0.02185957506299019
loss_c:1.6365011930465698
loss_r:0.021818673238158226
loss_c:1.4565906524658203
loss_r:0.023254306986927986
loss_c:1.621643304824829
loss_r:0.02147815003991127
loss_c:1.7244834899902344
loss_r:0.023623870685696602
loss_c:1.7791084051132202
loss_r:0.023317066952586174
loss_c:1.5950311422348022
loss_r:0.021529115736484528
loss_c:1.664257526397705
loss_r:0.021616792306303978
loss_c:1.552014708518982
loss_r:0.024129457771778107
loss_c:1.7576926946640015
loss_r:0.02158648520708084
loss_c:1.7533429861068726
loss_r:0.022822396829724312
loss_c:1.7765010595321655
loss_r:0.021282989531755447
loss_c:1.5722860097885132
loss_r:0.02399333193898201
loss_c:1.7437975406646729
loss_r:0.022409847006201744
loss_c:1.5888208150863647
loss_r:0.022672614082694054
loss_c:1.6726422309875488
loss_r:0.02116622030735016
loss_c:1.7477401494979858
loss_r:0.023351706564426422
loss_c:1.7355117797851562
loss_r:0.02145378291606903
loss_c:1.5326956510543823
loss_r:0.02284652553498745
loss_c:1.7198022603988647
loss_r:0.023086881265044212
loss_c:1.5003416538238525
loss_r:0.02308146096765995
loss_c:1.6602882146835327
loss_r:0.023931371048092842
loss_c:1.740482211112976
loss_r:0.025190573185682297
loss_c:1.747502088546753
loss_r:0.021264776587486267
loss_c:1.5338280200958252
loss_r:0.0245840884745121
loss_c:1.767224669456482
loss_r:0.02283632755279541
loss_c:1.4876842498779297
loss_r:0.02356039732694626
loss_c:1.546411395072937
loss_r:0.023680267855525017
loss_c:1.7362788915634155
loss_r:0.02531314268708229
loss_c:1.7292823791503906
loss_r:0.02033074200153351
loss_c:1.5283827781677246
loss_r:0.024073194712400436
loss_c:1.7250670194625854
loss_r:0.02469250001013279
loss_c:1.4938877820968628
loss_r:0.023413509130477905
loss_c:1.6181831359863281
loss_r:0.024022823199629784
loss_c:1.7737605571746826
loss_r:0.023496467620134354
loss_c:1.6428474187850952
loss_r:0.02014351263642311
loss_c:1.4404797554016113
loss_r:0.024425383657217026
loss_c:1.7114975452423096
loss_r:0.02525421977043152
loss_c:1.533975601196289
loss_r:0.02375597506761551
loss_c:1.586669683456421
loss_r:0.024703744798898697
loss_c:1.6836395263671875
loss_r:0.023416129872202873
loss_c:1.6300737857818604
loss_r:0.021163033321499825
loss_c:1.4787383079528809
loss_r:0.025024769827723503
loss_c:1.7502007484436035
loss_r:0.023868296295404434
loss_c:1.4556021690368652
loss_r:0.026001252233982086
loss_c:1.6452586650848389
loss_r:0.02335423231124878
loss_c:1.716207504272461
loss_r:0.02523672580718994
loss_c:1.7607473134994507
loss_r:0.02025524154305458
loss_c:1.5122618675231934
loss_r:0.02496548928320408
loss_c:1.7700021266937256
loss_r:0.02256283164024353
loss_c:1.4495772123336792
loss_r:0.02621348574757576
loss_c:1.6199753284454346
loss_r:0.023239554837346077
loss_c:1.5782064199447632
loss_r:0.02319248765707016
loss_c:1.6700382232666016
loss_r:0.01845531351864338
loss_c:1.4845314025878906
loss_r:0.025755735114216805
loss_c:1.817000150680542
loss_r:0.02196480892598629
loss_c:1.452018141746521
loss_r:0.027455098927021027
loss_c:1.6541545391082764
loss_r:0.02155037224292755
loss_c:1.5240962505340576
loss_r:0.02201271802186966
loss_c:1.6208609342575073
loss_r:0.01970716379582882
loss_c:1.4890589714050293
loss_r:0.024811098352074623
loss_c:1.782152533531189
loss_r:0.020776767283678055
loss_c:1.4273796081542969
loss_r:0.029521387070417404
loss_c:1.6752886772155762
loss_r:0.02219317853450775
loss_c:1.5510683059692383
loss_r:0.025602346286177635
loss_c:1.7087987661361694
loss_r:0.021504824981093407
loss_c:1.5263551473617554
loss_r:0.028690220788121223
loss_c:1.8244069814682007
loss_r:0.024061501026153564
loss_c:1.447525978088379
loss_r:0.03266480937600136
loss_c:1.6790492534637451
loss_r:0.025475680828094482
loss_c:1.5760420560836792
loss_r:0.02669559419155121
loss_c:1.704609751701355
loss_r:0.022929508239030838
loss_c:1.5140551328659058
loss_r:0.02705220691859722
loss_c:1.740877628326416
loss_r:0.021565573289990425
loss_c:1.4152555465698242
loss_r:0.0328204408288002
loss_c:1.7204303741455078
loss_r:0.025450430810451508
loss_c:1.582855224609375
loss_r:0.026708651334047318
loss_c:1.7126405239105225
loss_r:0.021771734580397606
loss_c:1.5391591787338257
loss_r:0.0280716884881258
loss_c:1.8459457159042358
loss_r:0.022572951391339302
loss_c:1.5111265182495117
loss_r:0.033359747380018234
loss_c:1.8186697959899902
loss_r:0.0269553754478693
loss_c:1.645359754562378
loss_r:0.0293149221688509
loss_c:1.7728583812713623
loss_r:0.024173181504011154
loss_c:1.5865792036056519
loss_r:0.0287184976041317
loss_c:1.8163096904754639
loss_r:0.02376399002969265
loss_c:1.5513026714324951
loss_r:0.033280983567237854
loss_c:1.7493748664855957
loss_r:0.02543766051530838
loss_c:1.6269543170928955
loss_r:0.03302488476037979
loss_c:1.959894061088562
loss_r:0.024057572707533836
loss_c:1.6263906955718994
loss_r:0.03004494123160839
loss_c:1.8696025609970093
loss_r:0.023302562534809113
loss_c:1.5485072135925293
loss_r:0.030359189957380295
loss_c:1.6946353912353516
loss_r:0.025048986077308655
loss_c:1.5931015014648438
loss_r:0.03022630140185356
loss_c:1.8183883428573608
loss_r:0.02437829226255417
loss_c:1.618779182434082
loss_r:0.03213532269001007
loss_c:1.94052255153656
loss_r:0.02153671719133854
loss_c:1.4789233207702637
loss_r:0.028622541576623917
loss_c:1.6203521490097046
loss_r:0.025918181985616684
loss_c:1.610090970993042
loss_r:0.03160365670919418
loss_c:1.812356948852539
loss_r:0.02276018261909485
loss_c:1.56740140914917
loss_r:0.029859626665711403
loss_c:1.8852437734603882
loss_r:0.021720794960856438
loss_c:1.4547832012176514
loss_r:0.027642872184515
loss_c:1.615698218345642
loss_r:0.024417929351329803
loss_c:1.586611032485962
loss_r:0.029597729444503784
loss_c:1.8400278091430664
loss_r:0.022863399237394333
loss_c:1.5764262676239014
loss_r:0.03153042495250702
loss_c:1.911886215209961
loss_r:0.021239079535007477
loss_c:1.4715235233306885
loss_r:0.025602931156754494
loss_c:1.5981563329696655
loss_r:0.024276800453662872
loss_c:1.583238959312439
loss_r:0.030253512784838676
loss_c:1.8746522665023804
loss_r:0.023071862757205963
loss_c:1.5910227298736572
loss_r:0.029928456991910934
loss_c:1.8748172521591187
loss_r:0.022180063650012016
loss_c:1.4745292663574219
loss_r:0.026101956143975258
loss_c:1.6354860067367554
loss_r:0.024728601798415184
loss_c:1.6114840507507324
loss_r:0.030614657327532768
loss_c:1.8747739791870117
loss_r:0.022678690031170845
loss_c:1.6149327754974365
loss_r:0.031136570498347282
loss_c:1.9570497274398804
loss_r:0.022437840700149536
loss_c:1.5081537961959839
loss_r:0.024143289774656296
loss_c:1.61428964138031
loss_r:0.023333624005317688
loss_c:1.5949844121932983
loss_r:0.029346555471420288
loss_c:1.8077963590621948
loss_r:0.024306410923600197
loss_c:1.5981792211532593
loss_r:0.03183533623814583
loss_c:1.932775855064392
loss_r:0.023729171603918076
loss_c:1.501020908355713
loss_r:0.027386456727981567
loss_c:1.5917015075683594
loss_r:0.02524653449654579
loss_c:1.5501058101654053
loss_r:0.034056589007377625
loss_c:1.8734300136566162
loss_r:0.023078547790646553
loss_c:1.5643829107284546
loss_r:0.03178511559963226
loss_c:1.8883287906646729
loss_r:0.022676745429635048
loss_c:1.4512590169906616
loss_r:0.027833882719278336
loss_c:1.6358449459075928
loss_r:0.026057876646518707
loss_c:1.5861287117004395
loss_r:0.03212267532944679
loss_c:1.8393348455429077
loss_r:0.02189326100051403
loss_c:1.5620288848876953
loss_r:0.028297416865825653
loss_c:1.8490197658538818
loss_r:0.021345138549804688
loss_c:1.4870808124542236
loss_r:0.026656601577997208
loss_c:1.629980444908142
loss_r:0.02444232441484928
loss_c:1.5833839178085327
loss_r:0.03139519318938255
loss_c:1.8306297063827515
loss_r:0.019148066639900208
loss_c:1.4948344230651855
loss_r:0.026673734188079834
loss_c:1.8071098327636719
loss_r:0.022914227098226547
loss_c:1.506326675415039
loss_r:0.02665768377482891
loss_c:1.7224149703979492
loss_r:0.025686683133244514
loss_c:1.6745179891586304
loss_r:0.02847193367779255
loss_c:1.8617174625396729
loss_r:0.020056018605828285
loss_c:1.6066131591796875
loss_r:0.0259418748319149
loss_c:1.8489186763763428
loss_r:0.022901786491274834
loss_c:1.5644339323043823
loss_r:0.02697758749127388
loss_c:1.710474967956543
loss_r:0.02541109174489975
loss_c:1.6548242568969727
loss_r:0.028050538152456284
loss_c:1.795052409172058
loss_r:0.02063152752816677
loss_c:1.565824270248413
loss_r:0.02676425129175186
loss_c:1.8527069091796875
loss_r:0.022295666858553886
loss_c:1.5234205722808838
loss_r:0.028376786038279533
loss_c:1.7318696975708008
loss_r:0.024741509929299355
loss_c:1.625128149986267
loss_r:0.027883030474185944
loss_c:1.7876436710357666
loss_r:0.020363839343190193
loss_c:1.6037445068359375
loss_r:0.028544289991259575
loss_c:1.9337881803512573
loss_r:0.024599483236670494
loss_c:1.6054372787475586
loss_r:0.028326302766799927
loss_c:1.810304045677185
loss_r:0.025860581547021866
loss_c:1.6500318050384521
loss_r:0.02826847694814205
loss_c:1.8046026229858398
loss_r:0.0201624296605587
loss_c:1.610887885093689
loss_r:0.028531916439533234
loss_c:1.892325758934021
loss_r:0.023765625432133675
loss_c:1.512803316116333
loss_r:0.029779687523841858
loss_c:1.7789857387542725
loss_r:0.02653101272881031
loss_c:1.6049216985702515
loss_r:0.029556013643741608
loss_c:1.7826013565063477
loss_r:0.021350072696805
loss_c:1.6208118200302124
loss_r:0.02944282814860344
loss_c:1.8453452587127686
loss_r:0.024899912998080254
loss_c:1.4961774349212646
loss_r:0.03295449540019035
loss_c:1.7660367488861084
loss_r:0.02829989790916443
loss_c:1.5548083782196045
loss_r:0.026362817734479904
loss_c:1.6690672636032104
loss_r:0.022548377513885498
loss_c:1.589465856552124
loss_r:0.03083808347582817
loss_c:1.8509912490844727
loss_r:0.024235524237155914
loss_c:1.5058021545410156
loss_r:0.032633837312459946
loss_c:1.7150821685791016
loss_r:0.02792554348707199
loss_c:1.5686416625976562
loss_r:0.030094198882579803
loss_c:1.740750789642334
loss_r:0.024663211777806282
loss_c:1.620634913444519
loss_r:0.029732193797826767
loss_c:1.828826665878296
loss_r:0.024907967075705528
loss_c:1.5125117301940918
loss_r:0.0315508134663105
loss_c:1.7769044637680054
loss_r:0.028419053182005882
loss_c:1.6830265522003174
loss_r:0.032229889184236526
loss_c:1.7965312004089355
loss_r:0.02399388886988163
loss_c:1.5943244695663452
loss_r:0.02797272615134716
loss_c:1.7115721702575684
loss_r:0.02608518861234188
loss_c:1.4744290113449097
loss_r:0.03565027564764023
loss_c:1.8210434913635254
loss_r:0.027050936594605446
loss_c:1.6440298557281494
loss_r:0.031061269342899323
loss_c:1.7393062114715576
loss_r:0.024866634979844093
loss_c:1.6653895378112793
loss_r:0.03099432960152626
loss_c:1.8481221199035645
loss_r:0.02626788429915905
loss_c:1.5078448057174683
loss_r:0.036079321056604385
loss_c:1.811185598373413
loss_r:0.029455894604325294
loss_c:1.7069371938705444
loss_r:0.029892979189753532
loss_c:1.7595593929290771
loss_r:0.024425728246569633
loss_c:1.6059165000915527
loss_r:0.029746944084763527
loss_c:1.7931621074676514
loss_r:0.026859601959586143
loss_c:1.5472649335861206
loss_r:0.03546050190925598
loss_c:1.8224098682403564
loss_r:0.028661273419857025
loss_c:1.688097357749939
loss_r:0.031859882175922394
loss_c:1.7524875402450562
loss_r:0.02243099920451641
loss_c:1.531309962272644
loss_r:0.027005285024642944
loss_c:1.7121890783309937
loss_r:0.024631431326270103
loss_c:1.4657258987426758
loss_r:0.03289429843425751
loss_c:1.76939058303833
loss_r:0.02359393611550331
loss_c:1.6150463819503784
loss_r:0.02652156911790371
loss_c:1.7021081447601318
loss_r:0.023185882717370987
loss_c:1.5897849798202515
loss_r:0.026904786005616188
loss_c:1.7162675857543945
loss_r:0.02897053025662899
loss_c:1.6116728782653809
loss_r:0.03237392008304596
loss_c:1.8078651428222656
loss_r:0.026006344705820084
loss_c:1.6819820404052734
loss_r:0.03030737303197384
loss_c:1.7467336654663086
loss_r:0.02515477128326893
loss_c:1.6295403242111206
loss_r:0.028676485642790794
loss_c:1.7697395086288452
loss_r:0.02838834747672081
loss_c:1.5534119606018066
loss_r:0.03474286198616028
loss_c:1.81417977809906
loss_r:0.026933325454592705
loss_c:1.63395094871521
loss_r:0.031036486849188805
loss_c:1.7650423049926758
loss_r:0.023317959159612656
loss_c:1.6204280853271484
loss_r:0.028418729081749916
loss_c:1.7505922317504883
loss_r:0.026563238352537155
loss_c:1.4904329776763916
loss_r:0.03291676566004753
loss_c:1.7471269369125366
loss_r:0.027982424944639206
loss_c:1.680917739868164
loss_r:0.03189444914460182
loss_c:1.7636876106262207
loss_r:0.022730249911546707
loss_c:1.6136324405670166
loss_r:0.02751927822828293
loss_c:1.7313992977142334
loss_r:0.027496779337525368
loss_c:1.5449929237365723
loss_r:0.0306689590215683
loss_c:1.7287921905517578
loss_r:0.025452855974435806
loss_c:1.6173372268676758
loss_r:0.031193820759654045
loss_c:1.7583932876586914
loss_r:0.02370850183069706
loss_c:1.6255720853805542
loss_r:0.027520915493369102
loss_c:1.7371201515197754
loss_r:0.025870049372315407
loss_c:1.5223233699798584
loss_r:0.03130478784441948
loss_c:1.8143119812011719
loss_r:0.024061620235443115
loss_c:1.5720170736312866
loss_r:0.03026164509356022
loss_c:1.764169454574585
loss_r:0.022486034780740738
loss_c:1.605222463607788
loss_r:0.027823450043797493
loss_c:1.7851247787475586
loss_r:0.024792658165097237
loss_c:1.5204600095748901
loss_r:0.029191814363002777
loss_c:1.780470848083496
loss_r:0.027366679161787033
loss_c:1.6674225330352783
loss_r:0.026892049238085747
loss_c:1.773681402206421
loss_r:0.021401800215244293
loss_c:1.5836786031723022
loss_r:0.02531828172504902
loss_c:1.7038707733154297
loss_r:0.02268996275961399
loss_c:1.4774656295776367
loss_r:0.029205186292529106
loss_c:1.7951202392578125
loss_r:0.025551144033670425
loss_c:1.693536639213562
loss_r:0.025816764682531357
loss_c:1.7994499206542969
loss_r:0.021605215966701508
loss_c:1.6187455654144287
loss_r:0.027352912351489067
loss_c:1.7981562614440918
loss_r:0.02776641584932804
loss_c:1.723454236984253
loss_r:0.028201615437865257
loss_c:1.8048913478851318
loss_r:0.02848316915333271
loss_c:1.8261938095092773
loss_r:0.028143148869276047
loss_c:1.8757585287094116
loss_r:0.02356147952377796
loss_c:1.6684367656707764
loss_r:0.023630591109395027
loss_c:1.8116528987884521
loss_r:0.022501423954963684
loss_c:1.6994457244873047
loss_r:0.024303223937749863
loss_c:1.8382104635238647
loss_r:0.023072071373462677
loss_c:1.8326867818832397
loss_r:0.022455040365457535
loss_c:1.849668264389038
loss_r:0.018463432788848877
loss_c:1.6084609031677246
loss_r:0.021603789180517197
loss_c:1.8226817846298218
loss_r:0.02120947651565075
loss_c:1.6483054161071777
loss_r:0.02395091950893402
loss_c:1.8072490692138672
loss_r:0.02571124956011772
loss_c:1.9294346570968628
loss_r:0.024989688768982887
loss_c:1.9508508443832397
loss_r:0.01995524950325489
loss_c:1.7303050756454468
loss_r:0.021490495651960373
loss_c:1.8190772533416748
loss_r:0.021216096356511116
loss_c:1.6778216361999512
loss_r:0.024800455197691917
loss_c:1.7986387014389038
loss_r:0.02521759830415249
loss_c:1.8337862491607666
loss_r:0.025150103494524956
loss_c:1.9101037979125977
loss_r:0.01903720758855343
loss_c:1.666383147239685
loss_r:0.024791119620203972
loss_c:1.9071439504623413
loss_r:0.021137090399861336
loss_c:1.644350528717041
loss_r:0.02597963437438011
loss_c:1.7858842611312866
loss_r:0.02475007437169552
loss_c:1.8018602132797241
loss_r:0.02370232343673706
loss_c:1.828871250152588
loss_r:0.02019583247601986
loss_c:1.669481635093689
loss_r:0.025081336498260498
loss_c:1.9118964672088623
loss_r:0.019457858055830002
loss_c:1.7032451629638672
loss_r:0.023912740871310234
loss_c:1.8790221214294434
loss_r:0.023186124861240387
loss_c:1.8629745244979858
loss_r:0.02341209352016449
loss_c:1.978280782699585
loss_r:0.02168569155037403
loss_c:1.730881690979004
loss_r:0.024451952427625656
loss_c:1.9636955261230469
loss_r:0.01883549988269806
loss_c:1.6353156566619873
loss_r:0.022995147854089737
loss_c:1.8271455764770508
loss_r:0.023089058697223663
loss_c:1.8837755918502808
loss_r:0.023222871124744415
loss_c:1.9583704471588135
loss_r:0.018398679792881012
loss_c:1.6717380285263062
loss_r:0.023123176768422127
loss_c:1.925970435142517
loss_r:0.0200639795511961
loss_c:1.6682333946228027
loss_r:0.02215171605348587
loss_c:1.7605230808258057
loss_r:0.02291608415544033
loss_c:1.8676071166992188
loss_r:0.023773783817887306
loss_c:1.9379498958587646
loss_r:0.01962897554039955
loss_c:1.7143707275390625
loss_r:0.02421990968286991
loss_c:2.0422728061676025
loss_r:0.019572513177990913
loss_c:1.7258672714233398
loss_r:0.022301603108644485
loss_c:1.8580541610717773
loss_r:0.023681335151195526
loss_c:1.94318425655365
loss_r:0.022676516324281693
loss_c:1.9769973754882812
loss_r:0.017770254984498024
loss_c:1.6993573904037476
loss_r:0.023357247933745384
loss_c:1.997148036956787
loss_r:0.019394470378756523
loss_c:1.6970360279083252
loss_r:0.024819882586598396
loss_c:1.9058914184570312
loss_r:0.023900115862488747
loss_c:1.9042787551879883
loss_r:0.024386253207921982
loss_c:1.9073045253753662
loss_r:0.019480030983686447
loss_c:1.7247012853622437
loss_r:0.025197353214025497
loss_c:2.0044050216674805
loss_r:0.020003413781523705
loss_c:1.6496243476867676
loss_r:0.02446863241493702
loss_c:1.8048324584960938
loss_r:0.02318926714360714
loss_c:1.823447585105896
loss_r:0.02372845448553562
loss_c:1.9067109823226929
loss_r:0.018544679507613182
loss_c:1.643816351890564
loss_r:0.02264881320297718
loss_c:1.9453548192977905
loss_r:0.01811133697628975
loss_c:1.6475210189819336
loss_r:0.022983364760875702
loss_c:1.8507102727890015
loss_r:0.023692617192864418
loss_c:1.9762367010116577
loss_r:0.023410039022564888
loss_c:1.9945926666259766
loss_r:0.019380085170269012
loss_c:1.7893584966659546
loss_r:0.02390732802450657
loss_c:2.0204310417175293
loss_r:0.02124437689781189
loss_c:1.7834581136703491
loss_r:0.027412816882133484
loss_c:1.96776282787323
loss_r:0.024235475808382034
loss_c:1.9413893222808838
loss_r:0.024388713762164116
loss_c:1.9270894527435303
loss_r:0.020813869312405586
loss_c:1.7996809482574463
loss_r:0.021273206919431686
loss_c:1.9286842346191406
loss_r:0.01979582943022251
loss_c:1.766161322593689
loss_r:0.02286052703857422
loss_c:1.8940143585205078
loss_r:0.022196585312485695
loss_c:1.9530143737792969
loss_r:0.02136871963739395
loss_c:1.9312400817871094
loss_r:0.018334200605750084
loss_c:1.793531894683838
loss_r:0.021394092589616776
loss_c:1.934195876121521
loss_r:0.019359616562724113
loss_c:1.7029861211776733
loss_r:0.022997859865427017
loss_c:1.850460410118103
loss_r:0.023756302893161774
loss_c:2.013939380645752
loss_r:0.021923204883933067
loss_c:1.9859685897827148
loss_r:0.018421409651637077
loss_c:1.7811412811279297
loss_r:0.021974122151732445
loss_c:1.960251808166504
loss_r:0.0214175283908844
loss_c:1.7734148502349854
loss_r:0.024439094588160515
loss_c:1.8579156398773193
loss_r:0.023518212139606476
loss_c:1.9245327711105347
loss_r:0.022200485691428185
loss_c:1.8992975950241089
loss_r:0.021194705739617348
loss_c:1.8119758367538452
loss_r:0.024671509861946106
loss_c:1.955918312072754
loss_r:0.023575080558657646
loss_c:1.7224982976913452
loss_r:0.024845315143465996
loss_c:1.778170108795166
loss_r:0.022966573014855385
loss_c:1.863389015197754
loss_r:0.01933552324771881
loss_c:1.7394664287567139
loss_r:0.019206473603844643
loss_c:1.6940538883209229
loss_r:0.022129565477371216
loss_c:1.865646243095398
loss_r:0.02175954170525074
loss_c:1.6129648685455322
loss_r:0.02403065375983715
loss_c:1.801802158355713
loss_r:0.022291701287031174
loss_c:1.879720687866211
loss_r:0.019645821303129196
loss_c:1.7223403453826904
loss_r:0.019551707431674004
loss_c:1.7060418128967285
loss_r:0.020385833457112312
loss_c:1.7944726943969727
loss_r:0.02072863094508648
loss_c:1.580160140991211
loss_r:0.020066017284989357
loss_c:1.7403104305267334
loss_r:0.019069122150540352
loss_c:1.7543944120407104
loss_r:0.01951702870428562
loss_c:1.74946928024292
loss_r:0.018451353535056114
loss_c:1.6336660385131836
loss_r:0.021054424345493317
loss_c:1.813199758529663
loss_r:0.023152604699134827
loss_c:1.6273059844970703
loss_r:0.02108500339090824
loss_c:1.7168080806732178
loss_r:0.01990051381289959
loss_c:1.7622020244598389
loss_r:0.016862740740180016
loss_c:1.6617546081542969
loss_r:0.02005080319941044
loss_c:1.6037397384643555
loss_r:0.02011820487678051
loss_c:1.717759609222412
loss_r:0.020786989480257034
loss_c:1.5908234119415283
loss_r:0.02056308090686798
loss_c:1.6611303091049194
loss_r:0.02386121265590191
loss_c:1.8980411291122437
loss_r:0.02314518578350544
loss_c:1.8101871013641357
loss_r:0.02055170387029648
loss_c:1.535743236541748
loss_r:0.021962245926260948
loss_c:1.789773941040039
loss_r:0.020563768222928047
loss_c:1.5485833883285522
loss_r:0.02122701145708561
loss_c:1.6929893493652344
loss_r:0.023626891896128654
loss_c:1.8362897634506226
loss_r:0.023062361404299736
loss_c:1.6990125179290771
loss_r:0.022741615772247314
loss_c:1.6371490955352783
loss_r:0.021478304639458656
loss_c:1.7639069557189941
loss_r:0.020032787695527077
loss_c:1.5014011859893799
loss_r:0.018761686980724335
loss_c:1.6041940450668335
loss_r:0.021618478000164032
loss_c:1.7542375326156616
loss_r:0.019918030127882957
loss_c:1.6407866477966309
loss_r:0.021283352747559547
loss_c:1.5067662000656128
loss_r:0.022912293672561646
loss_c:1.7409484386444092
loss_r:0.020684806630015373
loss_c:1.5378583669662476
loss_r:0.018786748871207237
loss_c:1.6008410453796387
loss_r:0.02042754366993904
loss_c:1.7672852277755737
loss_r:0.02078123763203621
loss_c:1.7207063436508179
loss_r:0.018899034708738327
loss_c:1.5110634565353394
loss_r:0.02215590700507164
loss_c:1.8228764533996582
loss_r:0.020352110266685486
loss_c:1.5888450145721436
loss_r:0.01660732552409172
loss_c:1.600733995437622
loss_r:0.02083064615726471
loss_c:1.8315662145614624
loss_r:0.024291347712278366
loss_c:1.8150959014892578
loss_r:0.020352832973003387
loss_c:1.5320285558700562
loss_r:0.02330397628247738
loss_c:1.7690871953964233
loss_r:0.023216715082526207
loss_c:1.5355148315429688
loss_r:0.020172342658042908
loss_c:1.4893076419830322
loss_r:0.022983066737651825
loss_c:1.6695411205291748
loss_r:0.02190406247973442
loss_c:1.6030242443084717
loss_r:0.02219868265092373
loss_c:1.4479856491088867
loss_r:0.02371048368513584
loss_c:1.659533977508545
loss_r:0.020939618349075317
loss_c:1.5401701927185059
loss_r:0.022297648712992668
loss_c:1.5377916097640991
loss_r:0.027178240939974785
loss_c:1.825486421585083
loss_r:0.023328440263867378
loss_c:1.6140321493148804
loss_r:0.0235404372215271
loss_c:1.4516849517822266
loss_r:0.02450399659574032
loss_c:1.6717394590377808
loss_r:0.024638017639517784
loss_c:1.4729174375534058
loss_r:0.023137206211686134
loss_c:1.5169360637664795
loss_r:0.024690894410014153
loss_c:1.737781047821045
loss_r:0.024180419743061066
loss_c:1.6021783351898193
loss_r:0.023979676887392998
loss_c:1.4803433418273926
loss_r:0.02483631670475006
loss_c:1.7860679626464844
loss_r:0.024705296382308006
loss_c:1.5490682125091553
loss_r:0.020743414759635925
loss_c:1.5155134201049805
loss_r:0.025001058354973793
loss_c:1.8620394468307495
loss_r:0.02426215261220932
loss_c:1.624596118927002
loss_r:0.024310816079378128
loss_c:1.4802583456039429
loss_r:0.022997258231043816
loss_c:1.6829464435577393
loss_r:0.02469148300588131
loss_c:1.5269184112548828
loss_r:0.020857498049736023
loss_c:1.4901788234710693
loss_r:0.0203503780066967
loss_c:1.626253366470337
loss_r:0.023633316159248352
loss_c:1.5201196670532227
loss_r:0.020631425082683563
loss_c:1.4633872509002686
loss_r:0.02230967953801155
loss_c:1.669564962387085
loss_r:0.023688046261668205
loss_c:1.5162910223007202
loss_r:0.01979798637330532
loss_c:1.489891529083252
loss_r:0.02086673118174076
loss_c:1.7367404699325562
loss_r:0.023520948365330696
loss_c:1.6183898448944092
loss_r:0.0236477330327034
loss_c:1.5003252029418945
loss_r:0.025591803714632988
loss_c:1.7975953817367554
loss_r:0.025319941341876984
loss_c:1.5407586097717285
loss_r:0.02104111947119236
loss_c:1.5125412940979004
loss_r:0.022869015112519264
loss_c:1.7139060497283936
loss_r:0.019994216039776802
loss_c:1.5161398649215698
loss_r:0.023592228069901466
loss_c:1.4698643684387207
loss_r:0.026296669617295265
loss_c:1.757071852684021
loss_r:0.025947635993361473
loss_c:1.5695109367370605
loss_r:0.020761709660291672
loss_c:1.5311663150787354
loss_r:0.021508904173970222
loss_c:1.7433733940124512
loss_r:0.021671347320079803
loss_c:1.5669124126434326
loss_r:0.02507617138326168
loss_c:1.5615630149841309
loss_r:0.023900503292679787
loss_c:1.76401686668396
loss_r:0.025590866804122925
loss_c:1.6471755504608154
loss_r:0.021754054352641106
loss_c:1.689762830734253
loss_r:0.023947451263666153
loss_c:1.7776345014572144
loss_r:0.023529743775725365
loss_c:1.665942668914795
loss_r:0.02227320335805416
loss_c:1.5414832830429077
loss_r:0.023228580132126808
loss_c:1.7224633693695068
loss_r:0.023119674995541573
loss_c:1.5429744720458984
loss_r:0.02350831776857376
loss_c:1.6564350128173828
loss_r:0.021635599434375763
loss_c:1.7192481756210327
loss_r:0.021320628002285957
loss_c:1.6061437129974365
loss_r:0.02061643823981285
loss_c:1.5004651546478271
loss_r:0.02083907462656498
loss_c:1.663064956665039
loss_r:0.019139710813760757
loss_c:1.5173559188842773
loss_r:0.019816305488348007
loss_c:1.6464855670928955
loss_r:0.019207894802093506
loss_c:1.7210798263549805
loss_r:0.017238469794392586
loss_c:1.5787160396575928
loss_r:0.021564660593867302
loss_c:1.6057164669036865
loss_r:0.01792309433221817
loss_c:1.6199196577072144
loss_r:0.019200945273041725
loss_c:1.5234907865524292
loss_r:0.018405241891741753
loss_c:1.635986089706421
loss_r:0.018266446888446808
loss_c:1.6866077184677124
loss_r:0.016989052295684814
loss_c:1.6147031784057617
loss_r:0.01898990571498871
loss_c:1.5917012691497803
loss_r:0.01877274364233017
loss_c:1.6889934539794922
loss_r:0.0194358229637146
loss_c:1.5722373723983765
loss_r:0.017867228016257286
loss_c:1.5781183242797852
loss_r:0.019991502165794373
loss_c:1.760237455368042
loss_r:0.01881597377359867
loss_c:1.6524771451950073
loss_r:0.02345426380634308
loss_c:1.6419628858566284
loss_r:0.021125368773937225
loss_c:1.7340657711029053
loss_r:0.021169442683458328
loss_c:1.6173896789550781
loss_r:0.021911736577749252
loss_c:1.6790978908538818
loss_r:0.02488323114812374
loss_c:1.8042901754379272
loss_r:0.020164960995316505
loss_c:1.7164020538330078
loss_r:0.02157697267830372
loss_c:1.6222984790802002
loss_r:0.020995933562517166
loss_c:1.6255605220794678
loss_r:0.020534930750727654
loss_c:1.5993800163269043
loss_r:0.018678689375519753
loss_c:1.6049463748931885
loss_r:0.020209819078445435
loss_c:1.6842635869979858
loss_r:0.01688876934349537
loss_c:1.6742463111877441
loss_r:0.018528271466493607
loss_c:1.496464729309082
loss_r:0.020287958905100822
loss_c:1.6948354244232178
loss_r:0.018419552594423294
loss_c:1.618913173675537
loss_r:0.01790977269411087
loss_c:1.6154468059539795
loss_r:0.018691033124923706
loss_c:1.7919666767120361
loss_r:0.017594313248991966
loss_c:1.6577657461166382
loss_r:0.01835840940475464
loss_c:1.533142328262329
loss_r:0.019767437130212784
loss_c:1.6881434917449951
loss_r:0.02006526105105877
loss_c:1.6829813718795776
loss_r:0.01527565997093916
loss_c:1.579617977142334
loss_r:0.018101826310157776
loss_c:1.7712600231170654
loss_r:0.0139227993786335
loss_c:1.6106021404266357
loss_r:0.016353212296962738
loss_c:1.507006049156189
loss_r:0.017539795488119125
loss_c:1.6574138402938843
loss_r:0.01629006490111351
loss_c:1.6053155660629272
loss_r:0.015087810344994068
loss_c:1.5340807437896729
loss_r:0.017654672265052795
loss_c:1.7705596685409546
loss_r:0.014416994526982307
loss_c:1.5931966304779053
loss_r:0.01596696861088276
loss_c:1.4487403631210327
loss_r:0.018931668251752853
loss_c:1.6792501211166382
loss_r:0.016547374427318573
loss_c:1.5304630994796753
loss_r:0.016074568033218384
loss_c:1.5609126091003418
loss_r:0.0185471773147583
loss_c:1.7386484146118164
loss_r:0.015984386205673218
loss_c:1.7114337682724
loss_r:0.016044117510318756
loss_c:1.4246315956115723
loss_r:0.019324228167533875
loss_c:1.7070095539093018
loss_r:0.017883535474538803
loss_c:1.6700637340545654
loss_r:0.015352733433246613
loss_c:1.5545562505722046
loss_r:0.018437061458826065
loss_c:1.7332687377929688
loss_r:0.01610576920211315
loss_c:1.7277097702026367
loss_r:0.016426682472229004
loss_c:1.4755481481552124
loss_r:0.01881614327430725
loss_c:1.6649396419525146
loss_r:0.016295449808239937
loss_c:1.5737890005111694
loss_r:0.01460286695510149
loss_c:1.5324435234069824
loss_r:0.019157471135258675
loss_c:1.731541633605957
loss_r:0.014965728856623173
loss_c:1.6774581670761108
loss_r:0.016393309459090233
loss_c:1.4734996557235718
loss_r:0.020646141842007637
loss_c:1.6983064413070679
loss_r:0.019418491050601006
loss_c:1.6437098979949951
loss_r:0.01679420657455921
loss_c:1.530695915222168
loss_r:0.019810959696769714
loss_c:1.7832698822021484
loss_r:0.01684911549091339
loss_c:1.7342028617858887
loss_r:0.01657039299607277
loss_c:1.4990959167480469
loss_r:0.019517436623573303
loss_c:1.7345514297485352
loss_r:0.020053379237651825
loss_c:1.6867682933807373
loss_r:0.01648280955851078
loss_c:1.5935242176055908
loss_r:0.018549757078289986
loss_c:1.7145450115203857
loss_r:0.01693309284746647
loss_c:1.7018264532089233
loss_r:0.017040492966771126
loss_c:1.4913477897644043
loss_r:0.021581411361694336
loss_c:1.7506320476531982
loss_r:0.021346114575862885
loss_c:1.6790040731430054
loss_r:0.01727144978940487
loss_c:1.544922113418579
loss_r:0.02247551828622818
loss_c:1.8311560153961182
loss_r:0.017650216817855835
loss_c:1.6989068984985352
loss_r:0.020660338923335075
loss_c:1.552128791809082
loss_r:0.02404223568737507
loss_c:1.7383636236190796
loss_r:0.022273704409599304
loss_c:1.6535041332244873
loss_r:0.019274476915597916
loss_c:1.5626084804534912
loss_r:0.02262508124113083
loss_c:1.8076566457748413
loss_r:0.021881569176912308
loss_c:1.8032296895980835
loss_r:0.021059442311525345
loss_c:1.5338939428329468
loss_r:0.024018699303269386
loss_c:1.7091500759124756
loss_r:0.024403909221291542
loss_c:1.654699683189392
loss_r:0.02095942758023739
loss_c:1.498816967010498
loss_r:0.02278297021985054
loss_c:1.731560468673706
loss_r:0.022036153823137283
loss_c:1.7776811122894287
loss_r:0.022391783073544502
loss_c:1.5427567958831787
loss_r:0.02476470172405243
loss_c:1.7754091024398804
loss_r:0.022691858932375908
loss_c:1.5835760831832886
loss_r:0.020526155829429626
loss_c:1.5816205739974976
loss_r:0.0230446457862854
loss_c:1.79355788230896
loss_r:0.021261248737573624
loss_c:1.7424798011779785
loss_r:0.021350858733057976
loss_c:1.5870044231414795
loss_r:0.023346878588199615
loss_c:1.7452456951141357
loss_r:0.023065943270921707
loss_c:1.5895600318908691
loss_r:0.02270127832889557
loss_c:1.654812216758728
loss_r:0.02366749383509159
loss_c:1.7928688526153564
loss_r:0.02067309059202671
loss_c:1.6225175857543945
loss_r:0.02135051228106022
loss_c:1.5581296682357788
loss_r:0.025150295346975327
loss_c:1.7847493886947632
loss_r:0.02167978137731552
loss_c:1.5901902914047241
loss_r:0.02057100273668766
loss_c:1.5639737844467163
loss_r:0.025073900818824768
loss_c:1.8568737506866455
loss_r:0.01940573751926422
loss_c:1.7242958545684814
loss_r:0.022083410993218422
loss_c:1.5691951513290405
loss_r:0.02565341256558895
loss_c:1.756113886833191
loss_r:0.02189810387790203
loss_c:1.5929222106933594
loss_r:0.022338664159178734
loss_c:1.5952215194702148
loss_r:0.026077061891555786
loss_c:1.8674638271331787
loss_r:0.02127108909189701
loss_c:1.7479451894760132
loss_r:0.022179819643497467
loss_c:1.5827608108520508
loss_r:0.02550348825752735
loss_c:1.7563989162445068
loss_r:0.022909391671419144
loss_c:1.5842136144638062
loss_r:0.023232750594615936
loss_c:1.667853593826294
loss_r:0.026392247527837753
loss_c:1.8700660467147827
loss_r:0.020462246611714363
loss_c:1.7362020015716553
loss_r:0.020779892802238464
loss_c:1.577688217163086
loss_r:0.025647597387433052
loss_c:1.7675803899765015
loss_r:0.023120123893022537
loss_c:1.615187406539917
loss_r:0.02268257550895214
loss_c:1.6625959873199463
loss_r:0.025242416188120842
loss_c:1.8041638135910034
loss_r:0.018396390601992607
loss_c:1.5625264644622803
loss_r:0.02510361559689045
loss_c:1.6959435939788818
loss_r:0.027571875602006912
loss_c:1.7996761798858643
loss_r:0.026283185929059982
loss_c:1.6879972219467163
loss_r:0.025987306609749794
loss_c:1.744472861289978
loss_r:0.026546990498900414
loss_c:1.763387680053711
loss_r:0.025390228256583214
loss_c:1.7816293239593506
loss_r:0.025559497997164726
loss_c:1.7256397008895874
loss_r:0.028264762833714485
loss_c:1.8217971324920654
loss_r:0.027055956423282623
loss_c:1.6465623378753662
loss_r:0.027601396664977074
loss_c:1.7399086952209473
loss_r:0.025876041501760483
loss_c:1.8017661571502686
loss_r:0.022591769695281982
loss_c:1.7387700080871582
loss_r:0.024127289652824402
loss_c:1.7595715522766113
loss_r:0.027065927162766457
loss_c:1.8712190389633179
loss_r:0.02666882984340191
loss_c:1.7240581512451172
loss_r:0.02584715187549591
loss_c:1.7872956991195679
loss_r:0.024955224245786667
loss_c:1.8284695148468018
loss_r:0.022984454408288002
loss_c:1.7264175415039062
loss_r:0.02642034739255905
loss_c:1.8209929466247559
loss_r:0.027062691748142242
loss_c:1.9043148756027222
loss_r:0.02781013585627079
loss_c:1.755598783493042
loss_r:0.028860772028565407
loss_c:1.860502004623413
loss_r:0.029163772240281105
loss_c:1.913464903831482
loss_r:0.026891794055700302
loss_c:1.8173469305038452
loss_r:0.02703869342803955
loss_c:1.810691237449646
loss_r:0.029123546555638313
loss_c:1.8772811889648438
loss_r:0.028114596381783485
loss_c:1.7088887691497803
loss_r:0.028075551614165306
loss_c:1.8082855939865112
loss_r:0.026700226590037346
loss_c:1.7983392477035522
loss_r:0.02758932299911976
loss_c:1.793273687362671
loss_r:0.025226017460227013
loss_c:1.7817189693450928
loss_r:0.026200391352176666
loss_c:1.8589117527008057
loss_r:0.025825662538409233
loss_c:1.7233076095581055
loss_r:0.026328735053539276
loss_c:1.8494975566864014
loss_r:0.02462693862617016
loss_c:1.8325166702270508
loss_r:0.024263404309749603
loss_c:1.8030412197113037
loss_r:0.026821086183190346
loss_c:1.8314530849456787
loss_r:0.024280741810798645
loss_c:1.8681666851043701
loss_r:0.025299014523625374
loss_c:1.6930406093597412
loss_r:0.025557968765497208
loss_c:1.8229984045028687
loss_r:0.023413173854351044
loss_c:1.8058907985687256
loss_r:0.023591207340359688
loss_c:1.760481357574463
loss_r:0.025176050141453743
loss_c:1.7846368551254272
loss_r:0.02477104403078556
loss_c:1.8807880878448486
loss_r:0.02733682654798031
loss_c:1.7375319004058838
total_val_loss:1.78139328956604
Validation loss decreased (1.800876 --> 1.781393).  Saving model ...
epoch: 4/20
loss_r:0.027266554534435272
loss_c:0.7620993852615356
tensor(1.2938, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023750951513648033
loss_c:0.8926761150360107
tensor(1.3497, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014686152338981628
loss_c:0.7787014842033386
tensor(1.2499, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.055296048521995544
loss_c:0.8182017803192139
tensor(1.4423, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019485216587781906
loss_c:0.8949117660522461
tensor(1.3329, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023747699335217476
loss_c:0.8268422484397888
tensor(1.3140, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02373083308339119
loss_c:0.7367309331893921
tensor(1.2651, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014461716637015343
loss_c:0.859463095664978
tensor(1.2925, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020397990942001343
loss_c:0.7929185628890991
tensor(1.2814, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017867624759674072
loss_c:0.8403477668762207
tensor(1.2964, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0186934694647789
loss_c:1.0466649532318115
tensor(1.4119, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01956898532807827
loss_c:0.8036528825759888
tensor(1.2836, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021639663726091385
loss_c:0.7665361762046814
tensor(1.2721, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0161618459969759
loss_c:0.9059879183769226
tensor(1.3247, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0283794105052948
loss_c:0.9870015978813171
tensor(1.4207, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015730464830994606
loss_c:0.7942366600036621
tensor(1.2619, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020214499905705452
loss_c:0.7345589399337769
tensor(1.2485, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016470717266201973
loss_c:1.012772798538208
tensor(1.3841, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034413546323776245
loss_c:0.8980907201766968
tensor(1.3982, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04012218862771988
loss_c:0.8573043346405029
tensor(1.4004, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020640572533011436
loss_c:0.9209479093551636
tensor(1.3518, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013743087649345398
loss_c:0.7326205968856812
tensor(1.2195, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02073453925549984
loss_c:0.9095689058303833
tensor(1.3459, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02406216971576214
loss_c:0.810776948928833
tensor(1.3063, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01691131480038166
loss_c:0.80882328748703
tensor(1.2745, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017997056245803833
loss_c:0.8562626242637634
tensor(1.3050, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021540330722928047
loss_c:0.8531032800674438
tensor(1.3185, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04105385020375252
loss_c:1.0244970321655273
tensor(1.4963, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029275912791490555
loss_c:0.7410511374473572
tensor(1.2905, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019338559359312057
loss_c:0.898949384689331
tensor(1.3341, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014310121536254883
loss_c:0.8672029376029968
tensor(1.2950, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036118585616350174
loss_c:0.9514405131340027
tensor(1.4352, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04077254608273506
loss_c:0.9763380885124207
tensor(1.4690, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012487897649407387
loss_c:0.7652109861373901
tensor(1.2313, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017377421259880066
loss_c:0.8846670985221863
tensor(1.3178, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03556780144572258
loss_c:0.8481022715568542
tensor(1.3762, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027490446344017982
loss_c:0.8844454288482666
tensor(1.3613, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03197411075234413
loss_c:0.8467038869857788
tensor(1.3599, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025438249111175537
loss_c:0.9131087064743042
tensor(1.3681, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01627975143492222
loss_c:0.852631688117981
tensor(1.2956, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03196483850479126
loss_c:1.0559648275375366
tensor(1.4745, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023369058966636658
loss_c:0.8233169317245483
tensor(1.3100, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014929006807506084
loss_c:0.7965332269668579
tensor(1.2591, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036173801869153976
loss_c:0.9174882769584656
tensor(1.4167, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01837020553648472
loss_c:0.7461292147636414
tensor(1.2463, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017506342381238937
loss_c:0.8964142799377441
tensor(1.3249, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01824985258281231
loss_c:0.9215670824050903
tensor(1.3419, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029910089448094368
loss_c:1.0850818157196045
tensor(1.4815, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0281236432492733
loss_c:0.7728348970413208
tensor(1.3029, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021826695650815964
loss_c:0.7480852007865906
tensor(1.2623, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021349383518099785
loss_c:0.903315544128418
tensor(1.3452, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021621381863951683
loss_c:0.9742464423179626
tensor(1.3852, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03479890525341034
loss_c:0.8854707479476929
tensor(1.3932, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022000571712851524
loss_c:0.8605760931968689
tensor(1.3246, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01859126053750515
loss_c:1.0633392333984375
tensor(1.4208, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01931997761130333
loss_c:0.9175571203231812
tensor(1.3442, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014432121999561787
loss_c:0.8981757164001465
tensor(1.3126, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026891667395830154
loss_c:0.9202440977096558
tensor(1.3782, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02077513374388218
loss_c:0.9443128108978271
tensor(1.3650, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01903640851378441
loss_c:0.9285247325897217
tensor(1.3489, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022453991696238518
loss_c:0.9768625497817993
tensor(1.3899, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023584524169564247
loss_c:0.9525332450866699
tensor(1.3815, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01625446416437626
loss_c:0.8506356477737427
tensor(1.2944, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014087121933698654
loss_c:0.803613543510437
tensor(1.2595, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018667059019207954
loss_c:0.8329805731773376
tensor(1.2952, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016858704388141632
loss_c:0.8242849111557007
tensor(1.2826, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016932427883148193
loss_c:0.8319520950317383
tensor(1.2871, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04263274371623993
loss_c:1.0513489246368408
tensor(1.5177, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0229706559330225
loss_c:1.0587446689605713
tensor(1.4362, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02673545852303505
loss_c:0.8436565399169922
tensor(1.3360, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0205264613032341
loss_c:0.7736639976501465
tensor(1.2711, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02272641845047474
loss_c:0.8586242198944092
tensor(1.3267, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03442218899726868
loss_c:0.8322110176086426
tensor(1.3634, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030213193967938423
loss_c:0.8868449926376343
tensor(1.3746, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019472872838377953
loss_c:0.9437274932861328
tensor(1.3585, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019010907039046288
loss_c:0.8551715612411499
tensor(1.3086, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02015836536884308
loss_c:0.9866636991500854
tensor(1.3847, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025235019624233246
loss_c:0.9748208522796631
tensor(1.4005, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03517144173383713
loss_c:0.8935369849205017
tensor(1.3999, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01804574951529503
loss_c:0.860633373260498
tensor(1.3074, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021634995937347412
loss_c:0.8916594982147217
tensor(1.3398, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017591232433915138
loss_c:0.922566831111908
tensor(1.3388, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025746876373887062
loss_c:0.8543167114257812
tensor(1.3376, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023764707148075104
loss_c:0.8771147727966309
tensor(1.3412, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01889513060450554
loss_c:0.9194931983947754
tensor(1.3429, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014016618020832539
loss_c:0.8181899785995483
tensor(1.2669, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01713346317410469
loss_c:0.9851856231689453
tensor(1.3706, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023929307237267494
loss_c:0.9161510467529297
tensor(1.3630, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035523779690265656
loss_c:0.8248562812805176
tensor(1.3645, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04360921308398247
loss_c:1.1643933057785034
tensor(1.5830, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02225131168961525
loss_c:0.8797711730003357
tensor(1.3361, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028643088415265083
loss_c:0.9329192042350769
tensor(1.3926, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03293459117412567
loss_c:0.9206076860427856
tensor(1.4047, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019001048058271408
loss_c:0.7512308955192566
tensor(1.2528, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01463557593524456
loss_c:0.8519206047058105
tensor(1.2879, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014474845491349697
loss_c:0.8425590991973877
tensor(1.2822, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023012137040495872
loss_c:0.7747904658317566
tensor(1.2830, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014316793531179428
loss_c:0.6924302577972412
tensor(1.2008, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018699143081903458
loss_c:0.9242215156555176
tensor(1.3445, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019137218594551086
loss_c:0.9542427062988281
tensor(1.3626, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018596496433019638
loss_c:0.8376257419586182
tensor(1.2974, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0171290785074234
loss_c:1.028485655784607
tensor(1.3938, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015147021040320396
loss_c:0.8290016055107117
tensor(1.2776, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019786445423960686
loss_c:0.7458274364471436
tensor(1.2530, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041787128895521164
loss_c:0.930747389793396
tensor(1.4493, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021666085347533226
loss_c:0.8787404894828796
tensor(1.3329, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021888747811317444
loss_c:0.9452035427093506
tensor(1.3698, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04266094043850899
loss_c:1.0042688846588135
tensor(1.4930, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01943119242787361
loss_c:0.8052949905395508
tensor(1.2834, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01630978472530842
loss_c:0.8878938555717468
tensor(1.3143, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024546237662434578
loss_c:0.9388589859008789
tensor(1.3780, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016878968104720116
loss_c:0.8574460744857788
tensor(1.3004, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016962921246886253
loss_c:0.771805465221405
tensor(1.2545, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023120462894439697
loss_c:1.1624221801757812
tensor(1.4926, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026126906275749207
loss_c:0.8785279989242554
tensor(1.3524, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02746492438018322
loss_c:0.8714978694915771
tensor(1.3545, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029604515060782433
loss_c:0.857388973236084
tensor(1.3563, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019902881234884262
loss_c:0.9292928576469421
tensor(1.3524, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029184171929955482
loss_c:0.8236589431762695
tensor(1.3362, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04359631985425949
loss_c:0.8594862818717957
tensor(1.4190, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024478629231452942
loss_c:1.0387368202209473
tensor(1.4316, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016194310039281845
loss_c:0.8288185000419617
tensor(1.2819, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02286352589726448
loss_c:0.9123911261558533
tensor(1.3563, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016667494550347328
loss_c:0.8507521152496338
tensor(1.2959, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03907648101449013
loss_c:0.9698218107223511
tensor(1.4584, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07804495096206665
loss_c:0.8879544138908386
tensor(1.5848, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01825624890625477
loss_c:0.809264600276947
tensor(1.2806, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020523851737380028
loss_c:0.8168891668319702
tensor(1.2946, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014187254942953587
loss_c:0.754270076751709
tensor(1.2334, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018198028206825256
loss_c:0.8934664726257324
tensor(1.3259, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028558766469359398
loss_c:0.8213838934898376
tensor(1.3319, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015330327674746513
loss_c:0.7710205912590027
tensor(1.2474, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021253731101751328
loss_c:0.8774822950363159
tensor(1.3306, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01594005897641182
loss_c:0.9157404899597168
tensor(1.3283, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03428542613983154
loss_c:0.9709774851799011
tensor(1.4374, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02501867152750492
loss_c:0.8151053190231323
tensor(1.3130, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019617021083831787
loss_c:0.8487296104431152
tensor(1.3080, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02767755836248398
loss_c:0.7952749729156494
tensor(1.3137, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016253070905804634
loss_c:0.8705304861068726
tensor(1.3053, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11852866411209106
loss_c:0.984562873840332
tensor(1.8076, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030613664537668228
loss_c:0.9355995059013367
tensor(1.4023, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01399949286133051
loss_c:0.7894155383110046
tensor(1.2519, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019339188933372498
loss_c:0.9054624438285828
tensor(1.3378, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02226698026061058
loss_c:0.9011964201927185
tensor(1.3480, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016108447685837746
loss_c:0.8080013990402222
tensor(1.2713, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022064659744501114
loss_c:0.8340853452682495
tensor(1.3107, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024138452485203743
loss_c:0.8436570167541504
tensor(1.3247, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014482238329946995
loss_c:0.8108953237533569
tensor(1.2661, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024237949401140213
loss_c:0.7230982184410095
tensor(1.2594, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016750110313296318
loss_c:0.784392774105072
tensor(1.2612, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037080567330121994
loss_c:0.8355064392089844
tensor(1.3747, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026394668966531754
loss_c:0.9590231776237488
tensor(1.3971, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029991207644343376
loss_c:0.9138604402542114
tensor(1.3876, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019849542528390884
loss_c:0.9675107002258301
tensor(1.3743, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018747955560684204
loss_c:0.9624702334403992
tensor(1.3669, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03086896426975727
loss_c:0.8811747431755066
tensor(1.3734, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022940397262573242
loss_c:0.9106082320213318
tensor(1.3562, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024977801367640495
loss_c:0.9088993072509766
tensor(1.3638, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03307178243994713
loss_c:0.9991344213485718
tensor(1.4471, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026295404881238937
loss_c:0.8966850638389587
tensor(1.3626, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020859649404883385
loss_c:0.8464495539665222
tensor(1.3124, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031130686402320862
loss_c:0.8497704863548279
tensor(1.3573, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026986438781023026
loss_c:0.757152795791626
tensor(1.2893, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01811864785850048
loss_c:0.8809460997581482
tensor(1.3197, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018795030191540718
loss_c:0.8664755821228027
tensor(1.3147, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03009874001145363
loss_c:0.7852030992507935
tensor(1.3177, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0180644690990448
loss_c:0.8661293387413025
tensor(1.3114, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02556823566555977
loss_c:0.8642298579216003
tensor(1.3418, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02196708880364895
loss_c:0.846145749092102
tensor(1.3168, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017768854275345802
loss_c:0.8749982118606567
tensor(1.3150, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017518827691674232
loss_c:0.7297927737236023
tensor(1.2345, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06232896074652672
loss_c:0.9528881907463074
tensor(1.5448, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03006569854915142
loss_c:0.8508211374282837
tensor(1.3534, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015181644819676876
loss_c:0.8542933464050293
tensor(1.2928, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01792198233306408
loss_c:0.7880985736846924
tensor(1.2681, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0272903461009264
loss_c:0.9177731275558472
tensor(1.3784, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019707513973116875
loss_c:1.0565125942230225
tensor(1.4227, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019756557419896126
loss_c:0.758840799331665
tensor(1.2597, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02003052644431591
loss_c:0.8542135953903198
tensor(1.3131, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016989288851618767
loss_c:0.8100535273551941
tensor(1.2761, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021332010626792908
loss_c:1.0343818664550781
tensor(1.4174, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020047502592206
loss_c:0.7451114058494568
tensor(1.2533, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016794564202427864
loss_c:0.9166330695152283
tensor(1.3336, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026357101276516914
loss_c:0.9632646441459656
tensor(1.3995, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019199799746274948
loss_c:0.7660355567932129
tensor(1.2611, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0178033709526062
loss_c:0.9188234210014343
tensor(1.3390, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024880753830075264
loss_c:0.8575531840324402
tensor(1.3353, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015775488689541817
loss_c:0.801917314529419
tensor(1.2662, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0217665396630764
loss_c:0.9427692890167236
tensor(1.3688, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016670770943164825
loss_c:0.8699231147766113
tensor(1.3071, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020427871495485306
loss_c:0.8744911551475525
tensor(1.3256, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03258020058274269
loss_c:0.8771754503250122
tensor(1.3789, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040816519409418106
loss_c:0.8816129565238953
tensor(1.4165, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014214485883712769
loss_c:0.7973442077636719
tensor(1.2567, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018360542133450508
loss_c:0.8930644989013672
tensor(1.3269, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016259416937828064
loss_c:0.835784912109375
tensor(1.2864, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025934157893061638
loss_c:0.9842365980148315
tensor(1.4093, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013871727511286736
loss_c:0.7244089841842651
tensor(1.2150, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033143300563097
loss_c:0.7522450685501099
tensor(1.3130, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027966700494289398
loss_c:0.8178523778915405
tensor(1.3268, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02915126644074917
loss_c:0.8671736121177673
tensor(1.3589, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02123970538377762
loss_c:0.9609659910202026
tensor(1.3764, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02405008301138878
loss_c:0.8940760493278503
tensor(1.3518, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02096288651227951
loss_c:0.7844762802124023
tensor(1.2782, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016379347071051598
loss_c:0.7728573083877563
tensor(1.2521, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018541676923632622
loss_c:0.9946033954620361
tensor(1.3833, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021622465923428535
loss_c:0.9732604026794434
tensor(1.3849, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027417030185461044
loss_c:0.994240403175354
tensor(1.4214, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029333289712667465
loss_c:0.7818376421928406
tensor(1.3129, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03640197589993477
loss_c:0.884124219417572
tensor(1.3998, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021013550460338593
loss_c:0.9566619396209717
tensor(1.3730, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024585889652371407
loss_c:0.8093993067741394
tensor(1.3076, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01946515403687954
loss_c:0.9422543048858643
tensor(1.3584, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017739444971084595
loss_c:0.9226069450378418
tensor(1.3401, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030509551987051964
loss_c:0.8557182550430298
tensor(1.3587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01980382576584816
loss_c:0.914114236831665
tensor(1.3444, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018687240779399872
loss_c:0.7487089037895203
tensor(1.2488, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03465990722179413
loss_c:0.9654294848442078
tensor(1.4368, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017668969929218292
loss_c:0.8509798049926758
tensor(1.3005, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028895419090986252
loss_c:0.8082412481307983
tensor(1.3257, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02056368999183178
loss_c:0.8044368624687195
tensor(1.2875, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017611250281333923
loss_c:0.7951055765151978
tensor(1.2696, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015424295328557491
loss_c:0.8730610609054565
tensor(1.3028, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02014298364520073
loss_c:0.934053897857666
tensor(1.3567, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023961849510669708
loss_c:0.7860444784164429
tensor(1.2921, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01960875652730465
loss_c:0.8029777407646179
tensor(1.2825, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018823372200131416
loss_c:1.036015272140503
tensor(1.4069, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019907750189304352
loss_c:0.7866719961166382
tensor(1.2748, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032091911882162094
loss_c:0.8586239814758301
tensor(1.3674, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01843944564461708
loss_c:0.8226346969604492
tensor(1.2881, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024510977789759636
loss_c:0.8175458908081055
tensor(1.3118, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018574267625808716
loss_c:0.7878092527389526
tensor(1.2695, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020431999117136
loss_c:1.0216549634933472
tensor(1.4060, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01922820881009102
loss_c:0.8833608627319336
tensor(1.3248, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01981518790125847
loss_c:0.9134135246276855
tensor(1.3439, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021145284175872803
loss_c:0.8875205516815186
tensor(1.3355, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016663717105984688
loss_c:0.9011101722717285
tensor(1.3232, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01908210664987564
loss_c:0.8864023089408875
tensor(1.3258, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023670228198170662
loss_c:0.8847245573997498
tensor(1.3450, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013027586974203587
loss_c:0.7976815104484558
tensor(1.2503, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021886363625526428
loss_c:0.9083726406097412
tensor(1.3501, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016075778752565384
loss_c:0.8454562425613403
tensor(1.2899, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03769427165389061
loss_c:1.174870252609253
tensor(1.5663, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01830514706671238
loss_c:0.8905996084213257
tensor(1.3245, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04704049602150917
loss_c:0.827877938747406
tensor(1.4174, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018957430496811867
loss_c:0.8943600058555603
tensor(1.3294, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016047650948166847
loss_c:0.7988561391830444
tensor(1.2642, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02547183446586132
loss_c:1.1411817073822021
tensor(1.4933, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03568936884403229
loss_c:0.8813910484313965
tensor(1.3964, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02457864210009575
loss_c:0.8899438381195068
tensor(1.3518, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039348483085632324
loss_c:0.9564091563224792
tensor(1.4535, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037767838686704636
loss_c:0.9642887115478516
tensor(1.4507, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04503199830651283
loss_c:0.929548978805542
tensor(1.4636, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020393863320350647
loss_c:0.7689533233642578
tensor(1.2675, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028696704655885696
loss_c:0.8145064115524292
tensor(1.3288, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017988033592700958
loss_c:0.8841568827629089
tensor(1.3197, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017768939957022667
loss_c:0.9464847445487976
tensor(1.3527, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018813585862517357
loss_c:0.8044168949127197
tensor(1.2801, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025476019829511642
loss_c:1.2148078680038452
tensor(1.5320, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01958070695400238
loss_c:0.9030450582504272
tensor(1.3370, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025164691731333733
loss_c:0.8326228857040405
tensor(1.3232, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024017352610826492
loss_c:0.9108263850212097
tensor(1.3606, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021697472780942917
loss_c:1.0416513681411743
tensor(1.4212, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019017649814486504
loss_c:0.8601757884025574
tensor(1.3114, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03434021398425102
loss_c:1.0078811645507812
tensor(1.4578, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03889559581875801
loss_c:0.8148421049118042
tensor(1.3733, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024638717994093895
loss_c:0.9515494108200073
tensor(1.3852, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015476358123123646
loss_c:0.7555817365646362
tensor(1.2399, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020931966602802277
loss_c:0.9426687955856323
tensor(1.3643, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01721949689090252
loss_c:0.7719817161560059
tensor(1.2564, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018316330388188362
loss_c:1.0309600830078125
tensor(1.4005, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022398458793759346
loss_c:0.8101577162742615
tensor(1.2993, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026710418984293938
loss_c:0.8701655268669128
tensor(1.3503, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031026126816868782
loss_c:0.9572922587394714
tensor(1.4158, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01635226234793663
loss_c:0.8840041160583496
tensor(1.3129, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020924879238009453
loss_c:0.8688923120498657
tensor(1.3246, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046844057738780975
loss_c:0.9591382741928101
tensor(1.4852, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029947688803076744
loss_c:0.8113827705383301
tensor(1.3327, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03599295765161514
loss_c:0.9196599721908569
tensor(1.4169, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030136486515402794
loss_c:0.9934288859367371
tensor(1.4312, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015035701915621758
loss_c:0.7409161925315857
tensor(1.2306, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1555688977241516
loss_c:1.1710224151611328
tensor(2.0658, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01888621412217617
loss_c:0.895140528678894
tensor(1.3302, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.049363214522600174
loss_c:1.1014657020568848
tensor(1.5704, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017274420708417892
loss_c:0.8853703737258911
tensor(1.3184, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022855397313833237
loss_c:0.9960051774978638
tensor(1.4013, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018491821363568306
loss_c:0.7670542597770691
tensor(1.2605, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024359118193387985
loss_c:0.8785260915756226
tensor(1.3447, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020705902948975563
loss_c:0.8612229228019714
tensor(1.3203, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.14417338371276855
loss_c:1.1453766822814941
tensor(1.9833, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0333123505115509
loss_c:0.9362627267837524
tensor(1.4125, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021306028589606285
loss_c:1.0103802680969238
tensor(1.4028, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020792223513126373
loss_c:0.8197969198226929
tensor(1.2992, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022793058305978775
loss_c:0.9853935241699219
tensor(1.3957, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01907086931169033
loss_c:0.9844595789909363
tensor(1.3803, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021885525435209274
loss_c:0.9539443850517273
tensor(1.3754, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017819568514823914
loss_c:0.8710955381393433
tensor(1.3151, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01757635362446308
loss_c:0.7457873225212097
tensor(1.2477, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017905669286847115
loss_c:0.9055468440055847
tensor(1.3340, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023354802280664444
loss_c:0.8423603773117065
tensor(1.3221, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1048290878534317
loss_c:1.111276626586914
tensor(1.7887, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03656171262264252
loss_c:0.9891075491905212
tensor(1.4524, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036620672792196274
loss_c:0.917778491973877
tensor(1.4147, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030761422589421272
loss_c:0.8259056806564331
tensor(1.3428, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01996673084795475
loss_c:0.7453675270080566
tensor(1.2578, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03709665685892105
loss_c:0.8547086715698242
tensor(1.3828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018877072259783745
loss_c:0.8699636459350586
tensor(1.3197, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037974365055561066
loss_c:1.0672664642333984
tensor(1.4988, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020264972001314163
loss_c:0.8934504389762878
tensor(1.3377, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09919816255569458
loss_c:0.9420518279075623
tensor(1.6699, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023802177980542183
loss_c:0.8537544012069702
tensor(1.3305, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029097797349095345
loss_c:0.7679516673088074
tensor(1.3055, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033542100340127945
loss_c:0.732284426689148
tensor(1.3036, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025148287415504456
loss_c:1.0019516944885254
tensor(1.4146, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020521443337202072
loss_c:0.9854660034179688
tensor(1.3882, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011882099322974682
loss_c:0.8220807313919067
tensor(1.2684, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0406346395611763
loss_c:0.9087764620780945
tensor(1.4243, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043278057128190994
loss_c:0.9416534304618835
tensor(1.4518, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022460760548710823
loss_c:0.8494248390197754
tensor(1.3234, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025557367131114006
loss_c:0.9773661494255066
tensor(1.4033, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01566658914089203
loss_c:0.8093265295028687
tensor(1.2763, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020618503913283348
loss_c:0.8001159429550171
tensor(1.2902, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034765828400850296
loss_c:0.9418627619743347
tensor(1.4194, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030190136283636093
loss_c:0.9420889616012573
tensor(1.4022, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01793123409152031
loss_c:0.8124570846557617
tensor(1.2865, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03123318962752819
loss_c:0.8599838614463806
tensor(1.3623, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024963773787021637
loss_c:0.7840509414672852
tensor(1.2979, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03214757889509201
loss_c:0.9182183146476746
tensor(1.3969, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017110224813222885
loss_c:0.8529857397079468
tensor(1.3048, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05334683507680893
loss_c:0.8770632743835449
tensor(1.4556, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023628883063793182
loss_c:0.8122267723083496
tensor(1.3077, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019269218668341637
loss_c:0.9079713821411133
tensor(1.3424, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018254192546010017
loss_c:0.8610471487045288
tensor(1.3133, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030780775472521782
loss_c:1.078773021697998
tensor(1.4779, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04809383302927017
loss_c:0.7899410724639893
tensor(1.3890, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029207952320575714
loss_c:1.0133357048034668
tensor(1.4369, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04567396268248558
loss_c:0.8980879783630371
tensor(1.4378, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02444775216281414
loss_c:0.8385658264160156
tensor(1.3248, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02536516822874546
loss_c:0.9721509218215942
tensor(1.4001, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019220836460590363
loss_c:0.9288946986198425
tensor(1.3534, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017548492178320885
loss_c:0.9012256860733032
tensor(1.3321, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023895399644970894
loss_c:0.8876373767852783
tensor(1.3490, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020872803404927254
loss_c:0.8529608249664307
tensor(1.3188, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018313271924853325
loss_c:0.8153132200241089
tensor(1.2887, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01816544122993946
loss_c:0.9497991800308228
tensor(1.3604, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014596257358789444
loss_c:0.7685316801071167
tensor(1.2491, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019861074164509773
loss_c:0.7610496878623962
tensor(1.2652, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0201723612844944
loss_c:0.788040816783905
tensor(1.2808, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020054884254932404
loss_c:0.7955204248428345
tensor(1.2843, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03116448037326336
loss_c:0.8694998621940613
tensor(1.3671, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019020434468984604
loss_c:1.005523681640625
tensor(1.3934, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017182400450110435
loss_c:0.8998994827270508
tensor(1.3291, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03492514789104462
loss_c:0.9439684152603149
tensor(1.4220, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01594134420156479
loss_c:0.762660026550293
tensor(1.2498, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027116842567920685
loss_c:0.927097499370575
tensor(1.3824, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022830426692962646
loss_c:0.9872316122055054
tensor(1.3981, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023381853476166725
loss_c:0.7141988277435303
tensor(1.2525, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025210944935679436
loss_c:0.9015885591506958
tensor(1.3611, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03960001468658447
loss_c:0.8996507525444031
tensor(1.4168, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01888405904173851
loss_c:0.8522642850875854
tensor(1.3093, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018198944628238678
loss_c:0.9022250175476074
tensor(1.3336, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036430198699235916
loss_c:0.8780579566955566
tensor(1.3928, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019391851499676704
loss_c:0.7645460367202759
tensor(1.2635, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022057853639125824
loss_c:0.9026607871055603
tensor(1.3490, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01751062460243702
loss_c:0.785630464553833
tensor(1.2673, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019499989226460457
loss_c:0.8122892379760742
tensor(1.2896, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023511655628681183
loss_c:0.8935583829879761
tensor(1.3498, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021295631304383278
loss_c:0.9404386281967163
tensor(1.3664, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020721586421132088
loss_c:0.7770953178405762
tensor(1.2751, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03180548921227455
loss_c:0.8548024892807007
tensor(1.3620, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03402964025735855
loss_c:0.964385449886322
tensor(1.4307, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021406181156635284
loss_c:1.0242390632629395
tensor(1.4124, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015994559973478317
loss_c:0.7669719457626343
tensor(1.2502, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01936372183263302
loss_c:1.0307538509368896
tensor(1.4077, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021225009113550186
loss_c:0.8175155520439148
tensor(1.2989, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021067921072244644
loss_c:0.7742952108383179
tensor(1.2746, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027802174910902977
loss_c:1.038719892501831
tensor(1.4462, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019692976027727127
loss_c:0.8828570246696472
tensor(1.3281, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018716098740696907
loss_c:0.7986869812011719
tensor(1.2782, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015582944266498089
loss_c:0.9242216348648071
tensor(1.3338, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025881221517920494
loss_c:0.8797625303268433
tensor(1.3516, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023034654557704926
loss_c:0.9546347856521606
tensor(1.3808, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016223248094320297
loss_c:0.7712454199790955
tensor(1.2527, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040909942239522934
loss_c:0.9275369048118591
tensor(1.4397, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02253643050789833
loss_c:0.8606224060058594
tensor(1.3274, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018317990005016327
loss_c:0.7836703062057495
tensor(1.2680, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019934598356485367
loss_c:0.8227178454399109
tensor(1.2959, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038515426218509674
loss_c:0.9910485744476318
tensor(1.4647, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026792077347636223
loss_c:1.0636241436004639
tensor(1.4557, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01644483394920826
loss_c:0.8744614124298096
tensor(1.3095, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032843396067619324
loss_c:0.8333330154418945
tensor(1.3553, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02522866241633892
loss_c:0.776383101940155
tensor(1.2926, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018545035272836685
loss_c:0.9179806113243103
tensor(1.3419, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01845443807542324
loss_c:0.8506180644035339
tensor(1.3048, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031086064875125885
loss_c:1.0254228115081787
tensor(1.4527, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02100767008960247
loss_c:0.9259332418441772
tensor(1.3564, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02483931928873062
loss_c:1.1122899055480957
tensor(1.4738, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04658070579171181
loss_c:0.8418178558349609
tensor(1.4176, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021984271705150604
loss_c:1.0121902227401733
tensor(1.4073, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027251021936535835
loss_c:0.8185700178146362
tensor(1.3241, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030333707109093666
loss_c:0.9663922786712646
tensor(1.4173, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019969727843999863
loss_c:1.0096535682678223
tensor(1.3973, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03352200984954834
loss_c:0.8241607546806335
tensor(1.3535, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017185337841510773
loss_c:0.8524624705314636
tensor(1.3005, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024232948198914528
loss_c:0.8772766590118408
tensor(1.3434, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02172299660742283
loss_c:0.9350289106369019
tensor(1.3641, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022960614413022995
loss_c:0.8393823504447937
tensor(1.3176, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024878449738025665
loss_c:0.8872013092041016
tensor(1.3515, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021244920790195465
loss_c:0.9556466937065125
tensor(1.3732, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020995642989873886
loss_c:0.900514543056488
tensor(1.3424, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01415818091481924
loss_c:0.8227280378341675
tensor(1.2718, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0169173963367939
loss_c:0.8056643009185791
tensor(1.2741, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.049111172556877136
loss_c:0.7888748049736023
tensor(1.4002, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018099859356880188
loss_c:0.8312704563140869
tensor(1.2928, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018197879195213318
loss_c:0.8853908777236938
tensor(1.3224, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020302308723330498
loss_c:0.8503683805465698
tensor(1.3123, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015393788926303387
loss_c:0.7610387802124023
tensor(1.2435, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039385225623846054
loss_c:0.838847815990448
tensor(1.3865, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02580898627638817
loss_c:0.9177408218383789
tensor(1.3719, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018844254314899445
loss_c:0.7822383642196655
tensor(1.2693, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03221314027905464
loss_c:0.8302854895591736
tensor(1.3516, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03290405124425888
loss_c:0.9077929854393005
tensor(1.3965, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0157600250095129
loss_c:0.8066096305847168
tensor(1.2693, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037755027413368225
loss_c:0.7824901938438416
tensor(1.3490, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017016038298606873
loss_c:0.82127845287323
tensor(1.2825, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016421334818005562
loss_c:0.9242210388183594
tensor(1.3359, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01935984194278717
loss_c:0.8423312902450562
tensor(1.3038, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017877351492643356
loss_c:1.0127601623535156
tensor(1.3902, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05246210843324661
loss_c:0.9665472507476807
tensor(1.5113, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030225493013858795
loss_c:0.9066448211669922
tensor(1.3847, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024918435141444206
loss_c:0.8845264315605164
tensor(1.3502, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021356558427214622
loss_c:0.9987437129020691
tensor(1.3974, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020621120929718018
loss_c:0.9476078748703003
tensor(1.3664, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039469677954912186
loss_c:1.0465099811553955
tensor(1.4998, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020223362371325493
loss_c:0.9154435992240906
tensor(1.3472, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023979801684617996
loss_c:0.9215989112854004
tensor(1.3664, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023332368582487106
loss_c:0.8166433572769165
tensor(1.3066, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019645841792225838
loss_c:0.8937503695487976
tensor(1.3330, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.051970161497592926
loss_c:0.9415113925933838
tensor(1.4951, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019567087292671204
loss_c:0.8651396632194519
tensor(1.3171, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026344411075115204
loss_c:0.9405905604362488
tensor(1.3866, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03354836627840996
loss_c:0.9246839284896851
tensor(1.4082, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028774533420801163
loss_c:0.8798614740371704
tensor(1.3639, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01919945515692234
loss_c:0.9144553542137146
tensor(1.3424, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026740530505776405
loss_c:1.058736801147461
tensor(1.4521, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02145843766629696
loss_c:0.9127992987632751
tensor(1.3510, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019815616309642792
loss_c:0.8670181035995483
tensor(1.3194, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016964662820100784
loss_c:0.8605706691741943
tensor(1.3040, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018945816904306412
loss_c:0.8490076065063477
tensor(1.3060, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0238006841391325
loss_c:0.7928227186203003
tensor(1.2961, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015457912348210812
loss_c:0.7973566055297852
tensor(1.2635, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02496456168591976
loss_c:0.7958887815475464
tensor(1.3026, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018741410225629807
loss_c:0.8876579999923706
tensor(1.3259, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018916485831141472
loss_c:0.8577195405960083
tensor(1.3105, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015916410833597183
loss_c:0.891892671585083
tensor(1.3163, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03346595913171768
loss_c:0.9913541674613953
tensor(1.4439, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01577773690223694
loss_c:0.7972461581230164
tensor(1.2645, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018989218398928642
loss_c:1.0097715854644775
tensor(1.3928, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02547547034919262
loss_c:0.8769195079803467
tensor(1.3484, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0316929966211319
loss_c:0.9002790451049805
tensor(1.3874, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03100709058344364
loss_c:0.9036426544189453
tensor(1.3863, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01607145182788372
loss_c:0.7607384920120239
tensor(1.2458, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04318588599562645
loss_c:0.9508779048919678
tensor(1.4635, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021239036694169044
loss_c:0.7543762922286987
tensor(1.2643, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02367742359638214
loss_c:0.842151403427124
tensor(1.3220, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020121436566114426
loss_c:0.7629131078720093
tensor(1.2641, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01817934587597847
loss_c:0.8686544299125671
tensor(1.3130, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014759214594960213
loss_c:0.7539582252502441
tensor(1.2363, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01662687584757805
loss_c:0.790402889251709
tensor(1.2639, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02575136348605156
loss_c:0.803314208984375
tensor(1.3097, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02946876548230648
loss_c:1.14400315284729
tensor(1.5104, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037870705127716064
loss_c:0.9820963144302368
tensor(1.4584, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014627352356910706
loss_c:0.858597457408905
tensor(1.2922, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0203073862940073
loss_c:0.8022836446762085
tensor(1.2858, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03437221422791481
loss_c:0.989342451095581
tensor(1.4475, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02745538204908371
loss_c:0.9364806413650513
tensor(1.3893, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01661299727857113
loss_c:0.8760337829589844
tensor(1.3101, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020217441022396088
loss_c:0.9093760251998901
tensor(1.3436, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02457375079393387
loss_c:0.7648882865905762
tensor(1.2837, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02032742276787758
loss_c:0.9163789749145508
tensor(1.3479, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025220734998583794
loss_c:0.8532705307006836
tensor(1.3345, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016971031203866005
loss_c:0.8617963194847107
tensor(1.3038, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020055674016475677
loss_c:0.9339264631271362
tensor(1.3562, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015553117729723454
loss_c:0.8259578943252563
tensor(1.2782, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02012961357831955
loss_c:0.8069674968719482
tensor(1.2875, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01697465591132641
loss_c:0.8412014842033386
tensor(1.2925, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018767567351460457
loss_c:0.8827770948410034
tensor(1.3228, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01608910784125328
loss_c:0.7976393699645996
tensor(1.2648, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017787670716643333
loss_c:0.8434921503067017
tensor(1.2971, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017090871930122375
loss_c:0.886469304561615
tensor(1.3174, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018033303320407867
loss_c:0.8350275754928589
tensor(1.2934, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02241159975528717
loss_c:0.8570493459701538
tensor(1.3244, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030906962230801582
loss_c:0.8730415105819702
tensor(1.3701, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021187642589211464
loss_c:0.8179444670677185
tensor(1.2977, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016441771760582924
loss_c:0.8701683878898621
tensor(1.3054, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02912372164428234
loss_c:0.809960126876831
tensor(1.3279, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034505877643823624
loss_c:0.8686131834983826
tensor(1.3836, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020873041823506355
loss_c:0.9605302810668945
tensor(1.3742, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01717921532690525
loss_c:0.8289378881454468
tensor(1.2860, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03320223465561867
loss_c:0.9694576263427734
tensor(1.4331, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016521457582712173
loss_c:0.8067306280136108
tensor(1.2709, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019299717620015144
loss_c:0.903841495513916
tensor(1.3363, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01475154422223568
loss_c:0.8805326819419861
tensor(1.3035, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04037648066878319
loss_c:0.920764148235321
tensor(1.4381, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023841362446546555
loss_c:0.8393847942352295
tensor(1.3209, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015263735316693783
loss_c:0.8979144096374512
tensor(1.3152, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04186633229255676
loss_c:0.9269803762435913
tensor(1.4481, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04364529252052307
loss_c:1.0567673444747925
tensor(1.5270, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03064107894897461
loss_c:0.9178140163421631
tensor(1.3937, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02397741936147213
loss_c:0.9020082950592041
tensor(1.3558, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02544582076370716
loss_c:0.8379842638969421
tensor(1.3272, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036870528012514114
loss_c:0.8222662806510925
tensor(1.3685, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02877291478216648
loss_c:0.7876521348953247
tensor(1.3142, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02216128259897232
loss_c:0.9656597971916199
tensor(1.3826, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019375141710042953
loss_c:0.98887699842453
tensor(1.3831, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03066331148147583
loss_c:0.7800865173339844
tensor(1.3182, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016825497150421143
loss_c:0.8481847643852234
tensor(1.2953, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021982071921229362
loss_c:0.9080497622489929
tensor(1.3504, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020823873579502106
loss_c:0.9520000219345093
tensor(1.3693, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023053405806422234
loss_c:0.860726535320282
tensor(1.3292, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026602229103446007
loss_c:0.8814857006072998
tensor(1.3558, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030214892700314522
loss_c:0.9129847884178162
tensor(1.3886, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015456246212124825
loss_c:0.85417640209198
tensor(1.2928, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021342042833566666
loss_c:0.8971046209335327
tensor(1.3416, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04553833603858948
loss_c:0.8745676875114441
tensor(1.4338, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02698993682861328
loss_c:0.7949833869934082
tensor(1.3104, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019364187493920326
loss_c:0.8981198072433472
tensor(1.3337, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0225897915661335
loss_c:0.9342095255851746
tensor(1.3672, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017413729801774025
loss_c:0.9237555265426636
tensor(1.3393, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018686499446630478
loss_c:0.7755497694015503
tensor(1.2641, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013946724124252796
loss_c:0.7553519010543823
tensor(1.2328, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02711535431444645
loss_c:0.7346519231796265
tensor(1.2781, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03808552026748657
loss_c:0.9919986128807068
tensor(1.4654, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016374291852116585
loss_c:0.8496426343917847
tensor(1.2945, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014801719225943089
loss_c:0.7526249885559082
tensor(1.2348, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03626178950071335
loss_c:0.8710858821868896
tensor(1.3917, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021034223958849907
loss_c:0.8880552053451538
tensor(1.3354, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04946132004261017
loss_c:0.8331390619277954
tensor(1.4277, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027746904641389847
loss_c:0.9268013834953308
tensor(1.3854, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021640900522470474
loss_c:0.8979368209838867
tensor(1.3435, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.050099994987249374
loss_c:0.942783534526825
tensor(1.4900, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013706089928746223
loss_c:0.7307157516479492
tensor(1.2182, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024173622950911522
loss_c:0.7991604208946228
tensor(1.3003, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01529714185744524
loss_c:0.7616244554519653
tensor(1.2419, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02450603060424328
loss_c:1.066110372543335
tensor(1.4479, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026592915877699852
loss_c:1.0026769638061523
tensor(1.4220, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02451336942613125
loss_c:0.909976601600647
tensor(1.3624, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01632021926343441
loss_c:0.8529133796691895
tensor(1.2963, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030939431861042976
loss_c:0.9571570158004761
tensor(1.4156, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020239118486642838
loss_c:1.0427238941192627
tensor(1.4168, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019478989765048027
loss_c:0.8897675275802612
tensor(1.3299, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018077852204442024
loss_c:0.8564685583114624
tensor(1.3058, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024263272061944008
loss_c:0.9526011347770691
tensor(1.3846, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02275671437382698
loss_c:0.8209561109542847
tensor(1.3063, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027770720422267914
loss_c:1.1789448261260986
tensor(1.5229, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02052740752696991
loss_c:0.8214275240898132
tensor(1.2971, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020643264055252075
loss_c:0.8012191653251648
tensor(1.2866, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01856754533946514
loss_c:0.8462395668029785
tensor(1.3023, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016325002536177635
loss_c:0.8542186617851257
tensor(1.2970, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02030911296606064
loss_c:0.8393377661705017
tensor(1.3059, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0563654862344265
loss_c:0.8688699007034302
tensor(1.4762, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018087254837155342
loss_c:0.8497552871704102
tensor(1.3021, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01596570760011673
loss_c:0.8293846845626831
tensor(1.2819, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03166637197136879
loss_c:0.8796228766441345
tensor(1.3764, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02211056463420391
loss_c:0.8741886615753174
tensor(1.3326, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01967933215200901
loss_c:0.8627979159355164
tensor(1.3160, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018199043348431587
loss_c:0.7934527397155762
tensor(1.2719, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02734309434890747
loss_c:0.844001293182373
tensor(1.3385, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029205698519945145
loss_c:0.7838784456253052
tensor(1.3138, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021157821640372276
loss_c:0.7143067717552185
tensor(1.2415, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021658046171069145
loss_c:0.7506574988365173
tensor(1.2633, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013940813951194286
loss_c:0.7389323115348816
tensor(1.2238, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01995699107646942
loss_c:1.0211377143859863
tensor(1.4035, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031205996870994568
loss_c:0.864974856376648
tensor(1.3665, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024491196498274803
loss_c:0.7612438201904297
tensor(1.2810, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044901374727487564
loss_c:0.8651592135429382
tensor(1.4255, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021646792069077492
loss_c:0.9738356471061707
tensor(1.3851, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02123235911130905
loss_c:0.8334142565727234
tensor(1.3064, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025832580402493477
loss_c:1.1184494495391846
tensor(1.4824, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020756518468260765
loss_c:0.8262597322463989
tensor(1.3004, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019604936242103577
loss_c:0.8398036956787109
tensor(1.3029, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021302076056599617
loss_c:0.7233606576919556
tensor(1.2463, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018180008977651596
loss_c:0.7713062763214111
tensor(1.2592, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014259126968681812
loss_c:0.767542839050293
tensor(1.2402, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016054289415478706
loss_c:0.8212692141532898
tensor(1.2774, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018515896052122116
loss_c:0.8527193069458008
tensor(1.3052, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01585914008319378
loss_c:0.8152072429656982
tensor(1.2731, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037280868738889694
loss_c:0.8236594200134277
tensor(1.3701, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02517509087920189
loss_c:0.8988018035888672
tensor(1.3593, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02103574015200138
loss_c:0.7941218614578247
tensor(1.2837, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015672333538532257
loss_c:0.8406041860580444
tensor(1.2861, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018974103033542633
loss_c:0.7531725764274597
tensor(1.2520, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0329228974878788
loss_c:0.8335172533988953
tensor(1.3569, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024277349933981895
loss_c:0.8242709040641785
tensor(1.3142, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016676170751452446
loss_c:0.8432925939559937
tensor(1.2918, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01994812861084938
loss_c:0.9088912010192871
tensor(1.3423, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029801232740283012
loss_c:0.9268344640731812
tensor(1.3951, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02286747470498085
loss_c:0.8512417674064636
tensor(1.3230, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040057338774204254
loss_c:1.0514953136444092
tensor(1.5090, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035373903810977936
loss_c:0.8637080192565918
tensor(1.3844, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022804144769906998
loss_c:1.0782482624053955
tensor(1.4488, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016915151849389076
loss_c:0.7773930430412292
tensor(1.2562, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016906287521123886
loss_c:0.7149736285209656
tensor(1.2216, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016969451680779457
loss_c:0.8405225276947021
tensor(1.2915, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025038277730345726
loss_c:0.8695739507675171
tensor(1.3426, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02632587030529976
loss_c:0.9122644662857056
tensor(1.3719, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015234184451401234
loss_c:0.8457581996917725
tensor(1.2868, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04102463275194168
loss_c:0.9019951820373535
tensor(1.4302, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01621176116168499
loss_c:0.8753242492675781
tensor(1.3074, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016333401203155518
loss_c:0.8853518962860107
tensor(1.3135, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026204511523246765
loss_c:0.8272368311882019
tensor(1.3243, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04265508055686951
loss_c:1.0951573848724365
tensor(1.5442, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03201232850551605
loss_c:0.7857705354690552
tensor(1.3266, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015647653490304947
loss_c:0.8222943544387817
tensor(1.2757, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019326338544487953
loss_c:0.9328799247741699
tensor(1.3528, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026162033900618553
loss_c:0.840120792388916
tensor(1.3312, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014586781151592731
loss_c:0.849433422088623
tensor(1.2861, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027282506227493286
loss_c:0.9440595507621765
tensor(1.3935, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01900646835565567
loss_c:0.7501999735832214
tensor(1.2506, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03145557641983032
loss_c:0.8553962707519531
tensor(1.3626, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016727972775697708
loss_c:0.7619084715843201
tensor(1.2472, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01895468682050705
loss_c:0.7893056869506836
tensor(1.2719, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017856601625680923
loss_c:0.8010644316673279
tensor(1.2736, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05124123767018318
loss_c:0.9485334753990173
tensor(1.5000, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014830132015049458
loss_c:0.759654700756073
tensor(1.2376, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020059479400515556
loss_c:1.018519401550293
tensor(1.4033, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01594783551990986
loss_c:0.802311897277832
tensor(1.2660, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02628924325108528
loss_c:0.8200730681419373
tensor(1.3207, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02287048101425171
loss_c:0.885166347026825
tensor(1.3418, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013723489828407764
loss_c:0.8419575691223145
tensor(1.2782, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01596880331635475
loss_c:0.9038590788841248
tensor(1.3222, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019926968961954117
loss_c:0.8511062860488892
tensor(1.3102, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024143824353814125
loss_c:0.9179317951202393
tensor(1.3655, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023901477456092834
loss_c:0.8801881670951843
tensor(1.3435, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018004558980464935
loss_c:0.8171273469924927
tensor(1.2830, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015046780928969383
loss_c:0.816814661026001
tensor(1.2699, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015017453581094742
loss_c:0.7726606726646423
tensor(1.2453, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018931293860077858
loss_c:0.9005314707756042
tensor(1.3330, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022117717191576958
loss_c:0.900009036064148
tensor(1.3467, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01952459290623665
loss_c:0.904360294342041
tensor(1.3377, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01968335174024105
loss_c:0.8787134885787964
tensor(1.3242, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017635570839047432
loss_c:0.8361769914627075
tensor(1.2917, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03327036648988724
loss_c:0.8429333567619324
tensor(1.3643, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01680287905037403
loss_c:0.8047351241111755
tensor(1.2705, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03336203098297119
loss_c:0.8014793395996094
tensor(1.3419, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022234121337532997
loss_c:0.7556037902832031
tensor(1.2674, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028059225529432297
loss_c:0.7965061068534851
tensor(1.3157, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017297646030783653
loss_c:0.7985202670097351
tensor(1.2692, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017499884590506554
loss_c:0.8534466624259949
tensor(1.3005, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01598891243338585
loss_c:0.6590898633003235
tensor(1.1860, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017148412764072418
loss_c:0.7514728903770447
tensor(1.2423, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016152940690517426
loss_c:0.8141094446182251
tensor(1.2726, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029625236988067627
loss_c:0.8944650888442993
tensor(1.3771, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014783866703510284
loss_c:0.9039669036865234
tensor(1.3163, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031559158116579056
loss_c:0.8777188062667847
tensor(1.3765, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014655719511210918
loss_c:0.8194867968559265
tensor(1.2687, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03460902348160744
loss_c:1.009629249572754
tensor(1.4638, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06490759551525116
loss_c:0.971796452999115
tensor(1.5781, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04109463095664978
loss_c:0.9541351795196533
tensor(1.4617, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0196517426520586
loss_c:0.9671823382377625
tensor(1.3733, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0190525371581316
loss_c:0.7836446762084961
tensor(1.2684, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017317291349172592
loss_c:0.9909806251525879
tensor(1.3762, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015245363116264343
loss_c:0.7929356098175049
tensor(1.2569, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01526135578751564
loss_c:0.7088907957077026
tensor(1.2102, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03358825668692589
loss_c:0.8310393691062927
tensor(1.3592, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02324335277080536
loss_c:0.7525790929794312
tensor(1.2698, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019832760095596313
loss_c:0.9876243472099304
tensor(1.3854, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02117258869111538
loss_c:0.8745178580284119
tensor(1.3285, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01629260741174221
loss_c:0.767108678817749
tensor(1.2473, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022442594170570374
loss_c:1.0647410154342651
tensor(1.4398, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0139950355514884
loss_c:0.7651115655899048
tensor(1.2361, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03153948113322258
loss_c:0.9371411204338074
tensor(1.4090, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020624922588467598
loss_c:0.9779109358787537
tensor(1.3834, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034888118505477905
loss_c:0.9886244535446167
tensor(1.4522, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019482221454381943
loss_c:0.9065443277359009
tensor(1.3387, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022037269547581673
loss_c:0.8273181915283203
tensor(1.3061, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023093223571777344
loss_c:0.9906765222549438
tensor(1.4012, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015647822991013527
loss_c:1.119526982307434
tensor(1.4395, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019126204773783684
loss_c:0.7813000082969666
tensor(1.2679, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022028179839253426
loss_c:0.8563567996025085
tensor(1.3222, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03793744370341301
loss_c:0.8030033111572266
tensor(1.3630, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04310467094182968
loss_c:0.8429188132286072
tensor(1.4077, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03764890506863594
loss_c:0.8724061250686646
tensor(1.3998, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04548060521483421
loss_c:0.9085661768913269
tensor(1.4540, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01376696303486824
loss_c:0.7997264862060547
tensor(1.2549, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018084455281496048
loss_c:0.8704387545585632
tensor(1.3127, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03883092850446701
loss_c:0.9526254534721375
tensor(1.4484, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01831185445189476
loss_c:0.7595117092132568
tensor(1.2530, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08527252078056335
loss_c:1.0735654830932617
tensor(1.7165, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02052576094865799
loss_c:0.9030553698539734
tensor(1.3414, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02014785446226597
loss_c:0.8019399642944336
tensor(1.2844, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02158815786242485
loss_c:0.8924226760864258
tensor(1.3402, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029885686933994293
loss_c:0.8304266929626465
tensor(1.3419, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021370790898799896
loss_c:0.8026876449584961
tensor(1.2903, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03826938197016716
loss_c:0.7884538173675537
tensor(1.3547, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013565409928560257
loss_c:0.7484259605407715
tensor(1.2275, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011650552041828632
loss_c:0.8170212507247925
tensor(1.2569, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02426624484360218
loss_c:0.7609046697616577
tensor(1.2798, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04094207286834717
loss_c:0.9016919136047363
tensor(1.4276, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018942154943943024
loss_c:0.8624265193939209
tensor(1.3128, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01220520120114088
loss_c:0.7831867933273315
tensor(1.2409, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014080128632485867
loss_c:0.8699294924736023
tensor(1.2964, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030932782217860222
loss_c:0.8035807609558105
tensor(1.3312, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02512584812939167
loss_c:0.9429229497909546
tensor(1.3832, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02051408961415291
loss_c:0.7475332617759705
tensor(1.2564, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016387397423386574
loss_c:0.8981854319572449
tensor(1.3217, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0161496140062809
loss_c:0.8259534239768982
tensor(1.2810, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018232600763440132
loss_c:0.8461682796478271
tensor(1.3009, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01955394074320793
loss_c:0.7237130999565125
tensor(1.2390, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01480548083782196
loss_c:0.856052815914154
tensor(1.2917, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02081507444381714
loss_c:0.7872857451438904
tensor(1.2792, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.048358846455812454
loss_c:0.9500902891159058
tensor(1.4861, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021098289638757706
loss_c:0.7946641445159912
tensor(1.2844, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016507359221577644
loss_c:0.8539974093437195
tensor(1.2977, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017355000600218773
loss_c:0.6841782927513123
tensor(1.2073, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.045984022319316864
loss_c:0.8539911508560181
tensor(1.4232, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025929264724254608
loss_c:0.7927781939506531
tensor(1.3038, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014897029846906662
loss_c:0.8120622634887695
tensor(1.2675, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03801150992512703
loss_c:0.9002712965011597
tensor(1.4149, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025224409997463226
loss_c:0.7699532508850098
tensor(1.2880, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014999888837337494
loss_c:0.8352165222167969
tensor(1.2807, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031955551356077194
loss_c:0.7570465803146362
tensor(1.3094, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01696193777024746
loss_c:0.7009869813919067
tensor(1.2143, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016098840162158012
loss_c:0.7987598776817322
tensor(1.2650, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021832168102264404
loss_c:0.9640695452690125
tensor(1.3818, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0197016429156065
loss_c:0.8472537398338318
tensor(1.3074, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08050879836082458
loss_c:0.9008306860923767
tensor(1.5969, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03309642896056175
loss_c:0.7511085271835327
tensor(1.3107, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01836479641497135
loss_c:0.8386213183403015
tensor(1.2970, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014366161078214645
loss_c:0.8609534502029419
tensor(1.2926, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02806122973561287
loss_c:0.904733419418335
tensor(1.3752, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01640263758599758
loss_c:0.764593780040741
tensor(1.2472, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04550204053521156
loss_c:0.8701412081718445
tensor(1.4297, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016651930287480354
loss_c:0.7472256422042847
tensor(1.2386, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025799380615353584
loss_c:0.7043447494506836
tensor(1.2531, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017095185816287994
loss_c:0.7476479411125183
tensor(1.2407, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033153798431158066
loss_c:1.1403212547302246
tensor(1.5294, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03134628012776375
loss_c:0.8673712611198425
tensor(1.3681, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023494908586144447
loss_c:0.7587041854858398
tensor(1.2739, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016295578330755234
loss_c:0.8838707208633423
tensor(1.3140, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02248901128768921
loss_c:0.9088459014892578
tensor(1.3541, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01663745753467083
loss_c:0.7988840937614441
tensor(1.2676, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027651656419038773
loss_c:0.8948886394500732
tensor(1.3680, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020303746685385704
loss_c:0.8052842617034912
tensor(1.2866, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018091918900609016
loss_c:0.7959885001182556
tensor(1.2721, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013669410720467567
loss_c:0.7958914637565613
tensor(1.2534, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017598764970898628
loss_c:0.8806549310684204
tensor(1.3176, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014576655812561512
loss_c:0.8000301122665405
tensor(1.2594, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015108944848179817
loss_c:0.9384208917617798
tensor(1.3395, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017431320622563362
loss_c:0.7701764106750488
tensor(1.2546, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0225555207580328
loss_c:0.979636549949646
tensor(1.3942, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02090638317167759
loss_c:0.7896699905395508
tensor(1.2802, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017342230305075645
loss_c:0.8560253977775574
tensor(1.3023, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02190132811665535
loss_c:0.9943264722824097
tensor(1.3995, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01615365967154503
loss_c:0.8819577693939209
tensor(1.3117, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027009498327970505
loss_c:0.8380414843559265
tensor(1.3335, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015268570743501186
loss_c:0.89520663022995
tensor(1.3151, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01593257673084736
loss_c:0.7603053450584412
tensor(1.2422, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016909247264266014
loss_c:0.8889066576957703
tensor(1.3185, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031144382432103157
loss_c:0.7984973788261414
tensor(1.3294, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019145503640174866
loss_c:0.8682211637496948
tensor(1.3164, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06497281789779663
loss_c:1.0113924741744995
tensor(1.5957, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02421841025352478
loss_c:0.9047274589538574
tensor(1.3589, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021673880517482758
loss_c:1.0187726020812988
tensor(1.4116, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014628025703132153
loss_c:0.7474290132522583
tensor(1.2293, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014567345380783081
loss_c:0.8061127662658691
tensor(1.2618, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024157652631402016
loss_c:0.8860306143760681
tensor(1.3481, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03213881701231003
loss_c:0.9079376459121704
tensor(1.3950, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01939641684293747
loss_c:0.9192718267440796
tensor(1.3458, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022461669519543648
loss_c:1.0361965894699097
tensor(1.4242, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043270137161016464
loss_c:0.8054713606834412
tensor(1.3864, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019702322781085968
loss_c:0.9510719180107117
tensor(1.3647, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03401957452297211
loss_c:0.8886784315109253
tensor(1.3923, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021377209573984146
loss_c:0.9775046706199646
tensor(1.3865, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05730558931827545
loss_c:0.8702098727226257
tensor(1.4831, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03193341940641403
loss_c:0.8811950087547302
tensor(1.3789, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06792103499174118
loss_c:1.2649421691894531
tensor(1.7463, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02292337454855442
loss_c:0.9365159869194031
tensor(1.3704, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019603611901402473
loss_c:0.8828756213188171
tensor(1.3266, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03237457573413849
loss_c:0.921726405620575
tensor(1.4025, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015900252386927605
loss_c:0.9339417219161987
tensor(1.3389, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03582390397787094
loss_c:0.8031473159790039
tensor(1.3521, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022838812321424484
loss_c:0.8754585981369019
tensor(1.3364, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01674460619688034
loss_c:0.8692811727523804
tensor(1.3073, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012410060502588749
loss_c:0.7742769718170166
tensor(1.2372, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022109022364020348
loss_c:0.9430559873580933
tensor(1.3702, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012318111024796963
loss_c:0.8015921115875244
tensor(1.2519, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023455221205949783
loss_c:0.8787211179733276
tensor(1.3408, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019147664308547974
loss_c:0.8672496676445007
tensor(1.3164, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042082078754901886
loss_c:0.8095515966415405
tensor(1.3818, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03179940581321716
loss_c:0.9978616237640381
tensor(1.4408, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019013764336705208
loss_c:0.9390860795974731
tensor(1.3549, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02217639796435833
loss_c:0.9726154804229736
tensor(1.3864, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03597000613808632
loss_c:0.841709554195404
tensor(1.3735, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02468177117407322
loss_c:0.9305967092514038
tensor(1.3742, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015868021175265312
loss_c:0.7993888258934021
tensor(1.2660, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01909773238003254
loss_c:0.907986044883728
tensor(1.3384, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024467339739203453
loss_c:0.895561158657074
tensor(1.3543, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013276002369821072
loss_c:0.7865862846374512
tensor(1.2482, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028138240799307823
loss_c:0.8712652921676636
tensor(1.3566, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021559378132224083
loss_c:0.7897213697433472
tensor(1.2847, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037182074040174484
loss_c:0.8520509600639343
tensor(1.3843, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025168433785438538
loss_c:1.0504835844039917
tensor(1.4411, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01977645233273506
loss_c:0.837134063243866
tensor(1.3028, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017529321834445
loss_c:0.9071246981620789
tensor(1.3313, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018001848831772804
loss_c:0.8651127815246582
tensor(1.3105, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015450467355549335
loss_c:0.7463671565055847
tensor(1.2354, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02023782581090927
loss_c:0.8752084970474243
tensor(1.3253, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013971774838864803
loss_c:0.8180574178695679
tensor(1.2678, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03095158375799656
loss_c:0.8534972071647644
tensor(1.3589, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029471104964613914
loss_c:0.9147686958312988
tensor(1.3859, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027187684550881386
loss_c:0.7390109896659851
tensor(1.2809, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025102704763412476
loss_c:0.8874975442886353
tensor(1.3526, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017914749681949615
loss_c:0.8663405776023865
tensor(1.3105, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017450062558054924
loss_c:0.9237997531890869
tensor(1.3397, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014348325319588184
loss_c:0.8125512003898621
tensor(1.2660, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016471464186906815
loss_c:0.7336656451225281
tensor(1.2321, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015288027934730053
loss_c:0.8493988513946533
tensor(1.2899, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022715236991643906
loss_c:0.7755271792411804
tensor(1.2814, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01860329695045948
loss_c:0.8424736261367798
tensor(1.3002, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01642393134534359
loss_c:0.7443259954452515
tensor(1.2372, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015309353359043598
loss_c:0.8262823820114136
tensor(1.2770, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021161308512091637
loss_c:0.8724643588066101
tensor(1.3274, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03927532210946083
loss_c:0.7984263300895691
tensor(1.3652, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035467375069856644
loss_c:0.7672080993652344
tensor(1.3316, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03280976414680481
loss_c:0.6786712408065796
tensor(1.2715, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0153697170317173
loss_c:0.7319788932800293
tensor(1.2250, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013980936259031296
loss_c:0.7785002589225769
tensor(1.2445, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01922289840877056
loss_c:0.9899278879165649
tensor(1.3838, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06833703070878983
loss_c:1.1666306257247925
tensor(1.6949, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019380131736397743
loss_c:0.8328165411949158
tensor(1.2977, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016239909455180168
loss_c:0.8682443499565125
tensor(1.3037, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03280757740139961
loss_c:0.8213080167770386
tensor(1.3496, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02356458269059658
loss_c:0.8485445976257324
tensor(1.3246, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019594715908169746
loss_c:0.8698716163635254
tensor(1.3192, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028361482545733452
loss_c:0.9039947390556335
tensor(1.3761, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01986234448850155
loss_c:0.941288948059082
tensor(1.3600, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02408871240913868
loss_c:0.8215862512588501
tensor(1.3119, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03296036273241043
loss_c:0.8148490786552429
tensor(1.3465, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022593166679143906
loss_c:0.8980698585510254
tensor(1.3478, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016826722770929337
loss_c:0.9051604270935059
tensor(1.3269, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020378731191158295
loss_c:0.8457633852958679
tensor(1.3093, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015370476059615612
loss_c:0.8275940418243408
tensor(1.2776, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014158710837364197
loss_c:0.8921105265617371
tensor(1.3081, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020350785925984383
loss_c:0.9097504019737244
tensor(1.3446, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030329035595059395
loss_c:0.7560269236564636
tensor(1.3026, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01665842905640602
loss_c:0.8127374053001404
tensor(1.2749, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015448086895048618
loss_c:0.9693411588668823
tensor(1.3564, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023287314921617508
loss_c:0.9979866743087769
tensor(1.4062, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03014250099658966
loss_c:0.9455074667930603
tensor(1.4068, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03314859792590141
loss_c:0.8868988752365112
tensor(1.3874, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013287702575325966
loss_c:0.7329990267753601
tensor(1.2161, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02083754539489746
loss_c:0.8316962718963623
tensor(1.3034, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01748540997505188
loss_c:1.0267990827560425
tensor(1.3967, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01893780194222927
loss_c:1.0481058359146118
tensor(1.4147, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03489409759640694
loss_c:0.8098258376121521
tensor(1.3526, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0244585108011961
loss_c:0.7408415675163269
tensor(1.2691, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02399981953203678
loss_c:0.8441988229751587
tensor(1.3241, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0312667042016983
loss_c:0.8808072805404663
tensor(1.3760, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01845981366932392
loss_c:0.7559820413589478
tensor(1.2514, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01818176917731762
loss_c:0.9541215896606445
tensor(1.3593, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018177447840571404
loss_c:0.8885369300842285
tensor(1.3231, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036444202065467834
loss_c:0.9824323654174805
tensor(1.4546, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019152693450450897
loss_c:0.8668174743652344
tensor(1.3154, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017683222889900208
loss_c:0.9236311316490173
tensor(1.3403, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022697173058986664
loss_c:0.8028784990310669
tensor(1.2957, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023968271911144257
loss_c:0.9075309634208679
tensor(1.3588, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01863379031419754
loss_c:0.834586501121521
tensor(1.2954, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015608060173690319
loss_c:0.8297712802886963
tensor(1.2795, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02351430431008339
loss_c:0.8080384135246277
tensor(1.3022, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02700040116906166
loss_c:0.8723348379135132
tensor(1.3528, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030814750120043755
loss_c:0.9021865725517273
tensor(1.3859, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026877623051404953
loss_c:0.8320622444152832
tensor(1.3301, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022515222430229187
loss_c:0.8794333934783936
tensor(1.3370, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028048858046531677
loss_c:0.8103770017623901
tensor(1.3234, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026564184576272964
loss_c:0.8597680926322937
tensor(1.3440, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026994775980710983
loss_c:1.055341124534607
tensor(1.4532, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027119100093841553
loss_c:0.8585178256034851
tensor(1.3457, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021199194714426994
loss_c:0.8771974444389343
tensor(1.3300, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02384360320866108
loss_c:0.9597181081771851
tensor(1.3869, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01879347860813141
loss_c:0.9565743207931519
tensor(1.3630, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026898331940174103
loss_c:0.7879871129989624
tensor(1.3061, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028377026319503784
loss_c:0.7821401357650757
tensor(1.3093, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021835479885339737
loss_c:0.707724928855896
tensor(1.2400, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11947080492973328
loss_c:1.0887541770935059
tensor(1.8751, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028559405356645584
loss_c:1.146353006362915
tensor(1.5095, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021767616271972656
loss_c:0.7995290160179138
tensor(1.2901, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020182952284812927
loss_c:0.9129015803337097
tensor(1.3453, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02640351466834545
loss_c:0.9283697009086609
tensor(1.3806, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014586873352527618
loss_c:0.819334864616394
tensor(1.2704, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01931857131421566
loss_c:0.8905950784683228
tensor(1.3296, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032616421580314636
loss_c:0.8399388790130615
tensor(1.3587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027197258546948433
loss_c:0.8928760886192322
tensor(1.3644, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0180592592805624
loss_c:0.8887205123901367
tensor(1.3234, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04013052210211754
loss_c:0.9012739062309265
tensor(1.4238, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022984886541962624
loss_c:0.8118627071380615
tensor(1.3024, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022807734087109566
loss_c:0.7958383560180664
tensor(1.2930, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01613854058086872
loss_c:0.9002684354782104
tensor(1.3218, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013679410330951214
loss_c:0.8773379325866699
tensor(1.2989, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018956556916236877
loss_c:0.7918175458908081
tensor(1.2746, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04457317292690277
loss_c:0.8919520378112793
tensor(1.4370, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019965343177318573
loss_c:0.9309257864952087
tensor(1.3546, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018529385328292847
loss_c:0.8521918058395386
tensor(1.3057, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02563609927892685
loss_c:0.9499368667602539
tensor(1.3889, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02182011306285858
loss_c:0.8878320455551147
tensor(1.3390, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019662074744701385
loss_c:0.7244634032249451
tensor(1.2409, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014783596619963646
loss_c:0.7660675048828125
tensor(1.2430, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02271498180925846
loss_c:0.8436448574066162
tensor(1.3186, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02882220968604088
loss_c:1.241119146347046
tensor(1.5612, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04079500585794449
loss_c:0.7652912139892578
tensor(1.3520, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017653541639447212
loss_c:0.7526466846466064
tensor(1.2477, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02557467296719551
loss_c:1.008414387702942
tensor(1.4205, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01866486296057701
loss_c:0.9054009318351746
tensor(1.3352, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020930368453264236
loss_c:0.9287309646606445
tensor(1.3575, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021502994000911713
loss_c:0.9585269689559937
tensor(1.3761, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02230432815849781
loss_c:0.9014590978622437
tensor(1.3484, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0330178327858448
loss_c:0.8099111914634705
tensor(1.3437, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02114083804190159
loss_c:0.9321002960205078
tensor(1.3601, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04088202491402626
loss_c:0.9102425575256348
tensor(1.4316, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03947459161281586
loss_c:1.012581706047058
tensor(1.4813, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02613973058760166
loss_c:0.876311182975769
tensor(1.3509, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020606353878974915
loss_c:0.8507845401763916
tensor(1.3137, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02208332158625126
loss_c:0.8841807246208191
tensor(1.3380, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03765203431248665
loss_c:0.8384618163108826
tensor(1.3788, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017359349876642227
loss_c:0.8300435543060303
tensor(1.2888, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05572089925408363
loss_c:0.8769568204879761
tensor(1.4756, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026930050924420357
loss_c:0.9488396644592285
tensor(1.3935, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02156660333275795
loss_c:0.8302282094955444
tensor(1.3067, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018585847690701485
loss_c:0.8370043635368347
tensor(1.2979, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0317469984292984
loss_c:0.8007450103759766
tensor(1.3333, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02526720054447651
loss_c:0.9722336530685425
tensor(1.3992, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021340323612093925
loss_c:0.9650022983551025
tensor(1.3789, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016301628202199936
loss_c:0.7969341278076172
tensor(1.2667, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0308759193867445
loss_c:0.9158501029014587
tensor(1.3920, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02124791219830513
loss_c:0.9152500033378601
tensor(1.3516, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018618758767843246
loss_c:0.8884152173995972
tensor(1.3261, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01873728260397911
loss_c:0.91241455078125
tensor(1.3396, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020335614681243896
loss_c:0.7646974325180054
tensor(1.2661, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02432059682905674
loss_c:0.9758619070053101
tensor(1.3972, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02651139907538891
loss_c:0.8034429550170898
tensor(1.3129, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05765029415488243
loss_c:0.9092490077018738
tensor(1.5003, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01821325160562992
loss_c:0.8312808871269226
tensor(1.2933, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022509373724460602
loss_c:0.8865736722946167
tensor(1.3413, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02596016600728035
loss_c:1.044285535812378
tensor(1.4412, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019995035603642464
loss_c:0.8946430087089539
tensor(1.3352, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02269853837788105
loss_c:0.9788614511489868
tensor(1.3921, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013400494121015072
loss_c:0.7636301517486572
tensor(1.2367, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018141429871320724
loss_c:0.8278573751449585
tensor(1.2912, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01829627901315689
loss_c:0.7751100063323975
tensor(1.2632, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026584701612591743
loss_c:0.9236993193626404
tensor(1.3784, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036027975380420685
loss_c:0.9111512899398804
tensor(1.4111, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020538151264190674
loss_c:0.8864933848381042
tensor(1.3329, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035565342754125595
loss_c:0.8939666152000427
tensor(1.3999, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013876248151063919
loss_c:0.7741246223449707
tensor(1.2441, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016925331205129623
loss_c:0.7518112659454346
tensor(1.2447, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021843619644641876
loss_c:0.9497243762016296
tensor(1.3727, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014340538531541824
loss_c:0.9348715543746948
tensor(1.3331, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017335830256342888
loss_c:0.7623838782310486
tensor(1.2520, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018763573840260506
loss_c:0.8768326640129089
tensor(1.3201, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039157141000032425
loss_c:0.8993973731994629
tensor(1.4183, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019565246999263763
loss_c:0.8330879211425781
tensor(1.2996, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018187377601861954
loss_c:0.8363732099533081
tensor(1.2955, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014043898321688175
loss_c:0.8785066604614258
tensor(1.3009, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03576820716261864
loss_c:0.8204590678215027
tensor(1.3613, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030661193653941154
loss_c:0.7374557256698608
tensor(1.2944, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018155759200453758
loss_c:0.8720278143882751
tensor(1.3147, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02876262180507183
loss_c:0.7727717161178589
tensor(1.3055, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023625316098332405
loss_c:0.8872013092041016
tensor(1.3462, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028939461335539818
loss_c:1.049084186553955
tensor(1.4572, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01532132551074028
loss_c:0.9032807350158691
tensor(1.3196, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02382906712591648
loss_c:0.9409300684928894
tensor(1.3764, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02483415976166725
loss_c:0.7597850561141968
tensor(1.2816, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03479865565896034
loss_c:0.8696283102035522
tensor(1.3842, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027772799134254456
loss_c:0.8589848279953003
tensor(1.3484, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08606313914060593
loss_c:0.8370984792709351
tensor(1.5850, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017987554892897606
loss_c:0.7545265555381775
tensor(1.2496, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016137095168232918
loss_c:0.8202096819877625
tensor(1.2777, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029294103384017944
loss_c:0.7118636965751648
tensor(1.2741, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032083768397569656
loss_c:0.9369783401489258
tensor(1.4093, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017466777935624123
loss_c:0.8423025012016296
tensor(1.2956, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04861749708652496
loss_c:0.8949088454246521
tensor(1.4559, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019054748117923737
loss_c:0.903972327709198
tensor(1.3363, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021886873990297318
loss_c:1.094545841217041
tensor(1.4530, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025768551975488663
loss_c:0.7878402471542358
tensor(1.3007, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027125686407089233
loss_c:0.986376166343689
tensor(1.4155, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015845075249671936
loss_c:0.8232385516166687
tensor(1.2786, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01748545654118061
loss_c:0.8191105723381042
tensor(1.2832, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016018496826291084
loss_c:0.9803082346916199
tensor(1.3657, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022111153230071068
loss_c:0.9101744890213013
tensor(1.3526, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018469592556357384
loss_c:0.91374671459198
tensor(1.3393, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04211830720305443
loss_c:0.7747992277145386
tensor(1.3620, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018834669142961502
loss_c:0.8523894548416138
tensor(1.3072, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028514249250292778
loss_c:0.9268441200256348
tensor(1.3885, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022983301430940628
loss_c:0.9713296890258789
tensor(1.3898, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03430281579494476
loss_c:0.9465688467025757
tensor(1.4235, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017087994143366814
loss_c:0.7677596807479858
tensor(1.2535, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01855589635670185
loss_c:0.9485356211662292
tensor(1.3587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015146206133067608
loss_c:0.8191932439804077
tensor(1.2735, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016822483390569687
loss_c:0.8968100547790527
tensor(1.3230, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02620002068579197
loss_c:1.0439836978912354
tensor(1.4429, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021312976256012917
loss_c:0.7185910940170288
tensor(1.2443, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016911016777157784
loss_c:0.747044563293457
tensor(1.2414, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018058614805340767
loss_c:0.9138395190238953
tensor(1.3374, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016529802232980728
loss_c:0.8661198616027832
tensor(1.3048, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023546526208519936
loss_c:0.8172692060470581
tensor(1.3076, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01806502789258957
loss_c:0.8517739176750183
tensor(1.3033, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03016039729118347
loss_c:0.8112281560897827
tensor(1.3323, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015395860187709332
loss_c:0.7475103139877319
tensor(1.2348, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04264828562736511
loss_c:0.9901906847953796
tensor(1.4834, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1023285761475563
loss_c:0.8613548278808594
tensor(1.6666, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.051067907363176346
loss_c:0.9430303573608398
tensor(1.4931, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02580704540014267
loss_c:0.8534835577011108
tensor(1.3370, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012831485830247402
loss_c:0.823068380355835
tensor(1.2657, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018216801807284355
loss_c:0.8605629205703735
tensor(1.3090, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03709220513701439
loss_c:0.8670150637626648
tensor(1.3916, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01805785857141018
loss_c:0.7985986471176147
tensor(1.2744, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01867055892944336
loss_c:0.8061427474021912
tensor(1.2812, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04278768599033356
loss_c:0.8556525707244873
tensor(1.4089, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01946169324219227
loss_c:0.8642975687980652
tensor(1.3164, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04261353984475136
loss_c:0.8666138648986816
tensor(1.4140, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022624528035521507
loss_c:1.0224394798278809
tensor(1.4165, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018944749608635902
loss_c:0.7306846380233765
tensor(1.2411, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018504388630390167
loss_c:0.8473677635192871
tensor(1.3034, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02167343907058239
loss_c:0.8467041254043579
tensor(1.3161, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014960256405174732
loss_c:0.8705455660820007
tensor(1.3015, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044215127825737
loss_c:0.8399804830551147
tensor(1.4055, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025248749181628227
loss_c:0.7690896987915039
tensor(1.2882, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01594529114663601
loss_c:0.8906516432762146
tensor(1.3167, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03348540514707565
loss_c:0.9409706592559814
tensor(1.4167, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01712971366941929
loss_c:0.816796064376831
tensor(1.2809, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015571496449410915
loss_c:0.8136627674102783
tensor(1.2728, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028360042721033096
loss_c:0.9482061266899109
tensor(1.3996, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021525908261537552
loss_c:0.9503817558288574
tensor(1.3726, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035859785974025726
loss_c:1.0108699798583984
tensor(1.4651, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028572892770171165
loss_c:0.8505188822746277
tensor(1.3467, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018661459907889366
loss_c:0.9253435134887695
tensor(1.3470, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01501847617328167
loss_c:0.8193318247795105
tensor(1.2736, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026241067796945572
loss_c:0.9946694374084473
tensor(1.4164, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014514741487801075
loss_c:0.8219043612480164
tensor(1.2728, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028815262019634247
loss_c:1.0833690166473389
tensor(1.4757, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022712253034114838
loss_c:0.8496543765068054
tensor(1.3220, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021801399067044258
loss_c:0.7724547386169434
tensor(1.2759, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01538752019405365
loss_c:0.8457440137863159
tensor(1.2894, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014695638790726662
loss_c:0.8191088438034058
tensor(1.2719, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029896574094891548
loss_c:0.9457725882530212
tensor(1.4045, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025823112577199936
loss_c:1.0633751153945923
tensor(1.4520, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03244209289550781
loss_c:0.8253816366195679
tensor(1.3493, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02393866330385208
loss_c:0.9038608074188232
tensor(1.3567, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03508824482560158
loss_c:0.7930430769920349
tensor(1.3427, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019060665741562843
loss_c:0.8308253288269043
tensor(1.2964, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02018546685576439
loss_c:0.8856385946273804
tensor(1.3310, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018207838758826256
loss_c:0.9742902517318726
tensor(1.3712, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021843723952770233
loss_c:0.9052051901817322
tensor(1.3486, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019561292603611946
loss_c:0.9030965566635132
tensor(1.3379, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035196587443351746
loss_c:1.046947956085205
tensor(1.4820, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0370183028280735
loss_c:0.9409064054489136
tensor(1.4318, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026738571003079414
loss_c:0.8256396055221558
tensor(1.3258, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02810673788189888
loss_c:0.8310958743095398
tensor(1.3345, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019729027524590492
loss_c:0.892633318901062
tensor(1.3328, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028725072741508484
loss_c:0.8643290400505066
tensor(1.3552, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021457239985466003
loss_c:0.9087876081466675
tensor(1.3488, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024724872782826424
loss_c:0.9965488314628601
tensor(1.4102, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024448098614811897
loss_c:0.9704801440238953
tensor(1.3949, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021379442885518074
loss_c:0.888884425163269
tensor(1.3377, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035323675721883774
loss_c:1.0177555084228516
tensor(1.4662, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02556689828634262
loss_c:0.840177059173584
tensor(1.3289, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024177338927984238
loss_c:0.8947389125823975
tensor(1.3526, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02825428731739521
loss_c:1.1532039642333984
tensor(1.5095, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032521750777959824
loss_c:0.9193081855773926
tensor(1.4009, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019107187166810036
loss_c:0.9010833501815796
tensor(1.3347, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017756426706910133
loss_c:0.7167736291885376
tensor(1.2297, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03321923315525055
loss_c:0.7821464538574219
tensor(1.3299, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020915547385811806
loss_c:0.8766776323318481
tensor(1.3292, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020872468128800392
loss_c:0.8207058310508728
tensor(1.2988, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01882755011320114
loss_c:0.8330955505371094
tensor(1.2969, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025700503960251808
loss_c:0.9697415828704834
tensor(1.3994, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02035694010555744
loss_c:1.0018343925476074
tensor(1.3942, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024799592792987823
loss_c:0.9027771353721619
tensor(1.3595, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023129288107156754
loss_c:0.8717474937438965
tensor(1.3358, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01866159588098526
loss_c:0.8028669357299805
tensor(1.2799, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018295887857675552
loss_c:0.8694114685058594
tensor(1.3141, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03707319125533104
loss_c:0.8804534673690796
tensor(1.3993, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031812120229005814
loss_c:0.9633259773254395
tensor(1.4217, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019795233383774757
loss_c:0.7284305095672607
tensor(1.2446, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04178036376833916
loss_c:1.0350764989852905
tensor(1.5025, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021745605394244194
loss_c:0.7579032778739929
tensor(1.2686, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023958545178174973
loss_c:0.9528395533561707
tensor(1.3829, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01944947987794876
loss_c:0.8414158821105957
tensor(1.3039, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036375369876623154
loss_c:0.8412504196166992
tensor(1.3752, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04109606519341469
loss_c:0.8582919836044312
tensor(1.4043, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03965629264712334
loss_c:1.0252313613891602
tensor(1.4881, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026630323380231857
loss_c:0.8661702871322632
tensor(1.3475, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01776766963303089
loss_c:0.8282068967819214
tensor(1.2898, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023276448249816895
loss_c:0.8361470103263855
tensor(1.3172, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016979007050395012
loss_c:0.828835129737854
tensor(1.2869, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03562683239579201
loss_c:0.9106828570365906
tensor(1.4092, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018215224146842957
loss_c:0.8372355699539185
tensor(1.2966, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04408253729343414
loss_c:0.9499549865722656
tensor(1.4657, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029351187869906425
loss_c:0.961474597454071
tensor(1.4103, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029556993395090103
loss_c:0.9563666582107544
tensor(1.4084, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020816411823034286
loss_c:1.0383483171463013
tensor(1.4162, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018926523625850677
loss_c:1.003616213798523
tensor(1.3896, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040607698261737823
loss_c:1.0568633079528809
tensor(1.5085, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016341309994459152
loss_c:0.7334758639335632
tensor(1.2331, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02481740713119507
loss_c:0.9421004056930542
tensor(1.3808, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02105025202035904
loss_c:0.8705223798751831
tensor(1.3266, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020303405821323395
loss_c:0.9158643484115601
tensor(1.3479, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0185155738145113
loss_c:0.8688108325004578
tensor(1.3152, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026488006114959717
loss_c:0.8403984904289246
tensor(1.3330, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0205086637288332
loss_c:0.8987163305282593
tensor(1.3395, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03407183662056923
loss_c:0.9164538383483887
tensor(1.4055, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014271849766373634
loss_c:0.8445366621017456
tensor(1.2845, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02553594671189785
loss_c:1.1592546701431274
tensor(1.5005, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024284036830067635
loss_c:0.8756122589111328
tensor(1.3428, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02404499240219593
loss_c:0.8146803379058838
tensor(1.3091, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01899651437997818
loss_c:0.9919742345809937
tensor(1.3832, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016660291701555252
loss_c:0.7722417712211609
tensor(1.2556, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020853107795119286
loss_c:0.8523601293563843
tensor(1.3160, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016552453860640526
loss_c:0.8694552183151245
tensor(1.3072, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031673613935709
loss_c:0.7449643015861511
tensor(1.3036, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025314269587397575
loss_c:0.8053678274154663
tensor(1.3094, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017173539847135544
loss_c:0.8539075255393982
tensor(1.3013, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023808930069208145
loss_c:0.9321613311767578
tensor(1.3711, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01672729104757309
loss_c:0.8227777481079102
tensor(1.2826, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020691461861133575
loss_c:0.8349809646606445
tensor(1.3058, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030226213857531548
loss_c:0.8178547620773315
tensor(1.3367, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020206855610013008
loss_c:1.0350093841552734
tensor(1.4113, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03782591596245766
loss_c:1.015195369720459
tensor(1.4752, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032488588243722916
loss_c:0.7570655345916748
tensor(1.3135, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030937282368540764
loss_c:0.8554760813713074
tensor(1.3600, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0184638649225235
loss_c:0.8940565586090088
tensor(1.3280, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019946249201893806
loss_c:1.0062211751937866
tensor(1.3948, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035771749913692474
loss_c:0.7867670059204102
tensor(1.3434, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015424124896526337
loss_c:0.8192000389099121
tensor(1.2747, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02370407059788704
loss_c:0.9091895818710327
tensor(1.3584, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028821023181080818
loss_c:0.7208685874938965
tensor(1.2783, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02047034539282322
loss_c:0.9352384805679321
tensor(1.3587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023405304178595543
loss_c:0.93505859375
tensor(1.3711, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02408950962126255
loss_c:0.7679962515830994
tensor(1.2836, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0164262093603611
loss_c:0.8359678983688354
tensor(1.2879, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024734755977988243
loss_c:0.7847249507904053
tensor(1.2953, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028828555718064308
loss_c:0.7753579020500183
tensor(1.3076, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03664000332355499
loss_c:0.9777697324752808
tensor(1.4506, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015287486836314201
loss_c:0.846089243888855
tensor(1.2884, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019927863031625748
loss_c:0.8329565525054932
tensor(1.3010, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016899600625038147
loss_c:0.8270449042320251
tensor(1.2848, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016263267025351524
loss_c:0.7851241827011108
tensor(1.2593, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021346991881728172
loss_c:0.953144907951355
tensor(1.3724, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04053307697176933
loss_c:0.7807113528251648
tensor(1.3602, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017131514847278595
loss_c:0.8776836395263672
tensor(1.3133, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02052575722336769
loss_c:0.8661734461784363
tensor(1.3214, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01716567948460579
loss_c:0.7687107920646667
tensor(1.2538, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015460534952580929
loss_c:0.7987620234489441
tensor(1.2629, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021502189338207245
loss_c:0.8192310333251953
tensor(1.2999, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031394388526678085
loss_c:0.8845405578613281
tensor(1.3780, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022395795211195946
loss_c:0.8231912851333618
tensor(1.3058, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016327928751707077
loss_c:0.8203643560409546
tensor(1.2781, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020144380629062653
loss_c:0.8235549330711365
tensor(1.2962, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016448426991701126
loss_c:0.8469656705856323
tensor(1.2932, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018119212239980698
loss_c:1.011715054512024
tensor(1.3910, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013546018861234188
loss_c:0.7883789539337158
tensor(1.2483, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028732817620038986
loss_c:0.7151245474815369
tensor(1.2735, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024786358699202538
loss_c:0.9107987284660339
tensor(1.3642, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019471317529678345
loss_c:0.7509973049163818
tensor(1.2530, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01579829677939415
loss_c:0.8258589506149292
tensor(1.2783, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02306307852268219
loss_c:0.9421110153198242
tensor(1.3741, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03673655912280083
loss_c:0.890997052192688
tensor(1.4055, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01812141016125679
loss_c:0.9674946665763855
tensor(1.3667, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014656621031463146
loss_c:0.852569580078125
tensor(1.2879, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032829996198415756
loss_c:0.9075862765312195
tensor(1.3978, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020845143124461174
loss_c:0.8385370969772339
tensor(1.3072, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018034664914011955
loss_c:0.8201755285263062
tensor(1.2847, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01969858445227146
loss_c:0.8892928957939148
tensor(1.3302, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01597578637301922
loss_c:0.8641015887260437
tensor(1.2999, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028207045048475266
loss_c:0.7844722270965576
tensor(1.3095, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02336331270635128
loss_c:0.9125165939331055
tensor(1.3591, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02195601351559162
loss_c:0.8090454936027527
tensor(1.2956, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0201680026948452
loss_c:1.008306860923767
tensor(1.3981, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020234141498804092
loss_c:0.8602385520935059
tensor(1.3164, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021641608327627182
loss_c:0.8776494860649109
tensor(1.3322, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03492714837193489
loss_c:1.0708762407302856
tensor(1.4978, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03400914743542671
loss_c:0.7193446159362793
tensor(1.2993, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03460434824228287
loss_c:0.81997150182724
tensor(1.3576, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02879513055086136
loss_c:0.9988130331039429
tensor(1.4307, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019575325772166252
loss_c:0.7669379115104675
tensor(1.2619, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027094155550003052
loss_c:0.8392901420593262
tensor(1.3350, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029776135459542274
loss_c:0.8987739086151123
tensor(1.3797, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013227756135165691
loss_c:0.8102826476097107
tensor(1.2581, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04700062423944473
loss_c:0.8763176202774048
tensor(1.4429, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019217712804675102
loss_c:0.9168569445610046
tensor(1.3433, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0305137038230896
loss_c:0.6932277679443359
tensor(1.2693, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040796685963869095
loss_c:0.9047102332115173
tensor(1.4309, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018865851685404778
loss_c:0.9599994421005249
tensor(1.3656, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022468585520982742
loss_c:1.0341447591781616
tensor(1.4223, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020625615492463112
loss_c:0.7991089820861816
tensor(1.2846, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02808898501098156
loss_c:0.8433747291564941
tensor(1.3414, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019510287791490555
loss_c:1.0077390670776367
tensor(1.3948, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021171728149056435
loss_c:0.7838869094848633
tensor(1.2786, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017736978828907013
loss_c:0.8138782978057861
tensor(1.2803, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02951459400355816
loss_c:0.8297244906425476
tensor(1.3400, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01693442091345787
loss_c:0.9168350696563721
tensor(1.3336, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01838669367134571
loss_c:0.7881945371627808
tensor(1.2690, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020558824762701988
loss_c:0.8922457098960876
tensor(1.3357, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03681553900241852
loss_c:0.8864102363586426
tensor(1.4028, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016170157119631767
loss_c:0.7803900241851807
tensor(1.2552, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021677421405911446
loss_c:0.8158115744590759
tensor(1.2985, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01685534045100212
loss_c:1.017231822013855
tensor(1.3885, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02977651171386242
loss_c:0.8918523192405701
tensor(1.3753, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02835574746131897
loss_c:0.8709196448326111
tensor(1.3577, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02138921245932579
loss_c:0.7247457504272461
tensor(1.2471, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022309834137558937
loss_c:0.852519690990448
tensor(1.3214, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017443835735321045
loss_c:0.8381503820419312
tensor(1.2924, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017218073830008507
loss_c:0.7815539836883545
tensor(1.2603, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03321211412549019
loss_c:0.9197276830673218
tensor(1.4056, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024451982229948044
loss_c:0.8840370178222656
tensor(1.3480, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02748207189142704
loss_c:0.9529845118522644
tensor(1.3991, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015636462718248367
loss_c:0.818558394908905
tensor(1.2738, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023868625983595848
loss_c:0.9865673780441284
tensor(1.4020, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016061432659626007
loss_c:0.8656277060508728
tensor(1.3015, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015493230894207954
loss_c:0.7329756617546082
tensor(1.2260, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02807713858783245
loss_c:0.8183831572532654
tensor(1.3276, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014871497638523579
loss_c:0.7752682566642761
tensor(1.2465, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01812083274126053
loss_c:0.9569293856620789
tensor(1.3606, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022652119398117065
loss_c:0.8465478420257568
tensor(1.3195, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022921476513147354
loss_c:0.8615576028823853
tensor(1.3290, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02084798365831375
loss_c:0.7087867259979248
tensor(1.2357, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025783734396100044
loss_c:1.0188974142074585
tensor(1.4282, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020233316347002983
loss_c:0.7816564440727234
tensor(1.2732, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02497466281056404
loss_c:0.7771036028862
tensor(1.2914, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013820962980389595
loss_c:0.8067070841789246
tensor(1.2588, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02294952981173992
loss_c:0.7864159345626831
tensor(1.2876, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02588438242673874
loss_c:0.8363914489746094
tensor(1.3281, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022336002439260483
loss_c:1.0103039741516113
tensor(1.4086, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022135328501462936
loss_c:0.8545224070549011
tensor(1.3216, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026901818811893463
loss_c:0.7237216234207153
tensor(1.2703, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018743092194199562
loss_c:0.8426003456115723
tensor(1.3001, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017963334918022156
loss_c:0.8778226375579834
tensor(1.3161, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01899406500160694
loss_c:0.7483012080192566
tensor(1.2489, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02042820118367672
loss_c:0.818747878074646
tensor(1.2942, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029697664082050323
loss_c:0.8767690658569336
tensor(1.3674, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024335158988833427
loss_c:0.9259551763534546
tensor(1.3710, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017027245834469795
loss_c:0.9781946539878845
tensor(1.3676, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03502360358834267
loss_c:0.9156457781791687
tensor(1.4126, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0167707372456789
loss_c:0.8153070211410522
tensor(1.2761, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01739427074790001
loss_c:0.8674988746643066
tensor(1.3078, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025296736508607864
loss_c:0.9680061340332031
tensor(1.3986, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017114266753196716
loss_c:0.8357283473014832
tensor(1.2889, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04219481721520424
loss_c:0.8778308629989624
tensor(1.4236, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021488770842552185
loss_c:0.9419649839401245
tensor(1.3672, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025568554177880287
loss_c:1.0670197010040283
tensor(1.4545, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022987838834524155
loss_c:0.8619667887687683
tensor(1.3295, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021398095414042473
loss_c:0.9402475357055664
tensor(1.3657, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026101063936948776
loss_c:0.8382878303527832
tensor(1.3302, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016212109476327896
loss_c:0.798515260219574
tensor(1.2644, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026275139302015305
loss_c:0.8008014559745789
tensor(1.3103, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033640872687101364
loss_c:0.8155025243759155
tensor(1.3510, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029999559745192528
loss_c:0.8266488909721375
tensor(1.3410, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015026510693132877
loss_c:0.7454214096069336
tensor(1.2300, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02266744151711464
loss_c:0.9775039553642273
tensor(1.3918, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018385345116257668
loss_c:0.9173919558525085
tensor(1.3397, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024908682331442833
loss_c:0.9377574920654297
tensor(1.3797, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024599403142929077
loss_c:0.8794155120849609
tensor(1.3462, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022138653323054314
loss_c:0.8184722661972046
tensor(1.3018, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021264033392071724
loss_c:1.020583152770996
tensor(1.4092, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02478008344769478
loss_c:0.8754215240478516
tensor(1.3448, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018642179667949677
loss_c:0.8321196436882019
tensor(1.2939, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01421803142875433
loss_c:0.9086073637008667
tensor(1.3164, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019161976873874664
loss_c:0.8532294034957886
tensor(1.3078, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02600381150841713
loss_c:0.7226158976554871
tensor(1.2663, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020871534943580627
loss_c:0.7730717658996582
tensor(1.2713, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01709931530058384
loss_c:0.7370395064353943
tensor(1.2348, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016571884974837303
loss_c:0.8085043430328369
tensor(1.2717, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017189469188451767
loss_c:0.8769533038139343
tensor(1.3120, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027272101491689682
loss_c:0.7944191694259644
tensor(1.3113, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02715321257710457
loss_c:0.7869431376457214
tensor(1.3067, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01508036907762289
loss_c:0.8096155524253845
tensor(1.2655, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03364939987659454
loss_c:0.9458218812942505
tensor(1.4231, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02574751153588295
loss_c:0.7805504202842712
tensor(1.2968, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08195763826370239
loss_c:0.9918451309204102
tensor(1.6634, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016281990334391594
loss_c:0.7592843770980835
tensor(1.2431, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022251149639487267
loss_c:0.7932853698730469
tensor(1.2883, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023505784571170807
loss_c:0.8207701444625854
tensor(1.3090, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017905494198203087
loss_c:0.900530219078064
tensor(1.3284, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02037125825881958
loss_c:0.7410723567008972
tensor(1.2511, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02278723567724228
loss_c:0.936766505241394
tensor(1.3700, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019478486850857735
loss_c:0.9552173614501953
tensor(1.3658, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021021196618676186
loss_c:0.8791183233261108
tensor(1.3304, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019773712381720543
loss_c:0.8963043689727783
tensor(1.3344, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01901080273091793
loss_c:0.85394686460495
tensor(1.3076, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02695349045097828
loss_c:0.9245466589927673
tensor(1.3816, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024229831993579865
loss_c:0.9243631362915039
tensor(1.3695, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024537140503525734
loss_c:0.888889491558075
tensor(1.3512, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02690514363348484
loss_c:0.7887069582939148
tensor(1.3061, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02582811936736107
loss_c:0.8583980798721313
tensor(1.3399, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03448333963751793
loss_c:0.8719808459281921
tensor(1.3853, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02288876660168171
loss_c:0.7601219415664673
tensor(1.2727, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01644524559378624
loss_c:0.7574801445007324
tensor(1.2431, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04944679141044617
loss_c:0.8989158868789673
tensor(1.4654, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020775096490979195
loss_c:0.8538113832473755
tensor(1.3154, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023760652169585228
loss_c:0.9577323794364929
tensor(1.3859, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020830294117331505
loss_c:0.7907690405845642
tensor(1.2807, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01877428963780403
loss_c:0.9400434494018555
tensor(1.3545, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020456938073039055
loss_c:0.8594710230827332
tensor(1.3172, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015079813078045845
loss_c:0.8343819379806519
tensor(1.2800, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0674702525138855
loss_c:0.8864121437072754
tensor(1.5359, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023623766377568245
loss_c:0.8310002088546753
tensor(1.3151, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04203839600086212
loss_c:0.8407882452011108
tensor(1.4001, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017854906618595123
loss_c:0.6988762617111206
tensor(1.2172, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032268233597278595
loss_c:0.8015956878662109
tensor(1.3360, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03155387192964554
loss_c:0.9573749303817749
tensor(1.4192, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017099233344197273
loss_c:0.786639392375946
tensor(1.2627, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025384120643138885
loss_c:0.7781565189361572
tensor(1.2934, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021914556622505188
loss_c:0.8347043991088867
tensor(1.3099, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017643772065639496
loss_c:0.8679308891296387
tensor(1.3102, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014237622730433941
loss_c:0.8902270197868347
tensor(1.3081, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05931505188345909
loss_c:0.9149179458618164
tensor(1.5136, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015171512961387634
loss_c:0.8487415313720703
tensor(1.2891, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03177770599722862
loss_c:0.7730205059051514
tensor(1.3175, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018702030181884766
loss_c:0.7932388782501221
tensor(1.2734, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05828246846795082
loss_c:0.8487889170646667
tensor(1.4716, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014697092585265636
loss_c:0.8079859614372253
tensor(1.2647, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02020830474793911
loss_c:0.8457310199737549
tensor(1.3090, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017848176881670952
loss_c:0.8074676394462585
tensor(1.2778, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038129597902297974
loss_c:0.9399227499961853
tensor(1.4368, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0196914691478014
loss_c:1.023153305053711
tensor(1.4057, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015605038963258266
loss_c:0.8319794535636902
tensor(1.2821, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014224610291421413
loss_c:0.8506795763969421
tensor(1.2868, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020780328661203384
loss_c:0.797065258026123
tensor(1.2844, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018102917820215225
loss_c:0.8468138575553894
tensor(1.3009, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02740267850458622
loss_c:0.9301540851593018
tensor(1.3862, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020833253860473633
loss_c:0.8338696360588074
tensor(1.3051, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01867453008890152
loss_c:0.856956958770752
tensor(1.3089, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03474872186779976
loss_c:0.8744688034057617
tensor(1.3862, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019270142540335655
loss_c:0.9182261228561401
tensor(1.3454, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03114737570285797
loss_c:0.8137590885162354
tensor(1.3373, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029167210683226585
loss_c:0.9294793605804443
tensor(1.3933, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018200285732746124
loss_c:0.8270210027694702
tensor(1.2902, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013880561105906963
loss_c:0.8230472803115845
tensor(1.2697, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06826705485582352
loss_c:0.8909876346588135
tensor(1.5367, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04258256033062935
loss_c:1.0929545164108276
tensor(1.5405, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036010824143886566
loss_c:0.9580689668655396
tensor(1.4378, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03217282518744469
loss_c:0.8493279814720154
tensor(1.3613, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027507852762937546
loss_c:0.8879956603050232
tensor(1.3631, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014976431615650654
loss_c:0.8399337530136108
tensor(1.2842, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021404970437288284
loss_c:0.9874547719955444
tensor(1.3926, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020684968680143356
loss_c:1.0023506879806519
tensor(1.3978, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015011832118034363
loss_c:0.719035804271698
tensor(1.2178, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08998312056064606
loss_c:1.3077055215835571
tensor(1.8542, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015717817470431328
loss_c:0.8246855735778809
tensor(1.2792, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022169243544340134
loss_c:0.8413226008415222
tensor(1.3152, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015338524244725704
loss_c:0.8992547988891602
tensor(1.3188, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026368863880634308
loss_c:0.7461566925048828
tensor(1.2804, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022579271346330643
loss_c:1.0037530660629272
tensor(1.4060, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015263890847563744
loss_c:0.9226016998291016
tensor(1.3314, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01681673526763916
loss_c:0.7730551958084106
tensor(1.2560, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017592642456293106
loss_c:0.7595834136009216
tensor(1.2519, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014613427221775055
loss_c:0.7114652991294861
tensor(1.2133, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03199639916419983
loss_c:0.9125509262084961
tensor(1.3947, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02134057693183422
loss_c:0.8801869750022888
tensor(1.3331, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015475929714739323
loss_c:0.8054999709129333
tensor(1.2681, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015982015058398247
loss_c:0.7905690670013428
tensor(1.2620, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09111900627613068
loss_c:0.8316601514816284
tensor(1.5954, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01878713071346283
loss_c:0.8041644096374512
tensor(1.2810, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026644432917237282
loss_c:0.9085502624511719
tensor(1.3705, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015245962888002396
loss_c:0.8507043123245239
tensor(1.2919, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020617028698325157
loss_c:0.7359577417373657
tensor(1.2512, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02195356786251068
loss_c:0.7595571279525757
tensor(1.2696, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02467988058924675
loss_c:0.8529372215270996
tensor(1.3320, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036851413547992706
loss_c:1.1148914098739624
tensor(1.5259, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026879100129008293
loss_c:1.2000669240951538
tensor(1.5315, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021698221564292908
loss_c:0.7729658484458923
tensor(1.2759, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013133457861840725
loss_c:0.7524834871292114
tensor(1.2294, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03557712584733963
loss_c:0.8993000984191895
tensor(1.4023, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023629534989595413
loss_c:0.8426626920700073
tensor(1.3220, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01884274184703827
loss_c:0.9301220774650574
tensor(1.3502, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.058430079370737076
loss_c:0.9078041911125183
tensor(1.5013, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02089213952422142
loss_c:0.9244617819786072
tensor(1.3556, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021860113367438316
loss_c:0.905596911907196
tensor(1.3492, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03014725260436535
loss_c:0.8781646490097046
tensor(1.3683, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040132831782102585
loss_c:0.9125756025314331
tensor(1.4282, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02226720191538334
loss_c:0.7983087301254272
tensor(1.2922, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021043406799435616
loss_c:0.87444007396698
tensor(1.3289, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02164568565785885
loss_c:1.0055676698684692
tensor(1.4030, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03216501697897911
loss_c:0.7908994555473328
tensor(1.3289, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018323076888918877
loss_c:0.8746809363365173
tensor(1.3179, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03848782181739807
loss_c:0.816776692867279
tensor(1.3689, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022123228758573532
loss_c:0.8815401792526245
tensor(1.3372, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02687785215675831
loss_c:0.9234597086906433
tensor(1.3796, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02086484245955944
loss_c:0.8620654940605164
tensor(1.3214, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046946294605731964
loss_c:0.9168776869773865
tensor(1.4582, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02040397934615612
loss_c:0.8408133387565613
tensor(1.3080, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016906628385186195
loss_c:0.8973330855369568
tensor(1.3245, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030735809355974197
loss_c:0.9153651595115662
tensor(1.3909, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01954982988536358
loss_c:0.9467835426330566
tensor(1.3623, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021483758464455605
loss_c:0.7737404108047485
tensor(1.2758, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038480862975120544
loss_c:0.9440531730651855
tensor(1.4383, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04161880165338516
loss_c:1.030019760131836
tensor(1.4979, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025836721062660217
loss_c:0.787013053894043
tensor(1.3009, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01638532429933548
loss_c:0.7978925108909607
tensor(1.2683, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019613569602370262
loss_c:0.8848673105239868
tensor(1.3288, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0164337195456028
loss_c:0.7044792175292969
tensor(1.2176, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01604876108467579
loss_c:0.7987276315689087
tensor(1.2673, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02965536154806614
loss_c:0.7765916585922241
tensor(1.3108, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025344889611005783
loss_c:1.0008671283721924
tensor(1.4155, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05920358747243881
loss_c:0.9362082481384277
tensor(1.5189, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014971401542425156
loss_c:0.8357387781143188
tensor(1.2830, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016446560621261597
loss_c:0.9435874819755554
tensor(1.3479, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04809506982564926
loss_c:0.8152486085891724
tensor(1.4073, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013499019667506218
loss_c:0.8336608409881592
tensor(1.2758, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02144021727144718
loss_c:0.8603546023368835
tensor(1.3229, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02853245660662651
loss_c:0.9080928564071655
tensor(1.3780, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02182317152619362
loss_c:0.9492241740226746
tensor(1.3730, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03191700205206871
loss_c:0.8242713212966919
tensor(1.3460, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01926114596426487
loss_c:0.7931594252586365
tensor(1.2772, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035132791846990585
loss_c:0.8695303201675415
tensor(1.3839, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015966292470693588
loss_c:0.681816577911377
tensor(1.2029, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022337431088089943
loss_c:0.70770663022995
tensor(1.2430, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021638693287968636
loss_c:0.965126633644104
tensor(1.3810, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0236506424844265
loss_c:0.868043839931488
tensor(1.3361, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017027059569954872
loss_c:0.8576779365539551
tensor(1.3032, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018878400325775146
loss_c:0.9956177473068237
tensor(1.3865, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0297728069126606
loss_c:0.8934852480888367
tensor(1.3752, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02780885063111782
loss_c:0.8885018825531006
tensor(1.3644, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02830522134900093
loss_c:0.8466222286224365
tensor(1.3435, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017476191744208336
loss_c:0.8165128231048584
tensor(1.2823, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016836609691381454
loss_c:0.7050681114196777
tensor(1.2184, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04709349572658539
loss_c:0.7490653991699219
tensor(1.3675, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04068215191364288
loss_c:0.8872172236442566
tensor(1.4170, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01678582653403282
loss_c:0.7794826030731201
tensor(1.2589, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01631956174969673
loss_c:0.8562099933624268
tensor(1.2992, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023152949288487434
loss_c:0.9652131795883179
tensor(1.3875, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02305830456316471
loss_c:0.8348839282989502
tensor(1.3153, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01253362838178873
loss_c:0.7632236480712891
tensor(1.2321, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03361956775188446
loss_c:0.801013708114624
tensor(1.3403, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01946563832461834
loss_c:0.9182348251342773
tensor(1.3463, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03350260481238365
loss_c:0.9704774618148804
tensor(1.4335, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020551370456814766
loss_c:0.8003430366516113
tensor(1.2857, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031322576105594635
loss_c:0.9400169253349304
tensor(1.4077, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04595145955681801
loss_c:0.956307590007782
tensor(1.4775, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04072358459234238
loss_c:0.9701181650161743
tensor(1.4634, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.052814166992902756
loss_c:0.9333123564720154
tensor(1.4931, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015868540853261948
loss_c:0.8627578020095825
tensor(1.3008, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014851566404104233
loss_c:0.7690666913986206
tensor(1.2450, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021547583863139153
loss_c:0.7652090787887573
tensor(1.2706, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02130374126136303
loss_c:0.9906730651855469
tensor(1.3940, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03793018311262131
loss_c:0.7679198980331421
tensor(1.3397, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021513037383556366
loss_c:0.9255659580230713
tensor(1.3590, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016115017235279083
loss_c:0.9344574809074402
tensor(1.3416, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030631758272647858
loss_c:0.807325005531311
tensor(1.3313, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015490971505641937
loss_c:0.8821290731430054
tensor(1.3102, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029450364410877228
loss_c:0.8302024602890015
tensor(1.3391, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07710063457489014
loss_c:0.8655542135238647
tensor(1.5549, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02886519767343998
loss_c:0.8114328384399414
tensor(1.3263, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020344402641057968
loss_c:0.8483940958976746
tensor(1.3117, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026080871000885963
loss_c:0.7926980257034302
tensor(1.3045, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0192763302475214
loss_c:0.8813947439193726
tensor(1.3256, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023658057674765587
loss_c:0.8979141712188721
tensor(1.3526, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029931340366601944
loss_c:0.9830806255340576
tensor(1.4252, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015725404024124146
loss_c:0.7879618406295776
tensor(1.2596, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021139204502105713
loss_c:0.8825823664665222
tensor(1.3339, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017676658928394318
loss_c:0.8561004400253296
tensor(1.3052, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016914498060941696
loss_c:0.8605713248252869
tensor(1.3045, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017615798860788345
loss_c:0.7924267053604126
tensor(1.2698, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03290386497974396
loss_c:0.9290492534637451
tensor(1.4076, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013257203623652458
loss_c:0.8746692538261414
tensor(1.2972, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022122187539935112
loss_c:0.7295546531677246
tensor(1.2535, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020793979987502098
loss_c:0.988519549369812
tensor(1.3908, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023421335965394974
loss_c:0.7362222671508789
tensor(1.2624, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0112689808011055
loss_c:0.7813010215759277
tensor(1.2372, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022466661408543587
loss_c:0.9424827098846436
tensor(1.3722, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020982136949896812
loss_c:0.8873202204704285
tensor(1.3356, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027567226439714432
loss_c:0.779685378074646
tensor(1.3034, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023060819134116173
loss_c:0.9535569548606873
tensor(1.3807, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01980690285563469
loss_c:0.8036984801292419
tensor(1.2845, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018562551587820053
loss_c:0.9217063784599304
tensor(1.3444, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0199052095413208
loss_c:0.9122948050498962
tensor(1.3447, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017241094261407852
loss_c:0.8026167750358582
tensor(1.2730, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020136339589953423
loss_c:0.8623983263969421
tensor(1.3181, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014310605823993683
loss_c:0.7014265060424805
tensor(1.2047, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0465015172958374
loss_c:1.0692853927612305
tensor(1.5432, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030349504202604294
loss_c:0.8092241287231445
tensor(1.3316, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020113594830036163
loss_c:1.0136034488677979
tensor(1.4013, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03241974115371704
loss_c:0.8333615064620972
tensor(1.3537, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029027549549937248
loss_c:0.8014687895774841
tensor(1.3218, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04046628996729851
loss_c:1.0160170793533325
tensor(1.4886, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01860443502664566
loss_c:0.7202393412590027
tensor(1.2330, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029639171436429024
loss_c:1.0779417753219604
tensor(1.4769, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025450896471738815
loss_c:0.8749260902404785
tensor(1.3472, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014816883951425552
loss_c:0.8420374393463135
tensor(1.2842, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026729309931397438
loss_c:0.7985228896141052
tensor(1.3105, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019492099061608315
loss_c:0.769320011138916
tensor(1.2639, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03563228249549866
loss_c:0.9286617040634155
tensor(1.4198, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02146013267338276
loss_c:0.9080104827880859
tensor(1.3486, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030756527557969093
loss_c:0.7112709879875183
tensor(1.2796, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020901784300804138
loss_c:1.035590410232544
tensor(1.4164, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02403223142027855
loss_c:1.0084092617034912
tensor(1.4147, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023381054401397705
loss_c:0.7475227117538452
tensor(1.2684, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0408225879073143
loss_c:1.0226821899414062
tensor(1.4934, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046361587941646576
loss_c:0.8395330309867859
tensor(1.4160, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023014603182673454
loss_c:0.8698203563690186
tensor(1.3341, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03784186765551567
loss_c:0.9567664861679077
tensor(1.4443, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030614469200372696
loss_c:0.9166392087936401
tensor(1.3918, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025489190593361855
loss_c:0.9447516202926636
tensor(1.3856, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01826658844947815
loss_c:0.8990559577941895
tensor(1.3303, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027826227247714996
loss_c:0.8336337804794312
tensor(1.3345, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01829373463988304
loss_c:0.7706643342971802
tensor(1.2602, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024460330605506897
loss_c:0.7796012759208679
tensor(1.2909, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032368745654821396
loss_c:0.9632546901702881
tensor(1.4244, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013981038704514503
loss_c:0.7976815104484558
tensor(1.2571, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021396463736891747
loss_c:0.7922147512435913
tensor(1.2851, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017689285799860954
loss_c:0.8875203132629395
tensor(1.3217, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016493575647473335
loss_c:0.884758472442627
tensor(1.3152, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03159549459815025
loss_c:0.8326758742332458
tensor(1.3497, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025796037167310715
loss_c:1.1210167407989502
tensor(1.4833, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023198192939162254
loss_c:0.9463833570480347
tensor(1.3769, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040542710572481155
loss_c:1.0767772197723389
tensor(1.5206, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02327985130250454
loss_c:0.9488999843597412
tensor(1.3785, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020387237891554832
loss_c:0.9283367991447449
tensor(1.3552, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041310977190732956
loss_c:0.7557578086853027
tensor(1.3485, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01711553893983364
loss_c:0.8272144198417664
tensor(1.2864, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01662994921207428
loss_c:0.7246341109275818
tensor(1.2286, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019242839887738228
loss_c:0.8334317207336426
tensor(1.2987, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016012415289878845
loss_c:0.7947471141815186
tensor(1.2642, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022184092551469803
loss_c:1.0228586196899414
tensor(1.4141, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01981974020600319
loss_c:0.7932500243186951
tensor(1.2792, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016328375786542892
loss_c:0.8783825635910034
tensor(1.3109, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0171040128916502
loss_c:0.872696042060852
tensor(1.3110, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029710885137319565
loss_c:0.9939769506454468
tensor(1.4299, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07048211991786957
loss_c:0.8882233500480652
tensor(1.5439, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020539043471217155
loss_c:0.8068380355834961
tensor(1.2895, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018848899751901627
loss_c:1.025549292564392
tensor(1.4014, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02332260273396969
loss_c:1.1676628589630127
tensor(1.4975, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027604063972830772
loss_c:0.9134335517883301
tensor(1.3772, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025089040398597717
loss_c:0.9282209873199463
tensor(1.3746, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016433555632829666
loss_c:0.9287476539611816
tensor(1.3386, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023414088413119316
loss_c:0.9242899417877197
tensor(1.3654, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022668832913041115
loss_c:0.830152690410614
tensor(1.3113, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01761273294687271
loss_c:0.781218409538269
tensor(1.2636, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02739809639751911
loss_c:0.8848525881767273
tensor(1.3608, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06979858130216599
loss_c:0.9481804370880127
tensor(1.5734, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022992869839072227
loss_c:0.8498861789703369
tensor(1.3234, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0613822415471077
loss_c:0.8052884340286255
tensor(1.4603, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01455709058791399
loss_c:0.8587731122970581
tensor(1.2929, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02821935899555683
loss_c:0.9129785299301147
tensor(1.3793, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015461149625480175
loss_c:0.8688011169433594
tensor(1.3023, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018927769735455513
loss_c:0.8454207181930542
tensor(1.3042, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03012661263346672
loss_c:0.8019212484359741
tensor(1.3272, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020375091582536697
loss_c:0.8248696327209473
tensor(1.2991, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015825215727090836
loss_c:0.7823674082756042
tensor(1.2573, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03846953809261322
loss_c:1.0833327770233154
tensor(1.5140, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017842059955000877
loss_c:0.9483757019042969
tensor(1.3554, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02827010117471218
loss_c:1.1406834125518799
tensor(1.5027, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018915828317403793
loss_c:0.8856922388076782
tensor(1.3260, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015550979413092136
loss_c:0.7869517803192139
tensor(1.2587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01880314014852047
loss_c:0.7413288950920105
tensor(1.2475, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033660728484392166
loss_c:0.908724308013916
tensor(1.3996, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03026251122355461
loss_c:0.7905985713005066
tensor(1.3217, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025523001328110695
loss_c:0.8738465309143066
tensor(1.3470, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034790921956300735
loss_c:0.8929468393325806
tensor(1.3958, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016661522909998894
loss_c:0.8150007128715515
tensor(1.2784, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017126355320215225
loss_c:0.7843524813652039
tensor(1.2637, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028261549770832062
loss_c:0.980336606502533
tensor(1.4159, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03480366989970207
loss_c:0.7909320592880249
tensor(1.3406, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036863431334495544
loss_c:0.7840757369995117
tensor(1.3454, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04325573891401291
loss_c:0.8120676875114441
tensor(1.3871, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024370301514863968
loss_c:0.9739007353782654
tensor(1.3964, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028527839109301567
loss_c:0.8132004737854004
tensor(1.3265, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03167868033051491
loss_c:0.8976526260375977
tensor(1.3853, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03686072304844856
loss_c:0.9003018140792847
tensor(1.4082, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019498853012919426
loss_c:0.8596041202545166
tensor(1.3143, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01974124275147915
loss_c:0.9026379585266113
tensor(1.3388, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02462141402065754
loss_c:0.9020638465881348
tensor(1.3586, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037906061857938766
loss_c:0.8461393117904663
tensor(1.3828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027652693912386894
loss_c:0.783413290977478
tensor(1.3065, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021240977570414543
loss_c:0.8610226511955261
tensor(1.3224, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023025210946798325
loss_c:0.9132701754570007
tensor(1.3582, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019760005176067352
loss_c:0.8505160212516785
tensor(1.3106, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023165063932538033
loss_c:0.8692189455032349
tensor(1.3347, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017496604472398758
loss_c:0.9125067591667175
tensor(1.3351, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028095128014683723
loss_c:0.8124631643295288
tensor(1.3240, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014903727918863297
loss_c:0.8493169546127319
tensor(1.2900, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014468895271420479
loss_c:0.7672021389007568
tensor(1.2433, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019079923629760742
loss_c:0.9721338152885437
tensor(1.3741, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017704352736473083
loss_c:0.7374815940856934
tensor(1.2402, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022012336179614067
loss_c:0.8869218230247498
tensor(1.3396, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019778089597821236
loss_c:0.860396146774292
tensor(1.3158, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02881014347076416
loss_c:0.8113460540771484
tensor(1.3263, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01161146443337202
loss_c:0.8181816935539246
tensor(1.2587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019546499475836754
loss_c:0.8786203265190125
tensor(1.3247, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020841721445322037
loss_c:0.844005286693573
tensor(1.3110, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01503247581422329
loss_c:0.8536102175712585
tensor(1.2920, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017605282366275787
loss_c:0.9095669984817505
tensor(1.3334, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041483260691165924
loss_c:0.8776916265487671
tensor(1.4160, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01573002152144909
loss_c:0.8466942310333252
tensor(1.2908, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01895732246339321
loss_c:0.9131070971488953
tensor(1.3408, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014667189680039883
loss_c:0.7747758626937866
tensor(1.2467, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014051520265638828
loss_c:0.874138355255127
tensor(1.2986, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021443437784910202
loss_c:0.8134490251541138
tensor(1.2964, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019450562074780464
loss_c:0.967998743057251
tensor(1.3729, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024126296862959862
loss_c:0.9511033892631531
tensor(1.3835, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029925968497991562
loss_c:1.0561234951019287
tensor(1.4661, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019770635291934013
loss_c:0.7759301066398621
tensor(1.2685, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017482591792941093
loss_c:0.9771583080291748
tensor(1.3693, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016550639644265175
loss_c:0.7947341799736023
tensor(1.2650, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02347542904317379
loss_c:0.9101058840751648
tensor(1.3581, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018127741292119026
loss_c:0.8336324691772461
tensor(1.2930, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024897314608097076
loss_c:0.8573386073112488
tensor(1.3352, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036061421036720276
loss_c:0.8002857565879822
tensor(1.3523, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014964668080210686
loss_c:0.854852557182312
tensor(1.2908, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015643995255231857
loss_c:0.8391731977462769
tensor(1.2851, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02123492956161499
loss_c:0.7987059354782104
tensor(1.2871, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016208268702030182
loss_c:0.8363093733787537
tensor(1.2859, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03894379734992981
loss_c:0.9489505290985107
tensor(1.4469, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03617094084620476
loss_c:0.906704843044281
tensor(1.4117, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025358397513628006
loss_c:0.8891632556915283
tensor(1.3548, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017986081540584564
loss_c:0.9353537559509277
tensor(1.3480, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019154425710439682
loss_c:0.8659197688102722
tensor(1.3149, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02688037045300007
loss_c:0.7670018076896667
tensor(1.2944, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0361027792096138
loss_c:0.8374878764152527
tensor(1.3734, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01483136136084795
loss_c:0.7999563217163086
tensor(1.2598, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03702173009514809
loss_c:0.8255061507225037
tensor(1.3708, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03593498468399048
loss_c:0.8299950361251831
tensor(1.3685, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020706698298454285
loss_c:0.810870885848999
tensor(1.2914, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02129434421658516
loss_c:0.8279830813407898
tensor(1.3034, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019466446712613106
loss_c:0.7869150042533875
tensor(1.2728, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023497983813285828
loss_c:0.7887568473815918
tensor(1.2914, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03451140224933624
loss_c:0.9367189407348633
tensor(1.4209, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024292679503560066
loss_c:0.8707884550094604
tensor(1.3400, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03832142800092697
loss_c:0.6783987879753113
tensor(1.2949, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016876142472028732
loss_c:0.7941507697105408
tensor(1.2655, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021491151303052902
loss_c:0.8446472883224487
tensor(1.3135, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017606325447559357
loss_c:0.894134521484375
tensor(1.3240, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03266782686114311
loss_c:0.8705908060073853
tensor(1.3762, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01724267192184925
loss_c:0.783845841884613
tensor(1.2614, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017178835347294807
loss_c:0.7865471243858337
tensor(1.2626, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019146712496876717
loss_c:0.8927230834960938
tensor(1.3300, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031334441155195236
loss_c:0.9205889105796814
tensor(1.3982, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024468019604682922
loss_c:0.7615097761154175
tensor(1.2802, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01611722819507122
loss_c:0.735188901424408
tensor(1.2294, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021421123296022415
loss_c:1.11786687374115
tensor(1.4651, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0245621670037508
loss_c:0.8501319885253906
tensor(1.3298, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020567944273352623
loss_c:0.790876030921936
tensor(1.2795, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015785416588187218
loss_c:0.967747151851654
tensor(1.3572, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019313262775540352
loss_c:0.7710509300231934
tensor(1.2630, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02726111002266407
loss_c:0.8771218061447144
tensor(1.3565, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022258056327700615
loss_c:0.906730592250824
tensor(1.3513, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016510510817170143
loss_c:0.8570759296417236
tensor(1.2987, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01507170032709837
loss_c:0.9073294401168823
tensor(1.3203, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03793274611234665
loss_c:0.8047239184379578
tensor(1.3628, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03092438168823719
loss_c:0.8702220916748047
tensor(1.3687, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022211415693163872
loss_c:0.8301256895065308
tensor(1.3084, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016451211646199226
loss_c:0.894660472869873
tensor(1.3192, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020807836204767227
loss_c:0.8427941203117371
tensor(1.3094, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01978454180061817
loss_c:0.9369730949401855
tensor(1.3572, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0202633123844862
loss_c:0.8203414678573608
tensor(1.2945, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024910546839237213
loss_c:0.786638617515564
tensor(1.2961, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019684093073010445
loss_c:0.8457506895065308
tensor(1.3061, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021292870864272118
loss_c:0.7949606776237488
tensor(1.2849, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018374716863036156
loss_c:0.8613228797912598
tensor(1.3089, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03701052442193031
loss_c:0.8949406147003174
tensor(1.4093, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019608652219176292
loss_c:0.9682895541191101
tensor(1.3738, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021639714017510414
loss_c:0.8692264556884766
tensor(1.3276, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017210431396961212
loss_c:0.9106359481811523
tensor(1.3312, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018112093210220337
loss_c:0.7631072998046875
tensor(1.2532, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01658800058066845
loss_c:0.8562314510345459
tensor(1.2982, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01628699153661728
loss_c:0.8102502226829529
tensor(1.2713, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016912581399083138
loss_c:0.815708339214325
tensor(1.2771, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02504025213420391
loss_c:0.7272894382476807
tensor(1.2638, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02185690402984619
loss_c:0.7310449481010437
tensor(1.2518, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017098605632781982
loss_c:0.7240160703659058
tensor(1.2268, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021266363561153412
loss_c:0.912259578704834
tensor(1.3498, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024457350373268127
loss_c:1.016707420349121
tensor(1.4221, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012744860723614693
loss_c:0.7541619539260864
tensor(1.2240, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019141819328069687
loss_c:0.7836653590202332
tensor(1.2688, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02357092685997486
loss_c:0.955927312374115
tensor(1.3844, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02765331044793129
loss_c:0.7986034154891968
tensor(1.3151, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02033630572259426
loss_c:0.72308349609375
tensor(1.2403, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017844615504145622
loss_c:0.7986218333244324
tensor(1.2712, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013838518410921097
loss_c:0.8238762617111206
tensor(1.2673, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0271737203001976
loss_c:0.7701615691184998
tensor(1.2971, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020811015740036964
loss_c:0.7716730833053589
tensor(1.2693, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01776387356221676
loss_c:0.8639370799064636
tensor(1.3072, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02861526980996132
loss_c:0.7997398376464844
tensor(1.3201, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02440858632326126
loss_c:0.7278239130973816
tensor(1.2609, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013565080240368843
loss_c:0.8405830264091492
tensor(1.2752, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04021378234028816
loss_c:0.9531227946281433
tensor(1.4585, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01774686947464943
loss_c:0.8300870656967163
tensor(1.2881, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0187141764909029
loss_c:0.8145014047622681
tensor(1.2837, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02993479184806347
loss_c:0.9486531019210815
tensor(1.4097, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016153885051608086
loss_c:0.7827924489974976
tensor(1.2543, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02098150923848152
loss_c:0.8277853727340698
tensor(1.3014, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022393222898244858
loss_c:0.9506608843803406
tensor(1.3769, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016940679401159286
loss_c:0.7561235427856445
tensor(1.2428, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017699459567666054
loss_c:0.7626104354858398
tensor(1.2499, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016134420409798622
loss_c:0.9352490305900574
tensor(1.3399, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02487781085073948
loss_c:0.8712552785873413
tensor(1.3435, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016353165730834007
loss_c:0.7475225329399109
tensor(1.2353, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019297583028674126
loss_c:0.8865236043930054
tensor(1.3268, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028222298249602318
loss_c:0.8241724967956543
tensor(1.3322, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020661862567067146
loss_c:0.8546851873397827
tensor(1.3150, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017510903999209404
loss_c:0.8830096125602722
tensor(1.3167, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02741570957005024
loss_c:0.7137665748596191
tensor(1.2664, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034915659576654434
loss_c:0.9051352739334106
tensor(1.4082, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029549235478043556
loss_c:0.8599238395690918
tensor(1.3584, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026950297877192497
loss_c:0.9247088432312012
tensor(1.3830, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028359850868582726
loss_c:0.8350309729576111
tensor(1.3389, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014227698557078838
loss_c:0.7954896688461304
tensor(1.2526, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015521866269409657
loss_c:0.8387631177902222
tensor(1.2828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017785904929041862
loss_c:0.89055335521698
tensor(1.3222, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017414649948477745
loss_c:0.8877609968185425
tensor(1.3190, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021283918991684914
loss_c:0.703514039516449
tensor(1.2329, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025968868285417557
loss_c:0.7711658477783203
tensor(1.2921, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03308427333831787
loss_c:0.8201397657394409
tensor(1.3519, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026932531967759132
loss_c:0.9636920690536499
tensor(1.4047, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031175188720226288
loss_c:0.840929388999939
tensor(1.3548, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02320392057299614
loss_c:0.7742952108383179
tensor(1.2813, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01643318124115467
loss_c:0.7758414149284363
tensor(1.2517, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022161172702908516
loss_c:0.9432830214500427
tensor(1.3717, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01579814963042736
loss_c:0.8976497054100037
tensor(1.3174, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015784703195095062
loss_c:0.7692632675170898
tensor(1.2451, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021510468795895576
loss_c:0.7421499490737915
tensor(1.2556, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028561221435666084
loss_c:0.7949769496917725
tensor(1.3171, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015088147483766079
loss_c:0.7378064393997192
tensor(1.2243, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033485494554042816
loss_c:0.8430279493331909
tensor(1.3663, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019281283020973206
loss_c:0.7001218795776367
tensor(1.2219, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01962135173380375
loss_c:0.8573386073112488
tensor(1.3119, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021382955834269524
loss_c:0.8751195669174194
tensor(1.3299, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017112409695982933
loss_c:0.9644730091094971
tensor(1.3611, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027992572635412216
loss_c:0.8612197637557983
tensor(1.3518, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018192678689956665
loss_c:0.8056212663650513
tensor(1.2763, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022475283592939377
loss_c:0.8944410085678101
tensor(1.3457, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03211819380521774
loss_c:0.8656643629074097
tensor(1.3729, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021162061020731926
loss_c:0.9075039625167847
tensor(1.3472, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03152412548661232
loss_c:0.8625468611717224
tensor(1.3684, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019718559458851814
loss_c:0.8382390737533569
tensor(1.3016, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03010662831366062
loss_c:0.9058312177658081
tensor(1.3863, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.050984472036361694
loss_c:0.8334860801696777
tensor(1.4392, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030336730182170868
loss_c:0.9421029090881348
tensor(1.4076, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013492514379322529
loss_c:0.7922258377075195
tensor(1.2480, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02159752883017063
loss_c:0.7857985496520996
tensor(1.2806, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020741458982229233
loss_c:0.7785808444023132
tensor(1.2728, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02641458436846733
loss_c:0.8455230593681335
tensor(1.3356, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013979312963783741
loss_c:0.8972432017326355
tensor(1.3095, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01981157436966896
loss_c:0.7023499011993408
tensor(1.2259, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04524196311831474
loss_c:0.880935549736023
tensor(1.4388, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0179003793746233
loss_c:0.8517772555351257
tensor(1.3014, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021618712693452835
loss_c:0.8435992002487183
tensor(1.3132, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017877431586384773
loss_c:0.7733224630355835
tensor(1.2573, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02358572743833065
loss_c:0.7217656373977661
tensor(1.2535, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013215065002441406
loss_c:0.6970618963241577
tensor(1.1939, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016893986612558365
loss_c:0.8949422836303711
tensor(1.3213, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019437484443187714
loss_c:0.8854121565818787
tensor(1.3272, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015933586284518242
loss_c:0.7667791843414307
tensor(1.2450, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02005193941295147
loss_c:0.7658517360687256
tensor(1.2626, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022472791373729706
loss_c:0.8172982931137085
tensor(1.3022, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01766260527074337
loss_c:0.8616713285446167
tensor(1.3060, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015740444883704185
loss_c:0.7152318954467773
tensor(1.2148, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01653359830379486
loss_c:0.7544206380844116
tensor(1.2404, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035187747329473495
loss_c:0.9122546911239624
tensor(1.4122, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020746486261487007
loss_c:0.8607124090194702
tensor(1.3190, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023524073883891106
loss_c:1.0204989910125732
tensor(1.4217, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03988692909479141
loss_c:1.0343635082244873
tensor(1.5023, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02294428087770939
loss_c:0.8121923208236694
tensor(1.3014, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013534759171307087
loss_c:0.7516814470291138
tensor(1.2254, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02170649543404579
loss_c:0.9117152094841003
tensor(1.3521, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018579386174678802
loss_c:0.8355578780174255
tensor(1.2952, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02772098034620285
loss_c:0.9308648109436035
tensor(1.3896, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019316699355840683
loss_c:0.8731288313865662
tensor(1.3196, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013121087104082108
loss_c:0.8699127435684204
tensor(1.2902, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019322063773870468
loss_c:0.8138836622238159
tensor(1.2862, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017262723296880722
loss_c:0.8429640531539917
tensor(1.2934, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016517529264092445
loss_c:0.8002370595932007
tensor(1.2660, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02161908522248268
loss_c:0.8018938302993774
tensor(1.2897, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018136806786060333
loss_c:0.8239433765411377
tensor(1.2866, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016760563477873802
loss_c:0.794407844543457
tensor(1.2638, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035993240773677826
loss_c:1.046309471130371
tensor(1.4916, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01700805313885212
loss_c:0.8182134628295898
tensor(1.2782, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01639489457011223
loss_c:0.7362925410270691
tensor(1.2294, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04340985417366028
loss_c:1.121430516242981
tensor(1.5671, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031691353768110275
loss_c:0.89215487241745
tensor(1.3857, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017770545557141304
loss_c:0.8701438307762146
tensor(1.3107, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02335352450609207
loss_c:0.8268205523490906
tensor(1.3116, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017186962068080902
loss_c:0.8698646426200867
tensor(1.3079, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020866403356194496
loss_c:0.8323196768760681
tensor(1.3035, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016667094081640244
loss_c:0.8069145679473877
tensor(1.2704, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01837652176618576
loss_c:0.8580830097198486
tensor(1.3067, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019581982865929604
loss_c:0.9170546531677246
tensor(1.3450, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020120427012443542
loss_c:0.9852795600891113
tensor(1.3854, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01636379398405552
loss_c:0.756500244140625
tensor(1.2410, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023961367085576057
loss_c:0.8373370170593262
tensor(1.3202, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05205012857913971
loss_c:0.7792272567749023
tensor(1.4145, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02689274214208126
loss_c:0.9191044569015503
tensor(1.3789, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02336270362138748
loss_c:1.0769556760787964
tensor(1.4508, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016676194965839386
loss_c:0.8429011702537537
tensor(1.2906, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022322725504636765
loss_c:0.9421942234039307
tensor(1.3711, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014038783498108387
loss_c:0.8216594457626343
tensor(1.2670, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021518228575587273
loss_c:0.8464339971542358
tensor(1.3143, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028424210846424103
loss_c:1.0442659854888916
tensor(1.4549, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01711437851190567
loss_c:0.7973605990409851
tensor(1.2674, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032348573207855225
loss_c:0.891465425491333
tensor(1.3878, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04007856920361519
loss_c:1.064223289489746
tensor(1.5179, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01757434941828251
loss_c:0.8224108219146729
tensor(1.2834, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10023614764213562
loss_c:0.9651755690574646
tensor(1.7317, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0152926379814744
loss_c:0.8671285510063171
tensor(1.2981, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022575566545128822
loss_c:0.809657096862793
tensor(1.2989, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0441570021212101
loss_c:0.9089322090148926
tensor(1.4486, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015662793070077896
loss_c:0.7894722819328308
tensor(1.2575, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013975185342133045
loss_c:0.8917052149772644
tensor(1.3064, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021411322057247162
loss_c:0.8433116674423218
tensor(1.3124, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019425570964813232
loss_c:0.7346739768981934
tensor(1.2442, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018766706809401512
loss_c:0.8099691271781921
tensor(1.2827, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01680239848792553
loss_c:0.7325735092163086
tensor(1.2318, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020181428641080856
loss_c:0.7983990907669067
tensor(1.2825, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014895237982273102
loss_c:0.8180549144744873
tensor(1.2704, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01568000763654709
loss_c:0.8749226331710815
tensor(1.3050, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019434364512562752
loss_c:0.9673497080802917
tensor(1.3721, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03333830088376999
loss_c:0.9306716918945312
tensor(1.4121, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020221969112753868
loss_c:0.8644563555717468
tensor(1.3189, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023750320076942444
loss_c:1.0503581762313843
tensor(1.4364, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019418222829699516
loss_c:0.8614127039909363
tensor(1.3138, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030717605724930763
loss_c:0.7943217158317566
tensor(1.3259, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019173748791217804
loss_c:0.969571590423584
tensor(1.3721, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0310568455606699
loss_c:1.0011156797409058
tensor(1.4409, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016723904758691788
loss_c:0.8624019622802734
tensor(1.3026, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015954121947288513
loss_c:0.7568076848983765
tensor(1.2414, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021616164594888687
loss_c:0.8072251081466675
tensor(1.2936, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017951389774680138
loss_c:0.8363894820213318
tensor(1.2937, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020587893202900887
loss_c:0.8314792513847351
tensor(1.3024, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01430964283645153
loss_c:0.7434864044189453
tensor(1.2268, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01631069742143154
loss_c:0.7497678995132446
tensor(1.2389, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013366706669330597
loss_c:0.690155029296875
tensor(1.1933, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0301152765750885
loss_c:0.7933580279350281
tensor(1.3229, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020544083788990974
loss_c:0.7973332405090332
tensor(1.2833, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02533400058746338
loss_c:0.870296835899353
tensor(1.3444, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014659381471574306
loss_c:0.7601773142814636
tensor(1.2368, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.048427511006593704
loss_c:0.9188522696495056
tensor(1.4727, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027715124189853668
loss_c:0.8413926959037781
tensor(1.3389, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03331596404314041
loss_c:1.0235705375671387
tensor(1.4642, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014025934040546417
loss_c:0.7245550155639648
tensor(1.2142, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018919017165899277
loss_c:0.9173092842102051
tensor(1.3423, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02033385820686817
loss_c:0.9590215682983398
tensor(1.3716, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018125010654330254
loss_c:0.8165801763534546
tensor(1.2830, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01905711181461811
loss_c:0.9230144023895264
tensor(1.3460, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03447367623448372
loss_c:0.8027870059013367
tensor(1.3472, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022407110780477524
loss_c:0.8059542179107666
tensor(1.2959, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02522420510649681
loss_c:0.8576099872589111
tensor(1.3369, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04365062713623047
loss_c:0.8154076337814331
tensor(1.3945, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019101208075881004
loss_c:0.7787501811981201
tensor(1.2663, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02144564315676689
loss_c:0.958023726940155
tensor(1.3760, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046527519822120667
loss_c:0.9003499746322632
tensor(1.4540, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03460555896162987
loss_c:0.8739330172538757
tensor(1.3870, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017911862581968307
loss_c:0.7439646124839783
tensor(1.2419, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02056499756872654
loss_c:0.7964681386947632
tensor(1.2826, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01939472369849682
loss_c:0.8258590698242188
tensor(1.2938, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0421115905046463
loss_c:0.9451589584350586
tensor(1.4589, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03638257458806038
loss_c:0.9217583537101746
tensor(1.4209, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022422611713409424
loss_c:0.9742235541343689
tensor(1.3895, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025239484384655952
loss_c:0.8352777361869812
tensor(1.3245, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020300881937146187
loss_c:0.8171176910400391
tensor(1.2931, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013616728596389294
loss_c:0.8448865413665771
tensor(1.2797, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01994934491813183
loss_c:0.8504761457443237
tensor(1.3101, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016773931682109833
loss_c:0.8056318759918213
tensor(1.2716, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02044563554227352
loss_c:0.7357849478721619
tensor(1.2486, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02103491500020027
loss_c:0.9130508303642273
tensor(1.3495, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02315906621515751
loss_c:0.7711238265037537
tensor(1.2799, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02089115045964718
loss_c:0.9972330331802368
tensor(1.3957, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021714434027671814
loss_c:0.9428920149803162
tensor(1.3690, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015769215300679207
loss_c:0.9890421628952026
tensor(1.3690, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046377405524253845
loss_c:1.0959484577178955
tensor(1.5603, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016973672434687614
loss_c:0.8239961862564087
tensor(1.2826, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025817083194851875
loss_c:0.7002067565917969
tensor(1.2522, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014755381271243095
loss_c:0.7784335613250732
tensor(1.2478, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01868569664657116
loss_c:0.8120433688163757
tensor(1.2834, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02592681162059307
loss_c:0.9487945437431335
tensor(1.3903, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01740402728319168
loss_c:0.8184068202972412
tensor(1.2813, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027093887329101562
loss_c:0.7499369382858276
tensor(1.2853, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029981540516018867
loss_c:0.8091696500778198
tensor(1.3306, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03676723316311836
loss_c:0.9473214149475098
tensor(1.4364, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02308064140379429
loss_c:1.090512752532959
tensor(1.4564, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02066769264638424
loss_c:0.8016985654830933
tensor(1.2862, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02177128754556179
loss_c:0.7684371471405029
tensor(1.2726, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019624019041657448
loss_c:0.793315589427948
tensor(1.2771, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019914016127586365
loss_c:0.8714025020599365
tensor(1.3215, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021578198298811913
loss_c:0.8556638956069946
tensor(1.3200, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017911680042743683
loss_c:0.837378978729248
tensor(1.2940, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026483168825507164
loss_c:0.7980133891105652
tensor(1.3093, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02100079320371151
loss_c:0.9965871572494507
tensor(1.3954, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04451052471995354
loss_c:0.9796967506408691
tensor(1.4879, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02468973584473133
loss_c:0.903465211391449
tensor(1.3598, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016255773603916168
loss_c:0.8165485262870789
tensor(1.2753, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01944168470799923
loss_c:0.9361449480056763
tensor(1.3551, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015148097649216652
loss_c:0.8486351370811462
tensor(1.2882, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.047635044902563095
loss_c:0.911742627620697
tensor(1.4638, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014095790684223175
loss_c:0.7231943607330322
tensor(1.2145, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014758174307644367
loss_c:0.8193291425704956
tensor(1.2704, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014223692007362843
loss_c:0.7716703414916992
tensor(1.2418, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01819383166730404
loss_c:0.7870562076568604
tensor(1.2674, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024926617741584778
loss_c:0.9652196168899536
tensor(1.3949, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016897104680538177
loss_c:0.8159403204917908
tensor(1.2777, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016148166730999947
loss_c:0.8251816630363464
tensor(1.2795, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02454354427754879
loss_c:0.8799260854721069
tensor(1.3462, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0174318328499794
loss_c:0.8098772764205933
tensor(1.2765, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027226554229855537
loss_c:0.8249675035476685
tensor(1.3276, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033143300563097
loss_c:0.945492684841156
tensor(1.4200, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027408968657255173
loss_c:0.8809568285942078
tensor(1.3593, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01707594096660614
loss_c:0.79310142993927
tensor(1.2656, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01812349259853363
loss_c:0.769063413143158
tensor(1.2568, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019302690401673317
loss_c:0.9772466421127319
tensor(1.3771, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01634952239692211
loss_c:0.8230041861534119
tensor(1.2788, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019540607929229736
loss_c:0.9278677701950073
tensor(1.3508, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014829502440989017
loss_c:0.7728632688522339
tensor(1.2443, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020713068544864655
loss_c:0.8478795289993286
tensor(1.3117, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022623363882303238
loss_c:0.9038857221603394
tensor(1.3511, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01294170692563057
loss_c:0.7304519414901733
tensor(1.2123, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018090320751070976
loss_c:0.8320964574813843
tensor(1.2913, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02066550962626934
loss_c:0.8650140762329102
tensor(1.3209, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02867612987756729
loss_c:0.8482770919799805
tensor(1.3472, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01296989619731903
loss_c:0.9006161689758301
tensor(1.3063, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020870249718427658
loss_c:1.0681138038635254
tensor(1.4343, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017227672040462494
loss_c:0.9105996489524841
tensor(1.3307, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017306126654148102
loss_c:0.6407067179679871
tensor(1.1816, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017048200592398643
loss_c:0.8289988040924072
tensor(1.2846, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014840132556855679
loss_c:0.7797877192497253
tensor(1.2474, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03047920949757099
loss_c:0.7805950045585632
tensor(1.3182, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026924870908260345
loss_c:0.8779792785644531
tensor(1.3562, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014460342936217785
loss_c:0.74224853515625
tensor(1.2247, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023843714967370033
loss_c:1.0071992874145508
tensor(1.4140, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013806023634970188
loss_c:0.7068171501159668
tensor(1.2019, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018109330907464027
loss_c:0.9564022421836853
tensor(1.3599, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025551525875926018
loss_c:0.8694275617599487
tensor(1.3454, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015218544751405716
loss_c:0.8113490343093872
tensor(1.2661, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021765263751149178
loss_c:1.1405664682388306
tensor(1.4788, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01767667941749096
loss_c:0.770161509513855
tensor(1.2544, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015387559309601784
loss_c:0.7220463752746582
tensor(1.2172, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01757964678108692
loss_c:0.8242130279541016
tensor(1.2839, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016978582367300987
loss_c:0.833793044090271
tensor(1.2864, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018103254958987236
loss_c:0.9699606895446777
tensor(1.3672, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017888300120830536
loss_c:0.9221532344818115
tensor(1.3396, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02227351814508438
loss_c:0.93719482421875
tensor(1.3681, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021131230518221855
loss_c:0.7121309638023376
tensor(1.2379, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033200204372406006
loss_c:1.1184582710266113
tensor(1.5193, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016402695327997208
loss_c:0.8899742960929871
tensor(1.3148, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024931468069553375
loss_c:0.7984980344772339
tensor(1.3035, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01775933988392353
loss_c:0.8418876528739929
tensor(1.2944, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013315432704985142
loss_c:0.7932488918304443
tensor(1.2468, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018461819738149643
loss_c:0.8044271469116211
tensor(1.2769, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01885262131690979
loss_c:0.780572772026062
tensor(1.2655, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0171376820653677
loss_c:0.8303291201591492
tensor(1.2850, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022891251370310783
loss_c:0.8973711729049683
tensor(1.3489, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02103428542613983
loss_c:0.745753288269043
tensor(1.2563, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0230537261813879
loss_c:0.7592725157737732
tensor(1.2732, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016250601038336754
loss_c:0.7769081592559814
tensor(1.2512, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023287948220968246
loss_c:0.8219320774078369
tensor(1.3090, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021854452788829803
loss_c:0.8750430941581726
tensor(1.3318, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017629990354180336
loss_c:0.8570885062217712
tensor(1.3020, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03247537836432457
loss_c:0.8452210426330566
tensor(1.3649, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023448051884770393
loss_c:0.8128594756126404
tensor(1.3047, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02223999984562397
loss_c:0.8121013641357422
tensor(1.2986, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03804813325405121
loss_c:0.9133070707321167
tensor(1.4288, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022436851635575294
loss_c:0.8755686283111572
tensor(1.3348, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019047768786549568
loss_c:0.8560413718223572
tensor(1.3081, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01905907690525055
loss_c:0.9024972915649414
tensor(1.3341, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02062121592462063
loss_c:0.9703139662742615
tensor(1.3791, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015258343890309334
loss_c:0.9864473342895508
tensor(1.3631, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018226314336061478
loss_c:0.7493886351585388
tensor(1.2450, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01726166345179081
loss_c:0.8084372878074646
tensor(1.2734, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01712203212082386
loss_c:0.7457253932952881
tensor(1.2378, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029162924736738205
loss_c:0.8683041334152222
tensor(1.3620, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01760791428387165
loss_c:0.8002108931541443
tensor(1.2704, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019833767786622047
loss_c:0.8299688100814819
tensor(1.2973, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015417606569826603
loss_c:0.8322535753250122
tensor(1.2780, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020933344960212708
loss_c:0.7993666529655457
tensor(1.2854, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016352027654647827
loss_c:0.7313622236251831
tensor(1.2262, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01864846795797348
loss_c:0.7608388662338257
tensor(1.2532, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02835831046104431
loss_c:0.7908326983451843
tensor(1.3151, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032149601727724075
loss_c:0.7888405323028564
tensor(1.3316, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04405643790960312
loss_c:0.7972294688224792
tensor(1.3917, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02526148594915867
loss_c:0.7433997988700867
tensor(1.2740, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01819791831076145
loss_c:0.8303550481796265
tensor(1.2899, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0190862026065588
loss_c:0.8535228967666626
tensor(1.3070, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02914085052907467
loss_c:1.154350996017456
tensor(1.5222, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021138468757271767
loss_c:0.8877050280570984
tensor(1.3357, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020719042047858238
loss_c:0.8014909625053406
tensor(1.2854, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019070599228143692
loss_c:0.7162356376647949
tensor(1.2300, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02130613662302494
loss_c:0.9432663917541504
tensor(1.3676, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022204969078302383
loss_c:0.785592794418335
tensor(1.2833, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011364789679646492
loss_c:0.7970033884048462
tensor(1.2400, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016896704211831093
loss_c:0.7742751836776733
tensor(1.2526, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027016758918762207
loss_c:0.8506377935409546
tensor(1.3418, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017640652135014534
loss_c:0.7497667074203491
tensor(1.2422, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022850431501865387
loss_c:0.8189252614974976
tensor(1.3049, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025412533432245255
loss_c:0.836129367351532
tensor(1.3263, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033232182264328
loss_c:0.8206567764282227
tensor(1.3534, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01197241060435772
loss_c:0.7881407737731934
tensor(1.2378, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039291705936193466
loss_c:0.9650236368179321
tensor(1.4623, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015812113881111145
loss_c:0.7704598307609558
tensor(1.2454, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01873830519616604
loss_c:0.9039516448974609
tensor(1.3340, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02302554063498974
loss_c:0.9162555932998657
tensor(1.3605, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02486882358789444
loss_c:0.838158369064331
tensor(1.3249, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020728429779410362
loss_c:0.959790825843811
tensor(1.3745, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023321816697716713
loss_c:0.9977704286575317
tensor(1.4077, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01483688224107027
loss_c:0.9204826354980469
tensor(1.3255, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02249155379831791
loss_c:1.045646071434021
tensor(1.4306, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013958554714918137
loss_c:0.7440232038497925
tensor(1.2224, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013996962457895279
loss_c:0.8053046464920044
tensor(1.2570, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02306877262890339
loss_c:0.8690890073776245
tensor(1.3340, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02748786099255085
loss_c:0.9268449544906616
tensor(1.3865, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021051058545708656
loss_c:0.8182465434074402
tensor(1.2964, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015043171122670174
loss_c:0.9211089611053467
tensor(1.3265, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020659631118178368
loss_c:0.9404454231262207
tensor(1.3628, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029569853097200394
loss_c:0.9160615801811218
tensor(1.3898, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02095220610499382
loss_c:0.791214108467102
tensor(1.2809, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03659949079155922
loss_c:0.7574995756149292
tensor(1.3335, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02571820095181465
loss_c:0.8148698210716248
tensor(1.3158, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026003677397966385
loss_c:0.9646978378295898
tensor(1.4005, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022034291177988052
loss_c:0.9367770552635193
tensor(1.3668, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019308164715766907
loss_c:0.7681059837341309
tensor(1.2607, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03416389599442482
loss_c:0.9256951808929443
tensor(1.4157, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017359744757413864
loss_c:0.85589998960495
tensor(1.3007, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025317635387182236
loss_c:0.9987499117851257
tensor(1.4160, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018090607598423958
loss_c:0.8175806403160095
tensor(1.2828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01654248684644699
loss_c:0.8023289442062378
tensor(1.2674, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021261276677250862
loss_c:0.942905068397522
tensor(1.3665, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02217799425125122
loss_c:0.8776902556419373
tensor(1.3346, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019198860973119736
loss_c:0.8552245497703552
tensor(1.3087, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01917933113873005
loss_c:0.953744113445282
tensor(1.3630, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025680456310510635
loss_c:0.9203797578811646
tensor(1.3739, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04240766912698746
loss_c:0.8473533391952515
tensor(1.4091, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019212542101740837
loss_c:0.9237200617790222
tensor(1.3465, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02056124433875084
loss_c:0.9297395944595337
tensor(1.3559, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018589479848742485
loss_c:0.7757924795150757
tensor(1.2623, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019001571461558342
loss_c:0.7663272619247437
tensor(1.2590, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016309883445501328
loss_c:0.7554512023925781
tensor(1.2409, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01898374781012535
loss_c:0.7982439398765564
tensor(1.2765, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042388420552015305
loss_c:1.142508864402771
tensor(1.5711, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018859967589378357
loss_c:0.8032444715499878
tensor(1.2787, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018443414941430092
loss_c:0.7717711925506592
tensor(1.2595, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018507447093725204
loss_c:0.8155546188354492
tensor(1.2839, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020411938428878784
loss_c:0.829270601272583
tensor(1.3000, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01883799582719803
loss_c:0.8887205123901367
tensor(1.3256, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014797701500356197
loss_c:0.8312356472015381
tensor(1.2758, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02353746071457863
loss_c:0.7072194814682007
tensor(1.2469, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021024543792009354
loss_c:0.8665809631347656
tensor(1.3232, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01914766989648342
loss_c:0.9105753898620605
tensor(1.3390, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017919452860951424
loss_c:0.9451349973678589
tensor(1.3525, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03031843528151512
loss_c:0.7528907656669617
tensor(1.3025, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017383523285388947
loss_c:0.8675793409347534
tensor(1.3074, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03170560300350189
loss_c:0.8391585350036621
tensor(1.3563, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015146369114518166
loss_c:0.7831124067306519
tensor(1.2507, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019549846649169922
loss_c:0.7916791439056396
tensor(1.2752, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020514942705631256
loss_c:0.830215573310852
tensor(1.3008, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029991907998919487
loss_c:0.8142892122268677
tensor(1.3348, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020509254187345505
loss_c:0.794588029384613
tensor(1.2811, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.12625010311603546
loss_c:0.9378271102905273
tensor(1.8378, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037518542259931564
loss_c:1.004326581954956
tensor(1.4735, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020707735791802406
loss_c:0.990767240524292
tensor(1.3906, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023997358977794647
loss_c:1.012601613998413
tensor(1.4173, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11389664560556412
loss_c:0.907660961151123
tensor(1.7561, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03382163867354393
loss_c:1.0619480609893799
tensor(1.4874, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02209465019404888
loss_c:1.0761284828186035
tensor(1.4439, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015783578157424927
loss_c:0.7347100973129272
tensor(1.2284, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03163062408566475
loss_c:0.856991708278656
tensor(1.3638, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014353807084262371
loss_c:0.8163596987724304
tensor(1.2679, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016150949522852898
loss_c:0.7909755706787109
tensor(1.2617, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02506265416741371
loss_c:0.7665278315544128
tensor(1.2860, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01748349331319332
loss_c:0.8130826950073242
tensor(1.2798, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032004464417696
loss_c:1.1152331829071045
tensor(1.5066, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01346115954220295
loss_c:0.8330199122428894
tensor(1.2742, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027288205921649933
loss_c:1.0339781045913696
tensor(1.4421, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01711268536746502
loss_c:0.8411166667938232
tensor(1.2940, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0218191035091877
loss_c:1.072150707244873
tensor(1.4402, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015850743278861046
loss_c:0.761157751083374
tensor(1.2451, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022410674020648003
loss_c:0.8237566947937012
tensor(1.3066, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015306440182030201
loss_c:0.8014358282089233
tensor(1.2650, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025779549032449722
loss_c:0.7521188259124756
tensor(1.2814, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01500372588634491
loss_c:0.8222619891166687
tensor(1.2751, device='cuda:0', grad_fn=<AddBackward0>)
total_train_loss:1.3391293287277222
loss_r:0.025479663163423538
loss_c:1.8506650924682617
loss_r:0.024077478796243668
loss_c:1.6811132431030273
loss_r:0.025352876633405685
loss_c:1.7190465927124023
loss_r:0.02570962905883789
loss_c:1.7892292737960815
loss_r:0.021979622542858124
loss_c:1.647538185119629
loss_r:0.02249797061085701
loss_c:1.6096506118774414
loss_r:0.023072749376296997
loss_c:1.822162389755249
loss_r:0.022964857518672943
loss_c:1.8179973363876343
loss_r:0.024546582251787186
loss_c:1.8860138654708862
loss_r:0.023650435730814934
loss_c:1.9184082746505737
loss_r:0.020512396469712257
loss_c:1.7999157905578613
loss_r:0.022032368928194046
loss_c:1.7397245168685913
loss_r:0.021085502579808235
loss_c:1.6577242612838745
loss_r:0.016870718449354172
loss_c:1.4792823791503906
loss_r:0.018826192244887352
loss_c:1.6094512939453125
loss_r:0.02355174347758293
loss_c:1.6837958097457886
loss_r:0.0183026771992445
loss_c:1.5438299179077148
loss_r:0.02004784159362316
loss_c:1.636053442955017
loss_r:0.02277710847556591
loss_c:1.6272354125976562
loss_r:0.018202897161245346
loss_c:1.482266902923584
loss_r:0.019528089091181755
loss_c:1.5800378322601318
loss_r:0.023702433332800865
loss_c:1.6748713254928589
loss_r:0.019471071660518646
loss_c:1.553481101989746
loss_r:0.021375272423028946
loss_c:1.6132588386535645
loss_r:0.023670710623264313
loss_c:1.6663564443588257
loss_r:0.017526080831885338
loss_c:1.4267349243164062
loss_r:0.021470842882990837
loss_c:1.6480464935302734
loss_r:0.02490723505616188
loss_c:1.6904816627502441
loss_r:0.021608635783195496
loss_c:1.5750720500946045
loss_r:0.022229913622140884
loss_c:1.6340034008026123
loss_r:0.024704966694116592
loss_c:1.727264642715454
loss_r:0.01776372268795967
loss_c:1.454270362854004
loss_r:0.021680442616343498
loss_c:1.6659716367721558
loss_r:0.024355512112379074
loss_c:1.6859474182128906
loss_r:0.01993928663432598
loss_c:1.5639833211898804
loss_r:0.020462967455387115
loss_c:1.5391196012496948
loss_r:0.026756346225738525
loss_c:1.8218324184417725
loss_r:0.01785600371658802
loss_c:1.5229833126068115
loss_r:0.02198312059044838
loss_c:1.7012033462524414
loss_r:0.023848844692111015
loss_c:1.6729419231414795
loss_r:0.0200275219976902
loss_c:1.59311044216156
loss_r:0.02055233344435692
loss_c:1.5750324726104736
loss_r:0.022850118577480316
loss_c:1.7460708618164062
loss_r:0.016229664906859398
loss_c:1.5498889684677124
loss_r:0.020223144441843033
loss_c:1.686254858970642
loss_r:0.021968740969896317
loss_c:1.6461095809936523
loss_r:0.01916240155696869
loss_c:1.6052411794662476
loss_r:0.020125525072216988
loss_c:1.6376922130584717
loss_r:0.0217023566365242
loss_c:1.7738244533538818
loss_r:0.017536746338009834
loss_c:1.6194748878479004
loss_r:0.021871156990528107
loss_c:1.8113354444503784
loss_r:0.02217661216855049
loss_c:1.7401926517486572
loss_r:0.01966334879398346
loss_c:1.6691298484802246
loss_r:0.0195318553596735
loss_c:1.5788512229919434
loss_r:0.020683664828538895
loss_c:1.7207826375961304
loss_r:0.019507572054862976
loss_c:1.8017549514770508
loss_r:0.02074166014790535
loss_c:1.8468055725097656
loss_r:0.021528704091906548
loss_c:1.6385376453399658
loss_r:0.01961720734834671
loss_c:1.668637990951538
loss_r:0.019151991233229637
loss_c:1.5812604427337646
loss_r:0.02284490503370762
loss_c:1.7856569290161133
loss_r:0.01794595457613468
loss_c:1.5776374340057373
loss_r:0.019396699965000153
loss_c:1.6400461196899414
loss_r:0.020993879064917564
loss_c:1.5643680095672607
loss_r:0.019709302112460136
loss_c:1.5324347019195557
loss_r:0.020347146317362785
loss_c:1.4855226278305054
loss_r:0.02539713867008686
loss_c:1.7100270986557007
loss_r:0.019301660358905792
loss_c:1.565962791442871
loss_r:0.021622495725750923
loss_c:1.6712591648101807
loss_r:0.02415267750620842
loss_c:1.612518310546875
loss_r:0.02086954563856125
loss_c:1.5423797369003296
loss_r:0.0203010942786932
loss_c:1.459252119064331
loss_r:0.024110477417707443
loss_c:1.7551019191741943
loss_r:0.019418029114603996
loss_c:1.6283481121063232
loss_r:0.02142980881035328
loss_c:1.6577997207641602
loss_r:0.024723419919610023
loss_c:1.6777384281158447
loss_r:0.02117786929011345
loss_c:1.5658128261566162
loss_r:0.020756041631102562
loss_c:1.494095802307129
loss_r:0.025320306420326233
loss_c:1.722261667251587
loss_r:0.020046766847372055
loss_c:1.694266676902771
loss_r:0.02317255549132824
loss_c:1.7900947332382202
loss_r:0.024483729153871536
loss_c:1.6252954006195068
loss_r:0.0205882266163826
loss_c:1.5763734579086304
loss_r:0.021010559052228928
loss_c:1.5067753791809082
loss_r:0.024940401315689087
loss_c:1.7599003314971924
loss_r:0.020199647173285484
loss_c:1.6291940212249756
loss_r:0.02301698736846447
loss_c:1.7391090393066406
loss_r:0.022635415196418762
loss_c:1.611446738243103
loss_r:0.022362757474184036
loss_c:1.6393396854400635
loss_r:0.021906474605202675
loss_c:1.5366332530975342
loss_r:0.02334282360970974
loss_c:1.7201718091964722
loss_r:0.01924549788236618
loss_c:1.611462116241455
loss_r:0.023310622200369835
loss_c:1.691807746887207
loss_r:0.0223727747797966
loss_c:1.5775742530822754
loss_r:0.021452229470014572
loss_c:1.6606849431991577
loss_r:0.02273888699710369
loss_c:1.5002673864364624
loss_r:0.025250233709812164
loss_c:1.67935311794281
loss_r:0.021244633942842484
loss_c:1.596294641494751
loss_r:0.02437371388077736
loss_c:1.701338529586792
loss_r:0.02156670205295086
loss_c:1.557084083557129
loss_r:0.023344820365309715
loss_c:1.6584901809692383
loss_r:0.022994831204414368
loss_c:1.5055488348007202
loss_r:0.024413028731942177
loss_c:1.6031969785690308
loss_r:0.022624697536230087
loss_c:1.6662554740905762
loss_r:0.02460792101919651
loss_c:1.6849949359893799
loss_r:0.02078741230070591
loss_c:1.549156904220581
loss_r:0.02220803126692772
loss_c:1.659263014793396
loss_r:0.024171192198991776
loss_c:1.4627026319503784
loss_r:0.025187116116285324
loss_c:1.6576917171478271
loss_r:0.02183358743786812
loss_c:1.6458439826965332
loss_r:0.024704709649086
loss_c:1.6884292364120483
loss_r:0.021074678748846054
loss_c:1.4680843353271484
loss_r:0.022839171811938286
loss_c:1.5873432159423828
loss_r:0.02466406486928463
loss_c:1.5120840072631836
loss_r:0.02439400926232338
loss_c:1.6301724910736084
loss_r:0.02028789557516575
loss_c:1.500999927520752
loss_r:0.022960662841796875
loss_c:1.6068377494812012
loss_r:0.020906267687678337
loss_c:1.5049285888671875
loss_r:0.023755157366394997
loss_c:1.6727969646453857
loss_r:0.023341063410043716
loss_c:1.4337549209594727
loss_r:0.025170277804136276
loss_c:1.6031343936920166
loss_r:0.020287854596972466
loss_c:1.5651028156280518
loss_r:0.0253495741635561
loss_c:1.7892425060272217
loss_r:0.021861102432012558
loss_c:1.5882682800292969
loss_r:0.023361211642622948
loss_c:1.6877384185791016
loss_r:0.02324221469461918
loss_c:1.450987696647644
loss_r:0.02446695603430271
loss_c:1.5767329931259155
loss_r:0.01900462433695793
loss_c:1.3794193267822266
loss_r:0.023546433076262474
loss_c:1.6719129085540771
loss_r:0.020243076607584953
loss_c:1.5692319869995117
loss_r:0.025334231555461884
loss_c:1.7573654651641846
loss_r:0.020597638562321663
loss_c:1.4186880588531494
loss_r:0.0246797613799572
loss_c:1.5642147064208984
loss_r:0.016979584470391273
loss_c:1.3609755039215088
loss_r:0.022136185318231583
loss_c:1.6260517835617065
loss_r:0.022089095786213875
loss_c:1.5952576398849487
loss_r:0.023524397984147072
loss_c:1.6772549152374268
loss_r:0.019264278933405876
loss_c:1.3841419219970703
loss_r:0.027627432718873024
loss_c:1.611964464187622
loss_r:0.018306167796254158
loss_c:1.3624401092529297
loss_r:0.02509026974439621
loss_c:1.6981189250946045
loss_r:0.02295912615954876
loss_c:1.617720603942871
loss_r:0.027415145188570023
loss_c:1.7519757747650146
loss_r:0.0248416755348444
loss_c:1.462290644645691
loss_r:0.030921244993805885
loss_c:1.6670374870300293
loss_r:0.021232018247246742
loss_c:1.4005630016326904
loss_r:0.026191961020231247
loss_c:1.70707106590271
loss_r:0.0244669821113348
loss_c:1.6074330806732178
loss_r:0.02485375851392746
loss_c:1.636216163635254
loss_r:0.02212582528591156
loss_c:1.394052505493164
loss_r:0.02973022870719433
loss_c:1.6677664518356323
loss_r:0.021046580746769905
loss_c:1.4545981884002686
loss_r:0.02728358283638954
loss_c:1.7186483144760132
loss_r:0.02320317178964615
loss_c:1.5978906154632568
loss_r:0.026592060923576355
loss_c:1.7502822875976562
loss_r:0.02393987588584423
loss_c:1.4725284576416016
loss_r:0.030685942620038986
loss_c:1.74080228805542
loss_r:0.023923302069306374
loss_c:1.548861026763916
loss_r:0.029931707307696342
loss_c:1.7782082557678223
loss_r:0.02465158700942993
loss_c:1.6253955364227295
loss_r:0.027190620079636574
loss_c:1.7519630193710327
loss_r:0.026069143787026405
loss_c:1.5398337841033936
loss_r:0.030258310958743095
loss_c:1.6551107168197632
loss_r:0.02102263830602169
loss_c:1.4833892583847046
loss_r:0.03213608264923096
loss_c:1.9052609205245972
loss_r:0.02420377917587757
loss_c:1.6510257720947266
loss_r:0.02922646515071392
loss_c:1.8218200206756592
loss_r:0.024098563939332962
loss_c:1.4862871170043945
loss_r:0.026607969775795937
loss_c:1.591660737991333
loss_r:0.02357451058924198
loss_c:1.530554175376892
loss_r:0.029872585088014603
loss_c:1.7821462154388428
loss_r:0.024046210572123528
loss_c:1.6145784854888916
loss_r:0.03142029047012329
loss_c:1.8759493827819824
loss_r:0.02266024984419346
loss_c:1.4714772701263428
loss_r:0.02657816931605339
loss_c:1.5742191076278687
loss_r:0.022821351885795593
loss_c:1.4972561597824097
loss_r:0.031547240912914276
loss_c:1.7919902801513672
loss_r:0.02238702028989792
loss_c:1.5798829793930054
loss_r:0.028515400364995003
loss_c:1.8171567916870117
loss_r:0.021781515330076218
loss_c:1.3785874843597412
loss_r:0.024785663932561874
loss_c:1.5198053121566772
loss_r:0.021577496081590652
loss_c:1.503645896911621
loss_r:0.029020993039011955
loss_c:1.7886651754379272
loss_r:0.022818295285105705
loss_c:1.617307424545288
loss_r:0.030908875167369843
loss_c:1.8715485334396362
loss_r:0.021149074658751488
loss_c:1.3942675590515137
loss_r:0.023300228640437126
loss_c:1.5148553848266602
loss_r:0.022381935268640518
loss_c:1.5168941020965576
loss_r:0.02963934652507305
loss_c:1.8335494995117188
loss_r:0.023010503500699997
loss_c:1.6230968236923218
loss_r:0.02953178994357586
loss_c:1.8277992010116577
loss_r:0.02187556028366089
loss_c:1.428423285484314
loss_r:0.023638596758246422
loss_c:1.547742247581482
loss_r:0.022496338933706284
loss_c:1.526139259338379
loss_r:0.02957194484770298
loss_c:1.8402249813079834
loss_r:0.02241329476237297
loss_c:1.6206310987472534
loss_r:0.03032718040049076
loss_c:1.9104549884796143
loss_r:0.021772222593426704
loss_c:1.4528591632843018
loss_r:0.022194888442754745
loss_c:1.5514194965362549
loss_r:0.022522319108247757
loss_c:1.5467524528503418
loss_r:0.029069475829601288
loss_c:1.7888917922973633
loss_r:0.02418549545109272
loss_c:1.6029362678527832
loss_r:0.030997036024928093
loss_c:1.887180209159851
loss_r:0.02471073530614376
loss_c:1.4796197414398193
loss_r:0.02468372881412506
loss_c:1.526435375213623
loss_r:0.024527866393327713
loss_c:1.5105499029159546
loss_r:0.03325377777218819
loss_c:1.8390873670578003
loss_r:0.02418031170964241
loss_c:1.5857188701629639
loss_r:0.03159355744719505
loss_c:1.8707575798034668
loss_r:0.02510097436606884
loss_c:1.4743854999542236
loss_r:0.024599548429250717
loss_c:1.536770224571228
loss_r:0.025347376242280006
loss_c:1.5538572072982788
loss_r:0.03111768513917923
loss_c:1.77432382106781
loss_r:0.02265802212059498
loss_c:1.5757869482040405
loss_r:0.028374532237648964
loss_c:1.8110363483428955
loss_r:0.02347320318222046
loss_c:1.5218194723129272
loss_r:0.02397364191710949
loss_c:1.5601472854614258
loss_r:0.02252882532775402
loss_c:1.5291967391967773
loss_r:0.032649580389261246
loss_c:1.8737399578094482
loss_r:0.021241968497633934
loss_c:1.5462477207183838
loss_r:0.02815002016723156
loss_c:1.7888703346252441
loss_r:0.024013515561819077
loss_c:1.5182737112045288
loss_r:0.02388591691851616
loss_c:1.6765871047973633
loss_r:0.024237141013145447
loss_c:1.638692855834961
loss_r:0.028613978996872902
loss_c:1.8909502029418945
loss_r:0.021326638758182526
loss_c:1.6570653915405273
loss_r:0.02670001983642578
loss_c:1.829406499862671
loss_r:0.02532028593122959
loss_c:1.5975208282470703
loss_r:0.024529537186026573
loss_c:1.6330792903900146
loss_r:0.022582821547985077
loss_c:1.571179747581482
loss_r:0.028997784480452538
loss_c:1.828120231628418
loss_r:0.021461201831698418
loss_c:1.602030634880066
loss_r:0.02771167643368244
loss_c:1.8315370082855225
loss_r:0.023674646392464638
loss_c:1.5271406173706055
loss_r:0.024820616468787193
loss_c:1.62259042263031
loss_r:0.02318575792014599
loss_c:1.5375412702560425
loss_r:0.028546040877699852
loss_c:1.8365625143051147
loss_r:0.022465119138360023
loss_c:1.6609313488006592
loss_r:0.02839560993015766
loss_c:1.890242338180542
loss_r:0.025165408849716187
loss_c:1.555084466934204
loss_r:0.026151468977332115
loss_c:1.7375234365463257
loss_r:0.024379689246416092
loss_c:1.6041110754013062
loss_r:0.029440253973007202
loss_c:1.8308112621307373
loss_r:0.02262711338698864
loss_c:1.6832183599472046
loss_r:0.029774749651551247
loss_c:1.9116767644882202
loss_r:0.023956896737217903
loss_c:1.551018476486206
loss_r:0.026884743943810463
loss_c:1.6692416667938232
loss_r:0.02492290735244751
loss_c:1.5759042501449585
loss_r:0.029850492253899574
loss_c:1.8001378774642944
loss_r:0.024193784222006798
loss_c:1.7036869525909424
loss_r:0.02981010638177395
loss_c:1.815902590751648
loss_r:0.02588285319507122
loss_c:1.507218837738037
loss_r:0.028027312830090523
loss_c:1.6590583324432373
loss_r:0.024850551038980484
loss_c:1.5022268295288086
loss_r:0.027809182181954384
loss_c:1.7256320714950562
loss_r:0.023636527359485626
loss_c:1.6443442106246948
loss_r:0.03130170702934265
loss_c:1.8304662704467773
loss_r:0.026233939453959465
loss_c:1.5276679992675781
loss_r:0.029648177325725555
loss_c:1.6474814414978027
loss_r:0.02544698305428028
loss_c:1.505403757095337
loss_r:0.03146519139409065
loss_c:1.8194745779037476
loss_r:0.02577042765915394
loss_c:1.6734111309051514
loss_r:0.030378596857190132
loss_c:1.8127601146697998
loss_r:0.0275319442152977
loss_c:1.533695101737976
loss_r:0.030253686010837555
loss_c:1.6831822395324707
loss_r:0.02719888649880886
loss_c:1.6056389808654785
loss_r:0.03392268717288971
loss_c:1.8294711112976074
loss_r:0.025225991383194923
loss_c:1.6008288860321045
loss_r:0.02872316539287567
loss_c:1.6739118099212646
loss_r:0.027669837698340416
loss_c:1.4857620000839233
loss_r:0.03270936384797096
loss_c:1.7004585266113281
loss_r:0.026589909568428993
loss_c:1.6601099967956543
loss_r:0.032344475388526917
loss_c:1.8087886571884155
loss_r:0.02473483234643936
loss_c:1.6670770645141602
loss_r:0.030314594507217407
loss_c:1.812061071395874
loss_r:0.02875535562634468
loss_c:1.5686734914779663
loss_r:0.03339588642120361
loss_c:1.658799648284912
loss_r:0.02807028777897358
loss_c:1.6579755544662476
loss_r:0.031240150332450867
loss_c:1.8493754863739014
loss_r:0.02448112703859806
loss_c:1.6159495115280151
loss_r:0.029269328340888023
loss_c:1.7738603353500366
loss_r:0.02803106978535652
loss_c:1.503567099571228
loss_r:0.034106191247701645
loss_c:1.664453387260437
loss_r:0.02700100466609001
loss_c:1.5957229137420654
loss_r:0.03110995516180992
loss_c:1.7242059707641602
loss_r:0.023572033271193504
loss_c:1.5315179824829102
loss_r:0.02647853083908558
loss_c:1.6943553686141968
loss_r:0.026147738099098206
loss_c:1.4941527843475342
loss_r:0.031177308410406113
loss_c:1.6581990718841553
loss_r:0.022354096174240112
loss_c:1.5188567638397217
loss_r:0.028483042493462563
loss_c:1.770272970199585
loss_r:0.024889979511499405
loss_c:1.630619764328003
loss_r:0.026564354076981544
loss_c:1.6453503370285034
loss_r:0.029491035267710686
loss_c:1.6414260864257812
loss_r:0.030305936932563782
loss_c:1.7133865356445312
loss_r:0.024663757532835007
loss_c:1.607372522354126
loss_r:0.030189869925379753
loss_c:1.7921695709228516
loss_r:0.025724805891513824
loss_c:1.6165803670883179
loss_r:0.025834836065769196
loss_c:1.6521766185760498
loss_r:0.029743334278464317
loss_c:1.5479190349578857
loss_r:0.032048549503088
loss_c:1.6853151321411133
loss_r:0.023979131132364273
loss_c:1.5148662328720093
loss_r:0.029595542699098587
loss_c:1.713505744934082
loss_r:0.0251951664686203
loss_c:1.5777335166931152
loss_r:0.027003390714526176
loss_c:1.695239782333374
loss_r:0.028144802898168564
loss_c:1.5033730268478394
loss_r:0.03207516670227051
loss_c:1.6785273551940918
loss_r:0.024833587929606438
loss_c:1.5052345991134644
loss_r:0.03201231732964516
loss_c:1.7341539859771729
loss_r:0.023777907714247704
loss_c:1.5403504371643066
loss_r:0.025017626583576202
loss_c:1.6203744411468506
loss_r:0.02920539304614067
loss_c:1.567211389541626
loss_r:0.02900698035955429
loss_c:1.682689905166626
loss_r:0.022579139098525047
loss_c:1.5069301128387451
loss_r:0.03041701950132847
loss_c:1.7632951736450195
loss_r:0.02472229115664959
loss_c:1.6291836500167847
loss_r:0.027378639206290245
loss_c:1.7275257110595703
loss_r:0.028055397793650627
loss_c:1.5029128789901733
loss_r:0.028811058029532433
loss_c:1.6879243850708008
loss_r:0.02063176780939102
loss_c:1.4602382183074951
loss_r:0.0298636294901371
loss_c:1.8135932683944702
loss_r:0.02359578013420105
loss_c:1.6303126811981201
loss_r:0.026713792234659195
loss_c:1.6985721588134766
loss_r:0.02734057791531086
loss_c:1.5437946319580078
loss_r:0.028209341689944267
loss_c:1.7017323970794678
loss_r:0.024610545486211777
loss_c:1.6075859069824219
loss_r:0.02665046416223049
loss_c:1.7835721969604492
loss_r:0.02267278917133808
loss_c:1.5623183250427246
loss_r:0.024856405332684517
loss_c:1.633685827255249
loss_r:0.02407698705792427
loss_c:1.4371793270111084
loss_r:0.028827808797359467
loss_c:1.690873622894287
loss_r:0.02444140985608101
loss_c:1.5978021621704102
loss_r:0.026022890582680702
loss_c:1.7491884231567383
loss_r:0.021599959582090378
loss_c:1.5588748455047607
loss_r:0.028065603226423264
loss_c:1.776166319847107
loss_r:0.02872498519718647
loss_c:1.6928209066390991
loss_r:0.03021318092942238
loss_c:1.7872047424316406
loss_r:0.02878464013338089
loss_c:1.800157904624939
loss_r:0.029175488278269768
loss_c:1.904123067855835
loss_r:0.023894881829619408
loss_c:1.6585865020751953
loss_r:0.024370618164539337
loss_c:1.7601784467697144
loss_r:0.023462548851966858
loss_c:1.6963857412338257
loss_r:0.02723309025168419
loss_c:1.7880719900131226
loss_r:0.02383379265666008
loss_c:1.829648733139038
loss_r:0.02366000972688198
loss_c:1.8743003606796265
loss_r:0.019618617370724678
loss_c:1.6522886753082275
loss_r:0.02204696461558342
loss_c:1.765136480331421
loss_r:0.022617030888795853
loss_c:1.6945780515670776
loss_r:0.024434633553028107
loss_c:1.768185019493103
loss_r:0.024358170107007027
loss_c:1.8790640830993652
loss_r:0.024017298594117165
loss_c:1.9574403762817383
loss_r:0.02009269781410694
loss_c:1.754564642906189
loss_r:0.022135600447654724
loss_c:1.8166658878326416
loss_r:0.021382484585046768
loss_c:1.698044776916504
loss_r:0.024212593212723732
loss_c:1.7254798412322998
loss_r:0.02319544553756714
loss_c:1.7957594394683838
loss_r:0.023380057886242867
loss_c:1.9374974966049194
loss_r:0.02026325650513172
loss_c:1.7159022092819214
loss_r:0.0245817843824625
loss_c:1.8597831726074219
loss_r:0.021778393536806107
loss_c:1.683542013168335
loss_r:0.025851959362626076
loss_c:1.7465131282806396
loss_r:0.02370615303516388
loss_c:1.758695363998413
loss_r:0.025738367810845375
loss_c:1.9262107610702515
loss_r:0.022188659757375717
loss_c:1.7446693181991577
loss_r:0.025441942736506462
loss_c:1.906120777130127
loss_r:0.02041049115359783
loss_c:1.6854981184005737
loss_r:0.02237863279879093
loss_c:1.7891162633895874
loss_r:0.02348143421113491
loss_c:1.83977210521698
loss_r:0.023202739655971527
loss_c:2.0089850425720215
loss_r:0.022464118897914886
loss_c:1.8068809509277344
loss_r:0.024471361190080643
loss_c:1.9281682968139648
loss_r:0.019682226702570915
loss_c:1.6612884998321533
loss_r:0.021857386454939842
loss_c:1.737762689590454
loss_r:0.02162211388349533
loss_c:1.8083146810531616
loss_r:0.024164428934454918
loss_c:2.03881573677063
loss_r:0.019220033660531044
loss_c:1.7482441663742065
loss_r:0.022527828812599182
loss_c:1.9017661809921265
loss_r:0.02025873400270939
loss_c:1.6812022924423218
loss_r:0.021690379828214645
loss_c:1.749589204788208
loss_r:0.021003859117627144
loss_c:1.8081891536712646
loss_r:0.023994943127036095
loss_c:2.0217132568359375
loss_r:0.02058141678571701
loss_c:1.7882840633392334
loss_r:0.023624340072274208
loss_c:1.9779386520385742
loss_r:0.02003829926252365
loss_c:1.7216322422027588
loss_r:0.02164839766919613
loss_c:1.802519679069519
loss_r:0.021439770236611366
loss_c:1.84177565574646
loss_r:0.023458149284124374
loss_c:2.047623634338379
loss_r:0.018780529499053955
loss_c:1.757646918296814
loss_r:0.022741353139281273
loss_c:1.9309558868408203
loss_r:0.019579635933041573
loss_c:1.7082160711288452
loss_r:0.02236383780837059
loss_c:1.8302719593048096
loss_r:0.022150574252009392
loss_c:1.8554924726486206
loss_r:0.024556437507271767
loss_c:2.0056252479553223
loss_r:0.01996554061770439
loss_c:1.7434715032577515
loss_r:0.02351047657430172
loss_c:1.9221261739730835
loss_r:0.02080434001982212
loss_c:1.6788915395736694
loss_r:0.02287432923913002
loss_c:1.7694547176361084
loss_r:0.021871156990528107
loss_c:1.8266475200653076
loss_r:0.023394286632537842
loss_c:1.9593784809112549
loss_r:0.019522935152053833
loss_c:1.7259048223495483
loss_r:0.02257706969976425
loss_c:1.8884563446044922
loss_r:0.01869547739624977
loss_c:1.700707197189331
loss_r:0.021542809903621674
loss_c:1.8109705448150635
loss_r:0.021510237827897072
loss_c:1.8836817741394043
loss_r:0.022535212337970734
loss_c:1.9917352199554443
loss_r:0.019785821437835693
loss_c:1.7969977855682373
loss_r:0.023523878306150436
loss_c:1.9836313724517822
loss_r:0.021932929754257202
loss_c:1.8191956281661987
loss_r:0.027013767510652542
loss_c:1.9378142356872559
loss_r:0.022531362250447273
loss_c:1.8763269186019897
loss_r:0.024221481755375862
loss_c:1.9681921005249023
loss_r:0.01997096836566925
loss_c:1.7233179807662964
loss_r:0.020802391692996025
loss_c:1.8375329971313477
loss_r:0.020002832636237144
loss_c:1.7630923986434937
loss_r:0.02259848266839981
loss_c:1.903383731842041
loss_r:0.020880287513136864
loss_c:1.9156855344772339
loss_r:0.022018035873770714
loss_c:1.9653681516647339
loss_r:0.018525980412960052
loss_c:1.7869619131088257
loss_r:0.020364392548799515
loss_c:1.846947431564331
loss_r:0.020506329834461212
loss_c:1.758496642112732
loss_r:0.02443908154964447
loss_c:1.927952527999878
loss_r:0.020349930971860886
loss_c:1.8972489833831787
loss_r:0.021697357296943665
loss_c:1.9735705852508545
loss_r:0.02001551166176796
loss_c:1.8001537322998047
loss_r:0.02144813910126686
loss_c:1.8842061758041382
loss_r:0.020682942122220993
loss_c:1.7287671566009521
loss_r:0.02437555603682995
loss_c:1.8373572826385498
loss_r:0.021596265956759453
loss_c:1.8624825477600098
loss_r:0.023253945633769035
loss_c:1.961915373802185
loss_r:0.022556595504283905
loss_c:1.8090208768844604
loss_r:0.0243921410292387
loss_c:1.8678319454193115
loss_r:0.02302679605782032
loss_c:1.7175853252410889
loss_r:0.02584870159626007
loss_c:1.8009637594223022
loss_r:0.02259727567434311
loss_c:1.7776858806610107
loss_r:0.01989884302020073
loss_c:1.7811578512191772
loss_r:0.020540602505207062
loss_c:1.7239253520965576
loss_r:0.0206172876060009
loss_c:1.7456443309783936
loss_r:0.022307908162474632
loss_c:1.6526241302490234
loss_r:0.024490395560860634
loss_c:1.858100175857544
loss_r:0.022381331771612167
loss_c:1.8279860019683838
loss_r:0.020475292578339577
loss_c:1.7449501752853394
loss_r:0.02114785835146904
loss_c:1.7278480529785156
loss_r:0.020512595772743225
loss_c:1.782025694847107
loss_r:0.020560968667268753
loss_c:1.6235268115997314
loss_r:0.023368433117866516
loss_c:1.847407341003418
loss_r:0.019114840775728226
loss_c:1.7548288106918335
loss_r:0.0208012443035841
loss_c:1.8551877737045288
loss_r:0.021208852529525757
loss_c:1.7340009212493896
loss_r:0.019769636914134026
loss_c:1.725568175315857
loss_r:0.022067630663514137
loss_c:1.629402995109558
loss_r:0.023132339119911194
loss_c:1.8516944646835327
loss_r:0.018842382356524467
loss_c:1.6519216299057007
loss_r:0.017676997929811478
loss_c:1.6427310705184937
loss_r:0.02170739881694317
loss_c:1.6320093870162964
loss_r:0.019771341234445572
loss_c:1.649200439453125
loss_r:0.021210283041000366
loss_c:1.5638679265975952
loss_r:0.022446895018219948
loss_c:1.7176116704940796
loss_r:0.02180390991270542
loss_c:1.7013134956359863
loss_r:0.0231802798807621
loss_c:1.7587321996688843
loss_r:0.022990556433796883
loss_c:1.6237268447875977
loss_r:0.019724447280168533
loss_c:1.664000391960144
loss_r:0.02060387283563614
loss_c:1.5434093475341797
loss_r:0.022315939888358116
loss_c:1.71345853805542
loss_r:0.023484058678150177
loss_c:1.8015480041503906
loss_r:0.024388356134295464
loss_c:1.72312331199646
loss_r:0.024264024570584297
loss_c:1.6024179458618164
loss_r:0.020829936489462852
loss_c:1.6414334774017334
loss_r:0.018390018492937088
loss_c:1.4615672826766968
loss_r:0.021296054124832153
loss_c:1.7089581489562988
loss_r:0.021558338776230812
loss_c:1.6917680501937866
loss_r:0.020509647205471992
loss_c:1.6312336921691895
loss_r:0.02152639627456665
loss_c:1.519087791442871
loss_r:0.021127615123987198
loss_c:1.6446869373321533
loss_r:0.019886484369635582
loss_c:1.5153077840805054
loss_r:0.020554685965180397
loss_c:1.6608656644821167
loss_r:0.020233549177646637
loss_c:1.7114150524139404
loss_r:0.02198091521859169
loss_c:1.737545371055603
loss_r:0.01886685937643051
loss_c:1.5052433013916016
loss_r:0.019257908686995506
loss_c:1.6742686033248901
loss_r:0.02003713697195053
loss_c:1.5595576763153076
loss_r:0.01771462708711624
loss_c:1.614048957824707
loss_r:0.020576216280460358
loss_c:1.8056854009628296
loss_r:0.023767948150634766
loss_c:1.7896031141281128
loss_r:0.020210327580571175
loss_c:1.4652984142303467
loss_r:0.022678270936012268
loss_c:1.7088119983673096
loss_r:0.022303152829408646
loss_c:1.5668872594833374
loss_r:0.020780974999070168
loss_c:1.5615547895431519
loss_r:0.02267695590853691
loss_c:1.6208829879760742
loss_r:0.02341475896537304
loss_c:1.6948795318603516
loss_r:0.02081947587430477
loss_c:1.4518150091171265
loss_r:0.022248636931180954
loss_c:1.5931620597839355
loss_r:0.021097294986248016
loss_c:1.573999285697937
loss_r:0.0222055334597826
loss_c:1.5864757299423218
loss_r:0.025185564532876015
loss_c:1.7749569416046143
loss_r:0.023663794621825218
loss_c:1.697453498840332
loss_r:0.022727690637111664
loss_c:1.4005358219146729
loss_r:0.02193431742489338
loss_c:1.5783014297485352
loss_r:0.023808974772691727
loss_c:1.457891821861267
loss_r:0.02257644012570381
loss_c:1.5198736190795898
loss_r:0.02520163170993328
loss_c:1.6941559314727783
loss_r:0.024088585749268532
loss_c:1.5743730068206787
loss_r:0.024323539808392525
loss_c:1.4432144165039062
loss_r:0.02532738260924816
loss_c:1.6980403661727905
loss_r:0.024617379531264305
loss_c:1.5269101858139038
loss_r:0.021568523719906807
loss_c:1.500772476196289
loss_r:0.023099714890122414
loss_c:1.746363639831543
loss_r:0.025273403152823448
loss_c:1.5882899761199951
loss_r:0.022359652444720268
loss_c:1.4375847578048706
loss_r:0.023468678817152977
loss_c:1.681503176689148
loss_r:0.022822381928563118
loss_c:1.5432370901107788
loss_r:0.02124800533056259
loss_c:1.5093169212341309
loss_r:0.020993411540985107
loss_c:1.5964401960372925
loss_r:0.024271979928016663
loss_c:1.5481748580932617
loss_r:0.0209004245698452
loss_c:1.4306941032409668
loss_r:0.021850956603884697
loss_c:1.5673284530639648
loss_r:0.022973686456680298
loss_c:1.4570810794830322
loss_r:0.02208852581679821
loss_c:1.5641230344772339
loss_r:0.021574068814516068
loss_c:1.6763103008270264
loss_r:0.023079685866832733
loss_c:1.5850307941436768
loss_r:0.024050861597061157
loss_c:1.523587942123413
loss_r:0.024915823712944984
loss_c:1.7121329307556152
loss_r:0.024725914001464844
loss_c:1.533974051475525
loss_r:0.021481264382600784
loss_c:1.5301737785339355
loss_r:0.022526200860738754
loss_c:1.6493934392929077
loss_r:0.02108120359480381
loss_c:1.5280636548995972
loss_r:0.023663843050599098
loss_c:1.4143341779708862
loss_r:0.02659313566982746
loss_c:1.6743495464324951
loss_r:0.022633610293269157
loss_c:1.4313949346542358
loss_r:0.021524732932448387
loss_c:1.4993594884872437
loss_r:0.020357642322778702
loss_c:1.6111019849777222
loss_r:0.020782511681318283
loss_c:1.5547994375228882
loss_r:0.02406761795282364
loss_c:1.5380592346191406
loss_r:0.023349450901150703
loss_c:1.7088778018951416
loss_r:0.024680696427822113
loss_c:1.6498111486434937
loss_r:0.021454621106386185
loss_c:1.6754893064498901
loss_r:0.02371852844953537
loss_c:1.729820966720581
loss_r:0.023348091170191765
loss_c:1.6421823501586914
loss_r:0.0227279681712389
loss_c:1.5019938945770264
loss_r:0.023024659603834152
loss_c:1.6227883100509644
loss_r:0.022850889712572098
loss_c:1.5022786855697632
loss_r:0.022587863728404045
loss_c:1.6565048694610596
loss_r:0.021415943279862404
loss_c:1.6334826946258545
loss_r:0.02043706551194191
loss_c:1.5720288753509521
loss_r:0.02024823985993862
loss_c:1.48417329788208
loss_r:0.02087903395295143
loss_c:1.5830104351043701
loss_r:0.016885953024029732
loss_c:1.4258759021759033
loss_r:0.01922672986984253
loss_c:1.6578019857406616
loss_r:0.018724773079156876
loss_c:1.6609309911727905
loss_r:0.018085671588778496
loss_c:1.5825669765472412
loss_r:0.01973641663789749
loss_c:1.5464861392974854
loss_r:0.01779935695230961
loss_c:1.5191186666488647
loss_r:0.017153915017843246
loss_c:1.4235066175460815
loss_r:0.018038718029856682
loss_c:1.6274492740631104
loss_r:0.018145989626646042
loss_c:1.6354854106903076
loss_r:0.016542751342058182
loss_c:1.5768935680389404
loss_r:0.017742807045578957
loss_c:1.5607179403305054
loss_r:0.017863230779767036
loss_c:1.5889320373535156
loss_r:0.017822707071900368
loss_c:1.5153326988220215
loss_r:0.017423169687390327
loss_c:1.5590976476669312
loss_r:0.01953742839396
loss_c:1.6606439352035522
loss_r:0.017710639163851738
loss_c:1.6145992279052734
loss_r:0.022323280572891235
loss_c:1.6166698932647705
loss_r:0.019566673785448074
loss_c:1.6160606145858765
loss_r:0.018951887264847755
loss_c:1.4737443923950195
loss_r:0.02013426460325718
loss_c:1.6280587911605835
loss_r:0.022413697093725204
loss_c:1.6867656707763672
loss_r:0.01912577450275421
loss_c:1.6456750631332397
loss_r:0.021256474778056145
loss_c:1.583847999572754
loss_r:0.01996932365000248
loss_c:1.5394923686981201
loss_r:0.018965447321534157
loss_c:1.5480432510375977
loss_r:0.018445195630192757
loss_c:1.5605950355529785
loss_r:0.020290467888116837
loss_c:1.6239259243011475
loss_r:0.016517238691449165
loss_c:1.6209595203399658
loss_r:0.018178563565015793
loss_c:1.4563931226730347
loss_r:0.018478874117136
loss_c:1.5789785385131836
loss_r:0.017017873004078865
loss_c:1.5162935256958008
loss_r:0.015879135578870773
loss_c:1.5350631475448608
loss_r:0.018300026655197144
loss_c:1.6716413497924805
loss_r:0.016462326049804688
loss_c:1.5577850341796875
loss_r:0.018503474071621895
loss_c:1.5019668340682983
loss_r:0.019087016582489014
loss_c:1.5812095403671265
loss_r:0.018323149532079697
loss_c:1.5993965864181519
loss_r:0.014452427625656128
loss_c:1.4984169006347656
loss_r:0.017790500074625015
loss_c:1.7076759338378906
loss_r:0.014505238272249699
loss_c:1.5310519933700562
loss_r:0.01721023954451084
loss_c:1.5095865726470947
loss_r:0.016923142597079277
loss_c:1.5948013067245483
loss_r:0.015141424722969532
loss_c:1.4849518537521362
loss_r:0.015073929913341999
loss_c:1.5403764247894287
loss_r:0.017677709460258484
loss_c:1.7206096649169922
loss_r:0.014605492353439331
loss_c:1.5188610553741455
loss_r:0.015868691727519035
loss_c:1.4677908420562744
loss_r:0.01846940442919731
loss_c:1.6069059371948242
loss_r:0.015568388625979424
loss_c:1.426802635192871
loss_r:0.016153529286384583
loss_c:1.5083074569702148
loss_r:0.019475027918815613
loss_c:1.6621897220611572
loss_r:0.01594623550772667
loss_c:1.646294116973877
loss_r:0.016512293368577957
loss_c:1.4846786260604858
loss_r:0.01909695193171501
loss_c:1.598917841911316
loss_r:0.018117830157279968
loss_c:1.5841357707977295
loss_r:0.015049641951918602
loss_c:1.5167144536972046
loss_r:0.018009213730692863
loss_c:1.629132628440857
loss_r:0.016034884378314018
loss_c:1.662805438041687
loss_r:0.01749938167631626
loss_c:1.4825468063354492
loss_r:0.01892983168363571
loss_c:1.6302831172943115
loss_r:0.016284286975860596
loss_c:1.4666774272918701
loss_r:0.014867198653519154
loss_c:1.533217191696167
loss_r:0.019467124715447426
loss_c:1.6455967426300049
loss_r:0.01611752063035965
loss_c:1.5874366760253906
loss_r:0.016706375405192375
loss_c:1.4631764888763428
loss_r:0.020495455712080002
loss_c:1.6451528072357178
loss_r:0.018537359312176704
loss_c:1.535560965538025
loss_r:0.0175706185400486
loss_c:1.501632571220398
loss_r:0.01904364302754402
loss_c:1.6638497114181519
loss_r:0.01591489650309086
loss_c:1.660825252532959
loss_r:0.018094396218657494
loss_c:1.5262954235076904
loss_r:0.019764062017202377
loss_c:1.6556932926177979
loss_r:0.018612390384078026
loss_c:1.5353131294250488
loss_r:0.016455499455332756
loss_c:1.5483694076538086
loss_r:0.01888320781290531
loss_c:1.6334474086761475
loss_r:0.017383448779582977
loss_c:1.6396945714950562
loss_r:0.017033573240041733
loss_c:1.4575051069259644
loss_r:0.02220993861556053
loss_c:1.705088496208191
loss_r:0.019669510424137115
loss_c:1.5867104530334473
loss_r:0.016958804801106453
loss_c:1.5226869583129883
loss_r:0.022041741758584976
loss_c:1.7345068454742432
loss_r:0.017954494804143906
loss_c:1.65872323513031
loss_r:0.019781669601798058
loss_c:1.5098509788513184
loss_r:0.02278881147503853
loss_c:1.70468270778656
loss_r:0.02110186591744423
loss_c:1.5647649765014648
loss_r:0.018873589113354683
loss_c:1.5310564041137695
loss_r:0.02248259261250496
loss_c:1.6972535848617554
loss_r:0.021719446405768394
loss_c:1.7800449132919312
loss_r:0.020941270515322685
loss_c:1.5280141830444336
loss_r:0.02570360153913498
loss_c:1.7092574834823608
loss_r:0.024394195526838303
loss_c:1.57174813747406
loss_r:0.020813744515180588
loss_c:1.5232367515563965
loss_r:0.021414633840322495
loss_c:1.6150627136230469
loss_r:0.022216234356164932
loss_c:1.6937073469161987
loss_r:0.021895118057727814
loss_c:1.5066657066345215
loss_r:0.025520717725157738
loss_c:1.7480677366256714
loss_r:0.02243432030081749
loss_c:1.5167264938354492
loss_r:0.020088788121938705
loss_c:1.5369691848754883
loss_r:0.021328847855329514
loss_c:1.687590479850769
loss_r:0.02052166871726513
loss_c:1.642221450805664
loss_r:0.021482985466718674
loss_c:1.572580099105835
loss_r:0.023725876584649086
loss_c:1.7304673194885254
loss_r:0.023263197392225266
loss_c:1.5114080905914307
loss_r:0.023288046941161156
loss_c:1.5973260402679443
loss_r:0.022819802165031433
loss_c:1.7120087146759033
loss_r:0.01992025226354599
loss_c:1.5713889598846436
loss_r:0.021213993430137634
loss_c:1.5179060697555542
loss_r:0.023703165352344513
loss_c:1.7069587707519531
loss_r:0.021871834993362427
loss_c:1.5512397289276123
loss_r:0.020326433703303337
loss_c:1.545986533164978
loss_r:0.02287466637790203
loss_c:1.7685273885726929
loss_r:0.01906786672770977
loss_c:1.6541122198104858
loss_r:0.021827904507517815
loss_c:1.5495465993881226
loss_r:0.02289166860282421
loss_c:1.671720266342163
loss_r:0.022753091529011726
loss_c:1.5237157344818115
loss_r:0.023150445893406868
loss_c:1.6263765096664429
loss_r:0.023505395278334618
loss_c:1.7313584089279175
loss_r:0.020341230556368828
loss_c:1.6531150341033936
loss_r:0.023018313571810722
loss_c:1.6003389358520508
loss_r:0.023440618067979813
loss_c:1.6553797721862793
loss_r:0.022988934069871902
loss_c:1.5177760124206543
loss_r:0.022683128714561462
loss_c:1.6405175924301147
loss_r:0.023651955649256706
loss_c:1.7757704257965088
loss_r:0.019943006336688995
loss_c:1.6525890827178955
loss_r:0.022290494292974472
loss_c:1.660456895828247
loss_r:0.02375974878668785
loss_c:1.6628098487854004
loss_r:0.022915294393897057
loss_c:1.5290167331695557
loss_r:0.02333376370370388
loss_c:1.6778401136398315
loss_r:0.023966152220964432
loss_c:1.703129529953003
loss_r:0.019295968115329742
loss_c:1.5895828008651733
loss_r:0.025790372863411903
loss_c:1.747896432876587
loss_r:0.025029726326465607
loss_c:1.7610063552856445
loss_r:0.02633681520819664
loss_c:1.6572515964508057
loss_r:0.02632042206823826
loss_c:1.8344367742538452
loss_r:0.024667849764227867
loss_c:1.7717676162719727
loss_r:0.024861685931682587
loss_c:1.7343835830688477
loss_r:0.024999381974339485
loss_c:1.7338905334472656
loss_r:0.02411503903567791
loss_c:1.7492130994796753
loss_r:0.026972830295562744
loss_c:1.664442777633667
loss_r:0.025627072900533676
loss_c:1.7913122177124023
loss_r:0.022730888798832893
loss_c:1.7289979457855225
loss_r:0.024087633937597275
loss_c:1.7280629873275757
loss_r:0.02367006242275238
loss_c:1.7905466556549072
loss_r:0.024217648431658745
loss_c:1.8352241516113281
loss_r:0.025003688409924507
loss_c:1.680822730064392
loss_r:0.026133451610803604
loss_c:1.8143830299377441
loss_r:0.023228252306580544
loss_c:1.753110408782959
loss_r:0.022936327382922173
loss_c:1.7096269130706787
loss_r:0.02565295435488224
loss_c:1.8117644786834717
loss_r:0.0253852978348732
loss_c:1.8606293201446533
loss_r:0.02715006284415722
loss_c:1.75198495388031
loss_r:0.02854742296040058
loss_c:1.8697112798690796
loss_r:0.0278982724994421
loss_c:1.8810205459594727
loss_r:0.025393124669790268
loss_c:1.783012866973877
loss_r:0.02627115696668625
loss_c:1.8016574382781982
loss_r:0.025302350521087646
loss_c:1.8161818981170654
loss_r:0.025856904685497284
loss_c:1.6918848752975464
loss_r:0.026455583050847054
loss_c:1.8506087064743042
loss_r:0.024822736158967018
loss_c:1.7733453512191772
loss_r:0.025990959256887436
loss_c:1.7497104406356812
loss_r:0.02562076225876808
loss_c:1.7773607969284058
loss_r:0.02416294813156128
loss_c:1.8218116760253906
loss_r:0.02521650865674019
loss_c:1.7303622961044312
loss_r:0.02585909143090248
loss_c:1.8884649276733398
loss_r:0.022863512858748436
loss_c:1.7766265869140625
loss_r:0.024820268154144287
loss_c:1.7854061126708984
loss_r:0.025007901713252068
loss_c:1.8257946968078613
loss_r:0.023152150213718414
loss_c:1.8294165134429932
loss_r:0.025235075503587723
loss_c:1.6917351484298706
loss_r:0.02506326511502266
loss_c:1.8392646312713623
loss_r:0.02249274030327797
loss_c:1.7495191097259521
loss_r:0.025036055594682693
loss_c:1.7006614208221436
loss_r:0.025009015575051308
loss_c:1.7618550062179565
loss_r:0.023349149152636528
loss_c:1.8257369995117188
loss_r:0.0269196555018425
loss_c:1.7071166038513184
total_val_loss:1.7678864002227783
Validation loss decreased (1.781393 --> 1.767886).  Saving model ...
epoch: 5/20
loss_r:0.029771972447633743
loss_c:0.7379940748214722
tensor(1.2903, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030868858098983765
loss_c:0.6523828506469727
tensor(1.2480, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015110882930457592
loss_c:0.7731113433837891
tensor(1.2485, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01724785752594471
loss_c:0.7632406949996948
tensor(1.2519, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03606690466403961
loss_c:0.8415929079055786
tensor(1.3731, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018881024792790413
loss_c:0.7623952627182007
tensor(1.2581, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016194047406315804
loss_c:0.9293596148490906
tensor(1.3386, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03367167338728905
loss_c:0.8562402129173279
tensor(1.3712, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01830914244055748
loss_c:0.7684097290039062
tensor(1.2587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01601136289536953
loss_c:0.78864586353302
tensor(1.2602, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015133779495954514
loss_c:0.8209303617477417
tensor(1.2743, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01912822388112545
loss_c:0.9005391597747803
tensor(1.3349, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02954808622598648
loss_c:0.8235068321228027
tensor(1.3360, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024879993870854378
loss_c:0.8907753825187683
tensor(1.3536, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021237995475530624
loss_c:0.843264102935791
tensor(1.3120, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014685751870274544
loss_c:0.7395147085189819
tensor(1.2268, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11448559910058975
loss_c:0.9638415575027466
tensor(1.7723, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01783427782356739
loss_c:0.8497838973999023
tensor(1.3013, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05184426158666611
loss_c:0.8499836921691895
tensor(1.4443, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016091009601950645
loss_c:0.8384121656417847
tensor(1.2878, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019372403621673584
loss_c:0.7296457290649414
tensor(1.2411, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031175067648291588
loss_c:0.9216877818107605
tensor(1.3972, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018560176715254784
loss_c:0.7774857878684998
tensor(1.2644, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02258940227329731
loss_c:0.9531598091125488
tensor(1.3790, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018713420256972313
loss_c:0.8243850469589233
tensor(1.2912, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025411881506443024
loss_c:0.9254024028778076
tensor(1.3753, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030255217105150223
loss_c:0.9285719394683838
tensor(1.3972, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027736932039260864
loss_c:0.865771472454071
tensor(1.3517, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02423246204853058
loss_c:0.8488341569900513
tensor(1.3278, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033276647329330444
loss_c:0.9260053634643555
tensor(1.4082, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0165854599326849
loss_c:0.8736780881881714
tensor(1.3100, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014918765053153038
loss_c:0.8296442031860352
tensor(1.2786, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025333309546113014
loss_c:0.7487338781356812
tensor(1.2766, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021598221734166145
loss_c:0.7967590093612671
tensor(1.2879, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01904759369790554
loss_c:0.765136182308197
tensor(1.2597, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032743994146585464
loss_c:0.94403475522995
tensor(1.4160, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024069979786872864
loss_c:0.8635560870170593
tensor(1.3353, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03130880743265152
loss_c:0.7450053095817566
tensor(1.2992, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01836419478058815
loss_c:0.7645142078399658
tensor(1.2565, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03185210004448891
loss_c:0.7793485522270203
tensor(1.3206, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01948796585202217
loss_c:0.7597267627716064
tensor(1.2584, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023162532597780228
loss_c:0.8456432223320007
tensor(1.3215, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05148301646113396
loss_c:0.9196432828903198
tensor(1.4803, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020169712603092194
loss_c:0.9440406560897827
tensor(1.3641, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06236029416322708
loss_c:0.9067069888114929
tensor(1.5181, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025502271950244904
loss_c:0.8346796035766602
tensor(1.3251, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032526031136512756
loss_c:0.8781590461730957
tensor(1.3784, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014310791157186031
loss_c:0.8119349479675293
tensor(1.2663, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015795281156897545
loss_c:0.7456323504447937
tensor(1.2354, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038866251707077026
loss_c:0.7683656215667725
tensor(1.3430, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025649037212133408
loss_c:0.8227289915084839
tensor(1.3191, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02094263583421707
loss_c:0.8270398378372192
tensor(1.3021, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0147471372038126
loss_c:0.7303632497787476
tensor(1.2226, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019784362986683846
loss_c:0.7707772254943848
tensor(1.2659, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0176071859896183
loss_c:0.855579137802124
tensor(1.3044, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016347981989383698
loss_c:0.7113844752311707
tensor(1.2184, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03735392913222313
loss_c:0.7913590669631958
tensor(1.3495, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020631760358810425
loss_c:0.8238255977630615
tensor(1.2990, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018513595685362816
loss_c:0.9568184614181519
tensor(1.3650, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011768238618969917
loss_c:0.7858433723449707
tensor(1.2411, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015091472305357456
loss_c:0.8914589881896973
tensor(1.3141, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.047489553689956665
loss_c:0.8248114585876465
tensor(1.4104, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02008124068379402
loss_c:0.8016642928123474
tensor(1.2841, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02638740837574005
loss_c:0.7323936820030212
tensor(1.2711, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03707350790500641
loss_c:0.8631894588470459
tensor(1.3891, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02771657519042492
loss_c:0.8417738676071167
tensor(1.3383, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02015090547502041
loss_c:0.7827271819114685
tensor(1.2736, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022320901975035667
loss_c:0.8046326637268066
tensor(1.2949, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026307204738259315
loss_c:0.7598373293876648
tensor(1.2861, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021140964701771736
loss_c:0.8501704931259155
tensor(1.3158, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016440631821751595
loss_c:0.8248891830444336
tensor(1.2819, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022396741434931755
loss_c:0.9066318273544312
tensor(1.3529, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025907067582011223
loss_c:1.0054595470428467
tensor(1.4235, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016994822770357132
loss_c:0.8868740797042847
tensor(1.3192, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01392603199928999
loss_c:0.7911095023155212
tensor(1.2522, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03596086427569389
loss_c:0.9277409315109253
tensor(1.4214, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019715500995516777
loss_c:0.816177248954773
tensor(1.2904, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016198109835386276
loss_c:0.942976176738739
tensor(1.3473, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.051412731409072876
loss_c:0.8138026595115662
tensor(1.4219, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024112610146403313
loss_c:0.952971339225769
tensor(1.3860, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021747929975390434
loss_c:0.7879757285118103
tensor(1.2830, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015398848801851273
loss_c:0.9436682462692261
tensor(1.3441, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014955665916204453
loss_c:0.787155032157898
tensor(1.2540, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019356442615389824
loss_c:0.9384957551956177
tensor(1.3577, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031579479575157166
loss_c:0.9739751219749451
tensor(1.4290, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018511639907956123
loss_c:0.727192759513855
tensor(1.2352, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07476212829351425
loss_c:0.9009013175964355
tensor(1.5701, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01743052341043949
loss_c:0.8720876574516296
tensor(1.3121, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01660468988120556
loss_c:0.8885078430175781
tensor(1.3178, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02217048965394497
loss_c:0.8220793604850769
tensor(1.3040, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025749558582901955
loss_c:0.9160405993461609
tensor(1.3717, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031602054834365845
loss_c:0.7538954615592957
tensor(1.3056, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024842940270900726
loss_c:0.8525199890136719
tensor(1.3323, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02473350428044796
loss_c:0.769295334815979
tensor(1.2853, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023583577945828438
loss_c:0.9108184576034546
tensor(1.3596, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01596730947494507
loss_c:0.9022331237792969
tensor(1.3228, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02217419259250164
loss_c:0.9754852056503296
tensor(1.3897, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015077621676027775
loss_c:0.7447043657302856
tensor(1.2311, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0545814149081707
loss_c:0.9321433901786804
tensor(1.5018, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014367230236530304
loss_c:0.75693678855896
tensor(1.2350, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018509456887841225
loss_c:0.8201779127120972
tensor(1.2876, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015983687713742256
loss_c:0.7633309364318848
tensor(1.2454, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022963957861065865
loss_c:0.9269616007804871
tensor(1.3659, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014449277892708778
loss_c:0.8214592933654785
tensor(1.2712, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019066225737333298
loss_c:0.73564213514328
tensor(1.2428, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022440819069743156
loss_c:1.0217030048370361
tensor(1.4164, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022663019597530365
loss_c:0.9554070234298706
tensor(1.3804, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041069887578487396
loss_c:0.9766610860824585
tensor(1.4701, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04151872172951698
loss_c:1.0438405275344849
tensor(1.5093, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06714535504579544
loss_c:0.9753983020782471
tensor(1.5796, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01868416555225849
loss_c:0.7942923307418823
tensor(1.2740, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01868208311498165
loss_c:0.8538435697555542
tensor(1.3071, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01757345348596573
loss_c:0.7657410502433777
tensor(1.2536, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018613504245877266
loss_c:0.828921914100647
tensor(1.2930, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018602870404720306
loss_c:0.807403564453125
tensor(1.2811, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020903659984469414
loss_c:0.8686968088150024
tensor(1.3247, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03563029319047928
loss_c:0.8379817008972168
tensor(1.3696, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01839372143149376
loss_c:0.9753303527832031
tensor(1.3731, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015545116737484932
loss_c:0.8118545413017273
tensor(1.2708, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01845375820994377
loss_c:0.9261157512664795
tensor(1.3461, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025921566411852837
loss_c:0.8706409931182861
tensor(1.3468, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02740796096622944
loss_c:1.0209345817565918
tensor(1.4360, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0425892174243927
loss_c:0.8448168039321899
tensor(1.4028, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013319535180926323
loss_c:0.7638136744499207
tensor(1.2349, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0219535194337368
loss_c:0.787340521812439
tensor(1.2842, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026449520140886307
loss_c:0.7918207049369812
tensor(1.3056, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02806444838643074
loss_c:0.8108537197113037
tensor(1.3229, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017129210755228996
loss_c:0.8669891357421875
tensor(1.3078, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015486755408346653
loss_c:0.8331047892570496
tensor(1.2822, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019779358059167862
loss_c:0.7386913299560547
tensor(1.2482, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02803732641041279
loss_c:0.8929486274719238
tensor(1.3681, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015226224437355995
loss_c:0.7997004389762878
tensor(1.2625, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014035015366971493
loss_c:0.8445298671722412
tensor(1.2822, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10619369894266129
loss_c:0.88551926612854
tensor(1.6953, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027460375800728798
loss_c:0.9733891487121582
tensor(1.4101, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014969205483794212
loss_c:0.8457083702087402
tensor(1.2869, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01965395361185074
loss_c:0.7795467376708984
tensor(1.2701, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04034924507141113
loss_c:0.7716324329376221
tensor(1.3528, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02202306129038334
loss_c:0.9512801170349121
tensor(1.3751, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030010150745511055
loss_c:0.881242036819458
tensor(1.3699, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020425349473953247
loss_c:0.837012529373169
tensor(1.3052, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02118021808564663
loss_c:0.8725428581237793
tensor(1.3281, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015416478738188744
loss_c:0.8110799193382263
tensor(1.2700, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029198642820119858
loss_c:0.9346182346343994
tensor(1.3959, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021397782489657402
loss_c:0.8166660070419312
tensor(1.2981, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01779950223863125
loss_c:0.9409710764884949
tensor(1.3519, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015327364206314087
loss_c:0.820929765701294
tensor(1.2751, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021623782813549042
loss_c:0.820006251335144
tensor(1.3009, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02173662558197975
loss_c:0.924217164516449
tensor(1.3590, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02886132337152958
loss_c:0.9007193446159363
tensor(1.3758, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014198917895555496
loss_c:0.8087605237960815
tensor(1.2635, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018130088225007057
loss_c:1.0128687620162964
tensor(1.3929, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015627441927790642
loss_c:0.8877123594284058
tensor(1.3131, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04303058236837387
loss_c:1.0756361484527588
tensor(1.5321, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030158910900354385
loss_c:1.0181828737258911
tensor(1.4461, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01808891072869301
loss_c:0.7662609815597534
tensor(1.2563, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013425197452306747
loss_c:0.736531138420105
tensor(1.2203, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03287533298134804
loss_c:0.9494463801383972
tensor(1.4196, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014804945327341557
loss_c:0.8335725665092468
tensor(1.2795, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020983004942536354
loss_c:1.0020198822021484
tensor(1.3983, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01840231381356716
loss_c:0.798885703086853
tensor(1.2756, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02066466584801674
loss_c:0.8678390979766846
tensor(1.3230, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025300443172454834
loss_c:1.0224312543869019
tensor(1.4276, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030455205589532852
loss_c:0.7849859595298767
tensor(1.3191, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024612491950392723
loss_c:0.8404809236526489
tensor(1.3248, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02803078480064869
loss_c:0.9523203372955322
tensor(1.4006, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04806986078619957
loss_c:0.9406776428222656
tensor(1.4795, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030893146991729736
loss_c:0.9113041162490845
tensor(1.3903, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014289899729192257
loss_c:0.8162482976913452
tensor(1.2677, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017637602984905243
loss_c:0.8934115171432495
tensor(1.3241, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01832243800163269
loss_c:0.8148325681686401
tensor(1.2841, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013966304250061512
loss_c:0.8334301710128784
tensor(1.2757, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021024568006396294
loss_c:0.8689563274383545
tensor(1.3251, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019408710300922394
loss_c:0.8996347188949585
tensor(1.3350, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014878924936056137
loss_c:0.8072234988212585
tensor(1.2652, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02929179184138775
loss_c:0.7709394693374634
tensor(1.3068, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01674654707312584
loss_c:0.7443928122520447
tensor(1.2387, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024063896387815475
loss_c:0.9044265747070312
tensor(1.3574, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034404534846544266
loss_c:0.78492271900177
tensor(1.3364, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020969610661268234
loss_c:0.816206157207489
tensor(1.2959, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025103706866502762
loss_c:1.0129603147506714
tensor(1.4213, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028782909736037254
loss_c:0.9018115997314453
tensor(1.3763, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017074119299650192
loss_c:0.847942054271698
tensor(1.2965, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038746427744627
loss_c:0.9283058047294617
tensor(1.4337, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021995265036821365
loss_c:0.8122279047966003
tensor(1.2981, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017007986083626747
loss_c:0.7142752408981323
tensor(1.2229, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02171989716589451
loss_c:0.8889660835266113
tensor(1.3389, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021654557436704636
loss_c:0.9595929980278015
tensor(1.3774, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03235718980431557
loss_c:0.7833367586135864
tensor(1.3268, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018429122865200043
loss_c:0.982632040977478
tensor(1.3762, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016217859461903572
loss_c:0.8230818510055542
tensor(1.2791, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017402544617652893
loss_c:0.8799554109573364
tensor(1.3154, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03270716592669487
loss_c:1.0575649738311768
tensor(1.4788, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02017497643828392
loss_c:0.8962284922599792
tensor(1.3362, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02454892359673977
loss_c:0.869837760925293
tensor(1.3406, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01909746043384075
loss_c:0.8192696571350098
tensor(1.2893, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014677109196782112
loss_c:0.8378753662109375
tensor(1.2804, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01895171031355858
loss_c:0.7654210925102234
tensor(1.2591, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021934041753411293
loss_c:0.8616129755973816
tensor(1.3248, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023285625502467155
loss_c:0.9290446043014526
tensor(1.3676, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025805827230215073
loss_c:0.8433756828308105
tensor(1.3316, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030596232041716576
loss_c:0.6833683848381042
tensor(1.2647, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019955551251769066
loss_c:0.8663458824157715
tensor(1.3187, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023245954886078835
loss_c:0.8219246864318848
tensor(1.3087, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.061842091381549835
loss_c:0.7501415014266968
tensor(1.4373, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01651850901544094
loss_c:0.854224681854248
tensor(1.2971, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024850618094205856
loss_c:0.87824547290802
tensor(1.3466, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015030610375106335
loss_c:0.8921451568603516
tensor(1.3116, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0223099198192358
loss_c:0.9766539931297302
tensor(1.3897, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03535380959510803
loss_c:0.8486936092376709
tensor(1.3759, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020266158506274223
loss_c:0.8170226812362671
tensor(1.2930, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03572438657283783
loss_c:0.8780238032341003
tensor(1.3936, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027773143723607063
loss_c:0.7044146060943604
tensor(1.2634, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027733808383345604
loss_c:0.7957975268363953
tensor(1.3136, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019747765734791756
loss_c:0.8366271257400513
tensor(1.3016, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02773572877049446
loss_c:0.8178012371063232
tensor(1.3256, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017516568303108215
loss_c:0.9443999528884888
tensor(1.3515, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014633259736001492
loss_c:0.8184040784835815
tensor(1.2695, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02948174439370632
loss_c:0.8506342768669128
tensor(1.3512, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017117729410529137
loss_c:0.8790091872215271
tensor(1.3137, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03453774005174637
loss_c:0.9558119177818298
tensor(1.4312, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02710914798080921
loss_c:0.8485547304153442
tensor(1.3399, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.057190679013729095
loss_c:1.0301040410995483
tensor(1.5698, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03103107586503029
loss_c:1.1722102165222168
tensor(1.5358, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021052034571766853
loss_c:0.9144880175590515
tensor(1.3503, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016955429688096046
loss_c:0.7911655306816101
tensor(1.2647, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032158225774765015
loss_c:0.8128165006637573
tensor(1.3416, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02237168326973915
loss_c:1.0088433027267456
tensor(1.4080, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01565462537109852
loss_c:0.877088189125061
tensor(1.3067, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022002410143613815
loss_c:0.8200287818908691
tensor(1.3023, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026249120011925697
loss_c:0.7614924311637878
tensor(1.2882, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016490602865815163
loss_c:0.6963809728622437
tensor(1.2110, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02034582756459713
loss_c:0.8127756118774414
tensor(1.2913, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02235829085111618
loss_c:0.8450440168380737
tensor(1.3176, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014703000895678997
loss_c:0.845770537853241
tensor(1.2855, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025334546342492104
loss_c:0.8883053660392761
tensor(1.3541, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02755163051187992
loss_c:1.1110026836395264
tensor(1.4862, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033968131989240646
loss_c:0.8240033984184265
tensor(1.3555, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01796978898346424
loss_c:0.8982433080673218
tensor(1.3282, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01811291091144085
loss_c:0.755061149597168
tensor(1.2501, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018532119691371918
loss_c:0.8897845149040222
tensor(1.3259, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017621256411075592
loss_c:0.8086289763450623
tensor(1.2774, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018864348530769348
loss_c:0.7951692938804626
tensor(1.2753, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020145118236541748
loss_c:1.0108517408370972
tensor(1.3993, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014871204271912575
loss_c:0.884676456451416
tensor(1.3073, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04593988507986069
loss_c:0.866289496421814
tensor(1.4304, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033166997134685516
loss_c:0.8182651400566101
tensor(1.3492, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014348454773426056
loss_c:0.7474410533905029
tensor(1.2295, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018981080502271652
loss_c:0.9530364871025085
tensor(1.3625, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04182202368974686
loss_c:0.877055823802948
tensor(1.4187, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02488422580063343
loss_c:0.9671220183372498
tensor(1.3955, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016825921833515167
loss_c:1.1150193214416504
tensor(1.4422, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019707104191184044
loss_c:0.7851313352584839
tensor(1.2733, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01836833730340004
loss_c:0.73778235912323
tensor(1.2416, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02308337762951851
loss_c:0.8336168527603149
tensor(1.3144, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015243546105921268
loss_c:0.7674075961112976
tensor(1.2444, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01434340700507164
loss_c:0.8423755168914795
tensor(1.2816, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02603795751929283
loss_c:0.7370327711105347
tensor(1.2741, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029694972559809685
loss_c:1.0697091817855835
tensor(1.4726, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031252048909664154
loss_c:1.0401170253753662
tensor(1.4631, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026658866554498672
loss_c:0.8654413223266602
tensor(1.3473, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04440109804272652
loss_c:0.8035876750946045
tensor(1.3900, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014668049290776253
loss_c:0.840874195098877
tensor(1.2821, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016811685636639595
loss_c:0.7936946153640747
tensor(1.2654, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012804021127521992
loss_c:0.8809932470321655
tensor(1.2960, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01831527054309845
loss_c:0.7761339545249939
tensor(1.2623, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03129938617348671
loss_c:0.8003205060958862
tensor(1.3316, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02188614383339882
loss_c:0.8458320498466492
tensor(1.3159, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01583467796444893
loss_c:0.7122008204460144
tensor(1.2163, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0171021930873394
loss_c:0.8061121702194214
tensor(1.2733, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03467390313744545
loss_c:0.9239826202392578
tensor(1.4143, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017888350412249565
loss_c:0.8659080266952515
tensor(1.3096, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03158693015575409
loss_c:0.7700092196464539
tensor(1.3162, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01789962314069271
loss_c:0.7760009765625
tensor(1.2600, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016131514683365822
loss_c:0.820809543132782
tensor(1.2770, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020090576261281967
loss_c:0.8061303496360779
tensor(1.2861, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021855143830180168
loss_c:0.7795900702476501
tensor(1.2791, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017758406698703766
loss_c:0.8860484957695007
tensor(1.3201, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017558712512254715
loss_c:0.7171734571456909
tensor(1.2257, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014911385253071785
loss_c:0.7374440431594849
tensor(1.2252, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020864635705947876
loss_c:0.8424731492996216
tensor(1.3094, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019945261999964714
loss_c:0.7927072048187256
tensor(1.2777, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04185516759753227
loss_c:0.9110271334648132
tensor(1.4396, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0152435302734375
loss_c:0.7986971139907837
tensor(1.2603, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025640876963734627
loss_c:0.8089556694030762
tensor(1.3116, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02239680103957653
loss_c:0.8821942210197449
tensor(1.3382, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03190380334854126
loss_c:0.8568584322929382
tensor(1.3659, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018430199474096298
loss_c:0.8670186996459961
tensor(1.3123, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04086736962199211
loss_c:0.7504314184188843
tensor(1.3459, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02553645893931389
loss_c:0.7836127281188965
tensor(1.2969, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019348546862602234
loss_c:0.9377862215042114
tensor(1.3560, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017104031518101692
loss_c:0.8330467939376831
tensor(1.2875, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016459429636597633
loss_c:0.8736939430236816
tensor(1.3075, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03103957511484623
loss_c:0.8221036791801453
tensor(1.3426, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017719969153404236
loss_c:0.9163508415222168
tensor(1.3369, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017323724925518036
loss_c:0.8464934825897217
tensor(1.2960, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027946822345256805
loss_c:0.8158971667289734
tensor(1.3256, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015944117680191994
loss_c:0.8203339576721191
tensor(1.2752, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015723997727036476
loss_c:0.8614618182182312
tensor(1.2973, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021472357213497162
loss_c:0.940892219543457
tensor(1.3672, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0281521026045084
loss_c:0.7288717031478882
tensor(1.2777, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02995326742529869
loss_c:0.8546980619430542
tensor(1.3562, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0169568732380867
loss_c:0.8157639503479004
tensor(1.2771, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02996773272752762
loss_c:0.9533462524414062
tensor(1.4117, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027898015454411507
loss_c:0.697108268737793
tensor(1.2587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027566932141780853
loss_c:1.1221303939819336
tensor(1.4958, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016952378675341606
loss_c:1.0143580436706543
tensor(1.3885, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016279732808470726
loss_c:0.7543683052062988
tensor(1.2397, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015059339813888073
loss_c:0.903282880783081
tensor(1.3177, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023441806435585022
loss_c:0.9520086646080017
tensor(1.3820, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01345886941999197
loss_c:0.8313062191009521
tensor(1.2703, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020240196958184242
loss_c:1.207706093788147
tensor(1.5106, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02440313622355461
loss_c:1.0313000679016113
tensor(1.4303, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02014501951634884
loss_c:0.820149302482605
tensor(1.2936, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02518303133547306
loss_c:0.848422646522522
tensor(1.3317, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04473729059100151
loss_c:0.7427351474761963
tensor(1.3598, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015821855515241623
loss_c:0.9169352054595947
tensor(1.3282, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0336306057870388
loss_c:0.9578725695610046
tensor(1.4298, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0261723343282938
loss_c:0.7840466499328613
tensor(1.3005, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018842846155166626
loss_c:0.8793088793754578
tensor(1.3207, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02217959426343441
loss_c:0.9483194351196289
tensor(1.3736, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021175676956772804
loss_c:0.8122970461845398
tensor(1.2940, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01734260842204094
loss_c:0.8093439936637878
tensor(1.2755, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015601159073412418
loss_c:0.7316453456878662
tensor(1.2250, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016567934304475784
loss_c:0.7249220609664917
tensor(1.2255, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04485218971967697
loss_c:1.0020307302474976
tensor(1.5035, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05775720253586769
loss_c:0.9604753255844116
tensor(1.5377, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028632208704948425
loss_c:0.7754310965538025
tensor(1.3067, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028873274102807045
loss_c:1.0069689750671387
tensor(1.4353, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025444962084293365
loss_c:0.8791157603263855
tensor(1.3497, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02111281268298626
loss_c:0.8955937623977661
tensor(1.3398, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022061865776777267
loss_c:1.0731308460235596
tensor(1.4416, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025275256484746933
loss_c:0.8153011798858643
tensor(1.3139, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03563524782657623
loss_c:0.8113319277763367
tensor(1.3569, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02097865752875805
loss_c:0.9079880714416504
tensor(1.3460, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020281845703721046
loss_c:0.8356159925460815
tensor(1.3033, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014455561526119709
loss_c:0.8192869424819946
tensor(1.2691, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015867149457335472
loss_c:0.6916446685791016
tensor(1.2053, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015488756820559502
loss_c:0.8365713953971863
tensor(1.2831, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019569888710975647
loss_c:0.8429197072982788
tensor(1.3043, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021861141547560692
loss_c:0.8531283736228943
tensor(1.3198, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019334981217980385
loss_c:0.8943096995353699
tensor(1.3314, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03083275631070137
loss_c:0.8525810241699219
tensor(1.3584, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018467295914888382
loss_c:0.859991729259491
tensor(1.3088, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023968247696757317
loss_c:0.8271970748901367
tensor(1.3147, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042928338050842285
loss_c:0.8407389521598816
tensor(1.4045, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024846583604812622
loss_c:0.6753117442131042
tensor(1.2350, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0201790239661932
loss_c:0.8136391043663025
tensor(1.2908, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03318466991186142
loss_c:0.8705445528030396
tensor(1.3785, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019729146733880043
loss_c:0.8943071365356445
tensor(1.3332, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02969055436551571
loss_c:0.7382874488830566
tensor(1.2904, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020129693672060966
loss_c:0.8438220024108887
tensor(1.3071, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018963610753417015
loss_c:0.8232783079147339
tensor(1.2908, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026722615584731102
loss_c:0.7634572386741638
tensor(1.2913, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02689388208091259
loss_c:1.159098505973816
tensor(1.5107, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012843460775911808
loss_c:0.8295249938964844
tensor(1.2677, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020739061757922173
loss_c:0.8700379133224487
tensor(1.3243, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015481432899832726
loss_c:0.9795956611633301
tensor(1.3621, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026600338518619537
loss_c:0.7808218002319336
tensor(1.3003, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016500087454915047
loss_c:0.80833899974823
tensor(1.2718, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020835330709815025
loss_c:0.9214023947715759
tensor(1.3531, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020020361989736557
loss_c:0.8012129664421082
tensor(1.2830, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021753601729869843
loss_c:0.9739437103271484
tensor(1.3861, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039192620664834976
loss_c:1.165607213973999
tensor(1.5679, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025037018582224846
loss_c:1.0989806652069092
tensor(1.4694, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028440020978450775
loss_c:0.869839072227478
tensor(1.3576, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014887365512549877
loss_c:0.7924541234970093
tensor(1.2560, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03262713924050331
loss_c:0.8685441017150879
tensor(1.3751, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01598777249455452
loss_c:0.8373295664787292
tensor(1.2855, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0329139418900013
loss_c:0.7576370239257812
tensor(1.3153, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031765829771757126
loss_c:0.7330465316772461
tensor(1.2968, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02004612423479557
loss_c:1.0216509103775024
tensor(1.4045, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06878824532032013
loss_c:0.82207190990448
tensor(1.5065, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022460414096713066
loss_c:0.7401012182235718
tensor(1.2603, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019939742982387543
loss_c:0.8260151743888855
tensor(1.2966, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025244684889912605
loss_c:0.8534227609634399
tensor(1.3346, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014731593430042267
loss_c:0.7574512362480164
tensor(1.2366, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014281999319791794
loss_c:0.7617220878601074
tensor(1.2370, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015468457713723183
loss_c:0.8027461767196655
tensor(1.2647, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026089230552315712
loss_c:0.914660632610321
tensor(1.3719, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015085273422300816
loss_c:0.8133645057678223
tensor(1.2688, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019739825278520584
loss_c:0.8974484205245972
tensor(1.3351, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017349770292639732
loss_c:0.9147636294364929
tensor(1.3344, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01680733822286129
loss_c:1.0018489360809326
tensor(1.3801, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01788487657904625
loss_c:0.8806376457214355
tensor(1.3178, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01505153626203537
loss_c:0.7788130640983582
tensor(1.2494, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02327643893659115
loss_c:0.8565670251846313
tensor(1.3278, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024110041558742523
loss_c:0.8336375951766968
tensor(1.3188, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025534044951200485
loss_c:0.9795123338699341
tensor(1.4054, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02831081673502922
loss_c:0.7549228668212891
tensor(1.2936, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018106864765286446
loss_c:0.9229134917259216
tensor(1.3419, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013209916651248932
loss_c:0.7900005578994751
tensor(1.2473, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016858233138918877
loss_c:0.9056473970413208
tensor(1.3269, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020218441262841225
loss_c:0.9081451296806335
tensor(1.3429, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02670993283390999
loss_c:0.8671311140060425
tensor(1.3486, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030636673793196678
loss_c:0.8256690502166748
tensor(1.3429, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014532278291881084
loss_c:0.8064936399459839
tensor(1.2619, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02913295291364193
loss_c:0.7486287951469421
tensor(1.2939, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01929362304508686
loss_c:0.9624027013778687
tensor(1.3687, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020964588969945908
loss_c:0.8648823499679565
tensor(1.3222, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02130183018743992
loss_c:0.9859813451766968
tensor(1.3905, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02610788680613041
loss_c:0.8196296691894531
tensor(1.3199, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018650537356734276
loss_c:1.0029786825180054
tensor(1.3882, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01413682010024786
loss_c:0.7367257475852966
tensor(1.2214, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030308185145258904
loss_c:0.8509546518325806
tensor(1.3557, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015170671045780182
loss_c:0.8203139305114746
tensor(1.2720, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.051782459020614624
loss_c:0.8096318244934082
tensor(1.4280, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023558061569929123
loss_c:0.7972092032432556
tensor(1.2963, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017800509929656982
loss_c:0.7571045160293579
tensor(1.2487, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03125104680657387
loss_c:0.9975199699401855
tensor(1.4408, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021112989634275436
loss_c:0.8856484889984131
tensor(1.3343, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01727275177836418
loss_c:0.9646036028862
tensor(1.3609, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021950267255306244
loss_c:0.9905531406402588
tensor(1.3959, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020635752007365227
loss_c:0.6970888376235962
tensor(1.2281, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02808546833693981
loss_c:0.8760143518447876
tensor(1.3597, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013168630190193653
loss_c:0.7653123736381531
tensor(1.2328, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016809429973363876
loss_c:0.8715624213218689
tensor(1.3075, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017502551898360252
loss_c:0.8059486746788025
tensor(1.2743, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01954745501279831
loss_c:0.9051685333251953
tensor(1.3381, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015740500763058662
loss_c:0.7698243856430054
tensor(1.2465, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028347644954919815
loss_c:0.7917226552963257
tensor(1.3144, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020662112161517143
loss_c:0.9187635779380798
tensor(1.3506, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01586071215569973
loss_c:0.7711641192436218
tensor(1.2477, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012625902891159058
loss_c:0.7787665724754333
tensor(1.2374, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03381187841296196
loss_c:0.8853824138641357
tensor(1.3906, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01945456676185131
loss_c:0.8611299395561218
tensor(1.3133, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033462412655353546
loss_c:0.7897388935089111
tensor(1.3362, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024120934307575226
loss_c:0.9118012189865112
tensor(1.3622, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07239649444818497
loss_c:0.9845069646835327
tensor(1.6178, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03548085689544678
loss_c:0.9259633421897888
tensor(1.4206, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02839312143623829
loss_c:0.7116742134094238
tensor(1.2702, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0212724506855011
loss_c:0.9320704936981201
tensor(1.3608, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017807526513934135
loss_c:0.7907238006591797
tensor(1.2672, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034613024443387985
loss_c:0.9215811491012573
tensor(1.4137, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021907959133386612
loss_c:0.8395236730575562
tensor(1.3123, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019763203337788582
loss_c:0.9633538722991943
tensor(1.3716, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014676989056169987
loss_c:0.8389782309532166
tensor(1.2804, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025759756565093994
loss_c:0.8547991514205933
tensor(1.3376, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017699992284178734
loss_c:0.9189571142196655
tensor(1.3380, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02954879403114319
loss_c:0.8174632787704468
tensor(1.3335, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.047254692763090134
loss_c:0.7819992899894714
tensor(1.3909, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012259763665497303
loss_c:0.7157213091850281
tensor(1.2019, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05111302435398102
loss_c:0.9904417991638184
tensor(1.5228, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021790355443954468
loss_c:0.81371009349823
tensor(1.2976, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01702711544930935
loss_c:0.7508686780929565
tensor(1.2422, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027964269742369652
loss_c:0.9289838671684265
tensor(1.3882, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015117219649255276
loss_c:0.7868673801422119
tensor(1.2540, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014143534936010838
loss_c:0.7720026969909668
tensor(1.2416, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10600171238183975
loss_c:0.983840823173523
tensor(1.7541, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02744060568511486
loss_c:0.7348703742027283
tensor(1.2781, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019333690404891968
loss_c:0.9454609751701355
tensor(1.3604, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02109546959400177
loss_c:0.8341273665428162
tensor(1.3062, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026216678321361542
loss_c:0.8049196004867554
tensor(1.3117, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021983027458190918
loss_c:0.8709833025932312
tensor(1.3305, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023899748921394348
loss_c:0.8124239444732666
tensor(1.3060, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017510436475276947
loss_c:0.8635973930358887
tensor(1.3076, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03088693507015705
loss_c:0.9563349485397339
tensor(1.4154, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01539374515414238
loss_c:0.7581623792648315
tensor(1.2402, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02061278745532036
loss_c:0.905359148979187
tensor(1.3439, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018869437277317047
loss_c:0.9410964846611023
tensor(1.3565, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030626004561781883
loss_c:0.8619304895401001
tensor(1.3617, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019756246358156204
loss_c:0.7906261682510376
tensor(1.2766, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02005808986723423
loss_c:0.9469884634017944
tensor(1.3648, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030306944623589516
loss_c:0.9888374209403992
tensor(1.4309, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02049524337053299
loss_c:0.8404964208602905
tensor(1.3074, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016420261934399605
loss_c:0.7443105578422546
tensor(1.2370, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.12979494035243988
loss_c:0.9128639101982117
tensor(1.8052, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016784120351076126
loss_c:0.9537390470504761
tensor(1.3549, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018285393714904785
loss_c:0.8044869303703308
tensor(1.2785, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018087882548570633
loss_c:0.8106100559234619
tensor(1.2811, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020418724045157433
loss_c:0.8000583648681641
tensor(1.2850, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0172276608645916
loss_c:0.8204001188278198
tensor(1.2831, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01730942539870739
loss_c:0.773851752281189
tensor(1.2577, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037921685725450516
loss_c:0.8369562029838562
tensor(1.3776, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015666281804442406
loss_c:0.8164117336273193
tensor(1.2746, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017462026327848434
loss_c:0.7412434816360474
tensor(1.2403, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01747438870370388
loss_c:0.7377504706382751
tensor(1.2384, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01683548465371132
loss_c:0.6997865438461304
tensor(1.2146, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012389247305691242
loss_c:0.7267132997512817
tensor(1.2111, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021962106227874756
loss_c:0.8868106603622437
tensor(1.3396, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03020692616701126
loss_c:0.9031976461410522
tensor(1.3828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0341232568025589
loss_c:0.9395834803581238
tensor(1.4193, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01758079044520855
loss_c:0.7845341563224792
tensor(1.2644, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023070812225341797
loss_c:0.9053849577903748
tensor(1.3545, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018551083281636238
loss_c:0.9018329977989197
tensor(1.3338, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027760809287428856
loss_c:0.7892999649047852
tensor(1.3091, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03194538503885269
loss_c:0.8137212991714478
tensor(1.3402, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0576845146715641
loss_c:0.9043528437614441
tensor(1.4978, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02794751338660717
loss_c:0.9388726949691772
tensor(1.3935, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013753673061728477
loss_c:0.7510125041007996
tensor(1.2296, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023306895047426224
loss_c:0.9412422180175781
tensor(1.3756, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025102391839027405
loss_c:0.853670597076416
tensor(1.3341, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02198929712176323
loss_c:0.8623476028442383
tensor(1.3260, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023794300854206085
loss_c:0.9253718256950378
tensor(1.3687, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017109552398324013
loss_c:0.9454590082168579
tensor(1.3522, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018933195620775223
loss_c:0.9061970114707947
tensor(1.3378, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03867035731673241
loss_c:0.7620560526847839
tensor(1.3393, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017291974276304245
loss_c:0.9342817068099976
tensor(1.3466, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015476210042834282
loss_c:0.8489956855773926
tensor(1.2914, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016898037865757942
loss_c:0.736463725566864
tensor(1.2346, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016134103760123253
loss_c:0.8421825170516968
tensor(1.2903, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01806299388408661
loss_c:0.9549943804740906
tensor(1.3611, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022341782227158546
loss_c:0.7274569869041443
tensor(1.2522, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017335165292024612
loss_c:0.8104516863822937
tensor(1.2774, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015085546299815178
loss_c:0.7619037628173828
tensor(1.2409, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016785426065325737
loss_c:0.8162487745285034
tensor(1.2782, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01659155637025833
loss_c:0.7984911203384399
tensor(1.2674, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01834459975361824
loss_c:0.8325880765914917
tensor(1.2937, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02406681701540947
loss_c:0.9214757680892944
tensor(1.3675, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02757549285888672
loss_c:0.7701059579849243
tensor(1.2979, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04624372720718384
loss_c:1.0117335319519043
tensor(1.5123, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02230997569859028
loss_c:0.9394285082817078
tensor(1.3700, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019530033692717552
loss_c:0.8409429788589478
tensor(1.3032, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020117033272981644
loss_c:0.9186649322509766
tensor(1.3490, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01599639654159546
loss_c:0.8246955275535583
tensor(1.2790, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02116861566901207
loss_c:0.7723305225372314
tensor(1.2719, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018049322068691254
loss_c:1.0205541849136353
tensor(1.3968, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0222786758095026
loss_c:1.2526181936264038
tensor(1.5442, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03820861876010895
loss_c:1.0117707252502441
tensor(1.4784, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01817917451262474
loss_c:0.8406809568405151
tensor(1.2971, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015989238396286964
loss_c:0.832007646560669
tensor(1.2828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013332964852452278
loss_c:0.803828239440918
tensor(1.2557, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011250401847064495
loss_c:0.8377010822296143
tensor(1.2654, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015901733189821243
loss_c:0.8527811765670776
tensor(1.2938, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023809470236301422
loss_c:0.7966521978378296
tensor(1.2970, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027674071490764618
loss_c:0.7269405126571655
tensor(1.2753, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025349045172333717
loss_c:0.7963773012161255
tensor(1.3036, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016754575073719025
loss_c:0.8782541155815125
tensor(1.3113, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01661704108119011
loss_c:0.7908308506011963
tensor(1.2624, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01935218647122383
loss_c:0.8736200332641602
tensor(1.3200, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02208538167178631
loss_c:0.7953259348869324
tensor(1.2887, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02305341139435768
loss_c:1.0832526683807373
tensor(1.4520, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018736569210886955
loss_c:0.8132466077804565
tensor(1.2839, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03550199046730995
loss_c:0.7624940276145935
tensor(1.3297, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015340855345129967
loss_c:0.8225617408752441
tensor(1.2740, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015303841792047024
loss_c:0.7712209224700928
tensor(1.2454, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023221835494041443
loss_c:0.7994967699050903
tensor(1.2960, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016249828040599823
loss_c:0.7172772288322449
tensor(1.2197, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05107735097408295
loss_c:1.0369012355804443
tensor(1.5508, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013122780248522758
loss_c:0.7818512916564941
tensor(1.2414, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03042641095817089
loss_c:0.8917484283447266
tensor(1.3790, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02938033640384674
loss_c:0.8190186023712158
tensor(1.3341, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013201677240431309
loss_c:0.7555407881736755
tensor(1.2272, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02919531799852848
loss_c:1.0071039199829102
tensor(1.4374, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021481303498148918
loss_c:0.7841967344284058
tensor(1.2797, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02025267854332924
loss_c:0.8798255920410156
tensor(1.3273, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017675157636404037
loss_c:0.9177182912826538
tensor(1.3368, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016305284574627876
loss_c:0.8769814372062683
tensor(1.3082, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01546592079102993
loss_c:0.8539779186248779
tensor(1.2917, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0447256937623024
loss_c:0.9194110631942749
tensor(1.4579, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022408215329051018
loss_c:0.8759741187095642
tensor(1.3347, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01498530525714159
loss_c:0.8198919296264648
tensor(1.2706, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03354924917221069
loss_c:0.8444849848747253
tensor(1.3667, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016369003802537918
loss_c:0.8506850004196167
tensor(1.2939, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02025928534567356
loss_c:0.7437049746513367
tensor(1.2518, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019931569695472717
loss_c:0.8359851837158203
tensor(1.3015, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019872212782502174
loss_c:0.8266550898551941
tensor(1.2961, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021714627742767334
loss_c:1.0591076612472534
tensor(1.4332, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02469758875668049
loss_c:0.802449107170105
tensor(1.3041, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02244720607995987
loss_c:0.9171175956726074
tensor(1.3577, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03750653192400932
loss_c:0.8870812654495239
tensor(1.4080, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023853128775954247
loss_c:0.865982711315155
tensor(1.3356, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01581786572933197
loss_c:0.927222490310669
tensor(1.3338, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020442144945263863
loss_c:0.8528375029563904
tensor(1.3131, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01766793802380562
loss_c:0.866386890411377
tensor(1.3083, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0199888925999403
loss_c:0.8588587641716003
tensor(1.3144, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027857860550284386
loss_c:1.0330101251602173
tensor(1.4458, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02742154896259308
loss_c:0.7934216856956482
tensor(1.3113, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01829555071890354
loss_c:0.8615952730178833
tensor(1.3084, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025520360097289085
loss_c:0.8214203715324402
tensor(1.3183, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033071067184209824
loss_c:0.8563178777694702
tensor(1.3712, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04666594788432121
loss_c:0.9998129606246948
tensor(1.5107, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02239721454679966
loss_c:0.9790419340133667
tensor(1.3915, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015470191836357117
loss_c:0.8521751165390015
tensor(1.2908, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022986866533756256
loss_c:0.9075682163238525
tensor(1.3546, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040266212075948715
loss_c:0.8706914186477661
tensor(1.4106, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019328370690345764
loss_c:0.9237282276153564
tensor(1.3473, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02430008165538311
loss_c:0.9600192904472351
tensor(1.3892, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02015254646539688
loss_c:0.9598582983016968
tensor(1.3708, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02181251533329487
loss_c:0.8916320204734802
tensor(1.3406, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021181121468544006
loss_c:0.8371924161911011
tensor(1.3080, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022945400327444077
loss_c:0.7790977954864502
tensor(1.2839, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021553127095103264
loss_c:0.7043811678886414
tensor(1.2369, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014940576627850533
loss_c:0.8557578921318054
tensor(1.2908, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017076890915632248
loss_c:0.8284632563591003
tensor(1.2853, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06938611716032028
loss_c:1.0148018598556519
tensor(1.6166, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026583652943372726
loss_c:0.9547390341758728
tensor(1.3960, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04653904214501381
loss_c:1.0071420669555664
tensor(1.5118, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030396537855267525
loss_c:0.8718757033348083
tensor(1.3672, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020756205543875694
loss_c:0.7869818210601807
tensor(1.2789, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01828823983669281
loss_c:0.9066516757011414
tensor(1.3336, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021563926711678505
loss_c:0.7001585960388184
tensor(1.2350, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028274288401007652
loss_c:0.8366219401359558
tensor(1.3385, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019839607179164886
loss_c:0.8308390378952026
tensor(1.2990, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021015893667936325
loss_c:0.9496023058891296
tensor(1.3690, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03119169920682907
loss_c:0.8523921966552734
tensor(1.3596, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02241896651685238
loss_c:0.8503475189208984
tensor(1.3208, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019924720749258995
loss_c:0.8357335925102234
tensor(1.3021, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025933099910616875
loss_c:0.7923886775970459
tensor(1.3042, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025294017046689987
loss_c:0.8469753265380859
tensor(1.3313, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016322167590260506
loss_c:0.7184042930603027
tensor(1.2226, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023052604869008064
loss_c:0.9183855056762695
tensor(1.3608, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013401622883975506
loss_c:0.7209655046463013
tensor(1.2114, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022002311423420906
loss_c:0.9079462885856628
tensor(1.3506, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015811968594789505
loss_c:0.7976569533348083
tensor(1.2636, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023612158372998238
loss_c:0.8812963366508484
tensor(1.3429, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016098983585834503
loss_c:0.8467106819152832
tensor(1.2917, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015295934863388538
loss_c:0.8111122846603394
tensor(1.2686, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01573370024561882
loss_c:0.8536947965621948
tensor(1.2938, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022099509835243225
loss_c:0.9005798697471619
tensor(1.3470, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019739622250199318
loss_c:0.7748926877975464
tensor(1.2676, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017698559910058975
loss_c:0.8540863990783691
tensor(1.3023, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027344336733222008
loss_c:0.8286104202270508
tensor(1.3300, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02638975903391838
loss_c:0.9096147418022156
tensor(1.3706, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02433495968580246
loss_c:0.8345436453819275
tensor(1.3202, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030002515763044357
loss_c:1.1328151226043701
tensor(1.5096, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013981812633574009
loss_c:0.7186732292175293
tensor(1.2112, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03019748069345951
loss_c:0.8062433004379272
tensor(1.3301, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016548331826925278
loss_c:0.8207696676254272
tensor(1.2787, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014297964982688427
loss_c:0.7791054248809814
tensor(1.2458, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04181593284010887
loss_c:0.9668154716491699
tensor(1.4697, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022473106160759926
loss_c:0.9608993530273438
tensor(1.3820, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025600995868444443
loss_c:1.0075962543487549
tensor(1.4214, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032771673053503036
loss_c:0.8436384201049805
tensor(1.3621, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020020559430122375
loss_c:0.8030204772949219
tensor(1.2840, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022746961563825607
loss_c:1.0590683221817017
tensor(1.4373, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023716354742646217
loss_c:0.9579458236694336
tensor(1.3857, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01805766671895981
loss_c:0.9431373476982117
tensor(1.3527, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02629428543150425
loss_c:0.8815295100212097
tensor(1.3547, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03003876842558384
loss_c:0.8571258783340454
tensor(1.3576, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027015235275030136
loss_c:0.7421209216117859
tensor(1.2811, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015946198254823685
loss_c:0.7966359853744507
tensor(1.2628, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02066039852797985
loss_c:0.9310464859008789
tensor(1.3573, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014423239976167679
loss_c:0.7420417666435242
tensor(1.2262, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016355058178305626
loss_c:0.7400296926498413
tensor(1.2335, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018318181857466698
loss_c:0.8025547862052917
tensor(1.2764, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03676160052418709
loss_c:0.8507755994796753
tensor(1.3836, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022457696497440338
loss_c:0.8493998050689697
tensor(1.3203, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024917805567383766
loss_c:0.833781361579895
tensor(1.3224, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03242509067058563
loss_c:0.9381024241447449
tensor(1.4128, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022915320470929146
loss_c:1.0002179145812988
tensor(1.4053, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017953308299183846
loss_c:0.874424934387207
tensor(1.3143, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015715159475803375
loss_c:0.7833830714225769
tensor(1.2544, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02666102908551693
loss_c:1.0227786302566528
tensor(1.4342, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020552361384034157
loss_c:0.9237428903579712
tensor(1.3528, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020893488079309464
loss_c:0.9847320318222046
tensor(1.3879, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024466462433338165
loss_c:0.7848760485649109
tensor(1.2936, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03324737027287483
loss_c:0.7488765716552734
tensor(1.3123, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030941952019929886
loss_c:0.8099722862243652
tensor(1.3358, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019894901663064957
loss_c:0.8324512243270874
tensor(1.2997, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02055986039340496
loss_c:0.8463784456253052
tensor(1.3103, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01994381472468376
loss_c:0.8897378444671631
tensor(1.3314, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014304130338132381
loss_c:0.7773513793945312
tensor(1.2449, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017319299280643463
loss_c:0.9891058802604675
tensor(1.3746, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016724487766623497
loss_c:0.7190794348716736
tensor(1.2234, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017539290711283684
loss_c:0.9669551849365234
tensor(1.3633, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039171867072582245
loss_c:1.1159944534301758
tensor(1.5404, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03074757568538189
loss_c:0.9072068929672241
tensor(1.3885, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023437032476067543
loss_c:1.0347986221313477
tensor(1.4265, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0211227647960186
loss_c:0.7618696093559265
tensor(1.2663, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01740340143442154
loss_c:0.7529608607292175
tensor(1.2451, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02201651781797409
loss_c:0.8313581943511963
tensor(1.3084, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02194584533572197
loss_c:0.8476148843765259
tensor(1.3170, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015025104396045208
loss_c:0.8363723754882812
tensor(1.2804, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01621367782354355
loss_c:0.7922937273979187
tensor(1.2614, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013329735957086086
loss_c:0.773993194103241
tensor(1.2386, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017107028514146805
loss_c:0.8255057334899902
tensor(1.2835, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02185966819524765
loss_c:0.771509051322937
tensor(1.2748, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0166640542447567
loss_c:0.7610687017440796
tensor(1.2460, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015927022323012352
loss_c:0.7298232316970825
tensor(1.2255, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0214905496686697
loss_c:0.8526721000671387
tensor(1.3177, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016119621694087982
loss_c:0.7296406626701355
tensor(1.2260, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021318458020687103
loss_c:0.8010778427124023
tensor(1.2884, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09647103399038315
loss_c:0.9935719966888428
tensor(1.7308, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018176328390836716
loss_c:0.9222412109375
tensor(1.3413, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021663805469870567
loss_c:0.9141544103622437
tensor(1.3525, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01624481752514839
loss_c:0.9038354754447937
tensor(1.3227, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01380873378366232
loss_c:0.7608749270439148
tensor(1.2328, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02196967415511608
loss_c:0.7798468470573425
tensor(1.2795, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014461196027696133
loss_c:0.7562191486358643
tensor(1.2331, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0297418050467968
loss_c:0.8662365674972534
tensor(1.3618, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03639611229300499
loss_c:0.9116227626800537
tensor(1.4165, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024086445569992065
loss_c:0.8528475761413574
tensor(1.3293, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01808282360434532
loss_c:0.8616231679916382
tensor(1.3076, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03380385413765907
loss_c:0.9403210878372192
tensor(1.4209, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0229759830981493
loss_c:0.7959517240524292
tensor(1.2928, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022125056013464928
loss_c:0.8844152688980103
tensor(1.3382, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020630499348044395
loss_c:0.9601825475692749
tensor(1.3737, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02318253181874752
loss_c:0.8496094942092896
tensor(1.3235, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02525220438838005
loss_c:0.9836732745170593
tensor(1.4071, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03497942537069321
loss_c:0.9113032817840576
tensor(1.4097, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031964391469955444
loss_c:0.7629624605178833
tensor(1.3140, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015034396201372147
loss_c:0.8307544589042664
tensor(1.2773, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01980557106435299
loss_c:0.8735513091087341
tensor(1.3220, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019683627411723137
loss_c:0.8861086368560791
tensor(1.3284, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022066708654165268
loss_c:0.9426368474960327
tensor(1.3702, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018067223951220512
loss_c:0.8386404514312744
tensor(1.2950, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020500700920820236
loss_c:0.9865707159042358
tensor(1.3876, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019749287515878677
loss_c:0.8417791128158569
tensor(1.3041, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018285097554326057
loss_c:0.8733396530151367
tensor(1.3152, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017612800002098083
loss_c:0.766399085521698
tensor(1.2531, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01982559636235237
loss_c:0.9782659411430359
tensor(1.3799, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0145920030772686
loss_c:0.8005449771881104
tensor(1.2587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02354850433766842
loss_c:0.7407202124595642
tensor(1.2650, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021590456366539
loss_c:0.7295856475830078
tensor(1.2502, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024261433631181717
loss_c:0.7965990304946899
tensor(1.2990, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01645929366350174
loss_c:1.005913257598877
tensor(1.3803, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014925218187272549
loss_c:0.7353741526603699
tensor(1.2239, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01633729413151741
loss_c:0.8716639280319214
tensor(1.3054, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027592778205871582
loss_c:0.8673739433288574
tensor(1.3529, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017403563484549522
loss_c:0.9955136179924011
tensor(1.3786, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018111050128936768
loss_c:0.8070807456970215
tensor(1.2774, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02883024513721466
loss_c:0.8085333108901978
tensor(1.3259, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021267935633659363
loss_c:0.7423686385154724
tensor(1.2556, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044431012123823166
loss_c:0.8941349387168884
tensor(1.4429, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01938486099243164
loss_c:0.6834518313407898
tensor(1.2146, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017894871532917023
loss_c:0.7474460601806641
tensor(1.2433, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02352331392467022
loss_c:0.799746036529541
tensor(1.2974, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02035902999341488
loss_c:0.8657786250114441
tensor(1.3199, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02837052009999752
loss_c:0.8848518133163452
tensor(1.3662, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020997315645217896
loss_c:0.7552005052566528
tensor(1.2613, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0366959348320961
loss_c:0.8457403182983398
tensor(1.3816, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012097159400582314
loss_c:0.7675585746765137
tensor(1.2284, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015129082836210728
loss_c:0.8293285369873047
tensor(1.2763, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01690654642879963
loss_c:0.7553129196166992
tensor(1.2430, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016145577654242516
loss_c:0.8825125694274902
tensor(1.3105, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013088391162455082
loss_c:0.7905022501945496
tensor(1.2454, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016643421724438667
loss_c:0.7253202199935913
tensor(1.2248, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016870608553290367
loss_c:0.8223813772201538
tensor(1.2800, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012282495386898518
loss_c:0.7214685678482056
tensor(1.2029, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04671875759959221
loss_c:1.0054343938827515
tensor(1.5167, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014151793904602528
loss_c:0.759333610534668
tensor(1.2323, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029885949566960335
loss_c:0.7407988905906677
tensor(1.2926, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.060630448162555695
loss_c:0.8463338613510132
tensor(1.4903, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016179289668798447
loss_c:0.8282903432846069
tensor(1.2801, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02503599412739277
loss_c:1.18882155418396
tensor(1.5229, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022348418831825256
loss_c:0.9495681524276733
tensor(1.3761, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022507667541503906
loss_c:0.8623886108398438
tensor(1.3277, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016831887885928154
loss_c:0.8054112792015076
tensor(1.2703, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03511364385485649
loss_c:0.9996232986450195
tensor(1.4612, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024403449147939682
loss_c:0.7840303182601929
tensor(1.2921, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02828409895300865
loss_c:0.741285502910614
tensor(1.2854, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02168028987944126
loss_c:0.9962493181228638
tensor(1.3992, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018643908202648163
loss_c:0.7856759428977966
tensor(1.2675, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04190109297633171
loss_c:0.8647035956382751
tensor(1.4151, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023090427741408348
loss_c:0.7342779040336609
tensor(1.2584, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01628206856548786
loss_c:0.9664661884307861
tensor(1.3585, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019161872565746307
loss_c:0.7662639617919922
tensor(1.2590, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016903730109333992
loss_c:0.863853931427002
tensor(1.3037, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02793346717953682
loss_c:0.9563784599304199
tensor(1.4043, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012640020810067654
loss_c:0.7147372961044312
tensor(1.2014, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013439067639410496
loss_c:0.7454417943954468
tensor(1.2222, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012591618113219738
loss_c:0.7442870140075684
tensor(1.2178, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03139594942331314
loss_c:0.7612420916557312
tensor(1.3103, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018470335751771927
loss_c:0.7429789304733276
tensor(1.2429, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021652517840266228
loss_c:0.8022938966751099
tensor(1.2902, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021952170878648758
loss_c:0.8544387221336365
tensor(1.3208, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015504398383200169
loss_c:0.6817070841789246
tensor(1.1952, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019514981657266617
loss_c:0.9216853380203247
tensor(1.3478, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06740733236074448
loss_c:0.8695223331451416
tensor(1.5311, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024126512929797173
loss_c:0.7191199064254761
tensor(1.2543, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014115937054157257
loss_c:0.939481258392334
tensor(1.3340, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027293503284454346
loss_c:0.9195329546928406
tensor(1.3811, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02159205451607704
loss_c:0.8824135661125183
tensor(1.3350, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034737586975097656
loss_c:0.8802816271781921
tensor(1.3919, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017443137243390083
loss_c:0.8305196166038513
tensor(1.2875, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021030273288488388
loss_c:0.8677343130111694
tensor(1.3243, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0516287162899971
loss_c:1.0237065553665161
tensor(1.5469, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018620088696479797
loss_c:0.7098235487937927
tensor(1.2248, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03415251523256302
loss_c:0.7829279899597168
tensor(1.3341, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017627427354454994
loss_c:0.7862740755081177
tensor(1.2636, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03300278261303902
loss_c:0.757754921913147
tensor(1.3148, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.047399941831827164
loss_c:1.0160536766052246
tensor(1.5229, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01951621286571026
loss_c:0.9015706777572632
tensor(1.3368, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018165256828069687
loss_c:0.7610616087913513
tensor(1.2520, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021756241098046303
loss_c:0.8449756503105164
tensor(1.3148, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0366675928235054
loss_c:0.8790497779846191
tensor(1.3984, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015904569998383522
loss_c:0.9853021502494812
tensor(1.3684, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023530321195721626
loss_c:0.977857768535614
tensor(1.3971, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02708582952618599
loss_c:0.8591506481170654
tensor(1.3457, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021401297301054
loss_c:0.9427000284194946
tensor(1.3681, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0189677607268095
loss_c:0.9363925457000732
tensor(1.3541, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03393948823213577
loss_c:0.9828702807426453
tensor(1.4443, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03133121132850647
loss_c:0.8519660234451294
tensor(1.3598, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0262734517455101
loss_c:0.9076836109161377
tensor(1.3692, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016141951084136963
loss_c:1.0235166549682617
tensor(1.3905, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017016880214214325
loss_c:0.8141684532165527
tensor(1.2775, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022837985306978226
loss_c:0.7967208623886108
tensor(1.2927, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016343606635928154
loss_c:0.8982591032981873
tensor(1.3214, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03953172639012337
loss_c:0.8773736953735352
tensor(1.4088, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017013374716043472
loss_c:0.7894270420074463
tensor(1.2639, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02776607871055603
loss_c:0.8044991493225098
tensor(1.3182, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06083209440112114
loss_c:0.9236550331115723
tensor(1.5253, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0189437884837389
loss_c:0.7896319627761841
tensor(1.2724, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017348363995552063
loss_c:0.911126971244812
tensor(1.3328, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022604040801525116
loss_c:0.8907318115234375
tensor(1.3439, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038629211485385895
loss_c:0.9642013311386108
tensor(1.4525, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017025720328092575
loss_c:0.7881171107292175
tensor(1.2636, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015129825100302696
loss_c:0.8238663673400879
tensor(1.2753, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03559994697570801
loss_c:0.9054040908813477
tensor(1.4070, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019804248586297035
loss_c:0.7846928834915161
tensor(1.2736, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02426217682659626
loss_c:0.777021586894989
tensor(1.2882, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019418377429246902
loss_c:0.8876726031303406
tensor(1.3288, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02003905177116394
loss_c:0.8474314212799072
tensor(1.3092, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013591118156909943
loss_c:0.7383103370666504
tensor(1.2218, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020863711833953857
loss_c:0.8140456080436707
tensor(1.2942, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01638796180486679
loss_c:0.8281580209732056
tensor(1.2831, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10845549404621124
loss_c:1.029571771621704
tensor(1.7845, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015850553289055824
loss_c:0.8812317252159119
tensor(1.3101, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01442992128431797
loss_c:0.7978578805923462
tensor(1.2582, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03453932702541351
loss_c:0.7401514053344727
tensor(1.3111, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024043245241045952
loss_c:0.934239387512207
tensor(1.3741, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017205948010087013
loss_c:0.8771127462387085
tensor(1.3138, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01951431855559349
loss_c:0.9749239683151245
tensor(1.3776, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021228104829788208
loss_c:0.8384450674057007
tensor(1.3094, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015165213495492935
loss_c:0.8055324554443359
tensor(1.2658, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028847647830843925
loss_c:0.876118540763855
tensor(1.3621, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032556310296058655
loss_c:0.8321512937545776
tensor(1.3534, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017357656732201576
loss_c:0.8035842776298523
tensor(1.2739, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030750935897231102
loss_c:0.8120033740997314
tensor(1.3347, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02234593965113163
loss_c:1.0936951637268066
tensor(1.4551, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01762099377810955
loss_c:0.810227632522583
tensor(1.2787, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02013617940247059
loss_c:0.781379222869873
tensor(1.2733, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014359843917191029
loss_c:0.723792552947998
tensor(1.2173, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016280096024274826
loss_c:0.929494321346283
tensor(1.3389, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01971927285194397
loss_c:0.8774906396865845
tensor(1.3246, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018043892458081245
loss_c:0.7125828266143799
tensor(1.2264, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015705639496445656
loss_c:0.7980965375900269
tensor(1.2637, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01793210208415985
loss_c:0.8635905981063843
tensor(1.3092, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0200822576880455
loss_c:0.8747207522392273
tensor(1.3244, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017617685720324516
loss_c:0.8027169108390808
tensor(1.2741, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016160327941179276
loss_c:0.7686015963554382
tensor(1.2489, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029047589749097824
loss_c:0.9058080911636353
tensor(1.3797, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022318506613373756
loss_c:0.8420681953430176
tensor(1.3157, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025259487330913544
loss_c:0.7620250582695007
tensor(1.2839, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016213148832321167
loss_c:0.7920834422111511
tensor(1.2618, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03493508696556091
loss_c:0.8302451968193054
tensor(1.3633, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021932413801550865
loss_c:0.7548202872276306
tensor(1.2655, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035895731300115585
loss_c:0.9298642873764038
tensor(1.4229, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018869435414671898
loss_c:0.7797811031341553
tensor(1.2661, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021262308582663536
loss_c:0.8657132983207703
tensor(1.3242, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029311947524547577
loss_c:0.9093741774559021
tensor(1.3833, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02069307118654251
loss_c:0.789296567440033
tensor(1.2792, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01828664168715477
loss_c:0.7368959188461304
tensor(1.2395, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012314882129430771
loss_c:1.0490611791610718
tensor(1.3879, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042780131101608276
loss_c:0.8266417980194092
tensor(1.3955, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014706382527947426
loss_c:0.7119497060775757
tensor(1.2100, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03345564752817154
loss_c:0.9458829760551453
tensor(1.4218, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02309444360435009
loss_c:0.7324458956718445
tensor(1.2577, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020051034167408943
loss_c:0.7984618544578552
tensor(1.2814, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018613051623106003
loss_c:0.7917601466178894
tensor(1.2714, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016081301495432854
loss_c:0.9002491235733032
tensor(1.3211, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013639516197144985
loss_c:0.9077404737472534
tensor(1.3147, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019966918975114822
loss_c:0.7909747362136841
tensor(1.2767, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013734611682593822
loss_c:0.7733153104782104
tensor(1.2397, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04301085323095322
loss_c:0.8996235728263855
tensor(1.4380, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04465443640947342
loss_c:0.9894345998764038
tensor(1.4955, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014946697279810905
loss_c:0.7134828567504883
tensor(1.2113, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02552957274019718
loss_c:0.707641065120697
tensor(1.2542, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017336973920464516
loss_c:0.8816274404525757
tensor(1.3160, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015364938415586948
loss_c:0.8096112012863159
tensor(1.2670, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015223466791212559
loss_c:0.847602367401123
tensor(1.2877, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01746002398431301
loss_c:0.8312299251556396
tensor(1.2882, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0194055438041687
loss_c:0.9171351194381714
tensor(1.3449, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021710369735956192
loss_c:0.9171003103256226
tensor(1.3550, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015240048989653587
loss_c:0.7581644058227539
tensor(1.2374, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018237294629216194
loss_c:0.8899410963058472
tensor(1.3245, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023904189467430115
loss_c:0.8056573867797852
tensor(1.3020, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027969522401690483
loss_c:0.7455031871795654
tensor(1.2861, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02416425757110119
loss_c:0.8589423894882202
tensor(1.3331, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015614619478583336
loss_c:0.9014333486557007
tensor(1.3193, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027374688535928726
loss_c:0.8558133840560913
tensor(1.3455, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014277957379817963
loss_c:0.828341007232666
tensor(1.2722, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035110875964164734
loss_c:0.9049735069274902
tensor(1.4074, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01825549453496933
loss_c:0.81551593542099
tensor(1.2826, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01810845173895359
loss_c:0.7497552633285522
tensor(1.2450, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018512684851884842
loss_c:0.830845832824707
tensor(1.2923, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011869588866829872
loss_c:0.805600643157959
tensor(1.2486, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037835001945495605
loss_c:0.9645247459411621
tensor(1.4533, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028242062777280807
loss_c:0.8029078245162964
tensor(1.3198, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0334453247487545
loss_c:0.993966817855835
tensor(1.4503, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0316079780459404
loss_c:0.9106029868125916
tensor(1.3953, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016169488430023193
loss_c:0.8221208453178406
tensor(1.2769, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01996275782585144
loss_c:0.8390435576438904
tensor(1.3033, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03604166954755783
loss_c:0.8312555551528931
tensor(1.3703, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018632933497428894
loss_c:0.81834477186203
tensor(1.2858, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017508165910840034
loss_c:0.7618686556816101
tensor(1.2492, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020091531798243523
loss_c:0.7686806917190552
tensor(1.2644, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019070900976657867
loss_c:0.7341865301132202
tensor(1.2406, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016165658831596375
loss_c:0.8911725878715515
tensor(1.3157, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021220875903964043
loss_c:1.1267940998077393
tensor(1.4703, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017907623201608658
loss_c:0.8920074701309204
tensor(1.3239, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01739233359694481
loss_c:0.7679809331893921
tensor(1.2521, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09146597981452942
loss_c:0.8386265635490417
tensor(1.6209, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024712977930903435
loss_c:0.6553649306297302
tensor(1.2215, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025625182315707207
loss_c:0.7162607908248901
tensor(1.2596, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0174493957310915
loss_c:0.71912682056427
tensor(1.2251, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020741047337651253
loss_c:0.8555035591125488
tensor(1.3161, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01455963496118784
loss_c:0.7318735122680664
tensor(1.2196, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018263082951307297
loss_c:0.8802396059036255
tensor(1.3191, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039525773376226425
loss_c:0.8858412504196167
tensor(1.4156, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019027233123779297
loss_c:0.8253591060638428
tensor(1.2917, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01581689715385437
loss_c:0.7607293128967285
tensor(1.2413, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016171006485819817
loss_c:0.8400969505310059
tensor(1.2875, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018335098400712013
loss_c:0.846193790435791
tensor(1.3004, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021126586943864822
loss_c:0.9457674026489258
tensor(1.3687, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018009768798947334
loss_c:0.8029250502586365
tensor(1.2746, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01834091730415821
loss_c:0.8042241930961609
tensor(1.2768, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021832965314388275
loss_c:0.9206551313400269
tensor(1.3577, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027073809877038002
loss_c:0.7216869592666626
tensor(1.2685, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016567915678024292
loss_c:0.7963575720787048
tensor(1.2645, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041046928614377975
loss_c:0.9864212870597839
tensor(1.4791, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025596708059310913
loss_c:0.9271761775016785
tensor(1.3779, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022949092090129852
loss_c:0.8085936307907104
tensor(1.2994, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030727623030543327
loss_c:1.026484727859497
tensor(1.4563, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03166600689291954
loss_c:0.9376530647277832
tensor(1.4103, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02969363145530224
loss_c:0.9479004740715027
tensor(1.4074, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0364450067281723
loss_c:1.277864694595337
tensor(1.6223, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02479632757604122
loss_c:1.1097068786621094
tensor(1.4765, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023714344948530197
loss_c:1.036473035812378
tensor(1.4304, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01645844243466854
loss_c:0.8872767686843872
tensor(1.3153, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016547352075576782
loss_c:0.830604076385498
tensor(1.2841, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03116023726761341
loss_c:0.8540111780166626
tensor(1.3606, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02565678395330906
loss_c:0.8160840272903442
tensor(1.3157, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013672971166670322
loss_c:0.8284132480621338
tensor(1.2705, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019702976569533348
loss_c:0.7922598719596863
tensor(1.2767, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031244095414876938
loss_c:0.8048850297927856
tensor(1.3338, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025308432057499886
loss_c:0.7829194068908691
tensor(1.2960, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01453112531453371
loss_c:0.8032426834106445
tensor(1.2605, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02598213031888008
loss_c:0.8851661682128906
tensor(1.3553, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011304561980068684
loss_c:0.761247992515564
tensor(1.2234, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037426721304655075
loss_c:0.8449236750602722
tensor(1.3827, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025759901851415634
loss_c:0.9994065761566162
tensor(1.4173, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016736121848225594
loss_c:0.8657993078231812
tensor(1.3045, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036945685744285583
loss_c:0.8856140971183777
tensor(1.4030, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015564227476716042
loss_c:0.8582291007041931
tensor(1.2953, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013984392397105694
loss_c:0.7600359320640564
tensor(1.2344, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024545159190893173
loss_c:0.9250807762145996
tensor(1.3710, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015803735703229904
loss_c:0.872331976890564
tensor(1.3041, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03411700576543808
loss_c:0.786841869354248
tensor(1.3365, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017425838857889175
loss_c:0.9264795184135437
tensor(1.3409, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02460123784840107
loss_c:0.9066445231437683
tensor(1.3611, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02285950444638729
loss_c:0.8238388299942017
tensor(1.3080, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018785620108246803
loss_c:0.883776843547821
tensor(1.3232, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019688598811626434
loss_c:0.7730080485343933
tensor(1.2663, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.15675088763237
loss_c:0.9135315418243408
tensor(1.9399, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031447917222976685
loss_c:0.8186159133911133
tensor(1.3423, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02418285794556141
loss_c:0.8661486506462097
tensor(1.3370, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05278097465634346
loss_c:0.8908002376556396
tensor(1.4730, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025174938142299652
loss_c:0.9619078636169434
tensor(1.3939, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019429272040724754
loss_c:0.8780410289764404
tensor(1.3234, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.046464141458272934
loss_c:0.8896539211273193
tensor(1.4439, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040658582001924515
loss_c:0.7589401006698608
tensor(1.3472, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019834378734230995
loss_c:0.991858959197998
tensor(1.3880, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015939414501190186
loss_c:0.827894926071167
tensor(1.2819, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02172444388270378
loss_c:0.869755744934082
tensor(1.3289, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015833817422389984
loss_c:0.9082397222518921
tensor(1.3258, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02285018190741539
loss_c:0.9961459040641785
tensor(1.4031, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01763272099196911
loss_c:0.766924262046814
tensor(1.2558, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02946520783007145
loss_c:0.8799468874931335
tensor(1.3665, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025665124878287315
loss_c:0.880815863609314
tensor(1.3514, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01616487093269825
loss_c:0.734050452709198
tensor(1.2319, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020376691594719887
loss_c:0.7191969752311707
tensor(1.2410, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028981344774365425
loss_c:0.813003659248352
tensor(1.3277, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02166931703686714
loss_c:0.9517025947570801
tensor(1.3739, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019882487133145332
loss_c:0.7258396148681641
tensor(1.2426, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02145901881158352
loss_c:1.040165901184082
tensor(1.4217, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028880346566438675
loss_c:0.9881056547164917
tensor(1.4235, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04131360352039337
loss_c:0.772842526435852
tensor(1.3561, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019288819283246994
loss_c:0.8533347845077515
tensor(1.3102, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02536999061703682
loss_c:0.8317841291427612
tensor(1.3232, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020399060100317
loss_c:0.8966708183288574
tensor(1.3385, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01523576769977808
loss_c:0.7712142467498779
tensor(1.2484, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014844339340925217
loss_c:0.7872327566146851
tensor(1.2556, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02455069310963154
loss_c:0.818532407283783
tensor(1.3125, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015548653900623322
loss_c:0.7039451599121094
tensor(1.2125, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015880052000284195
loss_c:0.7285321950912476
tensor(1.2272, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02016192115843296
loss_c:0.8745810389518738
tensor(1.3253, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026157233864068985
loss_c:0.8825162649154663
tensor(1.3544, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015146610327064991
loss_c:0.7727832794189453
tensor(1.2482, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019146369770169258
loss_c:0.8015467524528503
tensor(1.2806, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03856256604194641
loss_c:0.8571037650108337
tensor(1.3919, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01494530402123928
loss_c:0.8661729097366333
tensor(1.2987, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06264728307723999
loss_c:0.8983979225158691
tensor(1.5153, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018141744658350945
loss_c:0.8911439776420593
tensor(1.3258, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0169465821236372
loss_c:0.8279310464859009
tensor(1.2858, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016251729801297188
loss_c:0.8721308708190918
tensor(1.3074, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017398277297616005
loss_c:0.7978639602661133
tensor(1.2709, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013968759216368198
loss_c:0.7171384692192078
tensor(1.2116, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015776192769408226
loss_c:0.7125844955444336
tensor(1.2165, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016331862658262253
loss_c:0.854753851890564
tensor(1.2978, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03312983736395836
loss_c:0.8034707903862
tensor(1.3398, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01877705194056034
loss_c:0.7453071475028992
tensor(1.2470, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02131824754178524
loss_c:0.9500841498374939
tensor(1.3719, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03704551234841347
loss_c:0.9691833853721619
tensor(1.4490, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02389393374323845
loss_c:0.7146641612052917
tensor(1.2513, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027420472353696823
loss_c:0.9148871898651123
tensor(1.3781, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018448255956172943
loss_c:0.8079034686088562
tensor(1.2803, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018849113956093788
loss_c:0.9588407278060913
tensor(1.3664, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02404562011361122
loss_c:0.9797420501708984
tensor(1.4001, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026763642206788063
loss_c:1.098557472229004
tensor(1.4781, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013121547177433968
loss_c:0.8266204595565796
tensor(1.2680, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01695607788860798
loss_c:0.7370460033416748
tensor(1.2342, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02840937301516533
loss_c:0.829744815826416
tensor(1.3348, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023344242945313454
loss_c:0.8139553070068359
tensor(1.3044, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022516395896673203
loss_c:0.8625378012657166
tensor(1.3279, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020407719537615776
loss_c:1.0219208002090454
tensor(1.4078, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02236022800207138
loss_c:0.7256531715393066
tensor(1.2509, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014165670610964298
loss_c:0.7912005186080933
tensor(1.2523, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01755032129585743
loss_c:1.0621042251586914
tensor(1.4178, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013473907485604286
loss_c:0.8362816572189331
tensor(1.2743, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02448810636997223
loss_c:1.0424442291259766
tensor(1.4366, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021013479679822922
loss_c:0.7932926416397095
tensor(1.2828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013641524128615856
loss_c:0.7376267313957214
tensor(1.2199, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02780035138130188
loss_c:0.9781708717346191
tensor(1.4150, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019053323194384575
loss_c:0.8725773096084595
tensor(1.3183, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01963469386100769
loss_c:1.059303879737854
tensor(1.4245, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022431671619415283
loss_c:0.8562897443771362
tensor(1.3239, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03132112696766853
loss_c:0.7963722944259644
tensor(1.3296, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022139575332403183
loss_c:0.7215522527694702
tensor(1.2480, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029330840334296227
loss_c:0.8205869197845459
tensor(1.3344, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01645805314183235
loss_c:0.7237188220024109
tensor(1.2244, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017199013382196426
loss_c:0.6638306975364685
tensor(1.1944, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019629264250397682
loss_c:0.9144008159637451
tensor(1.3438, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015749581158161163
loss_c:0.6959341764450073
tensor(1.2057, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020336879417300224
loss_c:0.9268080592155457
tensor(1.3538, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01536403689533472
loss_c:0.8239873647689819
tensor(1.2748, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018775634467601776
loss_c:0.7426977157592773
tensor(1.2447, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03683478757739067
loss_c:0.7637171745300293
tensor(1.3362, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.051311127841472626
loss_c:0.8067498207092285
tensor(1.4243, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04614494740962982
loss_c:0.8139710426330566
tensor(1.4053, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023429198190569878
loss_c:0.8039576411247253
tensor(1.2992, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016606297343969345
loss_c:0.8407720327377319
tensor(1.2896, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019395679235458374
loss_c:0.9331225156784058
tensor(1.3534, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022045191377401352
loss_c:0.8671457171440125
tensor(1.3283, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03036062978208065
loss_c:0.7938594818115234
tensor(1.3239, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016774090006947517
loss_c:0.7637863159179688
tensor(1.2474, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018453143537044525
loss_c:0.807449996471405
tensor(1.2792, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016206882894039154
loss_c:0.7288308143615723
tensor(1.2253, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01547959540039301
loss_c:1.0075708627700806
tensor(1.3781, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06328790634870529
loss_c:0.8863816261291504
tensor(1.5203, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0484858863055706
loss_c:0.9275493621826172
tensor(1.4782, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020393380895256996
loss_c:0.7697324156761169
tensor(1.2665, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035325564444065094
loss_c:0.7641581892967224
tensor(1.3286, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03230167180299759
loss_c:0.7501813769340515
tensor(1.3075, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016579702496528625
loss_c:0.9142265319824219
tensor(1.3311, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022755056619644165
loss_c:0.7616077661514282
tensor(1.2723, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019082926213741302
loss_c:0.9500459432601929
tensor(1.3622, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019104856997728348
loss_c:0.7768685817718506
tensor(1.2651, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01687302440404892
loss_c:0.7526246905326843
tensor(1.2419, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022756202146410942
loss_c:0.9051711559295654
tensor(1.3529, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015434949658811092
loss_c:0.7651082873344421
tensor(1.2427, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02457713708281517
loss_c:0.71368408203125
tensor(1.2532, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028318217024207115
loss_c:0.8764476776123047
tensor(1.3608, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02954903431236744
loss_c:0.8725152015686035
tensor(1.3639, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013190079480409622
loss_c:0.7626007795333862
tensor(1.2316, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01618627831339836
loss_c:0.8137997984886169
tensor(1.2733, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02187061682343483
loss_c:1.003469467163086
tensor(1.4046, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028258774429559708
loss_c:0.9395343065261841
tensor(1.3962, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01966361328959465
loss_c:0.9677486419677734
tensor(1.3750, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04062855616211891
loss_c:0.810971736907959
tensor(1.3771, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01766820438206196
loss_c:0.7659667730331421
tensor(1.2527, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014557565562427044
loss_c:0.7795267105102539
tensor(1.2469, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035666052252054214
loss_c:0.8177449107170105
tensor(1.3595, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014501412399113178
loss_c:0.7682738304138184
tensor(1.2403, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043218620121479034
loss_c:0.9018032550811768
tensor(1.4394, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014918403699994087
loss_c:0.7129162549972534
tensor(1.2110, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015409658662974834
loss_c:0.8197256922721863
tensor(1.2732, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016373692080378532
loss_c:0.7796997427940369
tensor(1.2548, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01884700171649456
loss_c:0.8828295469284058
tensor(1.3236, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016750948503613472
loss_c:0.9145690202713013
tensor(1.3324, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03112827241420746
loss_c:0.8505828380584717
tensor(1.3585, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016079768538475037
loss_c:0.7269854545593262
tensor(1.2237, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033364906907081604
loss_c:0.7927888631820679
tensor(1.3356, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03396313637495041
loss_c:0.8306585550308228
tensor(1.3596, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016871251165866852
loss_c:0.8210461139678955
tensor(1.2801, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013313199393451214
loss_c:0.7951537370681763
tensor(1.2501, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01968522183597088
loss_c:0.970906674861908
tensor(1.3769, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016158541664481163
loss_c:0.7239459753036499
tensor(1.2222, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017252687364816666
loss_c:0.8127459287643433
tensor(1.2770, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014478666707873344
loss_c:0.8086639642715454
tensor(1.2626, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01669316738843918
loss_c:0.7917793989181519
tensor(1.2626, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033051442354917526
loss_c:0.8801068663597107
tensor(1.3839, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014822660945355892
loss_c:0.751680314540863
tensor(1.2317, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016665657982230186
loss_c:0.8817781209945679
tensor(1.3132, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022179771214723587
loss_c:0.8180672526359558
tensor(1.3013, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02520812302827835
loss_c:0.7958559989929199
tensor(1.3021, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05143788084387779
loss_c:1.1346509456634521
tensor(1.6092, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021465374156832695
loss_c:0.9627094268798828
tensor(1.3800, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017171630635857582
loss_c:0.8815290927886963
tensor(1.3152, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04130687564611435
loss_c:0.9234468340873718
tensor(1.4450, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027804983779788017
loss_c:0.8927675485610962
tensor(1.3682, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022678030654788017
loss_c:0.75248783826828
tensor(1.2666, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01864597760140896
loss_c:0.8070105314254761
tensor(1.2796, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01879035495221615
loss_c:0.8071088790893555
tensor(1.2803, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02499624341726303
loss_c:0.7702058553695679
tensor(1.2868, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018837295472621918
loss_c:0.7928652763366699
tensor(1.2726, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022689810022711754
loss_c:0.8915911912918091
tensor(1.3450, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01985262893140316
loss_c:0.8748675584793091
tensor(1.3231, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04760798439383507
loss_c:0.9657765626907349
tensor(1.4959, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019651947543025017
loss_c:0.9551149606704712
tensor(1.3673, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024625139310956
loss_c:0.9387822151184082
tensor(1.3799, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014691432006657124
loss_c:0.7727159261703491
tensor(1.2432, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018468108028173447
loss_c:1.166587471961975
tensor(1.4805, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017800362780690193
loss_c:0.9814392924308777
tensor(1.3737, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035812169313430786
loss_c:0.790434718132019
tensor(1.3457, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017429692670702934
loss_c:0.8180612325668335
tensor(1.2807, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02772298827767372
loss_c:0.7656781077384949
tensor(1.2966, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01918504759669304
loss_c:0.8623887896537781
tensor(1.3131, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016241764649748802
loss_c:0.805493950843811
tensor(1.2686, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014940498396754265
loss_c:0.8570970296859741
tensor(1.2916, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025919828563928604
loss_c:0.7642373442649841
tensor(1.2880, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018988417461514473
loss_c:0.8206852674484253
tensor(1.2890, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027667824178934097
loss_c:0.8352445960044861
tensor(1.3352, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021764444187283516
loss_c:1.0259976387023926
tensor(1.4153, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018651993945240974
loss_c:0.9676274061203003
tensor(1.3692, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013430987484753132
loss_c:0.7353786826133728
tensor(1.2173, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04165958613157272
loss_c:0.8607177138328552
tensor(1.4109, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026896828785538673
loss_c:0.8168001174926758
tensor(1.3216, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025939544662833214
loss_c:0.8399027585983276
tensor(1.3302, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017014481127262115
loss_c:0.7030514478683472
tensor(1.2151, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01588761806488037
loss_c:0.7773777842521667
tensor(1.2514, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015981001779437065
loss_c:0.8741772174835205
tensor(1.3055, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02111174538731575
loss_c:0.8856562376022339
tensor(1.3344, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013546423986554146
loss_c:0.7392445802688599
tensor(1.2198, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027490083128213882
loss_c:0.8812059164047241
tensor(1.3600, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019063111394643784
loss_c:0.7490699291229248
tensor(1.2495, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05670688673853874
loss_c:0.827223002910614
tensor(1.4591, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04387712478637695
loss_c:0.8269234895706177
tensor(1.4022, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01677665486931801
loss_c:0.8829998970031738
tensor(1.3138, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018142057582736015
loss_c:0.878135085105896
tensor(1.3172, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018787890672683716
loss_c:0.8392769694328308
tensor(1.2984, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01543821394443512
loss_c:0.8464406728744507
tensor(1.2877, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05550209805369377
loss_c:0.9623565673828125
tensor(1.5282, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01843591406941414
loss_c:0.8145374059677124
tensor(1.2831, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01824730634689331
loss_c:0.8010705709457397
tensor(1.2748, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018945926800370216
loss_c:0.7913669347763062
tensor(1.2725, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03094649687409401
loss_c:0.8251397013664246
tensor(1.3438, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039067234843969345
loss_c:0.7218303680419922
tensor(1.3216, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023522038012742996
loss_c:0.8499889373779297
tensor(1.3252, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015562783926725388
loss_c:0.8649060130119324
tensor(1.2989, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03403784707188606
loss_c:0.8462609052658081
tensor(1.3689, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0159830953925848
loss_c:0.8204144835472107
tensor(1.2759, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026131397113204002
loss_c:0.816415011882782
tensor(1.3178, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024657825008034706
loss_c:1.0300801992416382
tensor(1.4308, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014308927580714226
loss_c:0.831567645072937
tensor(1.2750, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027618108317255974
loss_c:0.8758267164230347
tensor(1.3574, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015652330592274666
loss_c:0.849921703338623
tensor(1.2911, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029756853356957436
loss_c:0.8075282573699951
tensor(1.3285, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02190111018717289
loss_c:0.9054087400436401
tensor(1.3492, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014257683418691158
loss_c:0.8511661887168884
tensor(1.2858, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0212212186306715
loss_c:0.8193160891532898
tensor(1.2981, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018836796283721924
loss_c:0.7862585783004761
tensor(1.2693, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015397360548377037
loss_c:0.9036285281181335
tensor(1.3199, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021780075505375862
loss_c:0.7725397944450378
tensor(1.2744, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014324447140097618
loss_c:0.8049672842025757
tensor(1.2601, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019755689427256584
loss_c:0.892713725566864
tensor(1.3327, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03974213823676109
loss_c:0.837495744228363
tensor(1.3889, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0351448692381382
loss_c:0.8881169557571411
tensor(1.3972, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02061760425567627
loss_c:1.0076607465744019
tensor(1.4007, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03028823807835579
loss_c:0.6754526495933533
tensor(1.2572, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01681363768875599
loss_c:0.8132128715515137
tensor(1.2754, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024405961856245995
loss_c:0.9493660926818848
tensor(1.3846, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015143689699470997
loss_c:0.7067932486534119
tensor(1.2087, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01260946225374937
loss_c:0.7011875510215759
tensor(1.1945, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017921321094036102
loss_c:0.8365020751953125
tensor(1.2932, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02836969867348671
loss_c:0.7440762519836426
tensor(1.2871, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030017167329788208
loss_c:0.8159810900688171
tensor(1.3346, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023255299776792526
loss_c:0.874358057975769
tensor(1.3377, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029846809804439545
loss_c:0.8547880053520203
tensor(1.3556, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01236804947257042
loss_c:0.7484650611877441
tensor(1.2195, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014167376793920994
loss_c:0.8493239283561707
tensor(1.2839, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02096562087535858
loss_c:0.8420848250389099
tensor(1.3096, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019780049100518227
loss_c:0.9275792837142944
tensor(1.3524, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021132836118340492
loss_c:1.0313224792480469
tensor(1.4166, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027699405327439308
loss_c:0.8073436617851257
tensor(1.3196, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020995911210775375
loss_c:0.9195014834403992
tensor(1.3531, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022938938811421394
loss_c:1.0868502855300903
tensor(1.4556, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022685542702674866
loss_c:0.7994139194488525
tensor(1.2932, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02752753533422947
loss_c:0.8673094511032104
tensor(1.3526, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031880613416433334
loss_c:0.9995301961898804
tensor(1.4458, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01824527606368065
loss_c:0.8021457195281982
tensor(1.2752, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01901944726705551
loss_c:0.8156561255455017
tensor(1.2862, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018184777349233627
loss_c:0.7863127589225769
tensor(1.2661, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017283692955970764
loss_c:0.8377245664596558
tensor(1.2908, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021354006603360176
loss_c:0.896848201751709
tensor(1.3418, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02234227955341339
loss_c:0.8100268244743347
tensor(1.2977, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014717666432261467
loss_c:0.7907964587211609
tensor(1.2532, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01652715355157852
loss_c:0.9109621047973633
tensor(1.3282, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019251232966780663
loss_c:0.6992086172103882
tensor(1.2222, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02677522972226143
loss_c:0.8870586156845093
tensor(1.3603, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027456821873784065
loss_c:0.9419761896133423
tensor(1.3940, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016782179474830627
loss_c:0.7868160605430603
tensor(1.2600, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018195437267422676
loss_c:0.7581824064254761
tensor(1.2503, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015566189773380756
loss_c:0.7861663699150085
tensor(1.2542, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03512434661388397
loss_c:0.8428763151168823
tensor(1.3731, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017003020271658897
loss_c:0.6872429847717285
tensor(1.2054, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014035111293196678
loss_c:0.8406094312667847
tensor(1.2776, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01885155774652958
loss_c:0.813260555267334
tensor(1.2838, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033127766102552414
loss_c:0.7941133379936218
tensor(1.3371, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022482749074697495
loss_c:0.7241687178611755
tensor(1.2503, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020823080092668533
loss_c:0.9396530985832214
tensor(1.3633, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020818505436182022
loss_c:0.8687607645988464
tensor(1.3236, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03457668051123619
loss_c:0.8774884939193726
tensor(1.3903, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01635945774614811
loss_c:0.8805726766586304
tensor(1.3103, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014770667999982834
loss_c:0.7370488047599792
tensor(1.2227, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014431245625019073
loss_c:0.7699340581893921
tensor(1.2396, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01686934381723404
loss_c:0.8686800003051758
tensor(1.3059, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02158948965370655
loss_c:0.8966048955917358
tensor(1.3428, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04310482740402222
loss_c:0.92138671875
tensor(1.4537, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015348992310464382
loss_c:0.7678978443145752
tensor(1.2424, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022730374708771706
loss_c:0.9361628293991089
tensor(1.3701, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020856792107224464
loss_c:0.93092942237854
tensor(1.3587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021361863240599632
loss_c:0.8300034999847412
tensor(1.3044, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020578349009156227
loss_c:0.894080638885498
tensor(1.3368, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01831630803644657
loss_c:0.8410972952842712
tensor(1.2968, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016356399282813072
loss_c:0.8582100868225098
tensor(1.2976, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01683981902897358
loss_c:0.7757390737533569
tensor(1.2535, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014457414858043194
loss_c:0.7047240138053894
tensor(1.2029, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027899209409952164
loss_c:0.7992388606071472
tensor(1.3167, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017769908532500267
loss_c:0.7967684268951416
tensor(1.2694, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01503289770334959
loss_c:0.8072804808616638
tensor(1.2629, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01940195821225643
loss_c:0.8267390131950378
tensor(1.2936, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02051742561161518
loss_c:0.9415524005889893
tensor(1.3631, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015998274087905884
loss_c:0.7474576830863953
tensor(1.2336, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012938101775944233
loss_c:0.7045408487319946
tensor(1.1955, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017076317220926285
loss_c:0.9975094795227051
tensor(1.3789, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01995290070772171
loss_c:0.8535029292106628
tensor(1.3111, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017719220370054245
loss_c:0.8169420957565308
tensor(1.2803, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02746875211596489
loss_c:0.9933247566223145
tensor(1.4242, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02321021631360054
loss_c:0.7006298899650574
tensor(1.2401, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015116766095161438
loss_c:0.8755221366882324
tensor(1.3012, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025745391845703125
loss_c:0.7740621566772461
tensor(1.2931, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020807618275284767
loss_c:0.8276264071464539
tensor(1.3004, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028761764988303185
loss_c:0.9912709593772888
tensor(1.4292, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02059721015393734
loss_c:0.8729097247123718
tensor(1.3249, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024265967309474945
loss_c:0.8008965849876404
tensor(1.3014, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030205214396119118
loss_c:0.8997873663902283
tensor(1.3844, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011859406717121601
loss_c:0.6598606109619141
tensor(1.1649, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01737639121711254
loss_c:0.8087271451950073
tensor(1.2740, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020224710926413536
loss_c:0.8354346752166748
tensor(1.3021, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027590757235884666
loss_c:0.8451873660087585
tensor(1.3416, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024269768968224525
loss_c:0.9621061086654663
tensor(1.3920, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014802987687289715
loss_c:0.7183389663696289
tensor(1.2112, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02231607213616371
loss_c:0.7803527116775513
tensor(1.2808, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024967392906546593
loss_c:0.8217353820800781
tensor(1.3163, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01827595755457878
loss_c:0.907265305519104
tensor(1.3335, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021665843203663826
loss_c:0.7759655714035034
tensor(1.2753, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020744115114212036
loss_c:0.8097140192985535
tensor(1.2900, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02271009422838688
loss_c:0.7538363337516785
tensor(1.2677, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03604332357645035
loss_c:0.967739462852478
tensor(1.4497, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02812434546649456
loss_c:0.8353127241134644
tensor(1.3385, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03940070420503616
loss_c:1.113473892211914
tensor(1.5471, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0170859694480896
loss_c:0.8574334979057312
tensor(1.3001, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030392879620194435
loss_c:0.8435065150260925
tensor(1.3534, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03079678677022457
loss_c:0.8707137107849121
tensor(1.3704, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03473583608865738
loss_c:0.8038232326507568
tensor(1.3508, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014563952572643757
loss_c:0.7807706594467163
tensor(1.2457, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017189715057611465
loss_c:0.8122105598449707
tensor(1.2754, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017783116549253464
loss_c:0.8183625936508179
tensor(1.2816, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021488789469003677
loss_c:0.9153992533683777
tensor(1.3528, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015591097064316273
loss_c:0.8481423258781433
tensor(1.2884, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028043700382113457
loss_c:0.9263947010040283
tensor(1.3887, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023620592430233955
loss_c:0.7614228129386902
tensor(1.2761, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023660464212298393
loss_c:0.727024257183075
tensor(1.2570, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014689401723444462
loss_c:0.8737177848815918
tensor(1.2988, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031050652265548706
loss_c:0.9262439012527466
tensor(1.4020, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016417570412158966
loss_c:0.7653598785400391
tensor(1.2458, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03447845205664635
loss_c:0.8200563192367554
tensor(1.3579, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03397569805383682
loss_c:0.9158971309661865
tensor(1.4093, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022908112034201622
loss_c:1.0035651922225952
tensor(1.4086, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015488456934690475
loss_c:0.7624679803848267
tensor(1.2402, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020846035331487656
loss_c:0.9205030202865601
tensor(1.3528, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02395237237215042
loss_c:0.8911147117614746
tensor(1.3502, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03569909930229187
loss_c:0.7654262781143188
tensor(1.3324, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020124956965446472
loss_c:0.8083998560905457
tensor(1.2868, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02240295149385929
loss_c:0.9134470224380493
tensor(1.3557, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0258333720266819
loss_c:0.8340092897415161
tensor(1.3266, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018688179552555084
loss_c:0.8011905550956726
tensor(1.2764, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032098934054374695
loss_c:0.7698469161987305
tensor(1.3186, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01823590323328972
loss_c:0.936977744102478
tensor(1.3504, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026631131768226624
loss_c:0.8669268488883972
tensor(1.3485, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018023435026407242
loss_c:0.804602324962616
tensor(1.2755, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023470688611268997
loss_c:0.7525178790092468
tensor(1.2705, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016189273446798325
loss_c:0.715934693813324
tensor(1.2178, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03285364806652069
loss_c:0.7796182632446289
tensor(1.3272, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022406337782740593
loss_c:0.8863350749015808
tensor(1.3406, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01795586757361889
loss_c:0.8267949819564819
tensor(1.2876, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028627939522266388
loss_c:0.7729920744895935
tensor(1.3047, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012741380371153355
loss_c:0.756215512752533
tensor(1.2250, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021006492897868156
loss_c:0.9733371734619141
tensor(1.3832, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015152499079704285
loss_c:0.8939880132675171
tensor(1.3129, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026669448241591454
loss_c:0.7361313700675964
tensor(1.2753, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02917681820690632
loss_c:0.7552372217178345
tensor(1.2971, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015646375715732574
loss_c:0.7951978445053101
tensor(1.2596, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025488780811429024
loss_c:0.9037394523620605
tensor(1.3641, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03333404287695885
loss_c:0.8257126212120056
tensor(1.3550, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01601739041507244
loss_c:0.789688229560852
tensor(1.2581, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02471824549138546
loss_c:0.8021363019943237
tensor(1.3036, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01627887226641178
loss_c:0.8081296682357788
tensor(1.2697, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021014604717493057
loss_c:1.0127426385879517
tensor(1.4057, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03357424587011337
loss_c:0.8500801920890808
tensor(1.3698, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016253400593996048
loss_c:1.1067657470703125
tensor(1.4376, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019758494570851326
loss_c:0.8738284111022949
tensor(1.3220, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01803857833147049
loss_c:0.8910364508628845
tensor(1.3240, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02013501711189747
loss_c:0.8427796363830566
tensor(1.3062, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04006978124380112
loss_c:1.152867078781128
tensor(1.5686, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026212826371192932
loss_c:1.031731367111206
tensor(1.4390, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03438947722315788
loss_c:0.8013100028038025
tensor(1.3461, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018377283588051796
loss_c:0.8964900970458984
tensor(1.3284, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023467816412448883
loss_c:0.9431861639022827
tensor(1.3770, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012464636005461216
loss_c:0.6969100832939148
tensor(1.1911, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016451053321361542
loss_c:0.6724947690963745
tensor(1.1952, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015801386907696724
loss_c:0.8165671825408936
tensor(1.2725, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016881244257092476
loss_c:0.974995493888855
tensor(1.3654, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014515380375087261
loss_c:0.7711303234100342
tensor(1.2415, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020105402916669846
loss_c:0.9464196562767029
tensor(1.3637, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024274464696645737
loss_c:0.7702800631523132
tensor(1.2843, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01320130005478859
loss_c:0.8347028493881226
tensor(1.2709, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018102657049894333
loss_c:0.7515838146209717
tensor(1.2465, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015531930141150951
loss_c:0.6980075836181641
tensor(1.2052, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023477492853999138
loss_c:0.8979017734527588
tensor(1.3517, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026446547359228134
loss_c:0.7897075414657593
tensor(1.3048, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03852061182260513
loss_c:0.8180364966392517
tensor(1.3747, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022772129625082016
loss_c:0.8442791700363159
tensor(1.3187, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020459739491343498
loss_c:0.8718010187149048
tensor(1.3237, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015426207333803177
loss_c:0.7447589635848999
tensor(1.2304, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02259473316371441
loss_c:0.7406529188156128
tensor(1.2602, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02668345905840397
loss_c:0.7638885378837585
tensor(1.2915, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025013674050569534
loss_c:0.8210894465446472
tensor(1.3158, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015168811194598675
loss_c:0.7451349496841431
tensor(1.2293, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014571559615433216
loss_c:0.7611640691757202
tensor(1.2355, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023673661053180695
loss_c:0.8226504325866699
tensor(1.3107, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013939701952040195
loss_c:0.703805685043335
tensor(1.2004, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017696887254714966
loss_c:0.8841440081596375
tensor(1.3182, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019462279975414276
loss_c:0.7941696047782898
tensor(1.2757, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023978644981980324
loss_c:0.9370037913322449
tensor(1.3763, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017118094488978386
loss_c:0.8275031447410583
tensor(1.2838, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017977295443415642
loss_c:0.8194091320037842
tensor(1.2831, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018090344965457916
loss_c:0.948239266872406
tensor(1.3560, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014683009125292301
loss_c:0.8034036159515381
tensor(1.2591, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01566842570900917
loss_c:0.858507513999939
tensor(1.2945, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01747996173799038
loss_c:0.9233848452568054
tensor(1.3392, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02548621967434883
loss_c:0.7434930205345154
tensor(1.2744, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016843097284436226
loss_c:0.7511509656906128
tensor(1.2392, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01801040582358837
loss_c:0.7766222953796387
tensor(1.2589, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01404909510165453
loss_c:0.8401386141777039
tensor(1.2765, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01499086432158947
loss_c:0.777110755443573
tensor(1.2452, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017412759363651276
loss_c:0.7322705984115601
tensor(1.2310, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018918287009000778
loss_c:0.8629908561706543
tensor(1.3117, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03666505590081215
loss_c:0.8550857901573181
tensor(1.3892, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02927006036043167
loss_c:0.7576960921287537
tensor(1.3000, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05288774147629738
loss_c:0.7360783815383911
tensor(1.3971, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043022520840168
loss_c:0.8472857475280762
tensor(1.4142, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021434351801872253
loss_c:0.8574463129043579
tensor(1.3202, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02949105016887188
loss_c:0.9909192323684692
tensor(1.4329, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026648836210370064
loss_c:0.8494037389755249
tensor(1.3395, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019591685384511948
loss_c:0.82273268699646
tensor(1.2921, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01741185411810875
loss_c:0.8772825598716736
tensor(1.3131, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028619907796382904
loss_c:0.8894437551498413
tensor(1.3711, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033098697662353516
loss_c:0.827107310295105
tensor(1.3560, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027237288653850555
loss_c:0.8510233759880066
tensor(1.3429, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012450159527361393
loss_c:0.9569709300994873
tensor(1.3360, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025386491790413857
loss_c:0.8402439951896667
tensor(1.3283, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017698725685477257
loss_c:0.7140621542930603
tensor(1.2222, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019435139372944832
loss_c:0.8127679824829102
tensor(1.2859, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021397091448307037
loss_c:0.7773444056510925
tensor(1.2747, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029064495116472244
loss_c:0.8034543395042419
tensor(1.3239, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026926686987280846
loss_c:0.8375446200370789
tensor(1.3336, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03366991505026817
loss_c:1.0199602842330933
tensor(1.4669, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016957974061369896
loss_c:0.7821926474571228
tensor(1.2577, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.010011251084506512
loss_c:0.7052963972091675
tensor(1.1832, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02044716291129589
loss_c:1.0039833784103394
tensor(1.3986, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018816133961081505
loss_c:0.8186237215995789
tensor(1.2866, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02562888339161873
loss_c:1.0776997804641724
tensor(1.4633, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022110270336270332
loss_c:0.7519316673278809
tensor(1.2637, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017886294052004814
loss_c:0.8294329047203064
tensor(1.2886, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015259119682013988
loss_c:0.8886450529098511
tensor(1.3102, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03117995709180832
loss_c:0.852428138256073
tensor(1.3608, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015780124813318253
loss_c:0.8900768160820007
tensor(1.3133, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01733235828578472
loss_c:0.8073207139968872
tensor(1.2736, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05289008468389511
loss_c:0.902922511100769
tensor(1.4862, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01792137324810028
loss_c:0.7208962440490723
tensor(1.2277, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018056482076644897
loss_c:0.8128592371940613
tensor(1.2800, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020685359835624695
loss_c:0.9005697965621948
tensor(1.3410, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022098565474152565
loss_c:0.7676628828048706
tensor(1.2727, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021263254806399345
loss_c:0.9278631210327148
tensor(1.3589, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029633497819304466
loss_c:0.8068057894706726
tensor(1.3282, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022188764065504074
loss_c:0.8644281625747681
tensor(1.3274, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023777533322572708
loss_c:0.7753826379776001
tensor(1.2845, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01920974999666214
loss_c:0.9050291776657104
tensor(1.3370, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016005786135792732
loss_c:0.7555397748947144
tensor(1.2388, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019625451415777206
loss_c:0.8406246900558472
tensor(1.3027, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01785794086754322
loss_c:0.9127807021141052
tensor(1.3353, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026912502944469452
loss_c:0.754737138748169
tensor(1.2869, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018209010362625122
loss_c:0.8262605667114258
tensor(1.2883, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036710888147354126
loss_c:0.8313050270080566
tensor(1.3735, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01836918108165264
loss_c:0.978489100933075
tensor(1.3744, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01829768344759941
loss_c:0.8932191133499146
tensor(1.3262, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012714754790067673
loss_c:0.7374998927116394
tensor(1.2141, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020297007635235786
loss_c:0.9529775977134705
tensor(1.3686, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02711096964776516
loss_c:0.7984399795532227
tensor(1.3124, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030767355114221573
loss_c:0.8157380819320679
tensor(1.3384, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0196662787348032
loss_c:0.8096768856048584
tensor(1.2855, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02707190439105034
loss_c:1.0704536437988281
tensor(1.4646, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021975811570882797
loss_c:0.9481216669082642
tensor(1.3733, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02146078087389469
loss_c:0.8875679969787598
tensor(1.3371, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019030027091503143
loss_c:0.7244422435760498
tensor(1.2350, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025204168632626534
loss_c:0.8876776695251465
tensor(1.3538, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03163788840174675
loss_c:0.8991478681564331
tensor(1.3889, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015568370930850506
loss_c:0.7740509510040283
tensor(1.2474, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019272180274128914
loss_c:0.941315770149231
tensor(1.3572, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01609591767191887
loss_c:0.7604053020477295
tensor(1.2421, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01678871549665928
loss_c:0.9596117734909058
tensor(1.3563, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03233926370739937
loss_c:0.6898302435874939
tensor(1.2754, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01705501601099968
loss_c:0.8253058195114136
tensor(1.2826, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01774968020617962
loss_c:1.0058722496032715
tensor(1.3863, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016268327832221985
loss_c:0.7064023017883301
tensor(1.2128, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015919802710413933
loss_c:0.8683227300643921
tensor(1.3014, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04427192732691765
loss_c:0.865321159362793
tensor(1.4268, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02125624567270279
loss_c:0.7842566967010498
tensor(1.2785, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03145008534193039
loss_c:0.8101527094841003
tensor(1.3386, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02846154011785984
loss_c:0.7630662322044373
tensor(1.2989, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026536930352449417
loss_c:0.7531466484069824
tensor(1.2848, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02909671701490879
loss_c:0.7203097343444824
tensor(1.2779, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03021305613219738
loss_c:0.9195342063903809
tensor(1.3939, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03582445904612541
loss_c:0.9103797674179077
tensor(1.4138, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014947443269193172
loss_c:0.7303640246391296
tensor(1.2203, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016963448375463486
loss_c:0.8050009608268738
tensor(1.2710, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029150696471333504
loss_c:0.9380970001220703
tensor(1.3995, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015860019251704216
loss_c:0.7770296931266785
tensor(1.2505, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019214970991015434
loss_c:0.732771098613739
tensor(1.2406, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03103644773364067
loss_c:0.8768080472946167
tensor(1.3735, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022251296788454056
loss_c:0.8786756992340088
tensor(1.3357, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014754735864698887
loss_c:0.8058414459228516
tensor(1.2617, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01521236076951027
loss_c:0.7699546813964844
tensor(1.2436, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013677039183676243
loss_c:0.765045166015625
tensor(1.2341, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01975923590362072
loss_c:0.9138979911804199
tensor(1.3445, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02278534695506096
loss_c:0.8142141103744507
tensor(1.3019, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022164177149534225
loss_c:0.8428895473480225
tensor(1.3152, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026396984234452248
loss_c:0.797355055809021
tensor(1.3084, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03675489127635956
loss_c:0.7020212411880493
tensor(1.3007, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021494880318641663
loss_c:0.906690776348114
tensor(1.3482, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027269765734672546
loss_c:0.7170825004577637
tensor(1.2670, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03332604467868805
loss_c:0.8005591630935669
tensor(1.3408, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019349122419953346
loss_c:0.8248202204704285
tensor(1.2926, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014072151854634285
loss_c:0.7830769419670105
tensor(1.2457, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01685856468975544
loss_c:0.8309929370880127
tensor(1.2851, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01879142038524151
loss_c:1.118224859237671
tensor(1.4559, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0182479377835989
loss_c:0.8021726608276367
tensor(1.2749, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024490702897310257
loss_c:0.7846980094909668
tensor(1.2927, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022685062140226364
loss_c:0.8559077978134155
tensor(1.3249, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016728267073631287
loss_c:0.7967943549156189
tensor(1.2651, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013427605852484703
loss_c:0.7502343058586121
tensor(1.2242, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01956147328019142
loss_c:0.814189612865448
tensor(1.2875, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024683944880962372
loss_c:0.9582478404045105
tensor(1.3917, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031801145523786545
loss_c:0.7371115684509277
tensor(1.2983, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03329140692949295
loss_c:0.9303692579269409
tensor(1.4143, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03548285365104675
loss_c:0.7969791293144226
tensor(1.3486, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025885744020342827
loss_c:0.9036878347396851
tensor(1.3662, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02115601859986782
loss_c:0.8286228179931641
tensor(1.3027, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08674651384353638
loss_c:0.8788353204727173
tensor(1.6222, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01392783410847187
loss_c:0.8119938373565674
tensor(1.2614, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025289064273238182
loss_c:0.8898495435714722
tensor(1.3556, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014814188703894615
loss_c:0.8099984526634216
tensor(1.2644, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02250250056385994
loss_c:0.9755541682243347
tensor(1.3917, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01365500409156084
loss_c:0.7288349866867065
tensor(1.2137, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03576386719942093
loss_c:1.2728993892669678
tensor(1.6173, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01843222789466381
loss_c:0.8250829577445984
tensor(1.2890, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02010863833129406
loss_c:0.7460778951644897
tensor(1.2519, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016198480501770973
loss_c:0.7839261889457703
tensor(1.2562, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01945122517645359
loss_c:0.8474605083465576
tensor(1.3061, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02701425738632679
loss_c:0.7776374220848083
tensor(1.2997, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028890063986182213
loss_c:0.901497483253479
tensor(1.3775, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02334757149219513
loss_c:0.7966956496238708
tensor(1.2945, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013949285261332989
loss_c:0.7195552587509155
tensor(1.2105, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018806448206305504
loss_c:0.7023200988769531
tensor(1.2219, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02352471463382244
loss_c:0.8182445764541626
tensor(1.3074, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018506331369280815
loss_c:0.868151068687439
tensor(1.3137, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024559523910284042
loss_c:0.8962318301200867
tensor(1.3557, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013213099911808968
loss_c:0.8311941027641296
tensor(1.2699, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028194060549139977
loss_c:0.8053740859031677
tensor(1.3205, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030014541000127792
loss_c:1.0690795183181763
tensor(1.4766, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030478840693831444
loss_c:0.8902915716171265
tensor(1.3781, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02346901036798954
loss_c:0.8673641085624695
tensor(1.3347, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012536166235804558
loss_c:0.6957804560661316
tensor(1.1909, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014629720710217953
loss_c:0.7114512324333191
tensor(1.2088, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018849460408091545
loss_c:0.8758997917175293
tensor(1.3194, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01639365591108799
loss_c:0.8357410430908203
tensor(1.2861, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020922238007187843
loss_c:0.9584951400756836
tensor(1.3748, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02100573293864727
loss_c:0.8566123843193054
tensor(1.3179, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023484742268919945
loss_c:0.7782589197158813
tensor(1.2848, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01988963410258293
loss_c:0.8843282461166382
tensor(1.3286, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014450042508542538
loss_c:0.832909107208252
tensor(1.2758, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021416805684566498
loss_c:0.8998303413391113
tensor(1.3439, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017534855753183365
loss_c:0.919831395149231
tensor(1.3380, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028497207909822464
loss_c:0.7361356616020203
tensor(1.2834, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027799151837825775
loss_c:0.915611982345581
tensor(1.3809, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014708127826452255
loss_c:0.8284339308738708
tensor(1.2742, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01207305770367384
loss_c:0.6483252048492432
tensor(1.1616, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026812203228473663
loss_c:0.8250097036361694
tensor(1.3258, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011849834583699703
loss_c:0.7436676025390625
tensor(1.2138, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015923308208584785
loss_c:0.8201079368591309
tensor(1.2747, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019221266731619835
loss_c:0.8033315539360046
tensor(1.2799, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01645493134856224
loss_c:1.0015215873718262
tensor(1.3787, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030584361404180527
loss_c:0.793120265007019
tensor(1.3250, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036091893911361694
loss_c:0.7289634943008423
tensor(1.3137, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014735383912920952
loss_c:0.8340468406677246
tensor(1.2769, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02495395950973034
loss_c:0.8970872163772583
tensor(1.3582, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05847968906164169
loss_c:1.0960171222686768
tensor(1.6206, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07395763695240021
loss_c:0.889493465423584
tensor(1.5738, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03788897767663002
loss_c:0.8065239787101746
tensor(1.3651, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02186032012104988
loss_c:0.9281871318817139
tensor(1.3617, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017169566825032234
loss_c:0.7210416793823242
tensor(1.2248, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023201901465654373
loss_c:0.7946007251739502
tensor(1.2927, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036150410771369934
loss_c:0.8527781963348389
tensor(1.3823, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02217835746705532
loss_c:0.7838656902313232
tensor(1.2822, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015851769596338272
loss_c:0.7064980268478394
tensor(1.2112, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020550474524497986
loss_c:0.9318005442619324
tensor(1.3581, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024950748309493065
loss_c:0.7515127062797546
tensor(1.2762, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02333124540746212
loss_c:0.8535012006759644
tensor(1.3264, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01482602208852768
loss_c:0.7802035808563232
tensor(1.2483, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016598064452409744
loss_c:0.8491299152374268
tensor(1.2947, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018661566078662872
loss_c:0.860295295715332
tensor(1.3100, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016163621097803116
loss_c:0.7990627288818359
tensor(1.2647, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014415929093956947
loss_c:0.7520946264266968
tensor(1.2308, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025419199839234352
loss_c:0.9982015490531921
tensor(1.4168, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017380554229021072
loss_c:0.8107703924179077
tensor(1.2765, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0167069174349308
loss_c:0.7907577753067017
tensor(1.2623, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01479343418031931
loss_c:0.8410767316818237
tensor(1.2823, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022052790969610214
loss_c:0.8975300788879395
tensor(1.3456, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027805959805846214
loss_c:0.822525680065155
tensor(1.3285, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02046429179608822
loss_c:0.8354470729827881
tensor(1.3037, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016776718199253082
loss_c:0.8421175479888916
tensor(1.2913, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011244636960327625
loss_c:0.7113898992538452
tensor(1.1935, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017283255234360695
loss_c:0.8962940573692322
tensor(1.3239, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035330578684806824
loss_c:0.7998319864273071
tensor(1.3489, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016926994547247887
loss_c:0.9412242770195007
tensor(1.3476, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02312243916094303
loss_c:0.7008744478225708
tensor(1.2396, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014223136007785797
loss_c:0.7496328353881836
tensor(1.2277, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01696125604212284
loss_c:0.8485433459281921
tensor(1.2955, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014849639497697353
loss_c:0.7598462104797363
tensor(1.2361, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012688934803009033
loss_c:0.7309421300888062
tensor(1.2101, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016291404142975807
loss_c:0.8295801877975464
tensor(1.2816, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0269088763743639
loss_c:0.8466812968254089
tensor(1.3385, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01973930187523365
loss_c:0.7789928913116455
tensor(1.2683, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03373431786894798
loss_c:0.8007763624191284
tensor(1.3432, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01262358482927084
loss_c:0.7794132232666016
tensor(1.2366, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019567452371120453
loss_c:0.9035825729370117
tensor(1.3379, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01823594607412815
loss_c:0.8851634860038757
tensor(1.3215, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014680261723697186
loss_c:0.7654568552970886
tensor(1.2377, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015204795636236668
loss_c:0.8038560748100281
tensor(1.2617, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012994966469705105
loss_c:0.8246888518333435
tensor(1.2635, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013423849828541279
loss_c:0.7199105024337769
tensor(1.2059, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01633528806269169
loss_c:0.7648857831954956
tensor(1.2445, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014962541870772839
loss_c:0.7129241824150085
tensor(1.2087, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013860017992556095
loss_c:0.7631669044494629
tensor(1.2320, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01777852326631546
loss_c:0.8537985682487488
tensor(1.3014, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018540628254413605
loss_c:0.8562172651290894
tensor(1.3063, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016612088307738304
loss_c:0.8539248704910278
tensor(1.2960, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027968185022473335
loss_c:0.8233410716056824
tensor(1.3311, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01699930429458618
loss_c:0.8194751143455505
tensor(1.2781, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022976916283369064
loss_c:0.8394302129745483
tensor(1.3172, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01846378855407238
loss_c:0.799592912197113
tensor(1.2735, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015241428278386593
loss_c:0.8467721939086914
tensor(1.2854, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01742040179669857
loss_c:0.8127783536911011
tensor(1.2761, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015422911383211613
loss_c:0.7546815276145935
tensor(1.2336, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014955390244722366
loss_c:0.8246857523918152
tensor(1.2713, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01878386177122593
loss_c:0.8458247184753418
tensor(1.3013, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02401045709848404
loss_c:0.8582741618156433
tensor(1.3330, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021961364895105362
loss_c:0.8734626770019531
tensor(1.3321, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016246918588876724
loss_c:0.8430413007736206
tensor(1.2877, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017555013298988342
loss_c:0.8512779474258423
tensor(1.2986, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02001396380364895
loss_c:0.8128969669342041
tensor(1.2883, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021222587674856186
loss_c:0.8965325355529785
tensor(1.3418, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029953183606266975
loss_c:0.7699739336967468
tensor(1.3110, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021028215065598488
loss_c:0.8354630470275879
tensor(1.3060, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04071168228983879
loss_c:0.8573536276817322
tensor(1.4121, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034877777099609375
loss_c:0.8582701086997986
tensor(1.3848, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038435254245996475
loss_c:0.932119607925415
tensor(1.4436, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014767533168196678
loss_c:0.7527354955673218
tensor(1.2292, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022778967395424843
loss_c:0.8912971019744873
tensor(1.3460, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016009870916604996
loss_c:0.746858537197113
tensor(1.2318, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028169307857751846
loss_c:0.8340827226638794
tensor(1.3387, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027410214766860008
loss_c:0.8485093116760254
tensor(1.3433, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042992398142814636
loss_c:0.7910194396972656
tensor(1.3834, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02275245077908039
loss_c:0.8631782531738281
tensor(1.3297, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019891442731022835
loss_c:0.8671157360076904
tensor(1.3186, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027389798313379288
loss_c:0.7605257034301758
tensor(1.2928, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028681540861725807
loss_c:0.8690294027328491
tensor(1.3603, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017675479874014854
loss_c:0.8593053817749023
tensor(1.3040, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018071604892611504
loss_c:0.921851396560669
tensor(1.3413, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014016823843121529
loss_c:0.6789044737815857
tensor(1.1849, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0182100348174572
loss_c:0.8324527740478516
tensor(1.2913, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019102394580841064
loss_c:0.9024138450622559
tensor(1.3351, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032129622995853424
loss_c:0.9657244682312012
tensor(1.4305, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018612822517752647
loss_c:0.9346679449081421
tensor(1.3511, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013620509766042233
loss_c:0.7506176829338074
tensor(1.2240, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01660088077187538
loss_c:0.736617922782898
tensor(1.2297, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033838607370853424
loss_c:0.8443585634231567
tensor(1.3693, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015287259593605995
loss_c:0.8712195754051208
tensor(1.3000, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019535353407263756
loss_c:0.7115036845207214
tensor(1.2290, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012349988333880901
loss_c:0.8394923210144043
tensor(1.2687, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01332366093993187
loss_c:0.8066767454147339
tensor(1.2545, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01911192201077938
loss_c:0.8756868243217468
tensor(1.3199, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018476413562893867
loss_c:0.7753398418426514
tensor(1.2602, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013478572480380535
loss_c:0.7487493753433228
tensor(1.2224, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01523156650364399
loss_c:0.7680238485336304
tensor(1.2412, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02808763086795807
loss_c:0.7819019556045532
tensor(1.3079, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016582554206252098
loss_c:0.7745789885520935
tensor(1.2510, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036850713193416595
loss_c:0.9998205900192261
tensor(1.4716, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027012012898921967
loss_c:0.7782748937606812
tensor(1.3009, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018580958247184753
loss_c:0.8577499389648438
tensor(1.3073, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022251266986131668
loss_c:0.8672988414764404
tensor(1.3295, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01842578500509262
loss_c:0.757908821105957
tensor(1.2500, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019586050882935524
loss_c:0.8986634016036987
tensor(1.3351, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017549706622958183
loss_c:0.8144634962081909
tensor(1.2780, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02714580111205578
loss_c:0.7531689405441284
tensor(1.2873, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015740523114800453
loss_c:0.8231672048568726
tensor(1.2746, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03780859708786011
loss_c:1.0165852308273315
tensor(1.4857, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02028430812060833
loss_c:0.6924230456352234
tensor(1.2214, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02088910900056362
loss_c:0.7957464456558228
tensor(1.2827, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02560610882937908
loss_c:0.7716077566146851
tensor(1.2907, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02844555489718914
loss_c:0.7558838129043579
tensor(1.2948, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019056033343076706
loss_c:0.7110390663146973
tensor(1.2263, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020181220024824142
loss_c:0.8083076477050781
tensor(1.2866, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011699308641254902
loss_c:0.7590498924255371
tensor(1.2198, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017434613779187202
loss_c:0.8118085265159607
tensor(1.2760, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01691615767776966
loss_c:0.8609391450881958
tensor(1.3016, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04555787891149521
loss_c:0.8713310956954956
tensor(1.4386, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017018243670463562
loss_c:0.866980791091919
tensor(1.3055, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03078848496079445
loss_c:0.8575371503829956
tensor(1.3631, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017389193177223206
loss_c:0.7488983869552612
tensor(1.2400, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019366759806871414
loss_c:0.9614243507385254
tensor(1.3701, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02508019097149372
loss_c:0.9490979909896851
tensor(1.3891, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01976659707725048
loss_c:0.8294806480407715
tensor(1.2968, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033412232995033264
loss_c:0.9360179901123047
tensor(1.4195, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015466145239770412
loss_c:0.8873859643936157
tensor(1.3101, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021897707134485245
loss_c:0.8682882785797119
tensor(1.3285, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03323059901595116
loss_c:0.8887412548065186
tensor(1.3916, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03386077657341957
loss_c:0.7806288599967957
tensor(1.3331, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013675296679139137
loss_c:0.7898592948913574
tensor(1.2467, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02357034757733345
loss_c:0.8832017779350281
tensor(1.3445, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027088608592748642
loss_c:0.9814978837966919
tensor(1.4160, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02573026344180107
loss_c:0.8516137003898621
tensor(1.3363, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014246138744056225
loss_c:0.8262047171592712
tensor(1.2701, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025553502142429352
loss_c:0.9348275065422058
tensor(1.3824, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024030590429902077
loss_c:0.9572334289550781
tensor(1.3881, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015172385610640049
loss_c:0.8313577175140381
tensor(1.2773, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015889227390289307
loss_c:0.7906911373138428
tensor(1.2576, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0226612351834774
loss_c:0.7701174020767212
tensor(1.2765, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01542800385504961
loss_c:0.8966094851493835
tensor(1.3151, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017112456262111664
loss_c:0.8205403685569763
tensor(1.2799, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031942740082740784
loss_c:0.7506136894226074
tensor(1.3074, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023595552891492844
loss_c:0.8858258128166199
tensor(1.3458, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01525693666189909
loss_c:0.805334746837616
tensor(1.2631, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01557689905166626
loss_c:0.7177491188049316
tensor(1.2154, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015812857076525688
loss_c:0.7636915445327759
tensor(1.2422, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03804400563240051
loss_c:0.7821292877197266
tensor(1.3527, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028376536443829536
loss_c:0.706335186958313
tensor(1.2666, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02537550777196884
loss_c:0.7872850298881531
tensor(1.2984, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022429607808589935
loss_c:0.9951908588409424
tensor(1.4020, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021464986726641655
loss_c:0.8287976980209351
tensor(1.3041, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01897653564810753
loss_c:0.750114917755127
tensor(1.2487, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021355757489800453
loss_c:0.9315770864486694
tensor(1.3615, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028875255957245827
loss_c:0.7495855093002319
tensor(1.2929, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020936787128448486
loss_c:0.8745523691177368
tensor(1.3275, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016695372760295868
loss_c:0.8244799971580505
tensor(1.2803, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04047592729330063
loss_c:0.9814753532409668
tensor(1.4756, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015270222909748554
loss_c:0.8103992342948914
tensor(1.2660, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020464932546019554
loss_c:0.9323720932006836
tensor(1.3580, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022575167939066887
loss_c:0.8207899332046509
tensor(1.3046, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015355909243226051
loss_c:0.6948341131210327
tensor(1.2014, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01552622951567173
loss_c:0.825694739818573
tensor(1.2758, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0215167123824358
loss_c:0.8967985510826111
tensor(1.3427, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01649721898138523
loss_c:0.8791476488113403
tensor(1.3102, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02409319020807743
loss_c:0.7845803499221802
tensor(1.2911, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01548891980201006
loss_c:0.7838863730430603
tensor(1.2520, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037984978407621384
loss_c:0.8764680624008179
tensor(1.4053, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013292417861521244
loss_c:0.7566146850585938
tensor(1.2267, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01802900992333889
loss_c:0.8322867751121521
tensor(1.2906, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014740322716534138
loss_c:0.8424147367477417
tensor(1.2815, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014284688048064709
loss_c:0.7499624490737915
tensor(1.2274, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02133568376302719
loss_c:0.8915613889694214
tensor(1.3389, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01484766136854887
loss_c:0.6998566389083862
tensor(1.2015, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021069595590233803
loss_c:0.8501056432723999
tensor(1.3143, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015931351110339165
loss_c:0.8450788855552673
tensor(1.2882, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019145822152495384
loss_c:0.6086838245391846
tensor(1.1694, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04491965472698212
loss_c:1.1483397483825684
tensor(1.5913, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016777850687503815
loss_c:0.7739400863647461
tensor(1.2518, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024514997377991676
loss_c:0.8468820452690125
tensor(1.3282, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018425796180963516
loss_c:0.6866122484207153
tensor(1.2099, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039867524057626724
loss_c:1.099114179611206
tensor(1.5407, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01929423026740551
loss_c:0.7967238426208496
tensor(1.2761, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019589371979236603
loss_c:0.7985562086105347
tensor(1.2785, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02384798415005207
loss_c:0.8171846270561218
tensor(1.3084, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018664414063096046
loss_c:0.8097023963928223
tensor(1.2806, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017903868108987808
loss_c:0.8083004355430603
tensor(1.2763, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02068556286394596
loss_c:0.7239386439323425
tensor(1.2413, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015473292209208012
loss_c:0.8346010446548462
tensor(1.2801, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024170968681573868
loss_c:0.8334119319915771
tensor(1.3190, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01566011644899845
loss_c:0.7007455825805664
tensor(1.2053, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01962323673069477
loss_c:0.9114550352096558
tensor(1.3425, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013540403917431831
loss_c:0.8128305673599243
tensor(1.2590, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016854822635650635
loss_c:0.7563151717185974
tensor(1.2420, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016847919672727585
loss_c:0.9641237258911133
tensor(1.3596, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027136484161019325
loss_c:0.8535496592521667
tensor(1.3441, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0180045273154974
loss_c:0.8699375987052917
tensor(1.3116, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022018911316990852
loss_c:0.73661208152771
tensor(1.2544, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01574632339179516
loss_c:0.8008038401603699
tensor(1.2620, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022384317591786385
loss_c:0.8132027387619019
tensor(1.2995, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016566263511776924
loss_c:0.7665252685546875
tensor(1.2463, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03031626157462597
loss_c:0.849389910697937
tensor(1.3565, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028710955753922462
loss_c:0.9045286178588867
tensor(1.3804, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018649689853191376
loss_c:0.8995901942253113
tensor(1.3313, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022725922986865044
loss_c:0.8552193641662598
tensor(1.3249, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016666540876030922
loss_c:0.7331690192222595
tensor(1.2278, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012881229631602764
loss_c:0.781899631023407
tensor(1.2380, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01138211227953434
loss_c:0.7147228717803955
tensor(1.1929, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012918291613459587
loss_c:0.7740710973739624
tensor(1.2336, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015623552724719048
loss_c:0.715347945690155
tensor(1.2127, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04046790301799774
loss_c:0.912595272064209
tensor(1.4398, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016096081584692
loss_c:0.7965394854545593
tensor(1.2609, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024028709158301353
loss_c:0.8274022936820984
tensor(1.3152, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02481619454920292
loss_c:0.9041840434074402
tensor(1.3625, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015557418577373028
loss_c:0.8184887766838074
tensor(1.2708, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01531263068318367
loss_c:0.7743103504180908
tensor(1.2445, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01957109570503235
loss_c:0.8009289503097534
tensor(1.2795, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026682110503315926
loss_c:0.7954723238945007
tensor(1.3095, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0131331542506814
loss_c:0.7876531481742859
tensor(1.2419, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023593781515955925
loss_c:0.8003537058830261
tensor(1.2979, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029396096244454384
loss_c:0.7163578867912292
tensor(1.2771, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015276480466127396
loss_c:0.8598767518997192
tensor(1.2930, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016619525849819183
loss_c:0.8244137763977051
tensor(1.2790, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019506508484482765
loss_c:0.8420430421829224
tensor(1.3026, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0267957653850317
loss_c:0.7397589683532715
tensor(1.2782, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01587079092860222
loss_c:0.9142774343490601
tensor(1.3268, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014001828618347645
loss_c:0.765432596206665
tensor(1.2331, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015324230305850506
loss_c:0.9002655744552612
tensor(1.3163, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02879173867404461
loss_c:0.9203038215637207
tensor(1.3907, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017467595636844635
loss_c:0.784468412399292
tensor(1.2601, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04330124333500862
loss_c:1.0230793952941895
tensor(1.5174, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019466977566480637
loss_c:0.90069580078125
tensor(1.3358, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029183151200413704
loss_c:1.0228523015975952
tensor(1.4509, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02195504494011402
loss_c:0.9088077545166016
tensor(1.3520, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08416268229484558
loss_c:0.8891698122024536
tensor(1.6311, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.053570665419101715
loss_c:0.8226568102836609
tensor(1.4497, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02436220832169056
loss_c:0.8412894606590271
tensor(1.3246, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01730761118233204
loss_c:0.8396160006523132
tensor(1.2912, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017567260190844536
loss_c:0.95953768491745
tensor(1.3603, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01700616627931595
loss_c:0.8279088735580444
tensor(1.2834, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01751869171857834
loss_c:0.852378249168396
tensor(1.2996, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02033742144703865
loss_c:0.891612708568573
tensor(1.3345, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021341564133763313
loss_c:0.8773543834686279
tensor(1.3309, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01400709804147482
loss_c:0.678784966468811
tensor(1.1862, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018586501479148865
loss_c:0.7741987109184265
tensor(1.2605, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01538762915879488
loss_c:0.7888309359550476
tensor(1.2545, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013702381402254105
loss_c:0.8089193105697632
tensor(1.2583, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011123770847916603
loss_c:0.7067057490348816
tensor(1.1893, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03510672599077225
loss_c:0.8967558741569519
tensor(1.4034, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017137708142399788
loss_c:0.8225103616714478
tensor(1.2813, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019917534664273262
loss_c:0.8186764717102051
tensor(1.2916, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014897572807967663
loss_c:0.9102398753166199
tensor(1.3206, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01379323285073042
loss_c:0.8153895139694214
tensor(1.2623, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02031669393181801
loss_c:0.8025187253952026
tensor(1.2842, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014748034067451954
loss_c:0.7354439496994019
tensor(1.2215, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03133609518408775
loss_c:0.7150058746337891
tensor(1.2845, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019617388024926186
loss_c:0.8303426504135132
tensor(1.2967, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01722675934433937
loss_c:0.8453091382980347
tensor(1.2944, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02551879547536373
loss_c:0.7690660357475281
tensor(1.2887, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01527060940861702
loss_c:0.8376448154449463
tensor(1.2812, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012575868517160416
loss_c:0.7039215564727783
tensor(1.1936, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03285268694162369
loss_c:1.0477650165557861
tensor(1.4792, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02636078931391239
loss_c:0.8369287252426147
tensor(1.3309, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03234464302659035
loss_c:0.7236514091491699
tensor(1.2940, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013546377420425415
loss_c:0.7329314947128296
tensor(1.2141, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.053813640028238297
loss_c:0.7744280695915222
tensor(1.4198, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024068685248494148
loss_c:0.8922184705734253
tensor(1.3517, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04291004315018654
loss_c:0.8540505170822144
tensor(1.4152, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016301432624459267
loss_c:0.8071627616882324
tensor(1.2686, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015245114453136921
loss_c:0.8084331750869751
tensor(1.2647, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016014868393540382
loss_c:0.8831086158752441
tensor(1.3105, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015741121023893356
loss_c:0.8111354112625122
tensor(1.2685, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013053878210484982
loss_c:0.7026044130325317
tensor(1.1950, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020314352586865425
loss_c:0.9330877065658569
tensor(1.3581, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017747990787029266
loss_c:0.8190892934799194
tensor(1.2820, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022041812539100647
loss_c:0.873224675655365
tensor(1.3319, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03593229502439499
loss_c:0.9273704290390015
tensor(1.4249, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01837841607630253
loss_c:0.7662966251373291
tensor(1.2549, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015845414251089096
loss_c:0.8370842933654785
tensor(1.2837, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012625685892999172
loss_c:0.7921570539474487
tensor(1.2437, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017565540969371796
loss_c:0.750083327293396
tensor(1.2420, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014125303365290165
loss_c:0.8085387945175171
tensor(1.2597, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02613016404211521
loss_c:0.8343603610992432
tensor(1.3283, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01732853800058365
loss_c:0.900371789932251
tensor(1.3261, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05049467459321022
loss_c:0.9304927587509155
tensor(1.4927, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02035914734005928
loss_c:0.8964730501174927
tensor(1.3375, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030193744227290154
loss_c:0.7399017810821533
tensor(1.2930, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0167898740619421
loss_c:0.8262783885002136
tensor(1.2817, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014087488874793053
loss_c:0.8108495473861694
tensor(1.2608, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02530852146446705
loss_c:0.7822902202606201
tensor(1.2951, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014203203842043877
loss_c:0.7618443965911865
tensor(1.2335, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027400970458984375
loss_c:0.8583759069442749
tensor(1.3476, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015244673006236553
loss_c:0.8124212622642517
tensor(1.2668, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018981261178851128
loss_c:0.8214137554168701
tensor(1.2888, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018250593915581703
loss_c:0.7509149312973022
tensor(1.2455, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035207539796829224
loss_c:0.8543423414230347
tensor(1.3806, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02507558837532997
loss_c:0.9763152003288269
tensor(1.4041, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02638484351336956
loss_c:0.839566171169281
tensor(1.3324, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019099727272987366
loss_c:0.8515818119049072
tensor(1.3064, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013778175227344036
loss_c:0.7563645243644714
tensor(1.2284, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017910927534103394
loss_c:0.9133667945861816
tensor(1.3361, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023822497576475143
loss_c:0.7954868078231812
tensor(1.2959, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012348433956503868
loss_c:0.7504595518112183
tensor(1.2186, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01923855021595955
loss_c:0.6918010711669922
tensor(1.2164, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01600002683699131
loss_c:0.735826849937439
tensor(1.2267, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013397580944001675
loss_c:0.7335107326507568
tensor(1.2136, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018540209159255028
loss_c:0.8257526159286499
tensor(1.2891, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03757185861468315
loss_c:0.8553783893585205
tensor(1.3923, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016827134415507317
loss_c:0.856576144695282
tensor(1.2988, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017152931541204453
loss_c:0.9114935398101807
tensor(1.3315, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036577533930540085
loss_c:1.0290398597717285
tensor(1.4867, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02247844636440277
loss_c:0.9116189479827881
tensor(1.3558, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0256802961230278
loss_c:0.7926418781280518
tensor(1.3027, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04253765568137169
loss_c:0.932243824005127
tensor(1.4587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016218753531575203
loss_c:0.6933083534240723
tensor(1.2034, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11531814187765121
loss_c:0.9783139228820801
tensor(1.8147, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013596968725323677
loss_c:0.8731500506401062
tensor(1.2938, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023994367569684982
loss_c:0.8804936408996582
tensor(1.3448, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020853620022535324
loss_c:1.0095300674438477
tensor(1.4038, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02093789167702198
loss_c:0.9310664534568787
tensor(1.3597, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09524450451135635
loss_c:0.9257282018661499
tensor(1.6858, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023267624899744987
loss_c:1.044407606124878
tensor(1.4338, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025058550760149956
loss_c:0.8629304766654968
tensor(1.3392, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030462808907032013
loss_c:0.7750897407531738
tensor(1.3133, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02927444316446781
loss_c:0.846791684627533
tensor(1.3483, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01397795882076025
loss_c:0.6997730135917664
tensor(1.2000, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019922785460948944
loss_c:0.8344361782073975
tensor(1.3011, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01639651507139206
loss_c:0.9178466200828552
tensor(1.3329, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01570175774395466
loss_c:0.7728605270385742
tensor(1.2488, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017887048423290253
loss_c:0.7263317108154297
tensor(1.2322, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01911819912493229
loss_c:0.8267523646354675
tensor(1.2936, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014855724759399891
loss_c:0.876765251159668
tensor(1.3036, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01969449408352375
loss_c:0.8034601211547852
tensor(1.2831, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02195032313466072
loss_c:0.7725876569747925
tensor(1.2754, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024033861234784126
loss_c:0.8510362505912781
tensor(1.3280, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07226115465164185
loss_c:1.0748484134674072
tensor(1.6573, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017627505585551262
loss_c:0.7402543425559998
tensor(1.2391, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021944085136055946
loss_c:0.7886528968811035
tensor(1.2844, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011723572388291359
loss_c:0.7134312391281128
tensor(1.1994, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022296957671642303
loss_c:0.7845182418823242
tensor(1.2836, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013068334199488163
loss_c:0.8060271739959717
tensor(1.2568, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014663700945675373
loss_c:0.7489252090454102
tensor(1.2315, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014996347948908806
loss_c:0.8198357820510864
tensor(1.2726, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02299916371703148
loss_c:0.7060438990592957
tensor(1.2425, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015688534826040268
loss_c:0.782690703868866
tensor(1.2545, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017017705366015434
loss_c:0.9809635877609253
tensor(1.3713, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01577254757285118
loss_c:0.854503333568573
tensor(1.2950, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038922298699617386
loss_c:0.9296204447746277
tensor(1.4354, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022105706855654716
loss_c:0.8959940671920776
tensor(1.3451, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02186541259288788
loss_c:0.8848426342010498
tensor(1.3378, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039346810430288315
loss_c:0.8267087936401367
tensor(1.3796, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.12959715723991394
loss_c:0.8625785708427429
tensor(1.7841, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01640329882502556
loss_c:0.7401618957519531
tensor(1.2335, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01850137487053871
loss_c:0.9141688346862793
tensor(1.3402, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03728392347693443
loss_c:0.9950668215751648
tensor(1.4648, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02042153850197792
loss_c:0.9158426523208618
tensor(1.3493, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036519937217235565
loss_c:0.8259484767913818
tensor(1.3663, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018229395151138306
loss_c:0.7919800281524658
tensor(1.2708, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03780309110879898
loss_c:0.7353949546813965
tensor(1.3206, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027732815593481064
loss_c:1.0862183570861816
tensor(1.4753, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019858095794916153
loss_c:0.7718110084533691
tensor(1.2665, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024609742686152458
loss_c:0.8698943853378296
tensor(1.3411, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01884850673377514
loss_c:0.8622263669967651
tensor(1.3131, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023096632212400436
loss_c:0.8938986659049988
tensor(1.3483, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024424737319350243
loss_c:0.8893243670463562
tensor(1.3513, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015853291377425194
loss_c:0.791832447052002
tensor(1.2615, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034470777958631516
loss_c:0.8877482414245605
tensor(1.3917, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025319481268525124
loss_c:0.8296896815299988
tensor(1.3216, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020323844626545906
loss_c:1.019695520401001
tensor(1.4072, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03476376459002495
loss_c:0.9729425311088562
tensor(1.4403, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029228022322058678
loss_c:0.8089474439620972
tensor(1.3261, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015282077714800835
loss_c:0.8334015607833862
tensor(1.2825, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019565215334296227
loss_c:0.7632037997245789
tensor(1.2610, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022491158917546272
loss_c:0.8758177757263184
tensor(1.3357, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018099477514624596
loss_c:0.8401846885681152
tensor(1.2979, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02511637844145298
loss_c:0.7431051135063171
tensor(1.2727, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016869181767106056
loss_c:0.7473739385604858
tensor(1.2412, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014969098381698132
loss_c:0.7215415835380554
tensor(1.2189, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02625149115920067
loss_c:0.7783308029174805
tensor(1.2969, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01792752370238304
loss_c:0.7917515635490417
tensor(1.2700, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017082281410694122
loss_c:0.7806433439254761
tensor(1.2602, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018142275512218475
loss_c:0.8977264761924744
tensor(1.3298, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021232260391116142
loss_c:0.803668200969696
tensor(1.2901, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015400451608002186
loss_c:0.8839588165283203
tensor(1.3106, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03462851047515869
loss_c:0.8239783048629761
tensor(1.3572, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04118603467941284
loss_c:0.8791384100914001
tensor(1.4154, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06346897780895233
loss_c:0.887976348400116
tensor(1.5135, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01774095930159092
loss_c:0.7993167638778687
tensor(1.2729, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.044917043298482895
loss_c:1.054292917251587
tensor(1.5289, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024268189445137978
loss_c:0.8637344837188721
tensor(1.3362, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013953150250017643
loss_c:0.7968415021896362
tensor(1.2559, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018035810440778732
loss_c:0.766666054725647
tensor(1.2560, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04241986572742462
loss_c:0.6873775720596313
tensor(1.3131, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019918594509363174
loss_c:0.8775577545166016
tensor(1.3259, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022558730095624924
loss_c:0.9180862307548523
tensor(1.3595, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022684048861265182
loss_c:0.7579443454742432
tensor(1.2705, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01615269109606743
loss_c:0.8341495394706726
tensor(1.2860, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02335830219089985
loss_c:0.7350009679794312
tensor(1.2604, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017697731032967567
loss_c:0.8504894971847534
tensor(1.3015, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018377602100372314
loss_c:0.792503297328949
tensor(1.2718, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016509655863046646
loss_c:0.9475940465927124
tensor(1.3510, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017323113977909088
loss_c:0.792661190032959
tensor(1.2675, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024250684306025505
loss_c:0.797071099281311
tensor(1.2988, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016636550426483154
loss_c:0.7628077864646912
tensor(1.2477, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024760115891695023
loss_c:0.7594683170318604
tensor(1.2798, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018144559115171432
loss_c:0.757461428642273
tensor(1.2508, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015605592168867588
loss_c:0.816983699798584
tensor(1.2736, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0408749021589756
loss_c:0.7874631881713867
tensor(1.3632, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023428065702319145
loss_c:0.8724589347839355
tensor(1.3376, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01717265322804451
loss_c:0.8018962144851685
tensor(1.2715, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031347695738077164
loss_c:0.798236072063446
tensor(1.3292, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013289681635797024
loss_c:0.7054824829101562
tensor(1.2005, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020268216729164124
loss_c:0.8493403196334839
tensor(1.3112, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018190963193774223
loss_c:0.8453740477561951
tensor(1.3001, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024701504036784172
loss_c:0.8769585490226746
tensor(1.3456, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017422616481781006
loss_c:0.7801353335380554
tensor(1.2599, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023630257695913315
loss_c:0.8925032019615173
tensor(1.3499, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03268454968929291
loss_c:0.7925271391868591
tensor(1.3319, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03346779942512512
loss_c:0.8271831274032593
tensor(1.3549, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020186685025691986
loss_c:0.9123908877372742
tensor(1.3465, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024005917832255363
loss_c:0.7940012216567993
tensor(1.2957, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023410722613334656
loss_c:0.8814024925231934
tensor(1.3427, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02323628030717373
loss_c:0.936212420463562
tensor(1.3730, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015204150229692459
loss_c:0.7936930060386658
tensor(1.2578, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018695617094635963
loss_c:0.8931365013122559
tensor(1.3291, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0162189994007349
loss_c:0.8120794296264648
tensor(1.2725, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017238080501556396
loss_c:0.7897123098373413
tensor(1.2641, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04364996403455734
loss_c:0.835314929485321
tensor(1.4037, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06816066801548004
loss_c:0.8084262609481812
tensor(1.4942, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01770416833460331
loss_c:0.8818012475967407
tensor(1.3183, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02122938446700573
loss_c:0.7541524767875671
tensor(1.2612, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022010354325175285
loss_c:0.8588496446609497
tensor(1.3238, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021572651341557503
loss_c:0.8518815040588379
tensor(1.3180, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015115724876523018
loss_c:0.7827748656272888
tensor(1.2512, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023719677701592445
loss_c:0.8486299514770508
tensor(1.3254, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029216354712843895
loss_c:0.9001395106315613
tensor(1.3781, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03555266559123993
loss_c:0.7658960223197937
tensor(1.3293, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020131057128310204
loss_c:0.8563620448112488
tensor(1.3144, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014480816200375557
loss_c:0.732302188873291
tensor(1.2200, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01808144710958004
loss_c:0.824009895324707
tensor(1.2873, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04768579825758934
loss_c:0.8153964281082153
tensor(1.4093, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016414044424891472
loss_c:0.7569856643676758
tensor(1.2422, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03048776090145111
loss_c:0.7906484007835388
tensor(1.3215, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024160612374544144
loss_c:0.9430097341537476
tensor(1.3808, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01746429316699505
loss_c:0.7654110789299011
tensor(1.2515, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02381460927426815
loss_c:0.6827187538146973
tensor(1.2318, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019713718444108963
loss_c:0.8712759017944336
tensor(1.3212, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013306792825460434
loss_c:0.8676303625106812
tensor(1.2917, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017197653651237488
loss_c:0.8938323259353638
tensor(1.3232, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018037961795926094
loss_c:0.8798992037773132
tensor(1.3189, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017505716532468796
loss_c:0.8660210371017456
tensor(1.3087, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01934412680566311
loss_c:0.8514074087142944
tensor(1.3082, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016951225697994232
loss_c:0.7843918204307556
tensor(1.2599, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028973668813705444
loss_c:0.9565505385398865
tensor(1.4092, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02817028947174549
loss_c:0.847859263420105
tensor(1.3442, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020378608256578445
loss_c:0.8492084741592407
tensor(1.3113, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014578104950487614
loss_c:0.779179573059082
tensor(1.2466, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11044534295797348
loss_c:0.8911211490631104
tensor(1.7247, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01823631301522255
loss_c:0.7510637640953064
tensor(1.2465, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016192033886909485
loss_c:0.7878624796867371
tensor(1.2586, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013859729282557964
loss_c:0.7548753023147583
tensor(1.2300, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0187597144395113
loss_c:0.910378098487854
tensor(1.3391, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015874290838837624
loss_c:0.78717440366745
tensor(1.2570, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016971055418252945
loss_c:0.7890629172325134
tensor(1.2628, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01622624322772026
loss_c:0.7694098353385925
tensor(1.2484, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02263229340314865
loss_c:0.9018397331237793
tensor(1.3509, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021320883184671402
loss_c:0.8873782157897949
tensor(1.3370, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013740227557718754
loss_c:0.9220461845397949
tensor(1.3241, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01836603507399559
loss_c:0.9090738296508789
tensor(1.3366, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03497662395238876
loss_c:0.825474739074707
tensor(1.3608, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014902515336871147
loss_c:0.7853271961212158
tensor(1.2516, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013582448475062847
loss_c:0.7779860496520996
tensor(1.2417, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01878073439002037
loss_c:0.6972769498825073
tensor(1.2185, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034520223736763
loss_c:1.0050551891326904
tensor(1.4605, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01739480532705784
loss_c:0.8672520518302917
tensor(1.3085, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025706011801958084
loss_c:0.7729873657226562
tensor(1.2912, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021768972277641296
loss_c:0.9459854960441589
tensor(1.3719, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01963994838297367
loss_c:0.9650821089744568
tensor(1.3734, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029068395495414734
loss_c:0.7549347877502441
tensor(1.2957, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015591809526085854
loss_c:0.7936140894889832
tensor(1.2590, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029434042051434517
loss_c:0.7824799418449402
tensor(1.3129, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016407914459705353
loss_c:0.9096574187278748
tensor(1.3279, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04178972914814949
loss_c:0.7743121385574341
tensor(1.3623, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012955852784216404
loss_c:0.701131284236908
tensor(1.1953, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01730208285152912
loss_c:0.8636597990989685
tensor(1.3058, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014372821897268295
loss_c:0.6860696077346802
tensor(1.1929, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0179335605353117
loss_c:0.8102793097496033
tensor(1.2784, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039432279765605927
loss_c:0.7418326139450073
tensor(1.3338, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014897633343935013
loss_c:0.8694011569023132
tensor(1.2985, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02896205708384514
loss_c:0.836616039276123
tensor(1.3415, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036572813987731934
loss_c:1.0118943452835083
tensor(1.4740, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0265482347458601
loss_c:0.7413935661315918
tensor(1.2772, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018644144758582115
loss_c:0.8246713876724243
tensor(1.2896, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017083443701267242
loss_c:0.8579959869384766
tensor(1.3016, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015294508077204227
loss_c:0.7561358213424683
tensor(1.2362, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027080878615379333
loss_c:0.7996629476547241
tensor(1.3124, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014209428802132607
loss_c:0.7169481515884399
tensor(1.2092, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022718243300914764
loss_c:0.8165782690048218
tensor(1.3029, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03231928125023842
loss_c:0.8862905502319336
tensor(1.3845, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032111771404743195
loss_c:0.8531216382980347
tensor(1.3648, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022721903398633003
loss_c:0.759831428527832
tensor(1.2707, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021509625017642975
loss_c:0.8718387484550476
tensor(1.3289, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01719711907207966
loss_c:1.0220377445220947
tensor(1.3951, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01223557535558939
loss_c:0.6978493928909302
tensor(1.1895, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015481238253414631
loss_c:0.8217883110046387
tensor(1.2740, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014064771123230457
loss_c:0.7273048162460327
tensor(1.2142, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03671697899699211
loss_c:0.887422502040863
tensor(1.4046, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019438182935118675
loss_c:0.6913668513298035
tensor(1.2174, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018181849271059036
loss_c:0.832852840423584
tensor(1.2921, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028681501746177673
loss_c:0.99297034740448
tensor(1.4293, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015852391719818115
loss_c:0.7622925043106079
tensor(1.2417, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03622835502028465
loss_c:0.9499010443687439
tensor(1.4382, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01801350712776184
loss_c:0.923545777797699
tensor(1.3427, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0248070377856493
loss_c:0.7932929396629333
tensor(1.2989, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05207255110144615
loss_c:0.872672438621521
tensor(1.4644, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01993042789399624
loss_c:0.7513537406921387
tensor(1.2535, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017673177644610405
loss_c:0.7531053423881531
tensor(1.2446, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01666531153023243
loss_c:0.8788410425186157
tensor(1.3114, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01869683340191841
loss_c:0.8261781930923462
tensor(1.2906, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035896413028240204
loss_c:0.8413872122764587
tensor(1.3750, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026915639638900757
loss_c:0.8780108690261841
tensor(1.3561, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023295272141695023
loss_c:0.7897674441337585
tensor(1.2902, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030011383816599846
loss_c:1.1195905208587646
tensor(1.5065, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01898747868835926
loss_c:0.8028950691223145
tensor(1.2787, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02366798371076584
loss_c:0.9810665845870972
tensor(1.4001, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015701118856668472
loss_c:0.7428843975067139
tensor(1.2304, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019092176109552383
loss_c:0.8436054587364197
tensor(1.3022, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02346106618642807
loss_c:0.8643113374710083
tensor(1.3331, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014619995839893818
loss_c:0.8940623998641968
tensor(1.3110, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01848135143518448
loss_c:0.8318650126457214
tensor(1.2929, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029320161789655685
loss_c:0.8592163920402527
tensor(1.3559, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021705934777855873
loss_c:0.7613614797592163
tensor(1.2674, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017841825261712074
loss_c:0.7958055734634399
tensor(1.2698, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01855599507689476
loss_c:0.8667432069778442
tensor(1.3128, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020781634375452995
loss_c:0.8557841181755066
tensor(1.3164, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02591351605951786
loss_c:0.8938800096511841
tensor(1.3604, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0259244441986084
loss_c:0.9252636432647705
tensor(1.3781, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016697796061635017
loss_c:0.851608157157898
tensor(1.2960, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020613644272089005
loss_c:0.7623469829559326
tensor(1.2632, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025688163936138153
loss_c:0.8326091170310974
tensor(1.3250, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018857739865779877
loss_c:0.7150936126708984
tensor(1.2290, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01848248764872551
loss_c:0.7998635172843933
tensor(1.2748, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016908738762140274
loss_c:0.737615704536438
tensor(1.2329, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02535943314433098
loss_c:0.9902734756469727
tensor(1.4121, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027322158217430115
loss_c:0.9112621545791626
tensor(1.3765, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024685679003596306
loss_c:0.704686164855957
tensor(1.2489, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021792687475681305
loss_c:0.8502081632614136
tensor(1.3177, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02347908355295658
loss_c:0.989723801612854
tensor(1.4035, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018245475366711617
loss_c:0.8891834616661072
tensor(1.3238, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03237379714846611
loss_c:0.9172186851501465
tensor(1.4023, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02664274536073208
loss_c:0.7381258010864258
tensor(1.2764, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017271695658564568
loss_c:0.950481116771698
tensor(1.3538, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01471079234033823
loss_c:0.7732157111167908
tensor(1.2431, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01845669373869896
loss_c:0.8420112133026123
tensor(1.2983, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02637670189142227
loss_c:0.8963732719421387
tensor(1.3639, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019422747194767
loss_c:0.8653866052627563
tensor(1.3156, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015569131821393967
loss_c:0.8959299921989441
tensor(1.3155, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021437566727399826
loss_c:0.8451477885246277
tensor(1.3132, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029698653146624565
loss_c:0.8622578382492065
tensor(1.3596, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015614070929586887
loss_c:0.7909197807312012
tensor(1.2569, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02902900241315365
loss_c:0.8130699992179871
tensor(1.3292, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026767149567604065
loss_c:0.8471641540527344
tensor(1.3382, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020344777032732964
loss_c:0.9230701327323914
tensor(1.3519, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022990060970187187
loss_c:0.8448173403739929
tensor(1.3200, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014214470051229
loss_c:0.7109917402267456
tensor(1.2061, device='cuda:0', grad_fn=<AddBackward0>)
total_train_loss:1.321916103363037
loss_r:0.030934134498238564
loss_c:1.8287181854248047
loss_r:0.029964985325932503
loss_c:1.7312387228012085
loss_r:0.031239308416843414
loss_c:1.7866454124450684
loss_r:0.029606811702251434
loss_c:1.760269045829773
loss_r:0.029513796791434288
loss_c:1.6982495784759521
loss_r:0.026986828073859215
loss_c:1.6298046112060547
loss_r:0.02740923874080181
loss_c:1.8291184902191162
loss_r:0.027154063805937767
loss_c:1.8184211254119873
loss_r:0.029867304489016533
loss_c:1.91598641872406
loss_r:0.02642332762479782
loss_c:1.9144214391708374
loss_r:0.023346206173300743
loss_c:1.724079966545105
loss_r:0.022466320544481277
loss_c:1.646329641342163
loss_r:0.023533668369054794
loss_c:1.6315997838974
loss_r:0.021260200068354607
loss_c:1.5690538883209229
loss_r:0.02423960529267788
loss_c:1.6448113918304443
loss_r:0.027097759768366814
loss_c:1.7131357192993164
loss_r:0.022102806717157364
loss_c:1.5550193786621094
loss_r:0.02269606851041317
loss_c:1.5680793523788452
loss_r:0.025637291371822357
loss_c:1.6227004528045654
loss_r:0.02093227580189705
loss_c:1.5057729482650757
loss_r:0.023887699469923973
loss_c:1.620877981185913
loss_r:0.026748599484562874
loss_c:1.723235845565796
loss_r:0.02240942232310772
loss_c:1.5318005084991455
loss_r:0.02559046447277069
loss_c:1.649004340171814
loss_r:0.02806907147169113
loss_c:1.6506013870239258
loss_r:0.022254308685660362
loss_c:1.4835336208343506
loss_r:0.025310970842838287
loss_c:1.67624831199646
loss_r:0.02818422205746174
loss_c:1.6769368648529053
loss_r:0.02489304728806019
loss_c:1.5589803457260132
loss_r:0.02499438263475895
loss_c:1.5989949703216553
loss_r:0.02699587494134903
loss_c:1.723436713218689
loss_r:0.021408814936876297
loss_c:1.52628755569458
loss_r:0.026967758312821388
loss_c:1.7863414287567139
loss_r:0.0277504101395607
loss_c:1.7578219175338745
loss_r:0.023644844070076942
loss_c:1.6112273931503296
loss_r:0.023341594263911247
loss_c:1.5306094884872437
loss_r:0.02850816585123539
loss_c:1.7532567977905273
loss_r:0.02167598158121109
loss_c:1.5966968536376953
loss_r:0.026030173525214195
loss_c:1.7228717803955078
loss_r:0.02659563533961773
loss_c:1.6804507970809937
loss_r:0.023551560938358307
loss_c:1.583949089050293
loss_r:0.02406296133995056
loss_c:1.5623812675476074
loss_r:0.02510916441679001
loss_c:1.7608342170715332
loss_r:0.020476598292589188
loss_c:1.653212547302246
loss_r:0.02481759898364544
loss_c:1.7815263271331787
loss_r:0.02575748972594738
loss_c:1.6581933498382568
loss_r:0.02316291257739067
loss_c:1.6186425685882568
loss_r:0.023811407387256622
loss_c:1.650564193725586
loss_r:0.02464115433394909
loss_c:1.7146344184875488
loss_r:0.021489884704351425
loss_c:1.7274055480957031
loss_r:0.026010552421212196
loss_c:1.8994653224945068
loss_r:0.025282084941864014
loss_c:1.771411418914795
loss_r:0.024110544472932816
loss_c:1.6917771100997925
loss_r:0.02355189248919487
loss_c:1.6301435232162476
loss_r:0.024051928892731667
loss_c:1.7037514448165894
loss_r:0.023006321862339973
loss_c:1.8272473812103271
loss_r:0.026365451514720917
loss_c:1.880131721496582
loss_r:0.02656649425625801
loss_c:1.7438682317733765
loss_r:0.024739930406212807
loss_c:1.7200982570648193
loss_r:0.0233232993632555
loss_c:1.6236796379089355
loss_r:0.025275152176618576
loss_c:1.7244056463241577
loss_r:0.023385819047689438
loss_c:1.7660883665084839
loss_r:0.024803783744573593
loss_c:1.7238764762878418
loss_r:0.0257246270775795
loss_c:1.6432737112045288
loss_r:0.02457507885992527
loss_c:1.639040231704712
loss_r:0.025341276079416275
loss_c:1.5244579315185547
loss_r:0.029831944033503532
loss_c:1.730075716972351
loss_r:0.02387700416147709
loss_c:1.6276706457138062
loss_r:0.026486527174711227
loss_c:1.7208220958709717
loss_r:0.027300244197249413
loss_c:1.63419771194458
loss_r:0.025848397985100746
loss_c:1.6236248016357422
loss_r:0.02435104176402092
loss_c:1.5913138389587402
loss_r:0.027098363265395164
loss_c:1.7540240287780762
loss_r:0.024078186601400375
loss_c:1.7204750776290894
loss_r:0.024617958813905716
loss_c:1.6910693645477295
loss_r:0.027691392228007317
loss_c:1.6390336751937866
loss_r:0.024994010105729103
loss_c:1.6611053943634033
loss_r:0.024743905290961266
loss_c:1.5124486684799194
loss_r:0.028350170701742172
loss_c:1.7440600395202637
loss_r:0.023785727098584175
loss_c:1.7214324474334717
loss_r:0.026505911722779274
loss_c:1.8151376247406006
loss_r:0.02860294282436371
loss_c:1.737675428390503
loss_r:0.024234656244516373
loss_c:1.647196650505066
loss_r:0.02489278092980385
loss_c:1.5415894985198975
loss_r:0.02995464950799942
loss_c:1.8139513731002808
loss_r:0.026616206392645836
loss_c:1.7670506238937378
loss_r:0.02755841426551342
loss_c:1.8381004333496094
loss_r:0.025914980098605156
loss_c:1.6846288442611694
loss_r:0.0255895983427763
loss_c:1.688976764678955
loss_r:0.025068635120987892
loss_c:1.5467510223388672
loss_r:0.02694089524447918
loss_c:1.7492995262145996
loss_r:0.02448103204369545
loss_c:1.7643070220947266
loss_r:0.026290958747267723
loss_c:1.7591619491577148
loss_r:0.025008847936987877
loss_c:1.6239722967147827
loss_r:0.02553630992770195
loss_c:1.6897600889205933
loss_r:0.02694409154355526
loss_c:1.5210274457931519
loss_r:0.028673050925135612
loss_c:1.7044103145599365
loss_r:0.027067774906754494
loss_c:1.7531360387802124
loss_r:0.02818967215716839
loss_c:1.729101538658142
loss_r:0.024327559396624565
loss_c:1.5768636465072632
loss_r:0.026662372052669525
loss_c:1.7036588191986084
loss_r:0.02598446048796177
loss_c:1.5039784908294678
loss_r:0.028111878782510757
loss_c:1.60068678855896
loss_r:0.027640847489237785
loss_c:1.7838644981384277
loss_r:0.028772613033652306
loss_c:1.7717121839523315
loss_r:0.024050261825323105
loss_c:1.6062893867492676
loss_r:0.0244396161288023
loss_c:1.664777159690857
loss_r:0.027222130447626114
loss_c:1.514050841331482
loss_r:0.026528825983405113
loss_c:1.65017831325531
loss_r:0.026758069172501564
loss_c:1.8003826141357422
loss_r:0.027707302942872047
loss_c:1.6888341903686523
loss_r:0.02336074411869049
loss_c:1.5303415060043335
loss_r:0.025472527369856834
loss_c:1.6465606689453125
loss_r:0.028287967666983604
loss_c:1.5470622777938843
loss_r:0.02676449343562126
loss_c:1.6572331190109253
loss_r:0.025187168270349503
loss_c:1.6543323993682861
loss_r:0.026008786633610725
loss_c:1.5973857641220093
loss_r:0.02452881447970867
loss_c:1.558845043182373
loss_r:0.02762575075030327
loss_c:1.7091493606567383
loss_r:0.027274059131741524
loss_c:1.4946602582931519
loss_r:0.029189839959144592
loss_c:1.619706630706787
loss_r:0.02699468657374382
loss_c:1.7347978353500366
loss_r:0.030930807814002037
loss_c:1.8221063613891602
loss_r:0.026024267077445984
loss_c:1.6078370809555054
loss_r:0.026922354474663734
loss_c:1.6934938430786133
loss_r:0.02741048112511635
loss_c:1.4832763671875
loss_r:0.02878561057150364
loss_c:1.5942845344543457
loss_r:0.024111544713377953
loss_c:1.5807981491088867
loss_r:0.028067205101251602
loss_c:1.7038148641586304
loss_r:0.023407459259033203
loss_c:1.5652045011520386
loss_r:0.026550179347395897
loss_c:1.7386268377304077
loss_r:0.02403254061937332
loss_c:1.428412914276123
loss_r:0.027752531692385674
loss_c:1.5591773986816406
loss_r:0.02196929231286049
loss_c:1.490938663482666
loss_r:0.025617625564336777
loss_c:1.6353375911712646
loss_r:0.023816538974642754
loss_c:1.5781205892562866
loss_r:0.02702711708843708
loss_c:1.7344549894332886
loss_r:0.023087861016392708
loss_c:1.4364004135131836
loss_r:0.0318942554295063
loss_c:1.6330140829086304
loss_r:0.02368587628006935
loss_c:1.5373597145080566
loss_r:0.029023442417383194
loss_c:1.7137954235076904
loss_r:0.026003295555710793
loss_c:1.5882742404937744
loss_r:0.03014974482357502
loss_c:1.7416493892669678
loss_r:0.02862575277686119
loss_c:1.481379508972168
loss_r:0.03521134331822395
loss_c:1.6483659744262695
loss_r:0.02821306884288788
loss_c:1.5932954549789429
loss_r:0.031495802104473114
loss_c:1.7298930883407593
loss_r:0.02832653932273388
loss_c:1.6037952899932861
loss_r:0.029131252318620682
loss_c:1.649680495262146
loss_r:0.026663560420274734
loss_c:1.4440906047821045
loss_r:0.03486707806587219
loss_c:1.6685752868652344
loss_r:0.026867587119340897
loss_c:1.582908034324646
loss_r:0.03140411898493767
loss_c:1.718948245048523
loss_r:0.025266950950026512
loss_c:1.5863666534423828
loss_r:0.031589340418577194
loss_c:1.8140113353729248
loss_r:0.027385612949728966
loss_c:1.5033764839172363
loss_r:0.03468328341841698
loss_c:1.7139997482299805
loss_r:0.028655804693698883
loss_c:1.6348295211791992
loss_r:0.03286109119653702
loss_c:1.7169926166534424
loss_r:0.02778441831469536
loss_c:1.651508092880249
loss_r:0.03175561875104904
loss_c:1.7798103094100952
loss_r:0.0294282678514719
loss_c:1.5644235610961914
loss_r:0.035590965300798416
loss_c:1.6789109706878662
loss_r:0.02684115618467331
loss_c:1.6137011051177979
loss_r:0.03551432117819786
loss_c:1.8721790313720703
loss_r:0.027153344824910164
loss_c:1.634217619895935
loss_r:0.03185153007507324
loss_c:1.8278082609176636
loss_r:0.028333235532045364
loss_c:1.547666311264038
loss_r:0.031139587983489037
loss_c:1.6174466609954834
loss_r:0.028251539915800095
loss_c:1.6213524341583252
loss_r:0.03222957253456116
loss_c:1.7661151885986328
loss_r:0.026600265875458717
loss_c:1.6289069652557373
loss_r:0.03473854809999466
loss_c:1.873204231262207
loss_r:0.026905551552772522
loss_c:1.5184587240219116
loss_r:0.02986811473965645
loss_c:1.5853145122528076
loss_r:0.028617434203624725
loss_c:1.61930251121521
loss_r:0.033371999859809875
loss_c:1.7833478450775146
loss_r:0.02562941052019596
loss_c:1.5682129859924316
loss_r:0.0317906029522419
loss_c:1.820303201675415
loss_r:0.026232875883579254
loss_c:1.4582974910736084
loss_r:0.02978852018713951
loss_c:1.5731902122497559
loss_r:0.026669342070817947
loss_c:1.5954699516296387
loss_r:0.030337203294038773
loss_c:1.7620996236801147
loss_r:0.02461891807615757
loss_c:1.5868327617645264
loss_r:0.033611081540584564
loss_c:1.8756825923919678
loss_r:0.025286350399255753
loss_c:1.4694989919662476
loss_r:0.02624339610338211
loss_c:1.5514552593231201
loss_r:0.027398599311709404
loss_c:1.63688063621521
loss_r:0.031901709735393524
loss_c:1.8047866821289062
loss_r:0.025980133563280106
loss_c:1.6222856044769287
loss_r:0.03254733607172966
loss_c:1.8424113988876343
loss_r:0.027070501819252968
loss_c:1.4911140203475952
loss_r:0.02814663201570511
loss_c:1.5880212783813477
loss_r:0.026952749118208885
loss_c:1.6103384494781494
loss_r:0.032679714262485504
loss_c:1.818333387374878
loss_r:0.025172391906380653
loss_c:1.6399450302124023
loss_r:0.03411738574504852
loss_c:1.923647165298462
loss_r:0.02612207643687725
loss_c:1.524067759513855
loss_r:0.024688642472028732
loss_c:1.5407092571258545
loss_r:0.026273518800735474
loss_c:1.6127278804779053
loss_r:0.030405348166823387
loss_c:1.76581609249115
loss_r:0.026369713246822357
loss_c:1.6315102577209473
loss_r:0.03237752616405487
loss_c:1.8868489265441895
loss_r:0.028364824131131172
loss_c:1.5642547607421875
loss_r:0.02757900580763817
loss_c:1.529235601425171
loss_r:0.0287858285009861
loss_c:1.6033085584640503
loss_r:0.03623805195093155
loss_c:1.808722734451294
loss_r:0.02632279321551323
loss_c:1.5865739583969116
loss_r:0.03352406248450279
loss_c:1.8405731916427612
loss_r:0.028733044862747192
loss_c:1.5268348455429077
loss_r:0.028761090710759163
loss_c:1.5874685049057007
loss_r:0.0287917647510767
loss_c:1.6351633071899414
loss_r:0.03473344072699547
loss_c:1.8168504238128662
loss_r:0.024905823171138763
loss_c:1.6179174184799194
loss_r:0.03083530068397522
loss_c:1.8311233520507812
loss_r:0.02590525709092617
loss_c:1.5685536861419678
loss_r:0.027307584881782532
loss_c:1.6036479473114014
loss_r:0.026679573580622673
loss_c:1.644188642501831
loss_r:0.034883156418800354
loss_c:1.8545072078704834
loss_r:0.022882431745529175
loss_c:1.554772138595581
loss_r:0.030758632346987724
loss_c:1.8080376386642456
loss_r:0.02686346136033535
loss_c:1.5485420227050781
loss_r:0.0282443817704916
loss_c:1.725538730621338
loss_r:0.027506496757268906
loss_c:1.7223222255706787
loss_r:0.031157467514276505
loss_c:1.8648183345794678
loss_r:0.02237144485116005
loss_c:1.6388238668441772
loss_r:0.028569485992193222
loss_c:1.8237557411193848
loss_r:0.028235135599970818
loss_c:1.6654332876205444
loss_r:0.02659917064011097
loss_c:1.6686662435531616
loss_r:0.027905955910682678
loss_c:1.706761121749878
loss_r:0.03236909583210945
loss_c:1.9031094312667847
loss_r:0.02450842410326004
loss_c:1.659942626953125
loss_r:0.029420984908938408
loss_c:1.8172109127044678
loss_r:0.02750205248594284
loss_c:1.6049331426620483
loss_r:0.02914007194340229
loss_c:1.7144169807434082
loss_r:0.026635223999619484
loss_c:1.6350078582763672
loss_r:0.031059306114912033
loss_c:1.8200286626815796
loss_r:0.02433720976114273
loss_c:1.6451820135116577
loss_r:0.02985270507633686
loss_c:1.8910057544708252
loss_r:0.028446592390537262
loss_c:1.6594326496124268
loss_r:0.028219228610396385
loss_c:1.7608070373535156
loss_r:0.02739923819899559
loss_c:1.6908814907073975
loss_r:0.030563853681087494
loss_c:1.7930421829223633
loss_r:0.02323300391435623
loss_c:1.6567306518554688
loss_r:0.03088991902768612
loss_c:1.900578260421753
loss_r:0.026747915893793106
loss_c:1.5872548818588257
loss_r:0.03024943359196186
loss_c:1.7667741775512695
loss_r:0.028802797198295593
loss_c:1.6639223098754883
loss_r:0.031643036752939224
loss_c:1.7749097347259521
loss_r:0.025135688483715057
loss_c:1.6660799980163574
loss_r:0.03125535696744919
loss_c:1.807987928390503
loss_r:0.028486303985118866
loss_c:1.5560191869735718
loss_r:0.03194887936115265
loss_c:1.7355927228927612
loss_r:0.030810685828328133
loss_c:1.647505521774292
loss_r:0.03039545938372612
loss_c:1.6979598999023438
loss_r:0.025538604706525803
loss_c:1.6510365009307861
loss_r:0.031439948827028275
loss_c:1.7885966300964355
loss_r:0.029267627745866776
loss_c:1.5732240676879883
loss_r:0.032140102237463
loss_c:1.6651854515075684
loss_r:0.030939094722270966
loss_c:1.668335199356079
loss_r:0.03272724896669388
loss_c:1.8001790046691895
loss_r:0.027417272329330444
loss_c:1.6755003929138184
loss_r:0.03206575661897659
loss_c:1.7952780723571777
loss_r:0.03112192451953888
loss_c:1.636453628540039
loss_r:0.03309245780110359
loss_c:1.7704319953918457
loss_r:0.032406002283096313
loss_c:1.7618660926818848
loss_r:0.03687410056591034
loss_c:1.8366329669952393
loss_r:0.02796155773103237
loss_c:1.6479284763336182
loss_r:0.03134391829371452
loss_c:1.715984582901001
loss_r:0.0309534203261137
loss_c:1.6094579696655273
loss_r:0.036309048533439636
loss_c:1.7950520515441895
loss_r:0.03167716786265373
loss_c:1.760495662689209
loss_r:0.035652030259370804
loss_c:1.8202869892120361
loss_r:0.028298750519752502
loss_c:1.7226448059082031
loss_r:0.03274749591946602
loss_c:1.8042881488800049
loss_r:0.031309694051742554
loss_c:1.5784562826156616
loss_r:0.03827012702822685
loss_c:1.748838186264038
loss_r:0.032173436135053635
loss_c:1.7297115325927734
loss_r:0.03557759150862694
loss_c:1.8455404043197632
loss_r:0.028293685987591743
loss_c:1.6602869033813477
loss_r:0.033047955483198166
loss_c:1.8619340658187866
loss_r:0.030312102288007736
loss_c:1.560848593711853
loss_r:0.036192212253808975
loss_c:1.7488534450531006
loss_r:0.03162000700831413
loss_c:1.7098077535629272
loss_r:0.033785656094551086
loss_c:1.7296580076217651
loss_r:0.027410244569182396
loss_c:1.6278808116912842
loss_r:0.028648249804973602
loss_c:1.6659806966781616
loss_r:0.028880054131150246
loss_c:1.481292963027954
loss_r:0.03480011969804764
loss_c:1.7328866720199585
loss_r:0.02935801073908806
loss_c:1.6535863876342773
loss_r:0.032442785799503326
loss_c:1.7773315906524658
loss_r:0.027190323919057846
loss_c:1.5892846584320068
loss_r:0.028914859518408775
loss_c:1.6604642868041992
loss_r:0.0330875888466835
loss_c:1.6331806182861328
loss_r:0.03502457216382027
loss_c:1.7495880126953125
loss_r:0.02964465692639351
loss_c:1.7238091230392456
loss_r:0.03468907251954079
loss_c:1.8027108907699585
loss_r:0.030300302430987358
loss_c:1.599618673324585
loss_r:0.031215615570545197
loss_c:1.764383316040039
loss_r:0.03328012302517891
loss_c:1.5921728610992432
loss_r:0.03654058277606964
loss_c:1.7146248817443848
loss_r:0.03025517426431179
loss_c:1.6474508047103882
loss_r:0.03450383245944977
loss_c:1.741887092590332
loss_r:0.028557082638144493
loss_c:1.609053373336792
loss_r:0.030214454978704453
loss_c:1.6885945796966553
loss_r:0.032353583723306656
loss_c:1.5483893156051636
loss_r:0.03511275723576546
loss_c:1.6706089973449707
loss_r:0.03072946146130562
loss_c:1.6412919759750366
loss_r:0.0363963283598423
loss_c:1.7380130290985107
loss_r:0.027244385331869125
loss_c:1.5122489929199219
loss_r:0.02787427045404911
loss_c:1.6876516342163086
loss_r:0.031596966087818146
loss_c:1.5343313217163086
loss_r:0.03322608023881912
loss_c:1.6727747917175293
loss_r:0.030827926471829414
loss_c:1.6893889904022217
loss_r:0.03875964134931564
loss_c:1.8805183172225952
loss_r:0.026927761733531952
loss_c:1.6324737071990967
loss_r:0.0302566010504961
loss_c:1.7210077047348022
loss_r:0.03029855713248253
loss_c:1.5122816562652588
loss_r:0.03375452756881714
loss_c:1.7018579244613647
loss_r:0.02815038338303566
loss_c:1.6194919347763062
loss_r:0.035194747149944305
loss_c:1.7823817729949951
loss_r:0.027529992163181305
loss_c:1.6364268064498901
loss_r:0.029649967327713966
loss_c:1.7190335988998413
loss_r:0.02982434630393982
loss_c:1.539797067642212
loss_r:0.031218329444527626
loss_c:1.6941382884979248
loss_r:0.03134787827730179
loss_c:1.6990940570831299
loss_r:0.03431147709488869
loss_c:1.8161349296569824
loss_r:0.027514107525348663
loss_c:1.6337697505950928
loss_r:0.02782629244029522
loss_c:1.6471179723739624
loss_r:0.027733126655220985
loss_c:1.4723875522613525
loss_r:0.03385486081242561
loss_c:1.7342904806137085
loss_r:0.02808835543692112
loss_c:1.6908869743347168
loss_r:0.03126911818981171
loss_c:1.741342306137085
loss_r:0.02640627510845661
loss_c:1.6000903844833374
loss_r:0.03210673853754997
loss_c:1.7933295965194702
loss_r:0.03154158964753151
loss_c:1.6592490673065186
loss_r:0.03289571776986122
loss_c:1.7847323417663574
loss_r:0.03522752597928047
loss_c:1.844436526298523
loss_r:0.03635094687342644
loss_c:1.9539226293563843
loss_r:0.02841002307832241
loss_c:1.6664295196533203
loss_r:0.0281632412225008
loss_c:1.8011564016342163
loss_r:0.02802654728293419
loss_c:1.7310278415679932
loss_r:0.029945580288767815
loss_c:1.8356454372406006
loss_r:0.030736902728676796
loss_c:1.9846851825714111
loss_r:0.029549792408943176
loss_c:1.8874807357788086
loss_r:0.023105913773179054
loss_c:1.6682162284851074
loss_r:0.027041805908083916
loss_c:1.8478249311447144
loss_r:0.025149906054139137
loss_c:1.6895503997802734
loss_r:0.02647382579743862
loss_c:1.763434648513794
loss_r:0.030667506158351898
loss_c:2.024724245071411
loss_r:0.027327310293912888
loss_c:1.9410585165023804
loss_r:0.022976946085691452
loss_c:1.7116639614105225
loss_r:0.026255382224917412
loss_c:1.782891035079956
loss_r:0.02517261542379856
loss_c:1.697988510131836
loss_r:0.030434634536504745
loss_c:1.8000545501708984
loss_r:0.0279320627450943
loss_c:1.8876923322677612
loss_r:0.02699941396713257
loss_c:1.89352548122406
loss_r:0.02150900848209858
loss_c:1.6865581274032593
loss_r:0.027639377862215042
loss_c:1.8454898595809937
loss_r:0.025382792577147484
loss_c:1.6814916133880615
loss_r:0.030356360599398613
loss_c:1.7439225912094116
loss_r:0.030226392671465874
loss_c:1.8514938354492188
loss_r:0.0324883796274662
loss_c:1.9741218090057373
loss_r:0.024798043072223663
loss_c:1.7055466175079346
loss_r:0.02962426096200943
loss_c:1.885896921157837
loss_r:0.02533837966620922
loss_c:1.7022533416748047
loss_r:0.0276811420917511
loss_c:1.8039335012435913
loss_r:0.02662707306444645
loss_c:1.8602862358093262
loss_r:0.02693348377943039
loss_c:1.9463145732879639
loss_r:0.02475186437368393
loss_c:1.737241506576538
loss_r:0.028353547677397728
loss_c:1.9133601188659668
loss_r:0.02410981059074402
loss_c:1.6643493175506592
loss_r:0.026348227635025978
loss_c:1.7937278747558594
loss_r:0.026713503524661064
loss_c:1.89460027217865
loss_r:0.02752104215323925
loss_c:2.0122122764587402
loss_r:0.022276384755969048
loss_c:1.7159183025360107
loss_r:0.026222867891192436
loss_c:1.874607801437378
loss_r:0.025295045226812363
loss_c:1.6997445821762085
loss_r:0.02658771350979805
loss_c:1.7153127193450928
loss_r:0.025357943028211594
loss_c:1.8342604637145996
loss_r:0.02684035152196884
loss_c:1.8793925046920776
loss_r:0.025100568309426308
loss_c:1.7372316122055054
loss_r:0.027205340564250946
loss_c:1.9892234802246094
loss_r:0.023172996938228607
loss_c:1.7538427114486694
loss_r:0.025097588077187538
loss_c:1.7740343809127808
loss_r:0.02543438784778118
loss_c:1.909909963607788
loss_r:0.02643088437616825
loss_c:1.9874128103256226
loss_r:0.02233855612576008
loss_c:1.6784614324569702
loss_r:0.027212252840399742
loss_c:1.919273853302002
loss_r:0.02360834926366806
loss_c:1.7087539434432983
loss_r:0.02670889161527157
loss_c:1.8477203845977783
loss_r:0.026887886226177216
loss_c:1.9138360023498535
loss_r:0.028712907806038857
loss_c:2.028640031814575
loss_r:0.023422550410032272
loss_c:1.7140464782714844
loss_r:0.027769504114985466
loss_c:1.9280908107757568
loss_r:0.02492588572204113
loss_c:1.6846656799316406
loss_r:0.027676666155457497
loss_c:1.7596559524536133
loss_r:0.02685013972222805
loss_c:1.859963297843933
loss_r:0.028540652245283127
loss_c:1.894317865371704
loss_r:0.023817019537091255
loss_c:1.6328977346420288
loss_r:0.027260955423116684
loss_c:1.916770339012146
loss_r:0.02393966354429722
loss_c:1.6974338293075562
loss_r:0.02603508159518242
loss_c:1.768509864807129
loss_r:0.02699900045990944
loss_c:1.9561231136322021
loss_r:0.027024436742067337
loss_c:1.9628880023956299
loss_r:0.024025529623031616
loss_c:1.764192819595337
loss_r:0.028655067086219788
loss_c:1.9744995832443237
loss_r:0.026040533557534218
loss_c:1.7692234516143799
loss_r:0.03182404488325119
loss_c:1.9255741834640503
loss_r:0.028497960418462753
loss_c:1.9840755462646484
loss_r:0.03071615658700466
loss_c:2.0351734161376953
loss_r:0.024597784504294395
loss_c:1.7295936346054077
loss_r:0.02574913389980793
loss_c:1.8641685247421265
loss_r:0.024841058999300003
loss_c:1.8065965175628662
loss_r:0.026969043537974358
loss_c:1.8888392448425293
loss_r:0.0255664624273777
loss_c:1.9692859649658203
loss_r:0.025172920897603035
loss_c:1.9852473735809326
loss_r:0.02153589576482773
loss_c:1.7784252166748047
loss_r:0.025690872222185135
loss_c:1.8804388046264648
loss_r:0.024923700839281082
loss_c:1.7480758428573608
loss_r:0.02813425473868847
loss_c:1.8545221090316772
loss_r:0.02519351802766323
loss_c:1.9800523519515991
loss_r:0.025765860453248024
loss_c:1.9920198917388916
loss_r:0.02253200300037861
loss_c:1.766170859336853
loss_r:0.025581764057278633
loss_c:1.911329984664917
loss_r:0.024852918460965157
loss_c:1.7639697790145874
loss_r:0.02887924201786518
loss_c:1.8828004598617554
loss_r:0.025744842365384102
loss_c:1.9290940761566162
loss_r:0.0268426351249218
loss_c:2.039375066757202
loss_r:0.0250022504478693
loss_c:1.8173397779464722
loss_r:0.02854056842625141
loss_c:1.8777765035629272
loss_r:0.026833239942789078
loss_c:1.7421865463256836
loss_r:0.03150022402405739
loss_c:1.7877696752548218
loss_r:0.026715099811553955
loss_c:1.8219614028930664
loss_r:0.023437991738319397
loss_c:1.8249824047088623
loss_r:0.02426832914352417
loss_c:1.7153141498565674
loss_r:0.02535049244761467
loss_c:1.815312147140503
loss_r:0.025895660743117332
loss_c:1.6489123106002808
loss_r:0.027308080345392227
loss_c:1.8153265714645386
loss_r:0.025112660601735115
loss_c:1.866468906402588
loss_r:0.02469915710389614
loss_c:1.7818024158477783
loss_r:0.023868730291724205
loss_c:1.6921794414520264
loss_r:0.02348165027797222
loss_c:1.7498868703842163
loss_r:0.024111432954669
loss_c:1.6216418743133545
loss_r:0.02510496973991394
loss_c:1.778833270072937
loss_r:0.023180650547146797
loss_c:1.898423194885254
loss_r:0.023692714050412178
loss_c:1.9085320234298706
loss_r:0.024327309802174568
loss_c:1.7663997411727905
loss_r:0.023927750065922737
loss_c:1.7179045677185059
loss_r:0.025994809344410896
loss_c:1.6295521259307861
loss_r:0.026089411228895187
loss_c:1.7937755584716797
loss_r:0.023248296231031418
loss_c:1.7473253011703491
loss_r:0.02057301625609398
loss_c:1.6641992330551147
loss_r:0.025811944156885147
loss_c:1.7211811542510986
loss_r:0.02359539456665516
loss_c:1.7084627151489258
loss_r:0.023854823783040047
loss_c:1.5856828689575195
loss_r:0.025310948491096497
loss_c:1.7124274969100952
loss_r:0.02687922492623329
loss_c:1.8703373670578003
loss_r:0.02630678564310074
loss_c:1.8746999502182007
loss_r:0.025250904262065887
loss_c:1.6758084297180176
loss_r:0.023068249225616455
loss_c:1.7498509883880615
loss_r:0.024139776825904846
loss_c:1.5609750747680664
loss_r:0.025538958609104156
loss_c:1.732304334640503
loss_r:0.02931203320622444
loss_c:1.9299025535583496
loss_r:0.02974872849881649
loss_c:1.8474624156951904
loss_r:0.027399856597185135
loss_c:1.7063989639282227
loss_r:0.02419414557516575
loss_c:1.70437753200531
loss_r:0.022769177332520485
loss_c:1.4597282409667969
loss_r:0.023718034848570824
loss_c:1.650649070739746
loss_r:0.025392629206180573
loss_c:1.8033241033554077
loss_r:0.023920642212033272
loss_c:1.6421312093734741
loss_r:0.02458846941590309
loss_c:1.5696181058883667
loss_r:0.02525506354868412
loss_c:1.7226665019989014
loss_r:0.024306539446115494
loss_c:1.598878264427185
loss_r:0.02385169081389904
loss_c:1.670978307723999
loss_r:0.02280120551586151
loss_c:1.7378572225570679
loss_r:0.024319296702742577
loss_c:1.723075270652771
loss_r:0.022862816229462624
loss_c:1.6027703285217285
loss_r:0.024226229637861252
loss_c:1.7709969282150269
loss_r:0.02311539463698864
loss_c:1.6105059385299683
loss_r:0.020976588129997253
loss_c:1.6680306196212769
loss_r:0.02536661922931671
loss_c:1.9319432973861694
loss_r:0.02678745612502098
loss_c:1.8605650663375854
loss_r:0.023160485550761223
loss_c:1.5812897682189941
loss_r:0.02738107554614544
loss_c:1.804247260093689
loss_r:0.02533063106238842
loss_c:1.5294908285140991
loss_r:0.02447628788650036
loss_c:1.5303151607513428
loss_r:0.02594815567135811
loss_c:1.7437458038330078
loss_r:0.025846656411886215
loss_c:1.7112886905670166
loss_r:0.025483548641204834
loss_c:1.5416206121444702
loss_r:0.026693465188145638
loss_c:1.6814520359039307
loss_r:0.022706972435116768
loss_c:1.5389859676361084
loss_r:0.024883687496185303
loss_c:1.5607821941375732
loss_r:0.028385700657963753
loss_c:1.8192832469940186
loss_r:0.027211733162403107
loss_c:1.6367387771606445
loss_r:0.028134634718298912
loss_c:1.4751381874084473
loss_r:0.025440312922000885
loss_c:1.6323919296264648
loss_r:0.028185006231069565
loss_c:1.4781558513641357
loss_r:0.026264825835824013
loss_c:1.4985196590423584
loss_r:0.028718437999486923
loss_c:1.798792839050293
loss_r:0.028760040178894997
loss_c:1.635156512260437
loss_r:0.027490125969052315
loss_c:1.4977436065673828
loss_r:0.028579380363225937
loss_c:1.7648541927337646
loss_r:0.029607051983475685
loss_c:1.6210031509399414
loss_r:0.024431079626083374
loss_c:1.5764169692993164
loss_r:0.030368516221642494
loss_c:1.970868468284607
loss_r:0.02885928750038147
loss_c:1.6920541524887085
loss_r:0.026117729023098946
loss_c:1.5153942108154297
loss_r:0.026929769665002823
loss_c:1.7268733978271484
loss_r:0.026202110573649406
loss_c:1.5431737899780273
loss_r:0.024731047451496124
loss_c:1.5090537071228027
loss_r:0.025276362895965576
loss_c:1.6776174306869507
loss_r:0.027237065136432648
loss_c:1.5562026500701904
loss_r:0.0264552254229784
loss_c:1.4800165891647339
loss_r:0.026365473866462708
loss_c:1.6634166240692139
loss_r:0.027648000046610832
loss_c:1.468647837638855
loss_r:0.026144318282604218
loss_c:1.5579416751861572
loss_r:0.025217097252607346
loss_c:1.7544732093811035
loss_r:0.026475315913558006
loss_c:1.6403878927230835
loss_r:0.029156461358070374
loss_c:1.5810441970825195
loss_r:0.02940647304058075
loss_c:1.7996395826339722
loss_r:0.02922738902270794
loss_c:1.5690813064575195
loss_r:0.02601729892194271
loss_c:1.5347541570663452
loss_r:0.02856787107884884
loss_c:1.8070402145385742
loss_r:0.025292888283729553
loss_c:1.5984570980072021
loss_r:0.0262446328997612
loss_c:1.467172622680664
loss_r:0.02938065491616726
loss_c:1.7795369625091553
loss_r:0.026602940633893013
loss_c:1.4757436513900757
loss_r:0.025904735550284386
loss_c:1.5371346473693848
loss_r:0.025317911058664322
loss_c:1.7898744344711304
loss_r:0.024643931537866592
loss_c:1.6206783056259155
loss_r:0.026825090870261192
loss_c:1.5925706624984741
loss_r:0.027804628014564514
loss_c:1.809409499168396
loss_r:0.02908678725361824
loss_c:1.6759284734725952
loss_r:0.023020382970571518
loss_c:1.6500847339630127
loss_r:0.027925167232751846
loss_c:1.8160557746887207
loss_r:0.026797369122505188
loss_c:1.697498083114624
loss_r:0.0267727542668581
loss_c:1.5987310409545898
loss_r:0.02560216747224331
loss_c:1.7041723728179932
loss_r:0.02669770084321499
loss_c:1.5357259511947632
loss_r:0.025950409471988678
loss_c:1.6553239822387695
loss_r:0.025903163477778435
loss_c:1.7475621700286865
loss_r:0.023618873208761215
loss_c:1.6309735774993896
loss_r:0.023565340787172318
loss_c:1.5400924682617188
loss_r:0.02304939366877079
loss_c:1.6828210353851318
loss_r:0.02194012701511383
loss_c:1.5227928161621094
loss_r:0.02165348082780838
loss_c:1.6356662511825562
loss_r:0.021862119436264038
loss_c:1.7711687088012695
loss_r:0.020685069262981415
loss_c:1.5834274291992188
loss_r:0.021870698779821396
loss_c:1.5742934942245483
loss_r:0.019957048818469048
loss_c:1.575843334197998
loss_r:0.021469807252287865
loss_c:1.4997262954711914
loss_r:0.020272837951779366
loss_c:1.619257926940918
loss_r:0.021634234115481377
loss_c:1.6983728408813477
loss_r:0.01947476528584957
loss_c:1.6299461126327515
loss_r:0.02048017457127571
loss_c:1.6113898754119873
loss_r:0.020609531551599503
loss_c:1.6609843969345093
loss_r:0.020963570103049278
loss_c:1.5609748363494873
loss_r:0.020113494247198105
loss_c:1.5694525241851807
loss_r:0.02245992422103882
loss_c:1.7161558866500854
loss_r:0.02126503922045231
loss_c:1.6679843664169312
loss_r:0.02356773056089878
loss_c:1.653520941734314
loss_r:0.020810652524232864
loss_c:1.6615240573883057
loss_r:0.022100312635302544
loss_c:1.5517810583114624
loss_r:0.02167540043592453
loss_c:1.6289552450180054
loss_r:0.02455122210085392
loss_c:1.779646873474121
loss_r:0.022845599800348282
loss_c:1.7372153997421265
loss_r:0.02338220924139023
loss_c:1.6563470363616943
loss_r:0.02209872007369995
loss_c:1.5992517471313477
loss_r:0.021933428943157196
loss_c:1.5940526723861694
loss_r:0.02079051174223423
loss_c:1.6160986423492432
loss_r:0.022708337754011154
loss_c:1.7044932842254639
loss_r:0.0199008509516716
loss_c:1.7094696760177612
loss_r:0.02030273526906967
loss_c:1.5473811626434326
loss_r:0.021638810634613037
loss_c:1.651146411895752
loss_r:0.02000565454363823
loss_c:1.6042441129684448
loss_r:0.01878758892416954
loss_c:1.604835033416748
loss_r:0.02135903760790825
loss_c:1.7674325704574585
loss_r:0.018902670592069626
loss_c:1.6284806728363037
loss_r:0.019948294386267662
loss_c:1.5984807014465332
loss_r:0.020423583686351776
loss_c:1.6656224727630615
loss_r:0.019874202087521553
loss_c:1.6216892004013062
loss_r:0.01670932024717331
loss_c:1.5511274337768555
loss_r:0.019731154665350914
loss_c:1.764208197593689
loss_r:0.016592010855674744
loss_c:1.5768531560897827
loss_r:0.018368367105722427
loss_c:1.565874457359314
loss_r:0.01906052976846695
loss_c:1.6323583126068115
loss_r:0.017633281648159027
loss_c:1.5689163208007812
loss_r:0.016873639076948166
loss_c:1.5454168319702148
loss_r:0.019811347126960754
loss_c:1.7709715366363525
loss_r:0.01606675796210766
loss_c:1.5805597305297852
loss_r:0.01829628460109234
loss_c:1.5418946743011475
loss_r:0.020007891580462456
loss_c:1.6547139883041382
loss_r:0.017665859311819077
loss_c:1.5116095542907715
loss_r:0.01669420301914215
loss_c:1.5355180501937866
loss_r:0.020995916798710823
loss_c:1.7508933544158936
loss_r:0.0166056826710701
loss_c:1.684196949005127
loss_r:0.0181527528911829
loss_c:1.552872657775879
loss_r:0.020001687109470367
loss_c:1.680351972579956
loss_r:0.019123656675219536
loss_c:1.6305770874023438
loss_r:0.015995366498827934
loss_c:1.5157407522201538
loss_r:0.019973330199718475
loss_c:1.7219403982162476
loss_r:0.01738717406988144
loss_c:1.7104419469833374
loss_r:0.017683466896414757
loss_c:1.5408551692962646
loss_r:0.019615251570940018
loss_c:1.6853293180465698
loss_r:0.017545359209179878
loss_c:1.563087821006775
loss_r:0.0163721926510334
loss_c:1.5663212537765503
loss_r:0.02199268341064453
loss_c:1.7279441356658936
loss_r:0.017406484112143517
loss_c:1.6831560134887695
loss_r:0.018330316990613937
loss_c:1.552809715270996
loss_r:0.02130945213139057
loss_c:1.6964781284332275
loss_r:0.02036111056804657
loss_c:1.6132733821868896
loss_r:0.01821032352745533
loss_c:1.531887412071228
loss_r:0.021069321781396866
loss_c:1.737837791442871
loss_r:0.018087243661284447
loss_c:1.7230314016342163
loss_r:0.019163500517606735
loss_c:1.5629757642745972
loss_r:0.02179701067507267
loss_c:1.728769063949585
loss_r:0.021099666133522987
loss_c:1.6173717975616455
loss_r:0.018144581466913223
loss_c:1.6196550130844116
loss_r:0.021139977499842644
loss_c:1.7192400693893433
loss_r:0.019087431952357292
loss_c:1.7069683074951172
loss_r:0.018270058557391167
loss_c:1.5355560779571533
loss_r:0.023209361359477043
loss_c:1.7627252340316772
loss_r:0.022509759292006493
loss_c:1.6635055541992188
loss_r:0.01781984604895115
loss_c:1.5676515102386475
loss_r:0.023765407502651215
loss_c:1.8069212436676025
loss_r:0.0191855039447546
loss_c:1.7175025939941406
loss_r:0.020410770550370216
loss_c:1.5652668476104736
loss_r:0.023701926693320274
loss_c:1.7372589111328125
loss_r:0.023164015263319016
loss_c:1.6079936027526855
loss_r:0.020458132028579712
loss_c:1.559434175491333
loss_r:0.024660907685756683
loss_c:1.7898788452148438
loss_r:0.02367750182747841
loss_c:1.8003714084625244
loss_r:0.02251722663640976
loss_c:1.6087143421173096
loss_r:0.026852715760469437
loss_c:1.765439748764038
loss_r:0.026580803096294403
loss_c:1.6298494338989258
loss_r:0.02170957252383232
loss_c:1.5314416885375977
loss_r:0.024692201986908913
loss_c:1.749882698059082
loss_r:0.024357127025723457
loss_c:1.734755516052246
loss_r:0.023287415504455566
loss_c:1.595493197441101
loss_r:0.026341265067458153
loss_c:1.7622073888778687
loss_r:0.02402311936020851
loss_c:1.5791683197021484
loss_r:0.02268175221979618
loss_c:1.624047040939331
loss_r:0.023707721382379532
loss_c:1.822054147720337
loss_r:0.021926898509263992
loss_c:1.7281383275985718
loss_r:0.022950541228055954
loss_c:1.6597602367401123
loss_r:0.0246783047914505
loss_c:1.778295874595642
loss_r:0.02437025122344494
loss_c:1.5566534996032715
loss_r:0.02457871288061142
loss_c:1.631770372390747
loss_r:0.023687252774834633
loss_c:1.7985568046569824
loss_r:0.02259242720901966
loss_c:1.6350843906402588
loss_r:0.02286102995276451
loss_c:1.610407829284668
loss_r:0.023660529404878616
loss_c:1.7600085735321045
loss_r:0.023939304053783417
loss_c:1.605666995048523
loss_r:0.02122711017727852
loss_c:1.5771692991256714
loss_r:0.025186989456415176
loss_c:1.862067699432373
loss_r:0.021370701491832733
loss_c:1.7455604076385498
loss_r:0.023231398314237595
loss_c:1.6600650548934937
loss_r:0.02467881143093109
loss_c:1.790907382965088
loss_r:0.02495204098522663
loss_c:1.6092647314071655
loss_r:0.024295233190059662
loss_c:1.6520990133285522
loss_r:0.025498973205685616
loss_c:1.8304961919784546
loss_r:0.02317335456609726
loss_c:1.7315998077392578
loss_r:0.0231375340372324
loss_c:1.632804274559021
loss_r:0.024939699098467827
loss_c:1.7314847707748413
loss_r:0.02518673613667488
loss_c:1.5781588554382324
loss_r:0.024908505380153656
loss_c:1.6945598125457764
loss_r:0.026607347652316093
loss_c:1.9057286977767944
loss_r:0.023262130096554756
loss_c:1.7956351041793823
loss_r:0.02323019504547119
loss_c:1.6952565908432007
loss_r:0.026503225788474083
loss_c:1.781852126121521
loss_r:0.024869544431567192
loss_c:1.6110622882843018
loss_r:0.025262627750635147
loss_c:1.6947507858276367
loss_r:0.025612911209464073
loss_c:1.8141359090805054
loss_r:0.022164350375533104
loss_c:1.6383947134017944
loss_r:0.026599954813718796
loss_c:1.7140430212020874
loss_r:0.027904843911528587
loss_c:1.75900399684906
loss_r:0.028797298669815063
loss_c:1.6938798427581787
loss_r:0.028388425707817078
loss_c:1.7850650548934937
loss_r:0.02765205129981041
loss_c:1.738649606704712
loss_r:0.025390246883034706
loss_c:1.7114648818969727
loss_r:0.028504814952611923
loss_c:1.7227486371994019
loss_r:0.02693226933479309
loss_c:1.7225244045257568
loss_r:0.029065575450658798
loss_c:1.6439950466156006
loss_r:0.02782447822391987
loss_c:1.7492694854736328
loss_r:0.02484404295682907
loss_c:1.7174943685531616
loss_r:0.02613028883934021
loss_c:1.7548489570617676
loss_r:0.027028420940041542
loss_c:1.7498061656951904
loss_r:0.027332507073879242
loss_c:1.7844403982162476
loss_r:0.02893373928964138
loss_c:1.707538366317749
loss_r:0.02874431386590004
loss_c:1.7725982666015625
loss_r:0.0246397964656353
loss_c:1.785989761352539
loss_r:0.02461119368672371
loss_c:1.719735026359558
loss_r:0.02926221862435341
loss_c:1.7923320531845093
loss_r:0.029712572693824768
loss_c:1.789817214012146
loss_r:0.029842214658856392
loss_c:1.7030935287475586
loss_r:0.03144434839487076
loss_c:1.8211369514465332
loss_r:0.030520418658852577
loss_c:1.8421472311019897
loss_r:0.029129156842827797
loss_c:1.7677644491195679
loss_r:0.030238768085837364
loss_c:1.8021329641342163
loss_r:0.028679152950644493
loss_c:1.7696837186813354
loss_r:0.029387814924120903
loss_c:1.660788893699646
loss_r:0.0287652425467968
loss_c:1.803496241569519
loss_r:0.027608796954154968
loss_c:1.7835769653320312
loss_r:0.028876015916466713
loss_c:1.721539855003357
loss_r:0.028263220563530922
loss_c:1.7536280155181885
loss_r:0.02815360762178898
loss_c:1.7788923978805542
loss_r:0.029198013246059418
loss_c:1.733748435974121
loss_r:0.027996977791190147
loss_c:1.8392131328582764
loss_r:0.02671254426240921
loss_c:1.7764592170715332
loss_r:0.026902155950665474
loss_c:1.7472984790802002
loss_r:0.029494689777493477
loss_c:1.8075644969940186
loss_r:0.027279622852802277
loss_c:1.7912657260894775
loss_r:0.028860796242952347
loss_c:1.671785831451416
loss_r:0.02878683991730213
loss_c:1.8133163452148438
loss_r:0.026238197460770607
loss_c:1.7963995933532715
loss_r:0.027830567210912704
loss_c:1.7150607109069824
loss_r:0.029111452400684357
loss_c:1.7819664478302002
loss_r:0.027076229453086853
loss_c:1.7819907665252686
loss_r:0.030269868671894073
loss_c:1.6864287853240967
total_val_loss:1.8123964071273804
EarlyStopping counter: 1 out of 2
epoch: 6/20
loss_r:0.024221397936344147
loss_c:0.7947384119033813
tensor(1.2975, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015912877395749092
loss_c:0.8293415904045105
tensor(1.2797, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03224985674023628
loss_c:0.8751111030578613
tensor(1.3783, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01766083762049675
loss_c:0.9282169342041016
tensor(1.3427, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015040702186524868
loss_c:0.7930134534835815
tensor(1.2555, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023885993286967278
loss_c:0.9334465265274048
tensor(1.3735, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04212969169020653
loss_c:0.87284255027771
tensor(1.4215, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015310893766582012
loss_c:0.7763270735740662
tensor(1.2473, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038936130702495575
loss_c:0.8020259737968445
tensor(1.3675, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014552722685039043
loss_c:0.7871267199516296
tensor(1.2500, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017561037093400955
loss_c:0.8131422996520996
tensor(1.2780, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028675613924860954
loss_c:0.7491966485977173
tensor(1.2920, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015601681545376778
loss_c:0.777411699295044
tensor(1.2493, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01860598847270012
loss_c:0.83036869764328
tensor(1.2923, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017456768080592155
loss_c:0.8484997749328613
tensor(1.2973, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0209531020373106
loss_c:0.8456775546073914
tensor(1.3114, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028198877349495888
loss_c:0.7590898275375366
tensor(1.2953, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03783003240823746
loss_c:0.860120952129364
tensor(1.3950, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03268411010503769
loss_c:0.8137450218200684
tensor(1.3459, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01784026436507702
loss_c:0.8118623495101929
tensor(1.2785, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027308229357004166
loss_c:0.8346723914146423
tensor(1.3336, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020950347185134888
loss_c:0.820220947265625
tensor(1.2971, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01662535034120083
loss_c:0.77606201171875
tensor(1.2530, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023513808846473694
loss_c:0.8901653289794922
tensor(1.3478, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09618175029754639
loss_c:0.8665797114372253
tensor(1.6580, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017037667334079742
loss_c:0.8233475089073181
tensor(1.2815, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016085516661405563
loss_c:0.7488831877708435
tensor(1.2355, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013288338668644428
loss_c:0.7786635756492615
tensor(1.2400, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022219806909561157
loss_c:0.8167917728424072
tensor(1.3008, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021737944334745407
loss_c:0.9259017705917358
tensor(1.3602, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01424301415681839
loss_c:0.7378801107406616
tensor(1.2214, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01993464305996895
loss_c:0.9008375406265259
tensor(1.3382, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0188243817538023
loss_c:0.8236976861953735
tensor(1.2899, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030631888657808304
loss_c:0.7739624977111816
tensor(1.3134, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0372331403195858
loss_c:0.8365510702133179
tensor(1.3776, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021388206630945206
loss_c:0.938869833946228
tensor(1.3662, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01456526480615139
loss_c:0.8529738187789917
tensor(1.2879, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022939525544643402
loss_c:0.7633692622184753
tensor(1.2738, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0206101406365633
loss_c:1.0094209909439087
tensor(1.4027, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04039773344993591
loss_c:0.8403067588806152
tensor(1.3933, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014836875721812248
loss_c:0.9177190065383911
tensor(1.3257, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01808851584792137
loss_c:0.7730045318603516
tensor(1.2582, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01541373785585165
loss_c:0.746071994304657
tensor(1.2314, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014292347244918346
loss_c:0.7956353425979614
tensor(1.2544, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.2599527835845947
loss_c:1.1877377033233643
tensor(2.5449, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1803451031446457
loss_c:0.9138456583023071
tensor(2.0374, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02861909009516239
loss_c:0.906814455986023
tensor(1.3790, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025235630571842194
loss_c:0.8649487495422363
tensor(1.3410, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016871416941285133
loss_c:0.8614753484725952
tensor(1.3043, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03608205169439316
loss_c:0.7847293615341187
tensor(1.3405, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035788100212812424
loss_c:0.8811510801315308
tensor(1.3931, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01335207000374794
loss_c:0.9204737544059753
tensor(1.3243, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04470118135213852
loss_c:0.93668532371521
tensor(1.4593, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021915368735790253
loss_c:0.816051721572876
tensor(1.3007, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02184993587434292
loss_c:1.0038716793060303
tensor(1.4056, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016293831169605255
loss_c:0.8047807216644287
tensor(1.2726, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015688061714172363
loss_c:0.8260482549667358
tensor(1.2823, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05415521562099457
loss_c:0.9443515539169312
tensor(1.4985, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.14969846606254578
loss_c:0.975398063659668
tensor(1.8867, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03359758108854294
loss_c:0.7323712706565857
tensor(1.3001, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023750804364681244
loss_c:0.8590306639671326
tensor(1.3327, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02597866766154766
loss_c:0.9303900599479675
tensor(1.3810, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02019752748310566
loss_c:0.7789894342422485
tensor(1.2751, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021789949387311935
loss_c:0.8503109216690063
tensor(1.3209, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024526171386241913
loss_c:0.8422185778617859
tensor(1.3268, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022321606054902077
loss_c:0.979874312877655
tensor(1.3949, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017157822847366333
loss_c:0.7428314089775085
tensor(1.2443, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03290669992566109
loss_c:0.920628547668457
tensor(1.4017, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.045415088534355164
loss_c:0.7930220365524292
tensor(1.3777, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018703557550907135
loss_c:0.6869623064994812
tensor(1.2195, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018141545355319977
loss_c:0.8280949592590332
tensor(1.2956, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02116777002811432
loss_c:0.84147709608078
tensor(1.3143, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03730546310544014
loss_c:0.7692112922668457
tensor(1.3342, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020898643881082535
loss_c:1.0707144737243652
tensor(1.4403, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024380238726735115
loss_c:0.8742544054985046
tensor(1.3444, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01702791638672352
loss_c:0.806838870048523
tensor(1.2797, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020456543192267418
loss_c:0.8988704681396484
tensor(1.3434, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0215433482080698
loss_c:0.9521521329879761
tensor(1.3769, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020825404673814774
loss_c:0.8194374442100525
tensor(1.3007, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01424100436270237
loss_c:0.7932325601577759
tensor(1.2616, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01649375446140766
loss_c:0.809271514415741
tensor(1.2788, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017623940482735634
loss_c:0.8677597045898438
tensor(1.3153, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.057428669184446335
loss_c:0.8868693113327026
tensor(1.4750, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02343396469950676
loss_c:0.9725038409233093
tensor(1.3949, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016708889976143837
loss_c:0.8137975931167603
tensor(1.2818, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036575477570295334
loss_c:0.8825457096099854
tensor(1.3945, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02708238922059536
loss_c:0.7616376876831055
tensor(1.2919, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017865071073174477
loss_c:0.7229177355766296
tensor(1.2357, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030008133500814438
loss_c:0.8863548040390015
tensor(1.3719, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015594972297549248
loss_c:0.8699096441268921
tensor(1.3082, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03528323024511337
loss_c:0.740254819393158
tensor(1.3110, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017963174730539322
loss_c:0.7219204902648926
tensor(1.2351, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028375858440995216
loss_c:0.8995717763900757
tensor(1.3730, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017892176285386086
loss_c:0.8588919639587402
tensor(1.3105, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015568106435239315
loss_c:0.8137218356132507
tensor(1.2765, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020406514406204224
loss_c:0.9230934977531433
tensor(1.3556, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02740822359919548
loss_c:0.7977892160415649
tensor(1.3128, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03332948312163353
loss_c:1.0875635147094727
tensor(1.4964, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01874014176428318
loss_c:0.7549880743026733
tensor(1.2556, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023450860753655434
loss_c:1.0327990055084229
tensor(1.4280, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017479147762060165
loss_c:0.7901341319084167
tensor(1.2701, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019493822008371353
loss_c:0.7133519649505615
tensor(1.2352, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026082012802362442
loss_c:0.7897367477416992
tensor(1.3030, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02209913730621338
loss_c:0.9075783491134644
tensor(1.3530, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022754408419132233
loss_c:0.8800368309020996
tensor(1.3402, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014021506533026695
loss_c:0.73839271068573
tensor(1.2274, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027330363169312477
loss_c:0.7963547706604004
tensor(1.3115, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01331122126430273
loss_c:0.8356353640556335
tensor(1.2783, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015212499536573887
loss_c:0.800431489944458
tensor(1.2660, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023386936634778976
loss_c:0.989646315574646
tensor(1.4034, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02422192320227623
loss_c:0.7544287443161011
tensor(1.2757, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015832336619496346
loss_c:0.8685838580131531
tensor(1.3060, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02990662306547165
loss_c:0.9705594778060913
tensor(1.4186, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01676839590072632
loss_c:0.8363399505615234
tensor(1.2915, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01671496592462063
loss_c:0.8575457334518433
tensor(1.3030, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018756655976176262
loss_c:0.7681194543838501
tensor(1.2613, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01997126266360283
loss_c:0.8704900741577148
tensor(1.3231, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021268371492624283
loss_c:0.9060167670249939
tensor(1.3480, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02085462026298046
loss_c:0.7514121532440186
tensor(1.2601, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019950905814766884
loss_c:0.9015557169914246
tensor(1.3401, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014039493165910244
loss_c:0.8707815408706665
tensor(1.2989, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017132265493273735
loss_c:0.7652158737182617
tensor(1.2525, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01811029389500618
loss_c:0.8013458251953125
tensor(1.2765, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02106444723904133
loss_c:0.8265087008476257
tensor(1.3025, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018217191100120544
loss_c:0.8036626577377319
tensor(1.2780, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016740979626774788
loss_c:0.7688735723495483
tensor(1.2524, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01776212453842163
loss_c:0.780357837677002
tensor(1.2629, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016085218638181686
loss_c:0.7651066184043884
tensor(1.2473, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02010900340974331
loss_c:0.8993567228317261
tensor(1.3389, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02375076711177826
loss_c:0.8469144701957703
tensor(1.3247, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020124655216932297
loss_c:1.0670562982559204
tensor(1.4327, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017566528171300888
loss_c:0.9346204996109009
tensor(1.3478, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02353578619658947
loss_c:0.7481063604354858
tensor(1.2684, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.15281738340854645
loss_c:1.0610835552215576
tensor(1.9870, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017339695245027542
loss_c:0.8603177070617676
tensor(1.3052, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025076040998101234
loss_c:0.8253752589225769
tensor(1.3181, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01987331733107567
loss_c:0.9812052249908447
tensor(1.3834, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018704675137996674
loss_c:0.872705340385437
tensor(1.3180, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021254336461424828
loss_c:0.9735497236251831
tensor(1.3848, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023196812719106674
loss_c:0.8554071187973022
tensor(1.3271, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03426789492368698
loss_c:0.8872923851013184
tensor(1.3909, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01546184066683054
loss_c:0.8049401044845581
tensor(1.2668, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03688619285821915
loss_c:0.7978066205978394
tensor(1.3520, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015264809131622314
loss_c:0.7381353378295898
tensor(1.2290, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027044275775551796
loss_c:0.9840508699417114
tensor(1.4145, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036649949848651886
loss_c:0.9134909510612488
tensor(1.4152, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01325713749974966
loss_c:0.8724344968795776
tensor(1.2953, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023929854854941368
loss_c:0.9486436247825623
tensor(1.3818, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016049401834607124
loss_c:0.7995001077651978
tensor(1.2665, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039555881172418594
loss_c:0.8592850565910339
tensor(1.3972, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027034206315875053
loss_c:1.0823402404785156
tensor(1.4687, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01810707151889801
loss_c:0.7378735542297363
tensor(1.2410, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027256174013018608
loss_c:0.7970746755599976
tensor(1.3117, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04665013402700424
loss_c:0.945758581161499
tensor(1.4744, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018802691251039505
loss_c:0.885539710521698
tensor(1.3255, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01638471521437168
loss_c:0.8716850280761719
tensor(1.3079, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022200066596269608
loss_c:0.7717299461364746
tensor(1.2768, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03347329795360565
loss_c:0.846867561340332
tensor(1.3650, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016619296744465828
loss_c:0.750208854675293
tensor(1.2419, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03044905886054039
loss_c:0.7559105157852173
tensor(1.3023, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019812704995274544
loss_c:0.7789663076400757
tensor(1.2709, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01769416406750679
loss_c:0.9398026466369629
tensor(1.3509, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05104001984000206
loss_c:0.8556618094444275
tensor(1.4428, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018744345754384995
loss_c:0.8307585716247559
tensor(1.2950, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014027112163603306
loss_c:0.7414555549621582
tensor(1.2261, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027280505746603012
loss_c:0.8592249751091003
tensor(1.3462, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01916765607893467
loss_c:0.8365901708602905
tensor(1.3000, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03877950459718704
loss_c:0.8823778033256531
tensor(1.4067, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1256725937128067
loss_c:0.9202364683151245
tensor(1.7883, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02108434960246086
loss_c:0.8002105951309204
tensor(1.2879, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013860530219972134
loss_c:0.7277712821960449
tensor(1.2180, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01878492534160614
loss_c:0.762277364730835
tensor(1.2575, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030109064653515816
loss_c:0.7913774847984314
tensor(1.3201, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04531332477927208
loss_c:0.9243962168693542
tensor(1.4562, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043632522225379944
loss_c:0.9642269015312195
tensor(1.4713, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0311683788895607
loss_c:0.6622735857963562
tensor(1.2526, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0286391768604517
loss_c:0.7361458539962769
tensor(1.2832, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01481885090470314
loss_c:0.783359944820404
tensor(1.2533, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018126629292964935
loss_c:0.736719012260437
tensor(1.2408, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01442807074636221
loss_c:0.7765530347824097
tensor(1.2480, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017332332208752632
loss_c:0.8114403486251831
tensor(1.2792, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015050976537168026
loss_c:0.7643402814865112
tensor(1.2436, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016883019357919693
loss_c:0.8212420344352722
tensor(1.2828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017704488709568977
loss_c:0.792962908744812
tensor(1.2703, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02251969277858734
loss_c:0.8340424299240112
tensor(1.3128, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029559263959527016
loss_c:0.6919674873352051
tensor(1.2615, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013398328796029091
loss_c:0.743611216545105
tensor(1.2249, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016021624207496643
loss_c:0.8636786341667175
tensor(1.3030, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01883845403790474
loss_c:0.8949031829833984
tensor(1.3320, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026261137798428535
loss_c:0.8521072268486023
tensor(1.3381, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016271792352199554
loss_c:0.8263079524040222
tensor(1.2828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015185699798166752
loss_c:0.859576404094696
tensor(1.2971, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029912332072854042
loss_c:0.8383767604827881
tensor(1.3453, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014534362591803074
loss_c:0.8227957487106323
tensor(1.2734, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03455262631177902
loss_c:0.712105929851532
tensor(1.2929, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016453253105282784
loss_c:0.8584704399108887
tensor(1.3014, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02262023277580738
loss_c:0.8140733242034912
tensor(1.3016, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015193695202469826
loss_c:0.7207893133163452
tensor(1.2180, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022455019876360893
loss_c:1.0657718181610107
tensor(1.4437, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02958359383046627
loss_c:0.8783585429191589
tensor(1.3668, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021610142663121223
loss_c:0.9681181907653809
tensor(1.3847, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014629396609961987
loss_c:0.7691460847854614
tensor(1.2428, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021595867350697517
loss_c:0.805823564529419
tensor(1.2925, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015491374768316746
loss_c:0.8982995748519897
tensor(1.3195, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01862505078315735
loss_c:0.7355096340179443
tensor(1.2402, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03524674475193024
loss_c:0.8927175998687744
tensor(1.3987, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033704355359077454
loss_c:0.7903474569320679
tensor(1.3343, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014154309406876564
loss_c:0.8337697386741638
tensor(1.2770, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017675263807177544
loss_c:0.8520728349685669
tensor(1.3021, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01624082587659359
loss_c:0.8268842101097107
tensor(1.2818, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022470062598586082
loss_c:0.8736178278923035
tensor(1.3344, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01848573051393032
loss_c:0.9342797994613647
tensor(1.3519, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018751556053757668
loss_c:0.8767176866531372
tensor(1.3204, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01211595069617033
loss_c:0.8262790441513062
tensor(1.2637, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015515233390033245
loss_c:0.7703781127929688
tensor(1.2464, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014322791248559952
loss_c:0.8752118349075317
tensor(1.3005, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019205132499337196
loss_c:1.0564353466033936
tensor(1.4236, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04348664730787277
loss_c:0.8620085716247559
tensor(1.4173, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016841135919094086
loss_c:0.894748866558075
tensor(1.3220, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01908944360911846
loss_c:0.8195940852165222
tensor(1.2892, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026484468951821327
loss_c:0.8987290859222412
tensor(1.3654, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018336651846766472
loss_c:0.8394915461540222
tensor(1.2971, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014016212895512581
loss_c:0.7257530093193054
tensor(1.2145, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017422925680875778
loss_c:0.7378120422363281
tensor(1.2359, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024879736825823784
loss_c:0.7496530413627625
tensor(1.2747, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018916519358754158
loss_c:0.8343321681022644
tensor(1.2965, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01824788562953472
loss_c:0.9152708053588867
tensor(1.3391, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021678995341062546
loss_c:0.7777504920959473
tensor(1.2767, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0154741695150733
loss_c:0.7580411434173584
tensor(1.2386, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030752116814255714
loss_c:0.938051700592041
tensor(1.4062, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042464036494493484
loss_c:0.7750989198684692
tensor(1.3657, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012499580159783363
loss_c:0.7121404409408569
tensor(1.1997, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01309262216091156
loss_c:0.7539666891098022
tensor(1.2257, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042791154235601425
loss_c:1.1214851140975952
tensor(1.5621, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018937142565846443
loss_c:0.8323630690574646
tensor(1.2953, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022254345938563347
loss_c:0.8791894912719727
tensor(1.3361, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04174463823437691
loss_c:1.21297025680542
tensor(1.6090, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016515661031007767
loss_c:0.8154925107955933
tensor(1.2752, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012290360406041145
loss_c:0.7422839999198914
tensor(1.2157, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023790670558810234
loss_c:0.7319450378417969
tensor(1.2602, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04396301880478859
loss_c:0.7838770747184753
tensor(1.3776, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018958117812871933
loss_c:0.7451326251029968
tensor(1.2465, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016916761174798012
loss_c:0.7849003672599792
tensor(1.2599, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023760782554745674
loss_c:0.7904950976371765
tensor(1.2929, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017637236043810844
loss_c:0.7077018618583679
tensor(1.2197, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06687208265066147
loss_c:0.79329913854599
tensor(1.4830, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016093678772449493
loss_c:0.7796148061752319
tensor(1.2533, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02217201329767704
loss_c:0.8065400123596191
tensor(1.2949, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01667465642094612
loss_c:0.7939189672470093
tensor(1.2639, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01747111789882183
loss_c:0.8963009715080261
tensor(1.3249, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020949266850948334
loss_c:0.8617784380912781
tensor(1.3207, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022451303899288177
loss_c:0.7157484889030457
tensor(1.2449, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016489489004015923
loss_c:0.7710362672805786
tensor(1.2501, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0182449109852314
loss_c:0.6606897711753845
tensor(1.1955, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013442937284708023
loss_c:0.7621971368789673
tensor(1.2318, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05842254310846329
loss_c:0.8476769328117371
tensor(1.4761, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030849331989884377
loss_c:0.9313957095146179
tensor(1.4033, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03647730499505997
loss_c:0.8472381830215454
tensor(1.3801, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04060449078679085
loss_c:0.9029747843742371
tensor(1.4296, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017824724316596985
loss_c:0.7944116592407227
tensor(1.2691, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030253227800130844
loss_c:0.8478391170501709
tensor(1.3533, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02391958422958851
loss_c:0.9259435534477234
tensor(1.3701, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039029695093631744
loss_c:0.7720297574996948
tensor(1.3481, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014980417676270008
loss_c:0.8218761682510376
tensor(1.2725, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013229270465672016
loss_c:0.7210574150085449
tensor(1.2078, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039412010461091995
loss_c:1.0614595413208008
tensor(1.5138, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016517771407961845
loss_c:0.8061360120773315
tensor(1.2704, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017351243644952774
loss_c:0.9110319018363953
tensor(1.3335, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016713671386241913
loss_c:0.8150728940963745
tensor(1.2763, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024971775710582733
loss_c:0.8999807834625244
tensor(1.3599, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016530947759747505
loss_c:0.8338823318481445
tensor(1.2862, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025812258943915367
loss_c:0.7984511852264404
tensor(1.3060, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01566578447818756
loss_c:0.6990089416503906
tensor(1.2061, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017884396016597748
loss_c:0.8010779619216919
tensor(1.2734, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043121207505464554
loss_c:0.7864658236503601
tensor(1.3736, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02128812111914158
loss_c:0.7492539882659912
tensor(1.2587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026882868260145187
loss_c:0.7888376116752625
tensor(1.3051, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018017174676060677
loss_c:0.8574413061141968
tensor(1.3059, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01763886958360672
loss_c:0.8637871742248535
tensor(1.3079, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022449515759944916
loss_c:0.8135720491409302
tensor(1.3001, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02251937985420227
loss_c:0.85478675365448
tensor(1.3238, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.048271819949150085
loss_c:0.8010146617889404
tensor(1.4040, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01623872108757496
loss_c:0.8403169512748718
tensor(1.2885, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018655534833669662
loss_c:1.0329968929290771
tensor(1.4083, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02454356476664543
loss_c:0.942003607749939
tensor(1.3819, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030765753239393234
loss_c:1.172032356262207
tensor(1.5390, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022109534591436386
loss_c:0.9084008932113647
tensor(1.3523, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01807730831205845
loss_c:0.7771576642990112
tensor(1.2607, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021336184814572334
loss_c:0.8661268949508667
tensor(1.3250, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016835050657391548
loss_c:0.8513562679290771
tensor(1.2973, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021415365859866142
loss_c:0.9085572957992554
tensor(1.3492, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019936181604862213
loss_c:0.8332885503768921
tensor(1.3004, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01694338023662567
loss_c:0.871478796005249
tensor(1.3090, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02676575817167759
loss_c:0.8131138682365417
tensor(1.3185, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02378624491393566
loss_c:0.75260990858078
tensor(1.2717, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014209954999387264
loss_c:0.8270788192749023
tensor(1.2722, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028228746727108955
loss_c:0.8449853658676147
tensor(1.3427, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020032973960042
loss_c:0.9307557940483093
tensor(1.3554, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020683597773313522
loss_c:0.8583523631095886
tensor(1.3176, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015554278157651424
loss_c:0.9243917465209961
tensor(1.3323, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0219253059476614
loss_c:1.0307886600494385
tensor(1.4194, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025691121816635132
loss_c:0.7607250213623047
tensor(1.2848, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016874346882104874
loss_c:0.9178522825241089
tensor(1.3342, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017394859343767166
loss_c:0.7364029288291931
tensor(1.2352, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024834860116243362
loss_c:0.7358371615409851
tensor(1.2673, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01776288077235222
loss_c:0.8933613300323486
tensor(1.3243, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04828108847141266
loss_c:0.7848166227340698
tensor(1.3969, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01992930844426155
loss_c:0.856010377407074
tensor(1.3129, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02093692496418953
loss_c:0.7739620208740234
tensor(1.2716, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017257748171687126
loss_c:0.8758139610290527
tensor(1.3122, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01504232082515955
loss_c:0.774125337600708
tensor(1.2459, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019736604765057564
loss_c:0.7972909212112427
tensor(1.2793, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017703106626868248
loss_c:0.7931441068649292
tensor(1.2681, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06889667361974716
loss_c:0.9268921613693237
tensor(1.5668, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03572448715567589
loss_c:0.9061498641967773
tensor(1.4099, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028254320845007896
loss_c:0.915672779083252
tensor(1.3825, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01790670119225979
loss_c:0.8106529116630554
tensor(1.2788, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029789917171001434
loss_c:0.8375134468078613
tensor(1.3456, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016320649534463882
loss_c:0.8171595335006714
tensor(1.2755, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02968754433095455
loss_c:0.8783397078514099
tensor(1.3678, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026143718510866165
loss_c:0.794782817363739
tensor(1.3058, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01987372525036335
loss_c:0.7519303560256958
tensor(1.2547, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025621339678764343
loss_c:0.779594898223877
tensor(1.2950, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014378867112100124
loss_c:0.9155645370483398
tensor(1.3221, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04255952686071396
loss_c:0.7976784706115723
tensor(1.3785, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11023084074258804
loss_c:0.9238443374633789
tensor(1.7420, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018596569076180458
loss_c:0.8006729483604431
tensor(1.2764, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015928033739328384
loss_c:0.7743061780929565
tensor(1.2503, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05085812881588936
loss_c:0.9065533876419067
tensor(1.4740, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05481342971324921
loss_c:0.8008397817611694
tensor(1.4314, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03254281356930733
loss_c:0.8757988214492798
tensor(1.3780, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019192924723029137
loss_c:0.9369912147521973
tensor(1.3556, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01906219683587551
loss_c:0.8145691156387329
tensor(1.2867, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01973864808678627
loss_c:0.8242958784103394
tensor(1.2951, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012411150150001049
loss_c:0.7827053070068359
tensor(1.2411, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01536731980741024
loss_c:0.8357656002044678
tensor(1.2833, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011715885251760483
loss_c:0.8170145750045776
tensor(1.2576, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018692197278141975
loss_c:0.9186891317367554
tensor(1.3436, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01665596291422844
loss_c:0.8272788524627686
tensor(1.2840, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034301865845918655
loss_c:0.8722208738327026
tensor(1.3829, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03206803649663925
loss_c:0.9143056273460388
tensor(1.3971, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01954115740954876
loss_c:0.8232122659683228
tensor(1.2938, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017956886440515518
loss_c:0.8982995748519897
tensor(1.3292, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026776164770126343
loss_c:0.7764537334442139
tensor(1.2979, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029335349798202515
loss_c:0.7528156638145447
tensor(1.2953, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016183175146579742
loss_c:0.8108603954315186
tensor(1.2729, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02066662721335888
loss_c:0.9053463935852051
tensor(1.3444, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01605876162648201
loss_c:0.7295217514038086
tensor(1.2268, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030780918896198273
loss_c:0.8822059631347656
tensor(1.3738, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020557362586259842
loss_c:0.8840379118919373
tensor(1.3320, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01761278696358204
loss_c:0.8812238574028015
tensor(1.3181, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014461073093116283
loss_c:0.7863439321517944
tensor(1.2518, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014342627488076687
loss_c:0.7558563947677612
tensor(1.2342, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02796938829123974
loss_c:0.7602702379226685
tensor(1.2938, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021097231656312943
loss_c:0.8623527884483337
tensor(1.3221, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0176466666162014
loss_c:0.7584015727043152
tensor(1.2493, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02380770444869995
loss_c:0.9847673177719116
tensor(1.4021, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017182692885398865
loss_c:0.773483157157898
tensor(1.2556, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025599783286452293
loss_c:0.727179765701294
tensor(1.2652, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01314386073499918
loss_c:0.7320877313613892
tensor(1.2152, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017784060910344124
loss_c:0.8756987452507019
tensor(1.3154, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014780952595174313
loss_c:0.7713418006896973
tensor(1.2440, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030270835384726524
loss_c:0.8177902102470398
tensor(1.3359, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018182527273893356
loss_c:0.7618829607963562
tensor(1.2529, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013142499141395092
loss_c:0.735029399394989
tensor(1.2162, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014827893115580082
loss_c:0.8132622241973877
tensor(1.2674, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017009638249874115
loss_c:0.7474150657653809
tensor(1.2395, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01645307056605816
loss_c:0.8614785075187683
tensor(1.3014, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016218062490224838
loss_c:0.8449832797050476
tensor(1.2910, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0165081936866045
loss_c:0.7860262393951416
tensor(1.2588, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01823318935930729
loss_c:0.6802595853805542
tensor(1.2063, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019377699121832848
loss_c:0.8295553922653198
tensor(1.2958, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0386652797460556
loss_c:0.9881595969200134
tensor(1.4696, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011550779454410076
loss_c:0.7970442771911621
tensor(1.2432, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023288948461413383
loss_c:0.970946729183197
tensor(1.3930, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013802723027765751
loss_c:0.7112134695053101
tensor(1.2040, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01573762856423855
loss_c:0.7557072639465332
tensor(1.2377, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019742567092180252
loss_c:0.8814960718154907
tensor(1.3267, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01375774946063757
loss_c:0.7613945007324219
tensor(1.2321, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01270205620676279
loss_c:0.7198283076286316
tensor(1.2037, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01572125218808651
loss_c:0.7644991874694824
tensor(1.2423, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014016715809702873
loss_c:0.7556914687156677
tensor(1.2296, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015142018906772137
loss_c:0.8423339128494263
tensor(1.2839, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019322840496897697
loss_c:0.9111534953117371
tensor(1.3416, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0164094939827919
loss_c:0.8630551099777222
tensor(1.3012, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021230533719062805
loss_c:0.8690232038497925
tensor(1.3261, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022491903975605965
loss_c:0.9346002340316772
tensor(1.3692, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01586710289120674
loss_c:0.7101618647575378
tensor(1.2113, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020089788362383842
loss_c:0.8820728063583374
tensor(1.3284, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016192151233553886
loss_c:0.8073693513870239
tensor(1.2681, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01300775445997715
loss_c:0.7209072113037109
tensor(1.2043, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01251105684787035
loss_c:0.741669774055481
tensor(1.2138, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028942957520484924
loss_c:0.7409542798995972
tensor(1.2880, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013759836554527283
loss_c:0.8786342144012451
tensor(1.2975, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029609445482492447
loss_c:0.7414648532867432
tensor(1.2914, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024855315685272217
loss_c:0.8620846271514893
tensor(1.3387, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02699919044971466
loss_c:0.8468332290649414
tensor(1.3398, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01788993924856186
loss_c:0.7025400400161743
tensor(1.2156, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02943110279738903
loss_c:0.9636228084564209
tensor(1.4178, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01907731033861637
loss_c:0.7636269330978394
tensor(1.2559, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01584782637655735
loss_c:0.7560024261474609
tensor(1.2367, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01815011166036129
loss_c:0.8556200265884399
tensor(1.3043, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022865064442157745
loss_c:0.8082089424133301
tensor(1.2988, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02517181634902954
loss_c:0.8431093096733093
tensor(1.3294, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016100134700536728
loss_c:0.7704719305038452
tensor(1.2461, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030776146799325943
loss_c:0.9997280836105347
tensor(1.4449, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014241361059248447
loss_c:0.7368217706680298
tensor(1.2182, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022927500307559967
loss_c:0.7773439884185791
tensor(1.2814, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0234773401170969
loss_c:0.8186464309692383
tensor(1.3076, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018027842044830322
loss_c:0.8275569677352905
tensor(1.2876, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016753220930695534
loss_c:0.8107154369354248
tensor(1.2721, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013327284716069698
loss_c:0.842631995677948
tensor(1.2745, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02108682319521904
loss_c:0.7895506620407104
tensor(1.2799, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020408377051353455
loss_c:0.8703407049179077
tensor(1.3231, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034510865807533264
loss_c:0.8476733565330505
tensor(1.3752, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012675512582063675
loss_c:0.7136467695236206
tensor(1.1976, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021044062450528145
loss_c:0.8931519389152527
tensor(1.3390, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0225643590092659
loss_c:0.9573826789855957
tensor(1.3828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017452634871006012
loss_c:0.8417055010795593
tensor(1.2930, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02167459763586521
loss_c:0.8598946332931519
tensor(1.3229, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020649343729019165
loss_c:0.9383391737937927
tensor(1.3629, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025508999824523926
loss_c:0.808648943901062
tensor(1.3114, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020239707082509995
loss_c:0.925301730632782
tensor(1.3535, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03691332787275314
loss_c:0.7282578945159912
tensor(1.3184, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028227631002664566
loss_c:0.7118887901306152
tensor(1.2688, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019855715334415436
loss_c:0.6962892413139343
tensor(1.2212, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029736939817667007
loss_c:0.904116153717041
tensor(1.3852, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019127067178487778
loss_c:0.8852766752243042
tensor(1.3255, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021341003477573395
loss_c:0.8709855079650879
tensor(1.3276, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01806708797812462
loss_c:0.9366182088851929
tensor(1.3498, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01460207812488079
loss_c:0.8255982398986816
tensor(1.2707, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016373371705412865
loss_c:0.8470052480697632
tensor(1.2910, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0260909553617239
loss_c:0.8211703300476074
tensor(1.3211, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03701940178871155
loss_c:0.8343009352684021
tensor(1.3788, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027195293456315994
loss_c:0.8821730613708496
tensor(1.3607, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.047720279544591904
loss_c:0.7755386829376221
tensor(1.3945, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014546515420079231
loss_c:0.7651097178459167
tensor(1.2363, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018842754885554314
loss_c:0.8127388954162598
tensor(1.2830, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017280247062444687
loss_c:0.8629218339920044
tensor(1.3043, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020295441150665283
loss_c:0.8152689933776855
tensor(1.2911, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014897930435836315
loss_c:0.7649256587028503
tensor(1.2380, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015372578985989094
loss_c:0.8457891941070557
tensor(1.2859, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012666856870055199
loss_c:0.8066379427909851
tensor(1.2514, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03035734035074711
loss_c:0.8102676272392273
tensor(1.3342, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026737116277217865
loss_c:0.8076700568199158
tensor(1.3162, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021685242652893066
loss_c:0.7996987104415894
tensor(1.2886, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03067505732178688
loss_c:0.76091068983078
tensor(1.3076, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026787495240569115
loss_c:1.0012390613555908
tensor(1.4261, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02631067857146263
loss_c:0.8186070322990417
tensor(1.3204, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02608473040163517
loss_c:0.8260334730148315
tensor(1.3235, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01689215376973152
loss_c:0.7780135869979858
tensor(1.2546, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02503517083823681
loss_c:0.8998004794120789
tensor(1.3605, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01457878015935421
loss_c:0.800214409828186
tensor(1.2567, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01968309096992016
loss_c:0.8406834602355957
tensor(1.3028, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011198551394045353
loss_c:0.7239343523979187
tensor(1.1982, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025585489347577095
loss_c:0.8046990633010864
tensor(1.3091, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018886497244238853
loss_c:0.8205794095993042
tensor(1.2878, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02486298978328705
loss_c:1.028123140335083
tensor(1.4325, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022759154438972473
loss_c:0.8996407985687256
tensor(1.3501, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028871720656752586
loss_c:0.8485856056213379
tensor(1.3489, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030938770622015
loss_c:0.7824176549911499
tensor(1.3208, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016255157068371773
loss_c:0.648648202419281
tensor(1.1786, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032575324177742004
loss_c:0.8700776100158691
tensor(1.3778, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016918055713176727
loss_c:0.9257267713546753
tensor(1.3384, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021125396713614464
loss_c:1.0279715061187744
tensor(1.4153, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013229960575699806
loss_c:0.7877715826034546
tensor(1.2437, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016817579045891762
loss_c:0.7215150594711304
tensor(1.2225, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04170365631580353
loss_c:0.747563362121582
tensor(1.3497, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07896428555250168
loss_c:1.0623857975006104
tensor(1.6959, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017482763156294823
loss_c:0.9287203550338745
tensor(1.3426, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01790570840239525
loss_c:0.8742494583129883
tensor(1.3138, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019794141873717308
loss_c:0.806524932384491
tensor(1.2841, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027866151183843613
loss_c:0.7738734483718872
tensor(1.3018, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029156625270843506
loss_c:0.6964019536972046
tensor(1.2639, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017392290756106377
loss_c:0.9222761392593384
tensor(1.3387, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017442509531974792
loss_c:0.7718235850334167
tensor(1.2542, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014632238075137138
loss_c:0.8070565462112427
tensor(1.2616, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020357493311166763
loss_c:0.9532965421676636
tensor(1.3694, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02026992104947567
loss_c:0.7571605443954468
tensor(1.2586, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032145000994205475
loss_c:0.8658028841018677
tensor(1.3724, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02018558420240879
loss_c:1.0138609409332275
tensor(1.4027, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01845555752515793
loss_c:0.7185715436935425
tensor(1.2289, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016219301149249077
loss_c:0.9792041778564453
tensor(1.3656, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016007039695978165
loss_c:0.848163366317749
tensor(1.2909, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024709392338991165
loss_c:0.8539644479751587
tensor(1.3327, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03709058463573456
loss_c:0.818408191204071
tensor(1.3677, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0180207472294569
loss_c:0.7515006065368652
tensor(1.2456, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021027984097599983
loss_c:0.8705343008041382
tensor(1.3257, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02232748083770275
loss_c:0.7550443410873413
tensor(1.2667, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03492574393749237
loss_c:0.8443275690078735
tensor(1.3726, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026238996535539627
loss_c:0.7739461660385132
tensor(1.2946, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01960388757288456
loss_c:0.9419134855270386
tensor(1.3595, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04307227209210396
loss_c:0.8848214149475098
tensor(1.4313, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029890261590480804
loss_c:0.8362656831741333
tensor(1.3457, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022139927372336388
loss_c:0.9233640432357788
tensor(1.3603, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029388103634119034
loss_c:0.8959405422210693
tensor(1.3768, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03455125540494919
loss_c:0.8407400846481323
tensor(1.3686, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013044409453868866
loss_c:0.716949462890625
tensor(1.2046, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015359819866716862
loss_c:0.7859618067741394
tensor(1.2535, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01834103837609291
loss_c:0.8934597969055176
tensor(1.3269, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016019199043512344
loss_c:0.7907271385192871
tensor(1.2591, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021093780174851418
loss_c:0.7438251376152039
tensor(1.2551, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016695456579327583
loss_c:0.7609488368034363
tensor(1.2454, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025470586493611336
loss_c:0.744713544845581
tensor(1.2747, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018244415521621704
loss_c:0.8071807622909546
tensor(1.2781, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03708431497216225
loss_c:0.8276207447052002
tensor(1.3721, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016369258984923363
loss_c:0.9296991229057312
tensor(1.3386, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03315378725528717
loss_c:0.8930798768997192
tensor(1.3917, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016317902132868767
loss_c:0.8479495048522949
tensor(1.2925, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.047359004616737366
loss_c:0.8535158634185791
tensor(1.4317, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020445112138986588
loss_c:0.8430182337760925
tensor(1.3078, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012710785493254662
loss_c:0.779765784740448
tensor(1.2384, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03078998066484928
loss_c:1.1512506008148193
tensor(1.5265, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01332586258649826
loss_c:0.7204214930534363
tensor(1.2078, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022710537537932396
loss_c:0.7543878555297852
tensor(1.2679, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020359905436635017
loss_c:0.8376116156578064
tensor(1.3044, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020605726167559624
loss_c:0.8481968641281128
tensor(1.3115, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03611493110656738
loss_c:0.8772022128105164
tensor(1.3956, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019916770979762077
loss_c:1.0421249866485596
tensor(1.4174, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02436341717839241
loss_c:0.9902465343475342
tensor(1.4077, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03510463982820511
loss_c:1.046299934387207
tensor(1.4860, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02416815422475338
loss_c:0.9870044589042664
tensor(1.4048, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06425286084413528
loss_c:0.852916955947876
tensor(1.5047, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021780213341116905
loss_c:0.772081732749939
tensor(1.2741, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017630357295274734
loss_c:0.8322398066520691
tensor(1.2897, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01854918710887432
loss_c:0.8609194159507751
tensor(1.3097, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031746041029691696
loss_c:0.8094560503959656
tensor(1.3383, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03787761926651001
loss_c:0.8316459655761719
tensor(1.3771, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0328487902879715
loss_c:0.8013951182365417
tensor(1.3385, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027796991169452667
loss_c:0.9306091070175171
tensor(1.3885, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021627094596624374
loss_c:0.7756320834159851
tensor(1.2757, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02768263779580593
loss_c:0.8181941509246826
tensor(1.3254, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03551310673356056
loss_c:0.7969533205032349
tensor(1.3472, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021570758894085884
loss_c:1.0309326648712158
tensor(1.4174, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024006957188248634
loss_c:0.7701302766799927
tensor(1.2830, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019388729706406593
loss_c:0.7173360586166382
tensor(1.2340, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015283464454114437
loss_c:0.7406429648399353
tensor(1.2294, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02991625666618347
loss_c:0.9094268083572388
tensor(1.3855, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013701964169740677
loss_c:0.7338113784790039
tensor(1.2189, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016230592504143715
loss_c:0.7908716201782227
tensor(1.2614, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022150970995426178
loss_c:0.857840895652771
tensor(1.3238, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.057921260595321655
loss_c:0.9221450686454773
tensor(1.5119, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027917848899960518
loss_c:0.8364129066467285
tensor(1.3364, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015108414925634861
loss_c:0.8458868861198425
tensor(1.2872, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01515048649162054
loss_c:0.7885870337486267
tensor(1.2555, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019400810822844505
loss_c:0.7809973955154419
tensor(1.2693, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015322720631957054
loss_c:0.712382972240448
tensor(1.2138, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02697404846549034
loss_c:0.965268075466156
tensor(1.4042, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07534012943506241
loss_c:0.9054600596427917
tensor(1.5764, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03522207587957382
loss_c:1.1128535270690918
tensor(1.5216, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017032921314239502
loss_c:0.7392348051071167
tensor(1.2360, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01812068186700344
loss_c:0.8185033798217773
tensor(1.2849, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023031340911984444
loss_c:0.8813266754150391
tensor(1.3407, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023775609210133553
loss_c:0.8693050742149353
tensor(1.3371, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01256312895566225
loss_c:0.791604220867157
tensor(1.2466, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019175022840499878
loss_c:0.8176581263542175
tensor(1.2890, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029842810705304146
loss_c:0.6886922717094421
tensor(1.2620, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02682354860007763
loss_c:0.7861630320549011
tensor(1.3036, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028338197618722916
loss_c:0.8588125705718994
tensor(1.3505, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06835678219795227
loss_c:1.2194757461547852
tensor(1.7206, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02038366161286831
loss_c:0.8713734149932861
tensor(1.3241, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0205063596367836
loss_c:0.8101828098297119
tensor(1.2905, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023676177486777306
loss_c:0.7284024953842163
tensor(1.2582, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020249832421541214
loss_c:0.7534806132316589
tensor(1.2578, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012816372327506542
loss_c:0.7368340492248535
tensor(1.2174, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018935758620500565
loss_c:0.8240070343017578
tensor(1.2917, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03121073730289936
loss_c:0.7645806670188904
tensor(1.3099, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03526182845234871
loss_c:1.0233525037765503
tensor(1.4714, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029315324500203133
loss_c:0.8603488802909851
tensor(1.3554, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012161958031356335
loss_c:0.7609695196151733
tensor(1.2281, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01364197675138712
loss_c:0.7648435831069946
tensor(1.2365, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015074515715241432
loss_c:0.7718299627304077
tensor(1.2463, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02187345363199711
loss_c:0.8604048490524292
tensor(1.3243, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015065062791109085
loss_c:0.788374125957489
tensor(1.2554, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01656782627105713
loss_c:0.9073824882507324
tensor(1.3283, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0286179818212986
loss_c:0.8376444578170776
tensor(1.3398, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017995337024331093
loss_c:0.6905126571655273
tensor(1.2127, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03173517435789108
loss_c:0.8969163298606873
tensor(1.3862, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01937238499522209
loss_c:0.8736955523490906
tensor(1.3211, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032007846981287
loss_c:0.8471080660820007
tensor(1.3595, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02544564940035343
loss_c:0.7944490313529968
tensor(1.3023, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0169688668102026
loss_c:0.811927318572998
tensor(1.2763, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04746648296713829
loss_c:0.8567728996276855
tensor(1.4304, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021744418889284134
loss_c:0.8645216226577759
tensor(1.3260, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017163129523396492
loss_c:0.7352018356323242
tensor(1.2339, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017321834340691566
loss_c:0.846045732498169
tensor(1.2969, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017724230885505676
loss_c:0.874809741973877
tensor(1.3147, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02383512631058693
loss_c:0.7961204051971436
tensor(1.2963, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023110022768378258
loss_c:0.8792042136192322
tensor(1.3400, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014249859377741814
loss_c:0.7585971355438232
tensor(1.2345, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024224188178777695
loss_c:0.7371839284896851
tensor(1.2648, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018794244155287743
loss_c:0.7113418579101562
tensor(1.2271, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013491492718458176
loss_c:0.8008049726486206
tensor(1.2549, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012511972337961197
loss_c:0.7523410320281982
tensor(1.2233, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020653707906603813
loss_c:0.824140727519989
tensor(1.2985, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017310092225670815
loss_c:0.7364815473556519
tensor(1.2346, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017039427533745766
loss_c:0.6945372819900513
tensor(1.2096, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027722623199224472
loss_c:0.8154762983322144
tensor(1.3238, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024072906002402306
loss_c:0.9031261205673218
tensor(1.3578, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022962313145399094
loss_c:0.8205191493034363
tensor(1.3062, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01665797084569931
loss_c:0.7366964221000671
tensor(1.2314, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011786740273237228
loss_c:0.7650973200798035
tensor(1.2263, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03257453069090843
loss_c:0.952497124671936
tensor(1.4229, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017480475828051567
loss_c:0.7924854159355164
tensor(1.2664, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03348175808787346
loss_c:0.7974981665611267
tensor(1.3388, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01592574082314968
loss_c:0.764269232749939
tensor(1.2435, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03312075510621071
loss_c:0.8564104437828064
tensor(1.3709, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013570246286690235
loss_c:0.7652730941772461
tensor(1.2337, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014532353729009628
loss_c:0.8085874319076538
tensor(1.2626, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0379318967461586
loss_c:0.8999640941619873
tensor(1.4169, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016752485185861588
loss_c:0.9088516235351562
tensor(1.3295, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01710992492735386
loss_c:0.835603654384613
tensor(1.2892, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015840312466025352
loss_c:0.938198447227478
tensor(1.3422, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016308501362800598
loss_c:0.9943673014640808
tensor(1.3763, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01753859780728817
loss_c:0.8311500549316406
tensor(1.2884, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033326249569654465
loss_c:0.8912203311920166
tensor(1.3920, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016205372288823128
loss_c:0.810783863067627
tensor(1.2708, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016496434807777405
loss_c:0.7049404978752136
tensor(1.2118, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020998215302824974
loss_c:0.8520456552505493
tensor(1.3154, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014940776862204075
loss_c:0.7193171977996826
tensor(1.2131, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019453976303339005
loss_c:0.8658971786499023
tensor(1.3164, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020566998049616814
loss_c:0.8695040941238403
tensor(1.3234, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0355227068066597
loss_c:0.8742625713348389
tensor(1.3924, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015970369800925255
loss_c:0.8136305809020996
tensor(1.2712, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020099539309740067
loss_c:0.8305403590202332
tensor(1.2991, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022721322253346443
loss_c:0.7919108271598816
tensor(1.2888, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03591359406709671
loss_c:0.8302909135818481
tensor(1.3694, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03512730449438095
loss_c:1.019600510597229
tensor(1.4734, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017034951597452164
loss_c:0.7902801036834717
tensor(1.2626, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015573025681078434
loss_c:0.7352971434593201
tensor(1.2249, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018890870735049248
loss_c:0.8180078268051147
tensor(1.2866, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.010516946204006672
loss_c:0.7328922152519226
tensor(1.2010, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01805531606078148
loss_c:0.7885672450065613
tensor(1.2661, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026676615700125694
loss_c:0.9967219233512878
tensor(1.4227, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015570403076708317
loss_c:0.7438892126083374
tensor(1.2297, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023458918556571007
loss_c:0.7714661955833435
tensor(1.2806, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014501230791211128
loss_c:0.7382329702377319
tensor(1.2216, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015359628014266491
loss_c:0.8665437698364258
tensor(1.2982, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03016774170100689
loss_c:0.8538813591003418
tensor(1.3574, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026500871405005455
loss_c:0.851699709892273
tensor(1.3397, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02151687815785408
loss_c:0.8379539847373962
tensor(1.3096, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014742538332939148
loss_c:0.7780847549438477
tensor(1.2451, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03658551350235939
loss_c:0.7251011729240417
tensor(1.3133, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016184845939278603
loss_c:0.7734296321868896
tensor(1.2489, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03501546382904053
loss_c:0.7138737440109253
tensor(1.2999, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016262326389551163
loss_c:0.7111803889274597
tensor(1.2139, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03392186015844345
loss_c:0.7658569812774658
tensor(1.3244, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023530157282948494
loss_c:0.7881091833114624
tensor(1.2903, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014526240527629852
loss_c:0.7933440208435059
tensor(1.2528, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01768548972904682
loss_c:0.7192623615264893
tensor(1.2247, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034538399428129196
loss_c:0.9807387590408325
tensor(1.4497, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022725526243448257
loss_c:0.7172683477401733
tensor(1.2461, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014568435959517956
loss_c:0.7587876319885254
tensor(1.2332, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020220668986439705
loss_c:0.7585351467132568
tensor(1.2584, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021255699917674065
loss_c:0.8152666091918945
tensor(1.2955, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017158683389425278
loss_c:0.8546540141105652
tensor(1.2997, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02715117484331131
loss_c:0.8383325338363647
tensor(1.3352, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021961523219943047
loss_c:0.8029796481132507
tensor(1.2916, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017301883548498154
loss_c:0.7958654165267944
tensor(1.2666, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018635597079992294
loss_c:0.8650588989257812
tensor(1.3123, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02549394592642784
loss_c:0.7902194857597351
tensor(1.3002, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025143034756183624
loss_c:0.8709474802017212
tensor(1.3450, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020741458982229233
loss_c:0.8364631533622742
tensor(1.3054, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027320977300405502
loss_c:0.788977324962616
tensor(1.3077, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021242963150143623
loss_c:0.7140771746635437
tensor(1.2373, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020645754411816597
loss_c:0.7902114391326904
tensor(1.2783, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012294113636016846
loss_c:0.7646161913871765
tensor(1.2261, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025919107720255852
loss_c:0.832626223564148
tensor(1.3265, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01939365081489086
loss_c:0.8680459856987
tensor(1.3175, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032218363136053085
loss_c:0.8809494972229004
tensor(1.3827, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01754649356007576
loss_c:0.792757511138916
tensor(1.2658, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01747848652303219
loss_c:0.7698955535888672
tensor(1.2524, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01777818612754345
loss_c:0.7739550471305847
tensor(1.2561, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03138034790754318
loss_c:0.956857442855835
tensor(1.4226, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026029488071799278
loss_c:0.8572374582290649
tensor(1.3412, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022305861115455627
loss_c:0.8937532305717468
tensor(1.3454, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017263619229197502
loss_c:1.0057826042175293
tensor(1.3870, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014842523261904716
loss_c:0.7267073392868042
tensor(1.2157, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019952481612563133
loss_c:0.9513763785362244
tensor(1.3677, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026736706495285034
loss_c:0.7281562685966492
tensor(1.2703, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02067851647734642
loss_c:0.7653116583824158
tensor(1.2642, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026603704318404198
loss_c:0.775542676448822
tensor(1.2969, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016974179074168205
loss_c:0.8745734095573425
tensor(1.3101, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014596549794077873
loss_c:0.7881953120231628
tensor(1.2499, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013597376644611359
loss_c:0.7217588424682617
tensor(1.2074, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025626718997955322
loss_c:0.7183642387390137
tensor(1.2598, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023353446274995804
loss_c:0.8008286952972412
tensor(1.2967, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019862735643982887
loss_c:0.8403741717338562
tensor(1.3035, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023380206897854805
loss_c:0.9236396551132202
tensor(1.3671, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012634956277906895
loss_c:0.693240761756897
tensor(1.1866, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03718500956892967
loss_c:1.0078558921813965
tensor(1.4779, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023888980969786644
loss_c:0.810766875743866
tensor(1.3048, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0292487982660532
loss_c:0.8276810646057129
tensor(1.3388, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03059348836541176
loss_c:0.7841691970825195
tensor(1.3200, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019803840667009354
loss_c:0.8441972136497498
tensor(1.3054, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018454158678650856
loss_c:0.8744809627532959
tensor(1.3166, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024575479328632355
loss_c:1.084324836730957
tensor(1.4642, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04655352607369423
loss_c:0.7994326949119568
tensor(1.4008, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03602036461234093
loss_c:0.9034575819969177
tensor(1.4124, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018333418294787407
loss_c:0.7748500108718872
tensor(1.2593, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014105027541518211
loss_c:0.7511657476425171
tensor(1.2268, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01669907756149769
loss_c:0.8498806357383728
tensor(1.2947, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022678673267364502
loss_c:1.0083940029144287
tensor(1.4117, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013375731185078621
loss_c:0.9169539213180542
tensor(1.3179, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016279596835374832
loss_c:1.1120314598083496
tensor(1.4416, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020360194146633148
loss_c:0.741640567779541
tensor(1.2498, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04992583394050598
loss_c:0.8087965250015259
tensor(1.4205, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02110910788178444
loss_c:0.7919954061508179
tensor(1.2817, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01983991637825966
loss_c:0.8514376878738403
tensor(1.3097, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024230971932411194
loss_c:0.783902645111084
tensor(1.2912, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025675686076283455
loss_c:0.99150550365448
tensor(1.4147, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01406536903232336
loss_c:0.7603642344474792
tensor(1.2326, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026891808956861496
loss_c:0.7939243316650391
tensor(1.3088, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01610776223242283
loss_c:0.7467307448387146
tensor(1.2341, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017908310517668724
loss_c:0.7908946871757507
tensor(1.2670, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01548600010573864
loss_c:0.7792183756828308
tensor(1.2496, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017276078462600708
loss_c:0.7245883345603943
tensor(1.2269, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018479203805327415
loss_c:0.8276044130325317
tensor(1.2902, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013524356298148632
loss_c:0.8252969980239868
tensor(1.2667, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015201042406260967
loss_c:0.7694988250732422
tensor(1.2427, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035116393119096756
loss_c:1.0771353244781494
tensor(1.5052, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03620920330286026
loss_c:0.8147392272949219
tensor(1.3624, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027087721973657608
loss_c:0.9877636432647705
tensor(1.4188, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014783891849219799
loss_c:0.7502772212028503
tensor(1.2300, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01665017195045948
loss_c:0.8579899668693542
tensor(1.2990, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014660277403891087
loss_c:0.7884830236434937
tensor(1.2510, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026636164635419846
loss_c:0.7674528360366821
tensor(1.2929, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02514553628861904
loss_c:0.7735316157341003
tensor(1.2896, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024442754685878754
loss_c:0.9687759280204773
tensor(1.3962, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017271408811211586
loss_c:0.8348538279533386
tensor(1.2887, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02254209667444229
loss_c:1.1035940647125244
tensor(1.4635, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012002219446003437
loss_c:0.780776858329773
tensor(1.2347, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016339639201760292
loss_c:0.9354779124259949
tensor(1.3410, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03303134813904762
loss_c:0.9741496443748474
tensor(1.4378, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022312982007861137
loss_c:0.9175994396209717
tensor(1.3578, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017598828300833702
loss_c:0.9137309789657593
tensor(1.3343, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020438561215996742
loss_c:0.8367487192153931
tensor(1.3040, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026315150782465935
loss_c:0.9159809947013855
tensor(1.3748, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02605724334716797
loss_c:1.0732067823410034
tensor(1.4613, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01846919022500515
loss_c:0.8619495630264282
tensor(1.3092, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014156213030219078
loss_c:0.7685446739196777
tensor(1.2377, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01492593064904213
loss_c:0.8692874908447266
tensor(1.2972, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013142172247171402
loss_c:0.7601109743118286
tensor(1.2285, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028729453682899475
loss_c:0.7475347518920898
tensor(1.2920, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03805490583181381
loss_c:0.8354122042655945
tensor(1.3830, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027629390358924866
loss_c:0.8510503172874451
tensor(1.3445, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03348686546087265
loss_c:0.7725058794021606
tensor(1.3274, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027964720502495766
loss_c:0.7473849654197693
tensor(1.2885, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04022083431482315
loss_c:0.8631700277328491
tensor(1.4080, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02376556023955345
loss_c:0.8070332407951355
tensor(1.3026, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025940893217921257
loss_c:0.8803167343139648
tensor(1.3530, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018485503271222115
loss_c:0.7970392107963562
tensor(1.2733, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018726792186498642
loss_c:0.7448816299438477
tensor(1.2454, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04632599279284477
loss_c:0.8350147008895874
tensor(1.4191, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023457463830709457
loss_c:0.8948276042938232
tensor(1.3499, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017604609951376915
loss_c:0.813774824142456
tensor(1.2787, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04264060780405998
loss_c:0.8469617366790771
tensor(1.4087, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033585648983716965
loss_c:0.9282776713371277
tensor(1.4135, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01476038247346878
loss_c:0.8795668482780457
tensor(1.3028, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017239946871995926
loss_c:0.7278938293457031
tensor(1.2294, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03002980537712574
loss_c:0.9758688807487488
tensor(1.4241, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021215949207544327
loss_c:0.7581931948661804
tensor(1.2639, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037500929087400436
loss_c:0.8603512048721313
tensor(1.3926, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018684810027480125
loss_c:0.9165500402450562
tensor(1.3410, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015025461092591286
loss_c:0.8888425827026367
tensor(1.3095, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0460527203977108
loss_c:0.8750437498092651
tensor(1.4380, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02470060996711254
loss_c:0.782808780670166
tensor(1.2929, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024902474135160446
loss_c:0.9742993712425232
tensor(1.4005, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019213493913412094
loss_c:0.9723256826400757
tensor(1.3745, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0479973666369915
loss_c:0.8048437833786011
tensor(1.4067, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02699592523276806
loss_c:0.9500293135643005
tensor(1.3960, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016626685857772827
loss_c:0.9242576360702515
tensor(1.3366, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01760384812951088
loss_c:0.7676672339439392
tensor(1.2538, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0293362345546484
loss_c:0.9436737895011902
tensor(1.4024, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017843633890151978
loss_c:0.7791761159896851
tensor(1.2614, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013894625939428806
loss_c:0.821378231048584
tensor(1.2678, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027919529005885124
loss_c:0.953393816947937
tensor(1.4015, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02432643063366413
loss_c:0.7362234592437744
tensor(1.2656, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024510812014341354
loss_c:0.9689801931381226
tensor(1.3955, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015652278438210487
loss_c:0.8091880083084106
tensor(1.2687, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017809085547924042
loss_c:0.8325694799423218
tensor(1.2910, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026351366192102432
loss_c:0.8993183970451355
tensor(1.3647, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020342348143458366
loss_c:0.7708916068077087
tensor(1.2677, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014240832068026066
loss_c:0.7805754542350769
tensor(1.2468, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02145911194384098
loss_c:0.850601851940155
tensor(1.3167, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028448551893234253
loss_c:0.7610377669334412
tensor(1.2972, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.12297230213880539
loss_c:1.133723258972168
tensor(1.9120, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012011554092168808
loss_c:0.8292607069015503
tensor(1.2642, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023986022919416428
loss_c:1.1046137809753418
tensor(1.4683, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019618656486272812
loss_c:0.8277241587638855
tensor(1.2962, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018473146483302116
loss_c:0.8453974723815918
tensor(1.3012, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031219644472002983
loss_c:0.7021640539169312
tensor(1.2763, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013122846372425556
loss_c:0.6866177916526794
tensor(1.1907, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025349074974656105
loss_c:1.085414171218872
tensor(1.4632, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027805473655462265
loss_c:1.0584608316421509
tensor(1.4587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023577861487865448
loss_c:0.791094183921814
tensor(1.2930, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016690228134393692
loss_c:0.7895485758781433
tensor(1.2630, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017462516203522682
loss_c:0.9129116535186768
tensor(1.3344, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03391660749912262
loss_c:0.7536172866821289
tensor(1.3161, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020424174144864082
loss_c:0.8953534364700317
tensor(1.3372, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01187921967357397
loss_c:0.770636260509491
tensor(1.2323, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016050932928919792
loss_c:0.8836383819580078
tensor(1.3123, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03293890878558159
loss_c:0.8616000413894653
tensor(1.3716, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015645187348127365
loss_c:0.8900070190429688
tensor(1.3140, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01502031460404396
loss_c:0.8177207708358765
tensor(1.2715, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031080128625035286
loss_c:0.7965685725212097
tensor(1.3279, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018385594710707664
loss_c:0.8467357158660889
tensor(1.3017, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018712827935814857
loss_c:0.8722519874572754
tensor(1.3171, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02011028118431568
loss_c:0.8053404092788696
tensor(1.2861, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02833719179034233
loss_c:0.7767549753189087
tensor(1.3053, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012798919342458248
loss_c:0.7500910758972168
tensor(1.2244, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038287751376628876
loss_c:0.8505171537399292
tensor(1.3886, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01712280698120594
loss_c:0.7701596021652222
tensor(1.2538, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01655016839504242
loss_c:0.7935642600059509
tensor(1.2642, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.047998443245887756
loss_c:0.8303745985031128
tensor(1.4191, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017786161974072456
loss_c:0.7885739207267761
tensor(1.2666, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018667414784431458
loss_c:0.941916823387146
tensor(1.3555, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016001667827367783
loss_c:0.9076583385467529
tensor(1.3251, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02145768702030182
loss_c:0.8600379824638367
tensor(1.3220, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03117099404335022
loss_c:0.7887002825737
tensor(1.3240, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039061713963747025
loss_c:0.8706121444702148
tensor(1.4034, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04269189015030861
loss_c:0.8215596079826355
tensor(1.3916, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019266685470938683
loss_c:1.0103133916854858
tensor(1.3962, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030373988673090935
loss_c:0.975853443145752
tensor(1.4246, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014455128461122513
loss_c:0.8030647039413452
tensor(1.2603, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017025604844093323
loss_c:0.7892419695854187
tensor(1.2637, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022002335637807846
loss_c:0.9605326652526855
tensor(1.3802, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01618402823805809
loss_c:0.8634690046310425
tensor(1.3013, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02333030104637146
loss_c:1.0627307891845703
tensor(1.4427, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015192419290542603
loss_c:0.8756495714187622
tensor(1.3038, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03608561307191849
loss_c:0.9809367656707764
tensor(1.4517, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030055813491344452
loss_c:0.901308000087738
tensor(1.3817, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020777931436896324
loss_c:0.7985386252403259
tensor(1.2850, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013866713270545006
loss_c:0.6863600015640259
tensor(1.1933, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015457483939826488
loss_c:0.7588962316513062
tensor(1.2402, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0201064832508564
loss_c:0.8544450998306274
tensor(1.3130, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028063245117664337
loss_c:1.0446531772613525
tensor(1.4525, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019418058916926384
loss_c:0.7695032358169556
tensor(1.2631, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01502883993089199
loss_c:0.8334544897079468
tensor(1.2795, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03057904727756977
loss_c:0.8992478251457214
tensor(1.3829, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023537451401352882
loss_c:0.8150152564048767
tensor(1.3059, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030841220170259476
loss_c:0.7882706522941589
tensor(1.3227, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017096413299441338
loss_c:0.8339589834213257
tensor(1.2886, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030132832005620003
loss_c:0.8460309505462646
tensor(1.3516, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038533009588718414
loss_c:0.8202568292617798
tensor(1.3736, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021820617839694023
loss_c:0.8701435327529907
tensor(1.3290, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02463781088590622
loss_c:0.8947662115097046
tensor(1.3548, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024209000170230865
loss_c:0.8497764468193054
tensor(1.3281, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020037328824400902
loss_c:0.9688079357147217
tensor(1.3759, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019092867150902748
loss_c:0.7678049802780151
tensor(1.2606, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02288847602903843
loss_c:0.9218174815177917
tensor(1.3622, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02195710502564907
loss_c:0.6877298355102539
tensor(1.2287, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020727775990962982
loss_c:0.7506513595581055
tensor(1.2582, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03421156853437424
loss_c:0.8351445198059082
tensor(1.3632, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0366482213139534
loss_c:0.7832381725311279
tensor(1.3449, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019005408510565758
loss_c:0.8696088790893555
tensor(1.3166, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019814562052488327
loss_c:0.8215150237083435
tensor(1.2934, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020904283970594406
loss_c:0.869646430015564
tensor(1.3248, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01600939780473709
loss_c:0.7229436635971069
tensor(1.2222, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019746296107769012
loss_c:0.7655875086784363
tensor(1.2620, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01714492030441761
loss_c:0.8250211477279663
tensor(1.2838, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017749927937984467
loss_c:0.8995756506919861
tensor(1.3279, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024560924619436264
loss_c:0.7866244316101074
tensor(1.2944, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01726781763136387
loss_c:0.8466401100158691
tensor(1.2962, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01901240274310112
loss_c:0.8682702779769897
tensor(1.3158, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03210190311074257
loss_c:0.9937865734100342
tensor(1.4427, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016220828518271446
loss_c:0.85295569896698
tensor(1.2951, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026882264763116837
loss_c:0.7872494459152222
tensor(1.3048, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01813194341957569
loss_c:0.850663423538208
tensor(1.3021, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015470660291612148
loss_c:0.9353176951408386
tensor(1.3378, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021091941744089127
loss_c:0.914197564125061
tensor(1.3505, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01805892586708069
loss_c:0.7313157916069031
tensor(1.2351, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01553262583911419
loss_c:0.7803341150283813
tensor(1.2514, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037007562816143036
loss_c:0.8444125056266785
tensor(1.3811, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01661144569516182
loss_c:0.7421779632568359
tensor(1.2347, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017189331352710724
loss_c:0.7894295454025269
tensor(1.2636, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01543367002159357
loss_c:0.7247545123100281
tensor(1.2196, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020722758024930954
loss_c:0.774181604385376
tensor(1.2705, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017159195616841316
loss_c:0.742931604385376
tensor(1.2372, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026114732027053833
loss_c:0.8680711984634399
tensor(1.3468, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06318135559558868
loss_c:0.9156507849693298
tensor(1.5372, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025419289246201515
loss_c:0.7649673223495483
tensor(1.2859, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020607875660061836
loss_c:1.1382328271865845
tensor(1.4744, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020566971972584724
loss_c:0.7887765169143677
tensor(1.2778, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03648804873228073
loss_c:0.8705611228942871
tensor(1.3939, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024284731596708298
loss_c:0.8512301445007324
tensor(1.3293, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014354323036968708
loss_c:0.7781123518943787
tensor(1.2445, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03658674284815788
loss_c:1.0379042625427246
tensor(1.4882, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013843145221471786
loss_c:0.7911074161529541
tensor(1.2497, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019347431138157845
loss_c:0.7689518928527832
tensor(1.2614, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018712662160396576
loss_c:0.7503387331962585
tensor(1.2482, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02947879210114479
loss_c:0.8553112745285034
tensor(1.3543, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0140248266980052
loss_c:0.6821541786193848
tensor(1.1893, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019909461960196495
loss_c:0.9331684112548828
tensor(1.3561, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016408082097768784
loss_c:0.8006152510643005
tensor(1.2663, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023327896371483803
loss_c:0.9633884429931641
tensor(1.3881, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03252560272812843
loss_c:0.7962872385978699
tensor(1.3346, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016933554783463478
loss_c:0.8095382452011108
tensor(1.2736, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016275547444820404
loss_c:0.7813436388969421
tensor(1.2548, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03062264434993267
loss_c:0.8035141825675964
tensor(1.3303, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014567540027201176
loss_c:0.9400577545166016
tensor(1.3365, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01709427498281002
loss_c:0.7766582369804382
tensor(1.2557, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030522311106324196
loss_c:0.8514336347579956
tensor(1.3569, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028812943026423454
loss_c:0.8304089307785034
tensor(1.3375, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01748660020530224
loss_c:0.7922644019126892
tensor(1.2662, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01755787432193756
loss_c:0.7575753927230835
tensor(1.2469, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0192925613373518
loss_c:0.8025951385498047
tensor(1.2799, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030823778361082077
loss_c:0.677495002746582
tensor(1.2603, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01295491959899664
loss_c:0.7442772388458252
tensor(1.2190, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03910911828279495
loss_c:0.9115838408470154
tensor(1.4289, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019559258595108986
loss_c:0.7827996015548706
tensor(1.2698, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019161829724907875
loss_c:0.8710750341415405
tensor(1.3179, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016956394538283348
loss_c:0.8888958692550659
tensor(1.3183, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012388939969241619
loss_c:0.8470330238342285
tensor(1.2744, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034722380340099335
loss_c:0.7726988792419434
tensor(1.3311, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01798008754849434
loss_c:0.7542855739593506
tensor(1.2466, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014095896854996681
loss_c:0.7879244685173035
tensor(1.2484, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027516767382621765
loss_c:0.7569870948791504
tensor(1.2904, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02033797651529312
loss_c:0.7639520168304443
tensor(1.2625, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018569910898804665
loss_c:0.7379452586174011
tensor(1.2398, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030653804540634155
loss_c:0.8872331976890564
tensor(1.3782, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019627699628472328
loss_c:0.887915313243866
tensor(1.3296, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020313922315835953
loss_c:1.0636653900146484
tensor(1.4325, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027276914566755295
loss_c:0.9104770421981812
tensor(1.3764, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018461797386407852
loss_c:0.8785775899887085
tensor(1.3191, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015463734976947308
loss_c:0.7848725318908691
tensor(1.2525, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021531622856855392
loss_c:0.6890686750411987
tensor(1.2252, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015752004459500313
loss_c:0.9749798774719238
tensor(1.3617, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024823535233736038
loss_c:0.804442822933197
tensor(1.3053, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020298048853874207
loss_c:0.7408844232559204
tensor(1.2491, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01843968592584133
loss_c:0.8853620290756226
tensor(1.3227, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028082555159926414
loss_c:0.8487069010734558
tensor(1.3450, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012683015316724777
loss_c:0.7622381448745728
tensor(1.2271, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05607110634446144
loss_c:0.8656370043754578
tensor(1.4800, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01501492876559496
loss_c:0.68062824010849
tensor(1.1913, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01681293547153473
loss_c:0.8165814280509949
tensor(1.2764, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018833540380001068
loss_c:1.0492784976959229
tensor(1.4174, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02014823444187641
loss_c:0.9270093441009521
tensor(1.3539, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013502547517418861
loss_c:0.7316241264343262
tensor(1.2135, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02407079190015793
loss_c:0.7439247965812683
tensor(1.2677, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018429860472679138
loss_c:0.8011886477470398
tensor(1.2749, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033935051411390305
loss_c:0.8483103513717651
tensor(1.3711, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018711863085627556
loss_c:0.9262566566467285
tensor(1.3470, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018356909975409508
loss_c:0.8262004256248474
tensor(1.2887, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027726253494620323
loss_c:0.7668122053146362
tensor(1.2971, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014162355102598667
loss_c:0.7095462679862976
tensor(1.2039, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018851175904273987
loss_c:0.6474350094795227
tensor(1.1897, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017657283693552017
loss_c:0.9055646657943726
tensor(1.3305, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02157342992722988
loss_c:0.7876331210136414
tensor(1.2813, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015444544143974781
loss_c:0.793103814125061
tensor(1.2568, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026468435302376747
loss_c:0.8421013355255127
tensor(1.3342, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021196015179157257
loss_c:0.9111161231994629
tensor(1.3497, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01803319714963436
loss_c:0.915917158126831
tensor(1.3381, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023205088451504707
loss_c:0.8563691973686218
tensor(1.3276, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03271753713488579
loss_c:0.7994462251663208
tensor(1.3383, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013761105015873909
loss_c:0.7399327158927917
tensor(1.2189, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017644774168729782
loss_c:0.6999515295028687
tensor(1.2137, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02113693207502365
loss_c:0.7648336291313171
tensor(1.2663, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016437973827123642
loss_c:0.8141916990280151
tensor(1.2731, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024561822414398193
loss_c:0.724692702293396
tensor(1.2589, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01966273784637451
loss_c:0.8363603353500366
tensor(1.3003, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02004733681678772
loss_c:0.9552118182182312
tensor(1.3697, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01756807044148445
loss_c:0.8508870005607605
tensor(1.2990, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013212176039814949
loss_c:0.7421054244041443
tensor(1.2173, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018233489245176315
loss_c:0.7458133697509766
tensor(1.2422, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04262653365731239
loss_c:0.8188499808311462
tensor(1.3948, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01817190833389759
loss_c:0.8183376789093018
tensor(1.2832, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020223544910550117
loss_c:0.8480864763259888
tensor(1.3095, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01825350522994995
loss_c:0.7857028245925903
tensor(1.2649, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01707126945257187
loss_c:0.8287559747695923
tensor(1.2841, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019836008548736572
loss_c:0.8677847385406494
tensor(1.3190, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014052072539925575
loss_c:0.7189658880233765
tensor(1.2076, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014854381792247295
loss_c:0.8627152442932129
tensor(1.2933, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017181916162371635
loss_c:0.861212968826294
tensor(1.3031, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01688479445874691
loss_c:0.826945960521698
tensor(1.2821, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017563657835125923
loss_c:0.8052412867546082
tensor(1.2728, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018104728311300278
loss_c:0.7771686315536499
tensor(1.2592, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018396001309156418
loss_c:0.8135005831718445
tensor(1.2813, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020096605643630028
loss_c:0.7740017175674438
tensor(1.2665, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018701469525694847
loss_c:0.7693808078765869
tensor(1.2574, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01845250464975834
loss_c:0.8159083127975464
tensor(1.2829, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023826438933610916
loss_c:0.9042202830314636
tensor(1.3582, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022451264783740044
loss_c:0.7399215698242188
tensor(1.2579, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022133368998765945
loss_c:0.7616672515869141
tensor(1.2688, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011462927795946598
loss_c:0.8426088094711304
tensor(1.2657, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015877265483140945
loss_c:0.7589162588119507
tensor(1.2382, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0291895754635334
loss_c:0.9239608645439148
tensor(1.3946, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015998605638742447
loss_c:0.7845216989517212
tensor(1.2534, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011504882015287876
loss_c:0.6976680159568787
tensor(1.1827, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01990330219268799
loss_c:1.0465031862258911
tensor(1.4216, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014097566716372967
loss_c:0.9448256492614746
tensor(1.3362, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020263712853193283
loss_c:0.8423060774803162
tensor(1.3063, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03185111656785011
loss_c:0.8492066264152527
tensor(1.3645, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011823521926999092
loss_c:0.6705276370048523
tensor(1.1685, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03347597271203995
loss_c:0.893479585647583
tensor(1.3975, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015280894935131073
loss_c:0.8699334859848022
tensor(1.2987, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024463629350066185
loss_c:0.7402123808860779
tensor(1.2677, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013798758387565613
loss_c:0.7349969744682312
tensor(1.2146, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02586934342980385
loss_c:0.7007209062576294
tensor(1.2517, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011427673511207104
loss_c:0.7769376039505005
tensor(1.2274, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019325269386172295
loss_c:0.9372442960739136
tensor(1.3561, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03959982469677925
loss_c:0.9175733327865601
tensor(1.4403, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022707514464855194
loss_c:0.9078556895256042
tensor(1.3552, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016095077618956566
loss_c:0.7280687689781189
tensor(1.2214, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036111488938331604
loss_c:1.089125394821167
tensor(1.5218, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036681536585092545
loss_c:0.7551146745681763
tensor(1.3336, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02466035820543766
loss_c:0.8909620642662048
tensor(1.3546, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020932096987962723
loss_c:0.9897577166557312
tensor(1.3934, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013746990822255611
loss_c:0.8110198378562927
tensor(1.2580, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027945786714553833
loss_c:0.7746543288230896
tensor(1.3036, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01583443582057953
loss_c:0.8560972213745117
tensor(1.2934, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021861767396330833
loss_c:0.779548168182373
tensor(1.2780, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02634720504283905
loss_c:0.7858096957206726
tensor(1.3024, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022388271987438202
loss_c:0.9255244135856628
tensor(1.3633, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019748002290725708
loss_c:0.8339409828186035
tensor(1.2991, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018230313435196877
loss_c:0.8552297353744507
tensor(1.3041, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02625790610909462
loss_c:0.9562408328056335
tensor(1.3985, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02027379348874092
loss_c:0.7677037119865417
tensor(1.2640, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02807009220123291
loss_c:0.8573209643363953
tensor(1.3508, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031828999519348145
loss_c:0.806891143321991
tensor(1.3396, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022083895280957222
loss_c:0.8996114730834961
tensor(1.3470, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017469773069024086
loss_c:0.8160055875778198
tensor(1.2785, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013978107832372189
loss_c:0.8169851303100586
tensor(1.2630, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024579841643571854
loss_c:0.7633672952651978
tensor(1.2815, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019713323563337326
loss_c:0.8672436475753784
tensor(1.3177, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015278245322406292
loss_c:0.8249186277389526
tensor(1.2735, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012451608665287495
loss_c:0.9190574884414673
tensor(1.3136, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01920907385647297
loss_c:0.7942529916763306
tensor(1.2743, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01589060202240944
loss_c:0.8793017268180847
tensor(1.3069, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0152441980317235
loss_c:0.7574776411056519
tensor(1.2353, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014423342421650887
loss_c:0.7786071300506592
tensor(1.2434, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019963020458817482
loss_c:0.7665764689445496
tensor(1.2621, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016305437311530113
loss_c:0.9480471611022949
tensor(1.3475, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01980465278029442
loss_c:0.8048800826072693
tensor(1.2830, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026635009795427322
loss_c:1.0540170669555664
tensor(1.4549, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031908806413412094
loss_c:0.8706318140029907
tensor(1.3760, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0964181050658226
loss_c:0.8356022834777832
tensor(1.6549, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03396446257829666
loss_c:0.8323604464530945
tensor(1.3637, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01885439082980156
loss_c:0.8649429082870483
tensor(1.3124, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013362285681068897
loss_c:0.7550159692764282
tensor(1.2256, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024070214480161667
loss_c:0.8277058601379395
tensor(1.3154, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01698574423789978
loss_c:0.941112220287323
tensor(1.3468, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02291949838399887
loss_c:0.7693182826042175
tensor(1.2773, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02975771576166153
loss_c:0.7641205787658691
tensor(1.3054, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015780922025442123
loss_c:0.8622292280197144
tensor(1.2972, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029354775324463844
loss_c:0.8430700302124023
tensor(1.3478, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020995300263166428
loss_c:0.8197572231292725
tensor(1.2970, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013649641536176205
loss_c:0.7398327589035034
tensor(1.2191, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02500857785344124
loss_c:0.8161944150924683
tensor(1.3130, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021082621067762375
loss_c:0.8219722509384155
tensor(1.2986, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01864863745868206
loss_c:0.8868885040283203
tensor(1.3241, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02253579907119274
loss_c:0.9044188261032104
tensor(1.3514, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018012389540672302
loss_c:0.7238249182701111
tensor(1.2297, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011694090440869331
loss_c:0.7590335607528687
tensor(1.2212, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017812468111515045
loss_c:0.7561997771263123
tensor(1.2470, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0161685049533844
loss_c:0.763647198677063
tensor(1.2438, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019597062841057777
loss_c:0.7303222417831421
tensor(1.2404, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02525707334280014
loss_c:0.9158210158348083
tensor(1.3702, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013213448226451874
loss_c:0.7487082481384277
tensor(1.2219, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018932580947875977
loss_c:0.7549190521240234
tensor(1.2511, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02082265354692936
loss_c:1.0145626068115234
tensor(1.4061, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02124343439936638
loss_c:0.8419191241264343
tensor(1.3105, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023381240665912628
loss_c:0.9896010160446167
tensor(1.4036, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01640263944864273
loss_c:0.7892566919326782
tensor(1.2589, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03247545659542084
loss_c:0.9725505113601685
tensor(1.4351, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015071336179971695
loss_c:0.787665069103241
tensor(1.2520, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01823195070028305
loss_c:0.8278398513793945
tensor(1.2889, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024067198857665062
loss_c:0.9224037528038025
tensor(1.3687, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017092162743210793
loss_c:0.8081725835800171
tensor(1.2727, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01698867604136467
loss_c:0.6598274111747742
tensor(1.1885, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014094318263232708
loss_c:0.7339473962783813
tensor(1.2172, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017131656408309937
loss_c:0.7289792895317078
tensor(1.2281, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01598949544131756
loss_c:0.7053550481796265
tensor(1.2095, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024409068748354912
loss_c:0.9106324911117554
tensor(1.3638, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017612850293517113
loss_c:0.7733638286590576
tensor(1.2552, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037886105477809906
loss_c:1.033584713935852
tensor(1.4950, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09419795125722885
loss_c:0.8894294500350952
tensor(1.6709, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018916593864560127
loss_c:0.7834002375602722
tensor(1.2668, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030237378552556038
loss_c:0.836683452129364
tensor(1.3484, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02654816210269928
loss_c:0.7982302904129028
tensor(1.3098, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019267916679382324
loss_c:0.8105732798576355
tensor(1.2839, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018210576847195625
loss_c:0.7159273624420166
tensor(1.2256, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02643571048974991
loss_c:0.7501683235168457
tensor(1.2820, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0187633465975523
loss_c:0.7480038404464722
tensor(1.2463, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01779402233660221
loss_c:0.9245520830154419
tensor(1.3420, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018670858815312386
loss_c:0.8460359573364258
tensor(1.3014, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01781737431883812
loss_c:0.9077967405319214
tensor(1.3327, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04482945799827576
loss_c:0.8117241859436035
tensor(1.3988, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018948061391711235
loss_c:0.8555688858032227
tensor(1.3081, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014942619949579239
loss_c:0.8062992095947266
tensor(1.2624, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02235710248351097
loss_c:0.7865898013114929
tensor(1.2842, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028903529047966003
loss_c:0.7101308703422546
tensor(1.2699, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01348610408604145
loss_c:0.7411081790924072
tensor(1.2190, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013521763496100903
loss_c:0.7810672521591187
tensor(1.2418, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015242701396346092
loss_c:0.7596803903579712
tensor(1.2373, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015826143324375153
loss_c:0.8117668032646179
tensor(1.2695, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018024802207946777
loss_c:0.9430977702140808
tensor(1.3540, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016610242426395416
loss_c:0.8615998029708862
tensor(1.3013, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021578289568424225
loss_c:0.8585127592086792
tensor(1.3216, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012588715180754662
loss_c:0.7278966903686523
tensor(1.2071, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032860010862350464
loss_c:0.7962343692779541
tensor(1.3365, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014746355824172497
loss_c:0.7850756645202637
tensor(1.2492, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013459116220474243
loss_c:0.6765086054801941
tensor(1.1815, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015837514773011208
loss_c:0.7474405169487
tensor(1.2325, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036582350730895996
loss_c:0.9510535001754761
tensor(1.4418, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012364860624074936
loss_c:0.7091106176376343
tensor(1.1949, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02207620069384575
loss_c:0.7255258560180664
tensor(1.2479, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020203037187457085
loss_c:0.7523342967033386
tensor(1.2548, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022910472005605698
loss_c:0.7003122568130493
tensor(1.2371, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016913238912820816
loss_c:0.8253620862960815
tensor(1.2817, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042407747358083725
loss_c:0.7884246706962585
tensor(1.3756, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019485527649521828
loss_c:0.8932956457138062
tensor(1.3323, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014724653214216232
loss_c:0.7850849032402039
tensor(1.2487, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02597920224070549
loss_c:0.9567161798477173
tensor(1.3981, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013439401984214783
loss_c:0.8180360198020935
tensor(1.2618, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017162086442112923
loss_c:0.8367184996604919
tensor(1.2893, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01877441443502903
loss_c:0.7446614503860474
tensor(1.2436, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01644900254905224
loss_c:0.7860445976257324
tensor(1.2569, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025230394676327705
loss_c:0.7605594396591187
tensor(1.2820, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026535533368587494
loss_c:0.7775118350982666
tensor(1.2977, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01443012710660696
loss_c:0.791968584060669
tensor(1.2511, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02669527381658554
loss_c:0.9667691588401794
tensor(1.4074, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025257954373955727
loss_c:0.9953359365463257
tensor(1.4174, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031144673004746437
loss_c:0.788761556148529
tensor(1.3252, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01994572952389717
loss_c:0.9201542139053345
tensor(1.3499, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024686740711331367
loss_c:0.7678354978561401
tensor(1.2838, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01744874007999897
loss_c:0.8207273483276367
tensor(1.2813, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017210548743605614
loss_c:0.7650240659713745
tensor(1.2482, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027271311730146408
loss_c:0.9676398038864136
tensor(1.4103, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015520920976996422
loss_c:0.8995344042778015
tensor(1.3178, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020564289763569832
loss_c:0.7863442301750183
tensor(1.2757, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01626107469201088
loss_c:0.8583006858825684
tensor(1.2974, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019692473113536835
loss_c:0.8338792324066162
tensor(1.2990, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03927212953567505
loss_c:1.1391942501068115
tensor(1.5628, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01379639096558094
loss_c:0.72966068983078
tensor(1.2126, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0164839755743742
loss_c:0.8736228346824646
tensor(1.3070, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02908339723944664
loss_c:0.8272351622581482
tensor(1.3379, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03808721527457237
loss_c:0.8015364408493042
tensor(1.3642, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018486427143216133
loss_c:0.8134498596191406
tensor(1.2818, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030269181355834007
loss_c:0.7864527702331543
tensor(1.3200, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020297108218073845
loss_c:0.8506665229797363
tensor(1.3112, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016852930188179016
loss_c:0.9609988927841187
tensor(1.3583, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016890544444322586
loss_c:0.8972969055175781
tensor(1.3222, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02021682821214199
loss_c:0.8569418787956238
tensor(1.3144, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018775440752506256
loss_c:0.8879868388175964
tensor(1.3254, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017794175073504448
loss_c:0.87042236328125
tensor(1.3110, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03160163760185242
loss_c:0.7969397306442261
tensor(1.3321, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019366957247257233
loss_c:0.8820397257804871
tensor(1.3247, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0249193012714386
loss_c:0.9430581331253052
tensor(1.3842, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015315675176680088
loss_c:0.8522230386734009
tensor(1.2894, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03614809364080429
loss_c:0.8349465131759644
tensor(1.3741, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03840521723031998
loss_c:0.8985357284545898
tensor(1.4201, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02502836100757122
loss_c:0.9153745174407959
tensor(1.3689, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01678975112736225
loss_c:0.7421388030052185
tensor(1.2344, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016160454601049423
loss_c:0.7571749687194824
tensor(1.2400, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015520909801125526
loss_c:0.9639388918876648
tensor(1.3531, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026991907507181168
loss_c:0.8893544673919678
tensor(1.3630, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026175471022725105
loss_c:0.7819284796714783
tensor(1.2991, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036471929401159286
loss_c:0.9209566116333008
tensor(1.4234, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016266752034425735
loss_c:0.7062076330184937
tensor(1.2122, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026327455416321754
loss_c:1.1195076704025269
tensor(1.4886, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02103394828736782
loss_c:0.9103261828422546
tensor(1.3478, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01576802134513855
loss_c:0.7385354042053223
tensor(1.2283, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026455361396074295
loss_c:0.850291907787323
tensor(1.3386, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018356723710894585
loss_c:0.8093354105949402
tensor(1.2794, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01575378142297268
loss_c:0.8446208238601685
tensor(1.2874, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013711568899452686
loss_c:0.8182350993156433
tensor(1.2636, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03223045915365219
loss_c:0.8181349635124207
tensor(1.3466, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029569871723651886
loss_c:0.7717564105987549
tensor(1.3088, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015662433579564095
loss_c:0.9229124784469604
tensor(1.3306, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014788704924285412
loss_c:0.7421243190765381
tensor(1.2260, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032985225319862366
loss_c:0.832288920879364
tensor(1.3578, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012954821810126305
loss_c:0.7446910738945007
tensor(1.2192, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016488879919052124
loss_c:0.7025599479675293
tensor(1.2116, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019420573487877846
loss_c:0.8972283601760864
tensor(1.3332, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017642764374613762
loss_c:0.7563640475273132
tensor(1.2466, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032233722507953644
loss_c:0.8595802187919617
tensor(1.3698, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021883845329284668
loss_c:0.7955436110496521
tensor(1.2875, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02796785719692707
loss_c:0.9601354598999023
tensor(1.4068, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016811029985547066
loss_c:0.7546969652175903
tensor(1.2418, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021530326455831528
loss_c:0.8962485194206238
tensor(1.3422, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02628670260310173
loss_c:0.8923954367637634
tensor(1.3615, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03174980357289314
loss_c:0.8418352603912354
tensor(1.3577, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02263021469116211
loss_c:0.7769899368286133
tensor(1.2804, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01501463819295168
loss_c:0.8110716342926025
tensor(1.2653, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014160370454192162
loss_c:0.7127026319503784
tensor(1.2063, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017509041354060173
loss_c:0.7612592577934265
tensor(1.2485, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018052197992801666
loss_c:0.8955588340759277
tensor(1.3263, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020731007680296898
loss_c:0.8642975091934204
tensor(1.3208, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01909760758280754
loss_c:0.7515344619750977
tensor(1.2501, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01772127114236355
loss_c:0.7995680570602417
tensor(1.2708, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018756162375211716
loss_c:0.7964379191398621
tensor(1.2737, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015254711732268333
loss_c:0.7975460886955261
tensor(1.2585, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015181498602032661
loss_c:0.8132710456848145
tensor(1.2670, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01741180568933487
loss_c:0.8918327689170837
tensor(1.3213, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019742976874113083
loss_c:0.7801319360733032
tensor(1.2689, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032637257128953934
loss_c:0.7999048233032227
tensor(1.3386, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024473724886775017
loss_c:1.0501008033752441
tensor(1.4427, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01818222552537918
loss_c:0.7477353811264038
tensor(1.2434, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017165111377835274
loss_c:0.6933133006095886
tensor(1.2081, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013283312320709229
loss_c:0.8167033195495605
tensor(1.2600, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014962257817387581
loss_c:0.8161789774894714
tensor(1.2673, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041619960218667984
loss_c:0.829209566116333
tensor(1.3964, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024016566574573517
loss_c:0.8961877226829529
tensor(1.3539, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029444843530654907
loss_c:0.8079090118408203
tensor(1.3288, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025277724489569664
loss_c:0.8004653453826904
tensor(1.3055, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01744966022670269
loss_c:0.8866928815841675
tensor(1.3185, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01856621541082859
loss_c:0.7440711855888367
tensor(1.2429, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02935933694243431
loss_c:0.8737232089042664
tensor(1.3656, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018465712666511536
loss_c:0.9156924486160278
tensor(1.3396, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02811003290116787
loss_c:0.8301234245300293
tensor(1.3352, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01750005967915058
loss_c:0.8081668615341187
tensor(1.2743, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1414974182844162
loss_c:0.9711310267448425
tensor(1.9321, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015004678629338741
loss_c:0.75797438621521
tensor(1.2347, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042219653725624084
loss_c:0.8971402049064636
tensor(1.4364, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02157779224216938
loss_c:0.8742859363555908
tensor(1.3304, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015810271725058556
loss_c:0.8317769765853882
tensor(1.2806, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01626478135585785
loss_c:0.7937631607055664
tensor(1.2613, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01547540258616209
loss_c:0.8054099082946777
tensor(1.2645, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022070033475756645
loss_c:0.7897736430168152
tensor(1.2848, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028619136661291122
loss_c:0.7869218587875366
tensor(1.3121, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014355786144733429
loss_c:0.7736581563949585
tensor(1.2419, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018345044925808907
loss_c:0.7114218473434448
tensor(1.2242, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019019223749637604
loss_c:0.8342437744140625
tensor(1.2967, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025575924664735794
loss_c:0.8014904856681824
tensor(1.3068, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017632050439715385
loss_c:0.7700408697128296
tensor(1.2543, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02802763693034649
loss_c:0.7270835638046265
tensor(1.2753, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015639446675777435
loss_c:0.7298304438591003
tensor(1.2228, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025404304265975952
loss_c:0.9848498702049255
tensor(1.4101, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018893325701355934
loss_c:0.7877156138420105
tensor(1.2698, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019800882786512375
loss_c:0.8537958860397339
tensor(1.3113, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01997986249625683
loss_c:0.8253334760665894
tensor(1.2959, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019503287971019745
loss_c:0.8314489126205444
tensor(1.2973, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02597745694220066
loss_c:0.8330920934677124
tensor(1.3265, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01960773393511772
loss_c:0.9198594093322754
tensor(1.3480, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02348843216896057
loss_c:0.9147695899009705
tensor(1.3620, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022773928940296173
loss_c:0.8812560439109802
tensor(1.3399, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024448389187455177
loss_c:0.8501055240631104
tensor(1.3295, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016846980899572372
loss_c:0.8429862856864929
tensor(1.2922, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018376752734184265
loss_c:0.8791989088058472
tensor(1.3194, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025329630821943283
loss_c:0.9008382558822632
tensor(1.3621, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030967647209763527
loss_c:0.7663302421569824
tensor(1.3105, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017934419214725494
loss_c:0.8273336887359619
tensor(1.2880, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036868806928396225
loss_c:0.8449985384941101
tensor(1.3809, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014002439565956593
loss_c:0.8074846267700195
tensor(1.2596, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016058681532740593
loss_c:0.8055512309074402
tensor(1.2675, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020723596215248108
loss_c:0.8072608709335327
tensor(1.2888, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01855975203216076
loss_c:0.8112413883209229
tensor(1.2816, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020242350175976753
loss_c:1.012654185295105
tensor(1.4030, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02124207653105259
loss_c:0.7043022513389587
tensor(1.2329, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01775454543530941
loss_c:0.7974040508270264
tensor(1.2702, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01535942405462265
loss_c:0.7838456630706787
tensor(1.2520, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014901417307555676
loss_c:0.7441849708557129
tensor(1.2275, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01809638738632202
loss_c:0.8406474590301514
tensor(1.2961, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024305973201990128
loss_c:0.9238120913505554
tensor(1.3705, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015256764367222786
loss_c:0.8354660272598267
tensor(1.2805, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02324243262410164
loss_c:0.8012751936912537
tensor(1.2965, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01592976599931717
loss_c:0.7492603063583374
tensor(1.2346, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013927623629570007
loss_c:0.7895116806030273
tensor(1.2484, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021698610857129097
loss_c:0.8022967576980591
tensor(1.2902, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014845133759081364
loss_c:0.7513965368270874
tensor(1.2308, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01666385680437088
loss_c:0.775519073009491
tensor(1.2525, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041388511657714844
loss_c:0.9050022959709167
tensor(1.4366, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01573142781853676
loss_c:0.958000659942627
tensor(1.3517, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01688072457909584
loss_c:0.7785494327545166
tensor(1.2551, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027322104200720787
loss_c:1.0310637950897217
tensor(1.4451, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016027480363845825
loss_c:0.8154642581939697
tensor(1.2721, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016099290922284126
loss_c:0.8590244054794312
tensor(1.2971, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014743619598448277
loss_c:0.7815997004508972
tensor(1.2471, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014889144338667393
loss_c:0.7492503523826599
tensor(1.2294, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019634298980236053
loss_c:0.7729787230491638
tensor(1.2642, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030789202079176903
loss_c:0.905062198638916
tensor(1.3896, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032102812081575394
loss_c:0.7958115935325623
tensor(1.3337, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014180862344801426
loss_c:0.8968417048454285
tensor(1.3095, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017433591187000275
loss_c:0.7268996238708496
tensor(1.2281, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019850457087159157
loss_c:0.7359237670898438
tensor(1.2442, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11279895901679993
loss_c:0.9671141505241394
tensor(1.7984, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037336017936468124
loss_c:0.7693783044815063
tensor(1.3425, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02335047535598278
loss_c:0.8319807052612305
tensor(1.3144, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014083324000239372
loss_c:0.7200283408164978
tensor(1.2093, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017626771703362465
loss_c:0.7019969820976257
tensor(1.2151, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013390530832111835
loss_c:0.7510044574737549
tensor(1.2239, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014916312880814075
loss_c:0.8446102142333984
tensor(1.2839, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015472283586859703
loss_c:0.7922117114067078
tensor(1.2566, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0218710508197546
loss_c:1.0109621286392212
tensor(1.4095, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017663108184933662
loss_c:0.8431625366210938
tensor(1.2954, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021426083520054817
loss_c:1.0260522365570068
tensor(1.4161, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016803497448563576
loss_c:0.7161239385604858
tensor(1.2194, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020850522443652153
loss_c:0.8182334899902344
tensor(1.2954, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025607915595173836
loss_c:0.7993839979171753
tensor(1.3059, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016293345019221306
loss_c:0.7916327714920044
tensor(1.2600, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019832052290439606
loss_c:0.9017855525016785
tensor(1.3383, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021765651181340218
loss_c:0.7798928022384644
tensor(1.2777, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10088484734296799
loss_c:0.9824347496032715
tensor(1.7457, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.1221204474568367
loss_c:0.9350471496582031
tensor(1.8120, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030377011746168137
loss_c:0.8391423225402832
tensor(1.3494, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02912072278559208
loss_c:0.8363789319992065
tensor(1.3421, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020079853013157845
loss_c:0.8891703486442566
tensor(1.3325, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020584791898727417
loss_c:0.8511573076248169
tensor(1.3132, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026678970083594322
loss_c:0.8121868968009949
tensor(1.3175, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019300464540719986
loss_c:0.9754656553268433
tensor(1.3781, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02837701328098774
loss_c:0.8660244345664978
tensor(1.3551, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013723826967179775
loss_c:0.7958711385726929
tensor(1.2531, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01605597324669361
loss_c:0.8258804082870483
tensor(1.2801, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01922285184264183
loss_c:0.7379719018936157
tensor(1.2440, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01614440232515335
loss_c:0.6994776725769043
tensor(1.2094, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017230821773409843
loss_c:0.7958027720451355
tensor(1.2683, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021689817309379578
loss_c:0.7788060903549194
tensor(1.2775, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021283159032464027
loss_c:0.8039201498031616
tensor(1.2900, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01691468060016632
loss_c:0.9762260317802429
tensor(1.3687, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017091872170567513
loss_c:0.8266846537590027
tensor(1.2851, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01866748183965683
loss_c:0.8815760612487793
tensor(1.3227, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016023268923163414
loss_c:0.7451604604721069
tensor(1.2346, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019208794459700584
loss_c:0.7802520990371704
tensor(1.2678, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027249712496995926
loss_c:0.874374270439148
tensor(1.3549, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02756842039525509
loss_c:0.8165695071220398
tensor(1.3236, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013912093825638294
loss_c:0.6844427585601807
tensor(1.1913, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015242962166666985
loss_c:0.7517623901367188
tensor(1.2348, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025077175348997116
loss_c:0.9381073713302612
tensor(1.3817, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014489356428384781
loss_c:0.7026911973953247
tensor(1.2038, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016273507848381996
loss_c:0.8239883184432983
tensor(1.2798, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0341346301138401
loss_c:0.8244149088859558
tensor(1.3561, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018594110384583473
loss_c:0.7000755667686462
tensor(1.2195, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024814065545797348
loss_c:0.81095951795578
tensor(1.3088, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03297491744160652
loss_c:0.7870407104492188
tensor(1.3301, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017962459474802017
loss_c:0.8566078543663025
tensor(1.3053, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017035651952028275
loss_c:0.7871147990226746
tensor(1.2619, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018484871834516525
loss_c:0.7943331599235535
tensor(1.2721, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016047464683651924
loss_c:0.772432804107666
tensor(1.2492, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03169221431016922
loss_c:0.9794163703918457
tensor(1.4341, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018045412376523018
loss_c:0.8181571960449219
tensor(1.2837, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027154725044965744
loss_c:0.8640264272689819
tensor(1.3490, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016019394621253014
loss_c:0.7809483408927917
tensor(1.2537, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016244499012827873
loss_c:0.792831540107727
tensor(1.2614, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022083602845668793
loss_c:0.7173730731010437
tensor(1.2437, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022325268015265465
loss_c:0.8062447905540466
tensor(1.2953, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02220636047422886
loss_c:0.8365468978881836
tensor(1.3120, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017014872282743454
loss_c:0.8708979487419128
tensor(1.3090, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019468994811177254
loss_c:0.8151969909667969
tensor(1.2879, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021129122003912926
loss_c:0.8518093824386597
tensor(1.3160, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03887192904949188
loss_c:0.9180788993835449
tensor(1.4312, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017356475815176964
loss_c:0.783704936504364
tensor(1.2607, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014062034897506237
loss_c:0.7094922065734863
tensor(1.2040, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.034022171050310135
loss_c:0.9152545928955078
tensor(1.4086, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021607814356684685
loss_c:0.8343491554260254
tensor(1.3081, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02329360693693161
loss_c:0.9750284552574158
tensor(1.3957, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017295166850090027
loss_c:0.6603460907936096
tensor(1.1900, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015783187001943588
loss_c:0.754368782043457
tensor(1.2370, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021447373554110527
loss_c:0.7677936553955078
tensor(1.2694, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028636932373046875
loss_c:0.8610492944717407
tensor(1.3542, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019374584779143333
loss_c:0.9503874182701111
tensor(1.3644, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014358319342136383
loss_c:0.7863426208496094
tensor(1.2488, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017207138240337372
loss_c:0.7193018794059753
tensor(1.2231, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01569519005715847
loss_c:0.8770303130149841
tensor(1.3063, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021017450839281082
loss_c:0.8878251314163208
tensor(1.3359, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10536127537488937
loss_c:0.8784197568893433
tensor(1.7036, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019813263788819313
loss_c:0.7851449847221375
tensor(1.2721, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0210876502096653
loss_c:0.7869953513145447
tensor(1.2788, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015311641618609428
loss_c:0.8809899091720581
tensor(1.3070, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015984995290637016
loss_c:0.8391590118408203
tensor(1.2861, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01845841109752655
loss_c:0.8137848377227783
tensor(1.2826, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022134501487016678
loss_c:0.8297322988510132
tensor(1.3078, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017189187929034233
loss_c:0.7560619115829468
tensor(1.2441, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024599049240350723
loss_c:1.0653955936431885
tensor(1.4527, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01878713071346283
loss_c:0.7452371120452881
tensor(1.2450, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021832184866070747
loss_c:0.703075110912323
tensor(1.2344, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04586184024810791
loss_c:0.933944582939148
tensor(1.4710, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029889296740293503
loss_c:0.8300167918205261
tensor(1.3419, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019335033372044563
loss_c:0.8069480657577515
tensor(1.2826, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017953479662537575
loss_c:0.7119719386100769
tensor(1.2226, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01637171395123005
loss_c:0.7895467281341553
tensor(1.2598, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016055261716246605
loss_c:0.7638181447982788
tensor(1.2438, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021560709923505783
loss_c:0.963411808013916
tensor(1.3813, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013515075668692589
loss_c:0.6912045478820801
tensor(1.1914, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015637613832950592
loss_c:0.7617428302764893
tensor(1.2407, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03539140522480011
loss_c:0.8457444906234741
tensor(1.3749, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015554327517747879
loss_c:0.7623087763786316
tensor(1.2406, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01522336807101965
loss_c:0.760698676109314
tensor(1.2382, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029138505458831787
loss_c:0.6923881769180298
tensor(1.2603, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014735694974660873
loss_c:0.8662782907485962
tensor(1.2961, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030661653727293015
loss_c:0.7633768320083618
tensor(1.3074, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0214915182441473
loss_c:0.9375693202018738
tensor(1.3665, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018061095848679543
loss_c:0.7892687320709229
tensor(1.2667, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012969731353223324
loss_c:0.8567037582397461
tensor(1.2828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02133883163332939
loss_c:0.8954523801803589
tensor(1.3418, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03269059211015701
loss_c:0.7830295562744141
tensor(1.3276, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016110043972730637
loss_c:0.8313319087028503
tensor(1.2821, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036237165331840515
loss_c:0.9610639810562134
tensor(1.4451, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02797195501625538
loss_c:0.784212589263916
tensor(1.3075, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03619776666164398
loss_c:1.0572845935821533
tensor(1.4998, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021492689847946167
loss_c:0.989051103591919
tensor(1.3958, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027288714423775673
loss_c:0.7403389811515808
tensor(1.2795, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013947314582765102
loss_c:0.823039710521698
tensor(1.2678, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017799457535147667
loss_c:0.85451340675354
tensor(1.3027, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027837129309773445
loss_c:0.8549014329910278
tensor(1.3472, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028044473379850388
loss_c:0.8587896227836609
tensor(1.3503, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02210915833711624
loss_c:0.9238870143890381
tensor(1.3611, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01960550621151924
loss_c:0.855451226234436
tensor(1.3112, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.10439411550760269
loss_c:0.9083477854728699
tensor(1.7145, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021824952214956284
loss_c:0.7005078196525574
tensor(1.2332, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01756931282579899
loss_c:0.9132103323936462
tensor(1.3350, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01356053352355957
loss_c:0.7363435626029968
tensor(1.2176, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013695347122848034
loss_c:0.7047070264816284
tensor(1.2004, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026685087010264397
loss_c:0.8276799917221069
tensor(1.3264, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036123234778642654
loss_c:0.8026818037033081
tensor(1.3533, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021238097921013832
loss_c:0.9388073682785034
tensor(1.3655, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014338726177811623
loss_c:0.8284206390380859
tensor(1.2734, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015213307924568653
loss_c:0.7591201663017273
tensor(1.2380, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022003943100571632
loss_c:0.803183913230896
tensor(1.2923, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018818847835063934
loss_c:0.7970856428146362
tensor(1.2751, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030369922518730164
loss_c:0.7766846418380737
tensor(1.3135, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02037210576236248
loss_c:0.7992235422134399
tensor(1.2830, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024278828874230385
loss_c:0.7007099986076355
tensor(1.2442, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.11131748557090759
loss_c:0.8728581666946411
tensor(1.7173, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015664108097553253
loss_c:0.8449203968048096
tensor(1.2886, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02825714834034443
loss_c:0.7960569262504578
tensor(1.3151, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016527295112609863
loss_c:0.77594393491745
tensor(1.2535, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027083512395620346
loss_c:0.9395136833190918
tensor(1.3912, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021771179512143135
loss_c:0.8086807131767273
tensor(1.2945, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01605246029794216
loss_c:0.806181788444519
tensor(1.2688, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014587551355361938
loss_c:0.7261813879013062
tensor(1.2173, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017894139513373375
loss_c:0.7917298078536987
tensor(1.2685, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017885074019432068
loss_c:0.7979269027709961
tensor(1.2720, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01710602082312107
loss_c:0.8053142428398132
tensor(1.2729, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03070148080587387
loss_c:0.9393123388290405
tensor(1.4066, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01709999516606331
loss_c:0.7475337982177734
tensor(1.2400, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021237695589661598
loss_c:0.9322651624679565
tensor(1.3625, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016509849578142166
loss_c:0.7325561046600342
tensor(1.2290, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01781005784869194
loss_c:0.7217111587524414
tensor(1.2283, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018653923645615578
loss_c:0.861240804195404
tensor(1.3111, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023307237774133682
loss_c:0.6667436361312866
tensor(1.2203, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04228078946471214
loss_c:0.8413125276565552
tensor(1.4004, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014899013563990593
loss_c:0.8833379745483398
tensor(1.3077, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03707585483789444
loss_c:0.8968609571456909
tensor(1.4099, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017595522105693817
loss_c:0.7761105298995972
tensor(1.2581, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016983725130558014
loss_c:0.7522753477096558
tensor(1.2419, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01402050070464611
loss_c:0.8903735876083374
tensor(1.3079, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03521483764052391
loss_c:0.9955651164054871
tensor(1.4584, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017718568444252014
loss_c:0.8250924348831177
tensor(1.2864, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01561908982694149
loss_c:0.7309993505477905
tensor(1.2238, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030735498294234276
loss_c:0.9461019039154053
tensor(1.4111, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01886156015098095
loss_c:0.8948698043823242
tensor(1.3310, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027978258207440376
loss_c:0.9079817533493042
tensor(1.3775, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028078464791178703
loss_c:0.9214271306991577
tensor(1.3856, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01680782251060009
loss_c:0.7892357707023621
tensor(1.2620, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017478231340646744
loss_c:0.7430793642997742
tensor(1.2387, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012458937242627144
loss_c:0.7876377105712891
tensor(1.2424, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02418169379234314
loss_c:0.7748597860336304
tensor(1.2855, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018160376697778702
loss_c:0.8077000975608826
tensor(1.2782, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018848026171326637
loss_c:0.7192608714103699
tensor(1.2310, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029164165258407593
loss_c:0.8504754900932312
tensor(1.3500, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014550747349858284
loss_c:0.753996729850769
tensor(1.2320, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02315686270594597
loss_c:0.8120171427726746
tensor(1.3022, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01928432658314705
loss_c:0.7997465133666992
tensor(1.2784, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016266562044620514
loss_c:0.7689574956893921
tensor(1.2478, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024527279660105705
loss_c:0.9948521852493286
tensor(1.4121, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015188515186309814
loss_c:0.8884908556938171
tensor(1.3110, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01749633066356182
loss_c:0.8480555415153503
tensor(1.2980, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015760798007249832
loss_c:0.7850426435470581
tensor(1.2545, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01794009655714035
loss_c:0.996868371963501
tensor(1.3844, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021883035078644753
loss_c:0.9677583575248718
tensor(1.3850, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023547803983092308
loss_c:0.679287314414978
tensor(1.2286, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01482316106557846
loss_c:0.7499551773071289
tensor(1.2303, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019871152937412262
loss_c:0.7642928957939148
tensor(1.2606, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020968498662114143
loss_c:0.9360575079917908
tensor(1.3629, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022202424705028534
loss_c:0.8352469205856323
tensor(1.3111, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018928028643131256
loss_c:0.8690943717956543
tensor(1.3158, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019778737798333168
loss_c:0.7976765632629395
tensor(1.2791, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020938970148563385
loss_c:0.7810378074645996
tensor(1.2748, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016311630606651306
loss_c:0.7667176723480225
tensor(1.2461, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035480041056871414
loss_c:0.8172285556793213
tensor(1.3601, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017084795981645584
loss_c:0.7849764823913574
tensor(1.2598, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018290871754288673
loss_c:0.7139875292778015
tensor(1.2249, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020088685676455498
loss_c:0.7424917221069336
tensor(1.2491, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024826254695653915
loss_c:1.0962145328521729
tensor(1.4709, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020893556997179985
loss_c:0.768593966960907
tensor(1.2674, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03051871992647648
loss_c:0.8510187864303589
tensor(1.3573, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027069879695773125
loss_c:0.789854884147644
tensor(1.3072, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029768595471978188
loss_c:0.7535207271575928
tensor(1.2987, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016742076724767685
loss_c:0.8447605967521667
tensor(1.2920, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016107207164168358
loss_c:0.7513965368270874
tensor(1.2362, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01628878526389599
loss_c:0.7975663542747498
tensor(1.2632, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015792831778526306
loss_c:0.8203670382499695
tensor(1.2739, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042205892503261566
loss_c:0.8380481004714966
tensor(1.4026, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036283720284700394
loss_c:0.9049167633056641
tensor(1.4140, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020899467170238495
loss_c:0.8194645643234253
tensor(1.2963, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016219865530729294
loss_c:0.8515133857727051
tensor(1.2935, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03683136776089668
loss_c:0.7846607565879822
tensor(1.3480, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024576418101787567
loss_c:0.6817218661308289
tensor(1.2345, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021522125229239464
loss_c:0.948176383972168
tensor(1.3723, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020324522629380226
loss_c:0.8755266070365906
tensor(1.3256, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014641910791397095
loss_c:0.7876436114311218
tensor(1.2503, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027024155482649803
loss_c:0.8590666651725769
tensor(1.3462, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01870769076049328
loss_c:0.9349956512451172
tensor(1.3522, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020442351698875427
loss_c:0.819368302822113
tensor(1.2942, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013826540671288967
loss_c:0.760905921459198
tensor(1.2315, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05372130870819092
loss_c:0.8612295985221863
tensor(1.4667, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015406189486384392
loss_c:0.7960401773452759
tensor(1.2585, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017504306510090828
loss_c:0.849780261516571
tensor(1.2984, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02022136002779007
loss_c:0.7060984969139099
tensor(1.2290, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017860567197203636
loss_c:0.7292096018791199
tensor(1.2316, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.036879733204841614
loss_c:0.8381872177124023
tensor(1.3782, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03264186903834343
loss_c:0.9045608043670654
tensor(1.3970, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014338682405650616
loss_c:0.78306645154953
tensor(1.2465, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017548739910125732
loss_c:0.8300774097442627
tensor(1.2875, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01440504752099514
loss_c:0.8150047063827515
tensor(1.2650, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021041590720415115
loss_c:0.7974733114242554
tensor(1.2845, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022749485448002815
loss_c:0.729448676109314
tensor(1.2534, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017270654439926147
loss_c:0.9010754823684692
tensor(1.3266, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015565916895866394
loss_c:0.811602771282196
tensor(1.2681, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02317151613533497
loss_c:0.820659339427948
tensor(1.3072, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024697503075003624
loss_c:0.6376543045043945
tensor(1.2098, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016552237793803215
loss_c:0.82078617811203
tensor(1.2777, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02905125543475151
loss_c:0.8323222994804382
tensor(1.3400, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013812310993671417
loss_c:0.778897225856781
tensor(1.2416, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016239600256085396
loss_c:0.757133960723877
tensor(1.2400, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0348258800804615
loss_c:0.8000354766845703
tensor(1.3475, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03260265290737152
loss_c:1.109958529472351
tensor(1.5146, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025068089365959167
loss_c:0.7120989561080933
tensor(1.2537, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04473179951310158
loss_c:0.8762744665145874
tensor(1.4353, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018125807866454124
loss_c:0.8969947099685669
tensor(1.3282, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021120639517903328
loss_c:0.7998201251029968
tensor(1.2861, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02999468892812729
loss_c:0.7861236333847046
tensor(1.3178, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02615048922598362
loss_c:0.7828902006149292
tensor(1.2989, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018567176535725594
loss_c:0.8811529874801636
tensor(1.3212, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024080706760287285
loss_c:0.9714632034301758
tensor(1.3972, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018344806507229805
loss_c:0.8360532522201538
tensor(1.2945, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021568451076745987
loss_c:0.8663463592529297
tensor(1.3261, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020860305055975914
loss_c:0.7584422826766968
tensor(1.2615, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014586208388209343
loss_c:0.7741756439208984
tensor(1.2426, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032824043184518814
loss_c:0.813117265701294
tensor(1.3456, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01985807530581951
loss_c:0.8451945781707764
tensor(1.3064, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022285092622041702
loss_c:0.9801043272018433
tensor(1.3940, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03288011997938156
loss_c:0.8387559652328491
tensor(1.3604, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023226603865623474
loss_c:0.7718102931976318
tensor(1.2796, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03405624255537987
loss_c:0.9189727306365967
tensor(1.4112, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032877467572689056
loss_c:0.8260873556137085
tensor(1.3531, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024594848975539207
loss_c:0.7710797786712646
tensor(1.2853, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01566699706017971
loss_c:0.849663496017456
tensor(1.2905, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01505565270781517
loss_c:0.647607684135437
tensor(1.1732, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012270405888557434
loss_c:0.7005441188812256
tensor(1.1910, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026581590995192528
loss_c:0.8058416247367859
tensor(1.3138, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016494987532496452
loss_c:0.9478673934936523
tensor(1.3500, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02439868077635765
loss_c:0.9669238924980164
tensor(1.3956, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029910443350672722
loss_c:0.8412922620773315
tensor(1.3486, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04210821911692619
loss_c:0.8301863670349121
tensor(1.3960, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033924225717782974
loss_c:0.7858686447143555
tensor(1.3347, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01978321187198162
loss_c:0.8862236738204956
tensor(1.3294, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02913602814078331
loss_c:0.745003879070282
tensor(1.2904, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016007356345653534
loss_c:0.7735376358032227
tensor(1.2490, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021109875291585922
loss_c:1.0181291103363037
tensor(1.4101, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02429540641605854
loss_c:0.8751775026321411
tensor(1.3430, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01602589339017868
loss_c:0.930910587310791
tensor(1.3383, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015681175515055656
loss_c:0.8462914824485779
tensor(1.2889, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016923660412430763
loss_c:0.8039277791976929
tensor(1.2703, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0169416181743145
loss_c:0.836520791053772
tensor(1.2888, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01899584010243416
loss_c:0.9049326181411743
tensor(1.3365, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02339925244450569
loss_c:0.7374565005302429
tensor(1.2612, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01908833347260952
loss_c:0.8644315600395203
tensor(1.3140, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019255030900239944
loss_c:0.785789430141449
tensor(1.2703, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.010532153770327568
loss_c:0.7893616557121277
tensor(1.2339, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030891405418515205
loss_c:0.8035035133361816
tensor(1.3315, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01569526642560959
loss_c:0.7035508155822754
tensor(1.2081, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017548296600580215
loss_c:0.7868295907974243
tensor(1.2633, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011701579205691814
loss_c:0.7521027326583862
tensor(1.2178, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023810628801584244
loss_c:0.8486007452011108
tensor(1.3258, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020821362733840942
loss_c:0.7110428214073181
tensor(1.2348, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01366223394870758
loss_c:0.754863440990448
tensor(1.2277, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03154373914003372
loss_c:0.8476240634918213
tensor(1.3597, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017331967130303383
loss_c:0.8770763278007507
tensor(1.3131, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02633202075958252
loss_c:0.8462727069854736
tensor(1.3358, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014283714815974236
loss_c:0.7843953371047974
tensor(1.2469, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013791417703032494
loss_c:0.7626725435256958
tensor(1.2324, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02358846925199032
loss_c:0.829155445098877
tensor(1.3139, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033620383590459824
loss_c:0.8829635381698608
tensor(1.3894, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015562666580080986
loss_c:0.8049038648605347
tensor(1.2641, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.08811459690332413
loss_c:0.896461009979248
tensor(1.6418, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020185155794024467
loss_c:1.019749402999878
tensor(1.4069, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012271007522940636
loss_c:0.7626520395278931
tensor(1.2255, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017061466351151466
loss_c:0.7249239683151245
tensor(1.2255, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01845267228782177
loss_c:0.7740833163261414
tensor(1.2597, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01880231499671936
loss_c:0.8215031027793884
tensor(1.2882, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04052449390292168
loss_c:0.8768291473388672
tensor(1.4164, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019043857231736183
loss_c:0.8870387077331543
tensor(1.3265, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03192600980401039
loss_c:0.730809211730957
tensor(1.2950, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020746486261487007
loss_c:0.8232743144035339
tensor(1.2979, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01660575531423092
loss_c:0.7325102686882019
tensor(1.2279, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015438053756952286
loss_c:0.8049275875091553
tensor(1.2639, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018971985206007957
loss_c:0.9421574473381042
tensor(1.3576, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02177726849913597
loss_c:0.799954891204834
tensor(1.2892, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013570183888077736
loss_c:0.7329853773117065
tensor(1.2147, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019344935193657875
loss_c:0.7762345671653748
tensor(1.2649, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.040176454931497574
loss_c:0.743675172328949
tensor(1.3388, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03318069502711296
loss_c:0.917421817779541
tensor(1.4067, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016789335757493973
loss_c:0.889755368232727
tensor(1.3182, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04316835105419159
loss_c:1.165242314338684
tensor(1.5920, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01465692650526762
loss_c:0.9774514436721802
tensor(1.3587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023242738097906113
loss_c:0.9615210294723511
tensor(1.3875, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018218442797660828
loss_c:0.8623964786529541
tensor(1.3089, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033468447625637054
loss_c:0.7547838687896729
tensor(1.3153, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.041459646075963974
loss_c:0.9669601321220398
tensor(1.4707, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019620288163423538
loss_c:0.8030757904052734
tensor(1.2816, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.051303617656230927
loss_c:1.2891367673873901
tensor(1.6957, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012796553783118725
loss_c:0.778127908706665
tensor(1.2376, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02124829962849617
loss_c:0.9525241851806641
tensor(1.3730, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017412928864359856
loss_c:0.6925324201583862
tensor(1.2100, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01318947784602642
loss_c:0.8983050584793091
tensor(1.3071, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01859697885811329
loss_c:0.7628165483474731
tensor(1.2548, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01833231747150421
loss_c:0.8501509428024292
tensor(1.3026, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029601823538541794
loss_c:0.8922866582870483
tensor(1.3754, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01963537186384201
loss_c:0.820389449596405
tensor(1.2917, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014195707626640797
loss_c:0.8221747279167175
tensor(1.2689, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03408508002758026
loss_c:0.7426339387893677
tensor(1.3115, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014530379325151443
loss_c:0.8481928706169128
tensor(1.2849, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02409709431231022
loss_c:0.8748346567153931
tensor(1.3416, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020739350467920303
loss_c:0.8123615980148315
tensor(1.2921, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0222470685839653
loss_c:0.848413348197937
tensor(1.3187, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.010404814966022968
loss_c:0.6847400665283203
tensor(1.1757, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01862245611846447
loss_c:1.179471731185913
tensor(1.4874, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01642029546201229
loss_c:0.8466191291809082
tensor(1.2922, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015384781174361706
loss_c:0.7091493606567383
tensor(1.2111, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01571846194565296
loss_c:0.7844328880310059
tensor(1.2544, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024958927184343338
loss_c:1.037200689315796
tensor(1.4357, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023690953850746155
loss_c:0.8001750707626343
tensor(1.2982, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02172582782804966
loss_c:0.9301033020019531
tensor(1.3618, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024951398372650146
loss_c:0.7569095492362976
tensor(1.2798, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02336350455880165
loss_c:1.058174729347229
tensor(1.4402, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012794965878129005
loss_c:0.7960903644561768
tensor(1.2478, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02240978367626667
loss_c:0.8550918102264404
tensor(1.3231, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04484547674655914
loss_c:0.9301950335502625
tensor(1.4644, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02162107452750206
loss_c:0.8462619781494141
tensor(1.3147, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02383790723979473
loss_c:0.8698367476463318
tensor(1.3376, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03822615370154381
loss_c:0.8022252917289734
tensor(1.3640, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030417941510677338
loss_c:1.166532278060913
tensor(1.5312, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02107926458120346
loss_c:0.9125050902366638
tensor(1.3490, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016508949920535088
loss_c:0.8204862475395203
tensor(1.2778, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024070914834737778
loss_c:1.0073997974395752
tensor(1.4147, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02910039760172367
loss_c:0.9594454169273376
tensor(1.4103, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01491808332502842
loss_c:0.7355231046676636
tensor(1.2241, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014126401394605637
loss_c:0.7281190156936646
tensor(1.2166, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019738228991627693
loss_c:0.8081509470939636
tensor(1.2855, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03109966218471527
loss_c:0.8893566131591797
tensor(1.3804, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024187272414565086
loss_c:0.8335675001144409
tensor(1.3192, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020189626142382622
loss_c:0.8169561624526978
tensor(1.2923, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019668933004140854
loss_c:0.9418796896934509
tensor(1.3588, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02307259850203991
loss_c:1.0770243406295776
tensor(1.4482, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015166619792580605
loss_c:0.7154199481010437
tensor(1.2143, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01865142025053501
loss_c:0.7619168162345886
tensor(1.2553, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02362281270325184
loss_c:0.7514544725418091
tensor(1.2715, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017104437574744225
loss_c:0.7783817052841187
tensor(1.2575, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01637580431997776
loss_c:0.8081949949264526
tensor(1.2706, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017269711941480637
loss_c:0.8273636698722839
tensor(1.2851, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027853919193148613
loss_c:0.676710307598114
tensor(1.2491, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02194722183048725
loss_c:0.7202317714691162
tensor(1.2467, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.050346873700618744
loss_c:1.012611985206604
tensor(1.5344, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015007787384092808
loss_c:0.7678389549255371
tensor(1.2420, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018428342416882515
loss_c:0.7449393272399902
tensor(1.2445, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03047816827893257
loss_c:0.763419508934021
tensor(1.3083, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04057992622256279
loss_c:0.7525895833969116
tensor(1.3471, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028767714276909828
loss_c:0.885330855846405
tensor(1.3681, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01678130403161049
loss_c:0.9002851247787476
tensor(1.3233, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016777731478214264
loss_c:0.7973679304122925
tensor(1.2661, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018066659569740295
loss_c:0.7876734733581543
tensor(1.2664, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014650808647274971
loss_c:0.7289866209030151
tensor(1.2186, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023955823853611946
loss_c:0.8402263522148132
tensor(1.3217, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0340418703854084
loss_c:1.0538184642791748
tensor(1.4855, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018674809485673904
loss_c:0.9098960757255554
tensor(1.3372, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015317919664084911
loss_c:0.8133175373077393
tensor(1.2684, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015719864517450333
loss_c:0.7795296907424927
tensor(1.2513, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02374390698969364
loss_c:0.8413941264152527
tensor(1.3214, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012298141606152058
loss_c:0.6989616751670837
tensor(1.1911, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.09969223290681839
loss_c:0.8441863059997559
tensor(1.6597, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015420788899064064
loss_c:0.7379459738731384
tensor(1.2267, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033489763736724854
loss_c:0.7659441828727722
tensor(1.3221, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013039165176451206
loss_c:0.8294237852096558
tensor(1.2675, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02041161060333252
loss_c:0.8743588328361511
tensor(1.3252, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01397476065903902
loss_c:0.7966502904891968
tensor(1.2534, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020145894959568977
loss_c:0.8351775407791138
tensor(1.3021, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031961675733327866
loss_c:0.8902003169059753
tensor(1.3848, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01998552866280079
loss_c:0.7273978590965271
tensor(1.2408, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02806122973561287
loss_c:0.802946925163269
tensor(1.3186, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015709834173321724
loss_c:0.7979788780212402
tensor(1.2618, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025254692882299423
loss_c:0.8525571823120117
tensor(1.3343, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03529782593250275
loss_c:0.8260740041732788
tensor(1.3632, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012413580901920795
loss_c:0.7064394950866699
tensor(1.1958, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013114072382450104
loss_c:0.8498059511184692
tensor(1.2798, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01754644885659218
loss_c:0.8655558824539185
tensor(1.3080, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01591724157333374
loss_c:0.8577770590782166
tensor(1.2965, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020827898755669594
loss_c:0.797358512878418
tensor(1.2837, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024676699191331863
loss_c:0.9532593488693237
tensor(1.3888, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02890423871576786
loss_c:0.7626141905784607
tensor(1.2994, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05433807522058487
loss_c:0.845181405544281
tensor(1.4574, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018810974434018135
loss_c:0.7660702466964722
tensor(1.2572, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018764687702059746
loss_c:0.7346696257591248
tensor(1.2392, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027273166924715042
loss_c:0.8554058074951172
tensor(1.3448, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016695717349648476
loss_c:0.7935938835144043
tensor(1.2636, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024261878803372383
loss_c:0.8264931440353394
tensor(1.3152, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06817202270030975
loss_c:0.7787232398986816
tensor(1.4796, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015039917081594467
loss_c:0.8834220170974731
tensor(1.3074, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01569831557571888
loss_c:0.7529684901237488
tensor(1.2363, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014508652500808239
loss_c:0.8349369764328003
tensor(1.2777, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017542077228426933
loss_c:0.7722587585449219
tensor(1.2552, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01653074100613594
loss_c:0.7702611684799194
tensor(1.2497, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017488712444901466
loss_c:0.74549400806427
tensor(1.2398, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017457902431488037
loss_c:0.9870511889457703
tensor(1.3771, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02896088920533657
loss_c:0.8930100202560425
tensor(1.3735, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037990640848875046
loss_c:0.9908016920089722
tensor(1.4684, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027511849999427795
loss_c:0.7479902505874634
tensor(1.2846, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039149075746536255
loss_c:0.8942705988883972
tensor(1.4184, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01560476515442133
loss_c:0.7533291578292847
tensor(1.2361, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0223661120980978
loss_c:0.8292290568351746
tensor(1.3086, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07303520292043686
loss_c:0.9351649284362793
tensor(1.5881, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02493269555270672
loss_c:1.0493195056915283
tensor(1.4447, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014361781999468803
loss_c:0.7473623156547546
tensor(1.2276, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028813228011131287
loss_c:1.230254054069519
tensor(1.5639, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01775101199746132
loss_c:0.7785288691520691
tensor(1.2601, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02760963886976242
loss_c:0.8221608996391296
tensor(1.3271, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024561556056141853
loss_c:0.837456226348877
tensor(1.3227, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02217400074005127
loss_c:0.9142057299613953
tensor(1.3558, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03809123858809471
loss_c:0.9066362380981445
tensor(1.4195, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017223304137587547
loss_c:0.780189037322998
tensor(1.2591, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01571935974061489
loss_c:0.7695218920707703
tensor(1.2468, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01577257737517357
loss_c:0.7521376609802246
tensor(1.2372, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021340113133192062
loss_c:0.7838053703308105
tensor(1.2788, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016273075714707375
loss_c:0.8147598505020142
tensor(1.2746, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023071404546499252
loss_c:0.9398481845855713
tensor(1.3739, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014052549377083778
loss_c:0.7844105958938599
tensor(1.2481, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019878359511494637
loss_c:0.7183141708374023
tensor(1.2358, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014455496333539486
loss_c:0.674191415309906
tensor(1.1878, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021474497392773628
loss_c:0.9044598937034607
tensor(1.3471, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02321782149374485
loss_c:0.9087230563163757
tensor(1.3570, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017570706084370613
loss_c:0.8860964775085449
tensor(1.3200, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012544269673526287
loss_c:0.6985800266265869
tensor(1.1930, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04384540393948555
loss_c:0.7532884478569031
tensor(1.3583, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028050590306520462
loss_c:0.8274631500244141
tensor(1.3321, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03153477981686592
loss_c:0.8546962738037109
tensor(1.3624, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042943548411130905
loss_c:0.8633430004119873
tensor(1.4164, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02557990327477455
loss_c:0.8712283968925476
tensor(1.3461, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012635045684874058
loss_c:0.7839664220809937
tensor(1.2413, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014036551117897034
loss_c:0.7248331904411316
tensor(1.2140, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02557605318725109
loss_c:0.8295788168907166
tensor(1.3226, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013530600816011429
loss_c:0.6817253828048706
tensor(1.1874, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025658387690782547
loss_c:0.8943938612937927
tensor(1.3595, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013152405619621277
loss_c:0.7049219608306885
tensor(1.1987, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016236862167716026
loss_c:0.7239922285079956
tensor(1.2227, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014270881190896034
loss_c:0.7257377505302429
tensor(1.2151, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023096533492207527
loss_c:0.8828267455101013
tensor(1.3421, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018813252449035645
loss_c:0.8518036603927612
tensor(1.3059, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.042778998613357544
loss_c:0.7901667356491089
tensor(1.3749, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014943122863769531
loss_c:0.7206419706344604
tensor(1.2147, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027142122387886047
loss_c:0.9358007907867432
tensor(1.3898, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019196249544620514
loss_c:0.8369995355606079
tensor(1.2992, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029410162940621376
loss_c:0.925175130367279
tensor(1.3937, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018868781626224518
loss_c:0.8075677752494812
tensor(1.2810, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01949973590672016
loss_c:0.8391702175140381
tensor(1.3017, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03317219018936157
loss_c:0.8086061477661133
tensor(1.3439, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04824000969529152
loss_c:1.1445964574813843
tensor(1.6007, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014449439942836761
loss_c:0.7953248023986816
tensor(1.2548, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04870554432272911
loss_c:0.820303201675415
tensor(1.4181, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01821829378604889
loss_c:0.7501642107963562
tensor(1.2456, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01453660149127245
loss_c:0.8638178706169128
tensor(1.2942, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014831825159490108
loss_c:0.699053168296814
tensor(1.2019, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015572946518659592
loss_c:0.7551015615463257
tensor(1.2370, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01856086589396
loss_c:0.7886929512023926
tensor(1.2690, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05444908142089844
loss_c:0.8507685661315918
tensor(1.4601, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.010084833018481731
loss_c:0.7837750315666199
tensor(1.2294, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02498055063188076
loss_c:0.7096325755119324
tensor(1.2519, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01845051907002926
loss_c:0.7745026350021362
tensor(1.2604, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02167917974293232
loss_c:0.7797069549560547
tensor(1.2774, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016773145645856857
loss_c:0.8941258192062378
tensor(1.3212, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016146747395396233
loss_c:0.7702502012252808
tensor(1.2480, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018943948671221733
loss_c:0.7727265357971191
tensor(1.2615, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02037840709090233
loss_c:0.8171842098236084
tensor(1.2930, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03972532972693443
loss_c:0.8359513282775879
tensor(1.3879, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020106054842472076
loss_c:0.8464627265930176
tensor(1.3085, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01615750417113304
loss_c:0.8495678901672363
tensor(1.2931, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02240469492971897
loss_c:0.9502226710319519
tensor(1.3778, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03058716654777527
loss_c:0.867165744304657
tensor(1.3660, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016168907284736633
loss_c:0.7969000339508057
tensor(1.2631, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01501256600022316
loss_c:0.7897738218307495
tensor(1.2540, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018576163798570633
loss_c:0.7895704507827759
tensor(1.2694, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.037767041474580765
loss_c:1.0053298473358154
tensor(1.4762, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018557406961917877
loss_c:0.7860509753227234
tensor(1.2673, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025507664307951927
loss_c:0.8319107890129089
tensor(1.3238, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016432449221611023
loss_c:0.7003070712089539
tensor(1.2091, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0202874094247818
loss_c:0.8987125754356384
tensor(1.3390, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02733718417584896
loss_c:0.751521110534668
tensor(1.2860, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02014402486383915
loss_c:0.909592866897583
tensor(1.3445, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02317073941230774
loss_c:0.7445472478866577
tensor(1.2638, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016323000192642212
loss_c:0.7400177717208862
tensor(1.2312, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01506386324763298
loss_c:0.7442321181297302
tensor(1.2280, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01891556940972805
loss_c:0.7684049606323242
tensor(1.2587, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018528982996940613
loss_c:0.8768590688705444
tensor(1.3188, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015002837404608727
loss_c:0.8394768238067627
tensor(1.2819, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015479917638003826
loss_c:0.6901016235351562
tensor(1.1988, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017645372077822685
loss_c:0.8957562446594238
tensor(1.3256, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.051020070910453796
loss_c:0.920931339263916
tensor(1.4876, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017281394451856613
loss_c:0.7184499502182007
tensor(1.2227, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03720342367887497
loss_c:0.8796653747558594
tensor(1.4030, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039175137877464294
loss_c:0.7896453738212585
tensor(1.3603, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04228641837835312
loss_c:0.830880343914032
tensor(1.3976, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01917521096765995
loss_c:0.8921012878417969
tensor(1.3303, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01171694602817297
loss_c:0.6171776056289673
tensor(1.1405, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017496313899755478
loss_c:0.932307243347168
tensor(1.3459, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.047021158039569855
loss_c:1.2424628734588623
tensor(1.6531, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019811533391475677
loss_c:0.8155173063278198
tensor(1.2894, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02065090462565422
loss_c:0.7520871162414551
tensor(1.2570, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02858234941959381
loss_c:0.8626612424850464
tensor(1.3548, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014001702889800072
loss_c:0.8611245155334473
tensor(1.2900, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018675953149795532
loss_c:0.8417189121246338
tensor(1.2994, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03207508474588394
loss_c:0.8431726694107056
tensor(1.3590, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01424449123442173
loss_c:0.7781165838241577
tensor(1.2439, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01349362637847662
loss_c:0.7162167429924011
tensor(1.2055, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01849658600986004
loss_c:0.9679754972457886
tensor(1.3703, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03001936338841915
loss_c:0.7558533549308777
tensor(1.3004, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019170012325048447
loss_c:0.7614591121673584
tensor(1.2560, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018648114055395126
loss_c:0.7759091258049011
tensor(1.2619, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01627242937684059
loss_c:0.7630809545516968
tensor(1.2442, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03226013481616974
loss_c:0.7816715240478516
tensor(1.3249, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023640908300876617
loss_c:0.7327126264572144
tensor(1.2593, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033650849014520645
loss_c:0.9896723031997681
tensor(1.4491, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014322301372885704
loss_c:0.8023418188095093
tensor(1.2579, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03674361854791641
loss_c:0.9632579684257507
tensor(1.4477, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04030535742640495
loss_c:0.8328975439071655
tensor(1.3893, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03738782927393913
loss_c:0.9153472781181335
tensor(1.4232, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01830916851758957
loss_c:0.7966145277023315
tensor(1.2722, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016767136752605438
loss_c:0.7801083326339722
tensor(1.2562, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01935865730047226
loss_c:0.7389634847640991
tensor(1.2442, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014273821376264095
loss_c:0.7411254644393921
tensor(1.2232, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013179738074541092
loss_c:0.6929094195365906
tensor(1.1911, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016436835750937462
loss_c:0.7497895956039429
tensor(1.2375, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013564130291342735
loss_c:0.7737267017364502
tensor(1.2385, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014062385074794292
loss_c:0.7571493983268738
tensor(1.2312, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01599952019751072
loss_c:0.8537241816520691
tensor(1.2945, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015967117622494698
loss_c:0.8261022567749023
tensor(1.2786, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019238902255892754
loss_c:0.8153284788131714
tensor(1.2868, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01701650209724903
loss_c:0.8537632822990417
tensor(1.2989, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013487695716321468
loss_c:0.7198584079742432
tensor(1.2070, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028124120086431503
loss_c:0.775194525718689
tensor(1.3031, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018339302390813828
loss_c:0.8154687285423279
tensor(1.2828, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01658305898308754
loss_c:0.7921404838562012
tensor(1.2616, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02470030076801777
loss_c:0.7538682818412781
tensor(1.2758, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013977066613733768
loss_c:0.7989498972892761
tensor(1.2538, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.06450604647397995
loss_c:0.8272894620895386
tensor(1.4953, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0191835667937994
loss_c:0.8769057989120483
tensor(1.3216, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013753082603216171
loss_c:0.7516162395477295
tensor(1.2256, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01664358749985695
loss_c:0.8457542657852173
tensor(1.2924, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014969817362725735
loss_c:0.8067728877067566
tensor(1.2626, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.028518695384263992
loss_c:0.7181633710861206
tensor(1.2723, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020845621824264526
loss_c:0.9968690872192383
tensor(1.3979, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030369417741894722
loss_c:0.8502453565597534
tensor(1.3563, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013181734830141068
loss_c:0.8203413486480713
tensor(1.2623, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02235872484743595
loss_c:0.9183429479598999
tensor(1.3596, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029157981276512146
loss_c:0.9181663393974304
tensor(1.3899, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026883604004979134
loss_c:0.7988321185112
tensor(1.3113, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015316983684897423
loss_c:0.7597455978393555
tensor(1.2371, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014145717956125736
loss_c:0.7980417609214783
tensor(1.2538, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017120137810707092
loss_c:0.8329077959060669
tensor(1.2871, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02346232160925865
loss_c:0.7482935786247253
tensor(1.2671, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014407141134142876
loss_c:0.99535071849823
tensor(1.3678, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013138552196323872
loss_c:0.9649313688278198
tensor(1.3447, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013872210867702961
loss_c:0.7434934973716736
tensor(1.2213, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014386462047696114
loss_c:0.7293846607208252
tensor(1.2155, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01868475414812565
loss_c:0.7848285436630249
tensor(1.2665, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016869716346263885
loss_c:0.804309606552124
tensor(1.2694, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.035105712711811066
loss_c:0.9222626686096191
tensor(1.4193, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017622020095586777
loss_c:0.7976145148277283
tensor(1.2689, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025201624259352684
loss_c:0.7658156156539917
tensor(1.2852, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02635863795876503
loss_c:1.0675350427627563
tensor(1.4625, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018144642934203148
loss_c:0.7796742916107178
tensor(1.2610, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015039988793432713
loss_c:0.8317569494247437
tensor(1.2766, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023001084104180336
loss_c:0.849212646484375
tensor(1.3227, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014071290381252766
loss_c:0.7337884902954102
tensor(1.2163, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017364826053380966
loss_c:0.912254273891449
tensor(1.3329, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.029718274250626564
loss_c:0.8648254871368408
tensor(1.3623, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016479486599564552
loss_c:0.8277994990348816
tensor(1.2807, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016335805878043175
loss_c:0.7964811325073242
tensor(1.2623, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02191653475165367
loss_c:0.9024142622947693
tensor(1.3480, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.07508465647697449
loss_c:0.8708285093307495
tensor(1.5738, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019709445536136627
loss_c:0.8451997637748718
tensor(1.3054, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03129803389310837
loss_c:0.8808864951133728
tensor(1.3786, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017707740887999535
loss_c:0.890777587890625
tensor(1.3221, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021292777732014656
loss_c:0.9349538683891296
tensor(1.3634, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01920195482671261
loss_c:0.806206464767456
tensor(1.2810, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018606098368763924
loss_c:0.8459744453430176
tensor(1.3008, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019500475376844406
loss_c:0.8300948143005371
tensor(1.2959, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018378479406237602
loss_c:0.7905489802360535
tensor(1.2685, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012388534843921661
loss_c:0.7452022433280945
tensor(1.2158, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01573571376502514
loss_c:0.8189558982849121
tensor(1.2726, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023534156382083893
loss_c:0.8993092775344849
tensor(1.3533, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020851757377386093
loss_c:0.8042436838150024
tensor(1.2875, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014059944078326225
loss_c:0.7835488319396973
tensor(1.2450, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016582144424319267
loss_c:0.8264613151550293
tensor(1.2806, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011199853383004665
loss_c:0.745072066783905
tensor(1.2103, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01460166834294796
loss_c:0.7642935514450073
tensor(1.2365, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03506853058934212
loss_c:0.8621828556060791
tensor(1.3849, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015818141400814056
loss_c:0.7546345591545105
tensor(1.2365, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.057449568063020706
loss_c:0.9328609704971313
tensor(1.5271, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03778642416000366
loss_c:1.0064027309417725
tensor(1.4788, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017562253400683403
loss_c:0.833821713924408
tensor(1.2892, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016575101763010025
loss_c:0.8267638683319092
tensor(1.2807, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033140793442726135
loss_c:0.8906387090682983
tensor(1.3920, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.031928107142448425
loss_c:0.7481812238693237
tensor(1.3061, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0212126262485981
loss_c:1.1114332675933838
tensor(1.4623, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020166249945759773
loss_c:0.7487434148788452
tensor(1.2532, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016523325815796852
loss_c:0.8662444949150085
tensor(1.3029, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01693582534790039
loss_c:0.7506186366081238
tensor(1.2397, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014253851026296616
loss_c:0.7275353670120239
tensor(1.2147, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01593911275267601
loss_c:0.7486410140991211
tensor(1.2341, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022795844823122025
loss_c:0.6773437261581421
tensor(1.2249, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022081781178712845
loss_c:0.8131496906280518
tensor(1.2981, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027700942009687424
loss_c:0.7803915739059448
tensor(1.3050, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020791681483387947
loss_c:0.9124019145965576
tensor(1.3482, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014970065094530582
loss_c:0.7813726663589478
tensor(1.2481, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0648847445845604
loss_c:0.8639647960662842
tensor(1.5199, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016594979912042618
loss_c:0.7876696586608887
tensor(1.2590, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02271566540002823
loss_c:0.8290688991546631
tensor(1.3099, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019583579152822495
loss_c:0.708643913269043
tensor(1.2278, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01494233962148428
loss_c:0.7863086462020874
tensor(1.2509, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015446335077285767
loss_c:0.8121280670166016
tensor(1.2677, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.032827090471982956
loss_c:0.8846448659896851
tensor(1.3867, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03372308239340782
loss_c:0.9790169596672058
tensor(1.4441, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018633004277944565
loss_c:0.8767766356468201
tensor(1.3186, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03445885330438614
loss_c:0.7166509628295898
tensor(1.2988, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017165865749120712
loss_c:0.8417354822158813
tensor(1.2923, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026777254417538643
loss_c:0.7746295928955078
tensor(1.2972, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02626633085310459
loss_c:0.9570026397705078
tensor(1.3982, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01688687689602375
loss_c:0.819133996963501
tensor(1.2783, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01865183189511299
loss_c:0.7919638156890869
tensor(1.2708, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02163095772266388
loss_c:0.8739402294158936
tensor(1.3305, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030544189736247063
loss_c:0.7915124893188477
tensor(1.3234, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01397875975817442
loss_c:0.7257938385009766
tensor(1.2126, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016205022111535072
loss_c:0.9041144251823425
tensor(1.3235, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016609270125627518
loss_c:0.7407779097557068
tensor(1.2327, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04173106700181961
loss_c:0.8208763003349304
tensor(1.3898, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014694929122924805
loss_c:1.0036430358886719
tensor(1.3733, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03188078850507736
loss_c:0.8528189659118652
tensor(1.3641, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020808322355151176
loss_c:0.8286465406417847
tensor(1.3012, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020552566275000572
loss_c:0.8743484020233154
tensor(1.3260, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03926217555999756
loss_c:0.9292832612991333
tensor(1.4401, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03536539152264595
loss_c:0.9995598196983337
tensor(1.4625, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01300277654081583
loss_c:0.8225946426391602
tensor(1.2633, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02318328619003296
loss_c:0.8428751826286316
tensor(1.3198, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01960640586912632
loss_c:0.9726870059967041
tensor(1.3773, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01664649322628975
loss_c:0.7336195707321167
tensor(1.2293, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038618702441453934
loss_c:1.1917083263397217
tensor(1.5846, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016964592039585114
loss_c:0.8544707298278809
tensor(1.2989, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016190670430660248
loss_c:0.8639890551567078
tensor(1.3008, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01813388615846634
loss_c:0.8868293762207031
tensor(1.3222, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03201931715011597
loss_c:0.8145672678947449
tensor(1.3428, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014788609929382801
loss_c:0.7399188876152039
tensor(1.2251, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018474895507097244
loss_c:0.7626060843467712
tensor(1.2541, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026956496760249138
loss_c:0.8603886365890503
tensor(1.3462, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03191632032394409
loss_c:0.8836538195610046
tensor(1.3810, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03325540944933891
loss_c:1.02583646774292
tensor(1.4664, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02205852046608925
loss_c:0.8109773397445679
tensor(1.2970, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027371294796466827
loss_c:0.8863205909729004
tensor(1.3624, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017000671476125717
loss_c:0.8566403388977051
tensor(1.3002, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015510465018451214
loss_c:0.748959481716156
tensor(1.2337, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.011948716826736927
loss_c:0.6558825373649597
tensor(1.1662, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013965223915874958
loss_c:0.7010175585746765
tensor(1.2002, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.053660884499549866
loss_c:0.8736644983291626
tensor(1.4711, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019049054011702538
loss_c:0.7890016436576843
tensor(1.2715, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012606019154191017
loss_c:0.7003469467163086
tensor(1.1937, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017754023894667625
loss_c:0.8329223990440369
tensor(1.2903, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.038145363330841064
loss_c:0.8242441415786743
tensor(1.3752, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018233904615044594
loss_c:0.8544377088546753
tensor(1.3044, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01257361937314272
loss_c:0.7054054141044617
tensor(1.1962, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016397889703512192
loss_c:0.7265377044677734
tensor(1.2247, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026238877326250076
loss_c:0.7865272760391235
tensor(1.3016, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01606890559196472
loss_c:0.7653506994247437
tensor(1.2449, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01908452808856964
loss_c:0.7755889296531677
tensor(1.2639, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01882016286253929
loss_c:0.7260518074035645
tensor(1.2348, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03455576300621033
loss_c:0.7916860580444336
tensor(1.3412, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021892566233873367
loss_c:0.8403052091598511
tensor(1.3126, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014344273135066032
loss_c:0.6513559818267822
tensor(1.1726, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01626116782426834
loss_c:0.747633695602417
tensor(1.2353, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03601054847240448
loss_c:0.8324207067489624
tensor(1.3707, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022950327023863792
loss_c:0.8158888220787048
tensor(1.3035, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0231558196246624
loss_c:0.8352162837982178
tensor(1.3153, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023985201492905617
loss_c:0.7471272945404053
tensor(1.2690, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014728949405252934
loss_c:0.7757010459899902
tensor(1.2441, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.021297333762049675
loss_c:0.8361992239952087
tensor(1.3077, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023905416950583458
loss_c:0.9904094934463501
tensor(1.4072, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026636937633156776
loss_c:0.750717282295227
tensor(1.2826, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0165939312428236
loss_c:0.7245113253593445
tensor(1.2231, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0218293908983469
loss_c:0.7032866477966309
tensor(1.2341, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.039588164538145065
loss_c:1.0960290431976318
tensor(1.5376, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023545851930975914
loss_c:0.9897595643997192
tensor(1.4055, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020394351333379745
loss_c:0.7600738406181335
tensor(1.2602, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017485950142145157
loss_c:0.743440568447113
tensor(1.2378, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018406614661216736
loss_c:0.8110038638114929
tensor(1.2805, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0215982086956501
loss_c:0.862738311290741
tensor(1.3242, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027552692219614983
loss_c:0.7112838625907898
tensor(1.2641, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.020869078114628792
loss_c:0.8511024713516235
tensor(1.3143, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.025851113721728325
loss_c:1.0241751670837402
tensor(1.4355, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013016204349696636
loss_c:0.7259978652000427
tensor(1.2079, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02033444680273533
loss_c:0.8488833904266357
tensor(1.3107, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019868241623044014
loss_c:0.8086735606193542
tensor(1.2856, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019765133038163185
loss_c:0.7848986983299255
tensor(1.2716, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02864336408674717
loss_c:1.0131864547729492
tensor(1.4415, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019182827323675156
loss_c:0.8383983373641968
tensor(1.2995, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01811799593269825
loss_c:0.7966204881668091
tensor(1.2709, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018706537783145905
loss_c:0.9124630689620972
tensor(1.3396, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027047740295529366
loss_c:0.7849685549736023
tensor(1.3041, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013907899148762226
loss_c:0.6554036736488342
tensor(1.1716, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013562697917222977
loss_c:0.7854627370834351
tensor(1.2442, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017333954572677612
loss_c:0.8121042251586914
tensor(1.2762, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01691257953643799
loss_c:0.7909119129180908
tensor(1.2622, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017585715278983116
loss_c:0.7278134226799011
tensor(1.2292, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02062728814780712
loss_c:0.7669711112976074
tensor(1.2651, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015019077807664871
loss_c:0.8414143323898315
tensor(1.2823, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03683361038565636
loss_c:0.8374495506286621
tensor(1.3784, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015996713191270828
loss_c:0.7036275267601013
tensor(1.2080, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02730041928589344
loss_c:0.737019419670105
tensor(1.2781, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01320493221282959
loss_c:0.7774257659912109
tensor(1.2374, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026507535949349403
loss_c:0.7564376592636108
tensor(1.2856, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.027812587097287178
loss_c:0.8959712386131287
tensor(1.3713, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02165919728577137
loss_c:0.9463877081871033
tensor(1.3724, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030642278492450714
loss_c:0.8042404055595398
tensor(1.3317, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024153640493750572
loss_c:0.8087179064750671
tensor(1.3048, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022554796189069748
loss_c:0.8023471832275391
tensor(1.2939, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014360257424414158
loss_c:0.7650059461593628
tensor(1.2354, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018629761412739754
loss_c:0.8613778948783875
tensor(1.3100, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016593890264630318
loss_c:0.7628533244132996
tensor(1.2443, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.024580806493759155
loss_c:0.9054171442985535
tensor(1.3622, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01586105115711689
loss_c:0.8656405806541443
tensor(1.2999, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013643731363117695
loss_c:0.7861779928207397
tensor(1.2442, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02685089036822319
loss_c:0.8517135977745056
tensor(1.3418, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019847720861434937
loss_c:0.8183745741844177
tensor(1.2908, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023378562182188034
loss_c:0.8961523771286011
tensor(1.3514, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01718536578118801
loss_c:0.8404726982116699
tensor(1.2914, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.018986856564879417
loss_c:0.8431837558746338
tensor(1.3011, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.061394140124320984
loss_c:0.8042489886283875
tensor(1.4721, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.022644586861133575
loss_c:0.7176162600517273
tensor(1.2459, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.053060781210660934
loss_c:1.0033332109451294
tensor(1.5476, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05852070450782776
loss_c:0.8797072172164917
tensor(1.5012, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05557720735669136
loss_c:0.8433744311332703
tensor(1.4664, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.0231916680932045
loss_c:1.0342447757720947
tensor(1.4292, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02015163004398346
loss_c:0.8341765403747559
tensor(1.3014, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016041520982980728
loss_c:0.8062695264816284
tensor(1.2673, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.013255578465759754
loss_c:0.8350695967674255
tensor(1.2714, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01889769546687603
loss_c:0.9443873763084412
tensor(1.3586, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.017417164519429207
loss_c:0.8647732734680176
tensor(1.3068, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01718674600124359
loss_c:0.7915204763412476
tensor(1.2643, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02155434899032116
loss_c:0.7516368627548218
tensor(1.2609, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01389585342258215
loss_c:0.7589470744132996
tensor(1.2315, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023195434361696243
loss_c:0.933799684047699
tensor(1.3714, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.026097122579813004
loss_c:0.9656181335449219
tensor(1.4021, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.043283700942993164
loss_c:0.8135985136032104
tensor(1.3913, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.023097047582268715
loss_c:0.9346461296081543
tensor(1.3713, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.05562016740441322
loss_c:0.8889917135238647
tensor(1.4875, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015205387957394123
loss_c:0.7138813734054565
tensor(1.2122, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01586984097957611
loss_c:0.9955590963363647
tensor(1.3741, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.033451080322265625
loss_c:1.023819088935852
tensor(1.4663, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016027534380555153
loss_c:0.82146155834198
tensor(1.2767, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01634906232357025
loss_c:0.953158974647522
tensor(1.3522, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02488253265619278
loss_c:0.9131593704223633
tensor(1.3666, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015975307673215866
loss_c:0.8834809064865112
tensor(1.3114, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019584516063332558
loss_c:0.8736676573753357
tensor(1.3215, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014833229593932629
loss_c:0.7784318923950195
tensor(1.2476, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015910381451249123
loss_c:0.7947829961776733
tensor(1.2615, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02859007939696312
loss_c:0.8380012512207031
tensor(1.3404, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01574750803411007
loss_c:0.8008944988250732
tensor(1.2642, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02853325381875038
loss_c:0.8343214392662048
tensor(1.3382, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.012388340197503567
loss_c:0.7267478704452515
tensor(1.2082, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.02844788320362568
loss_c:0.9725841283798218
tensor(1.4149, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.015169120393693447
loss_c:0.766261100769043
tensor(1.2423, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014728628098964691
loss_c:0.6981226801872253
tensor(1.2024, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.01364919263869524
loss_c:0.6310929656028748
tensor(1.1602, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.04818640649318695
loss_c:0.7510871291160583
tensor(1.3775, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.014348002150654793
loss_c:0.7124814391136169
tensor(1.2084, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.030819613486528397
loss_c:0.8157671689987183
tensor(1.3379, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.016588911414146423
loss_c:0.851656436920166
tensor(1.2959, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.03487217426300049
loss_c:0.7095025777816772
tensor(1.2961, device='cuda:0', grad_fn=<AddBackward0>)
loss_r:0.019274476915597916
loss_c:0.9004247188568115
tensor(1.3349, device='cuda:0', grad_fn=<AddBackward0>)
total_train_loss:1.314724326133728
loss_r:0.0345132052898407
loss_c:1.81266188621521
loss_r:0.0325557179749012
loss_c:1.719769835472107
loss_r:0.03317366912961006
loss_c:1.7477983236312866
loss_r:0.03406846150755882
loss_c:1.7624645233154297
loss_r:0.03313406556844711
loss_c:1.7276828289031982
loss_r:0.028879905119538307
loss_c:1.644903540611267
loss_r:0.02926141582429409
loss_c:1.8247299194335938
loss_r:0.030622828751802444
loss_c:1.8038890361785889
loss_r:0.03221038728952408
loss_c:1.8670005798339844
loss_r:0.028600523248314857
loss_c:1.9004796743392944
loss_r:0.02577507495880127
loss_c:1.7869404554367065
loss_r:0.023707116022706032
loss_c:1.6247878074645996
loss_r:0.024851830676198006
loss_c:1.6247248649597168
loss_r:0.023195704445242882
loss_c:1.5337131023406982
loss_r:0.02508903481066227
loss_c:1.5735872983932495
loss_r:0.02711469866335392
loss_c:1.6599960327148438
loss_r:0.025193404406309128
loss_c:1.5793403387069702
loss_r:0.02366217039525509
loss_c:1.5983327627182007
loss_r:0.02664867229759693
loss_c:1.6153533458709717
loss_r:0.023863503709435463
loss_c:1.501288652420044
loss_r:0.024150840938091278
loss_c:1.5428880453109741
loss_r:0.028470827266573906
loss_c:1.6155574321746826
loss_r:0.02538309060037136
loss_c:1.5686558485031128
loss_r:0.025986038148403168
loss_c:1.6253050565719604
loss_r:0.02827218733727932
loss_c:1.6453776359558105
loss_r:0.023766444995999336
loss_c:1.4638512134552002
loss_r:0.02806386724114418
loss_c:1.642086386680603
loss_r:0.030328813940286636
loss_c:1.6613245010375977
loss_r:0.029645374044775963
loss_c:1.5917705297470093
loss_r:0.028932681307196617
loss_c:1.5995869636535645
loss_r:0.030146831646561623
loss_c:1.7424386739730835
loss_r:0.024922145530581474
loss_c:1.5144116878509521
loss_r:0.028257183730602264
loss_c:1.7104709148406982
loss_r:0.029291486367583275
loss_c:1.7096107006072998
loss_r:0.025031741708517075
loss_c:1.5856122970581055
loss_r:0.02492586150765419
loss_c:1.4715999364852905
loss_r:0.029318898916244507
loss_c:1.759850263595581
loss_r:0.023119274526834488
loss_c:1.572148084640503
loss_r:0.026747893542051315
loss_c:1.693170428276062
loss_r:0.02812880463898182
loss_c:1.6367334127426147
loss_r:0.025530407205224037
loss_c:1.5890640020370483
loss_r:0.024991648271679878
loss_c:1.546961784362793
loss_r:0.02658073976635933
loss_c:1.7016065120697021
loss_r:0.022002514451742172
loss_c:1.7006200551986694
loss_r:0.025716444477438927
loss_c:1.7120460271835327
loss_r:0.026727311313152313
loss_c:1.6241024732589722
loss_r:0.02427053637802601
loss_c:1.6516005992889404
loss_r:0.02444739267230034
loss_c:1.642582654953003
loss_r:0.026325948536396027
loss_c:1.765697956085205
loss_r:0.02349792793393135
loss_c:1.7441604137420654
loss_r:0.02665010467171669
loss_c:1.7586545944213867
loss_r:0.025391967967152596
loss_c:1.6746476888656616
loss_r:0.025217195972800255
loss_c:1.6595087051391602
loss_r:0.02391688898205757
loss_c:1.600893259048462
loss_r:0.024772178381681442
loss_c:1.6910686492919922
loss_r:0.023639418184757233
loss_c:1.735217809677124
loss_r:0.0246519036591053
loss_c:1.7331260442733765
loss_r:0.026542214676737785
loss_c:1.6770236492156982
loss_r:0.02679862454533577
loss_c:1.721383810043335
loss_r:0.0240951981395483
loss_c:1.5541088581085205
loss_r:0.02628806233406067
loss_c:1.7433242797851562
loss_r:0.023035088554024696
loss_c:1.6460118293762207
loss_r:0.024141943082213402
loss_c:1.5880898237228394
loss_r:0.02609478309750557
loss_c:1.5694650411605835
loss_r:0.025854216888546944
loss_c:1.575956106185913
loss_r:0.025326086208224297
loss_c:1.4846152067184448
loss_r:0.029786063358187675
loss_c:1.6844964027404785
loss_r:0.025822483003139496
loss_c:1.6283372640609741
loss_r:0.02654171548783779
loss_c:1.644968032836914
loss_r:0.02785670943558216
loss_c:1.5818675756454468
loss_r:0.029033977538347244
loss_c:1.6761425733566284
loss_r:0.025374239310622215
loss_c:1.5267693996429443
loss_r:0.026897769421339035
loss_c:1.6859219074249268
loss_r:0.023887820541858673
loss_c:1.6376922130584717
loss_r:0.02486259862780571
loss_c:1.6139583587646484
loss_r:0.02946404553949833
loss_c:1.6619832515716553
loss_r:0.027600236237049103
loss_c:1.6875951290130615
loss_r:0.02585506998002529
loss_c:1.5215203762054443
loss_r:0.029009591788053513
loss_c:1.6575543880462646
loss_r:0.024562761187553406
loss_c:1.6794513463974
loss_r:0.02773040346801281
loss_c:1.7750725746154785
loss_r:0.027591925114393234
loss_c:1.6171090602874756
loss_r:0.025362664833664894
loss_c:1.631692886352539
loss_r:0.02575673535466194
loss_c:1.4867029190063477
loss_r:0.031139817088842392
loss_c:1.7537606954574585
loss_r:0.026268985122442245
loss_c:1.723158597946167
loss_r:0.02760297618806362
loss_c:1.7440152168273926
loss_r:0.02687940001487732
loss_c:1.5314916372299194
loss_r:0.027140136808156967
loss_c:1.6833889484405518
loss_r:0.025449007749557495
loss_c:1.4817883968353271
loss_r:0.027413809671998024
loss_c:1.633479356765747
loss_r:0.023885628208518028
loss_c:1.6718368530273438
loss_r:0.025494953617453575
loss_c:1.6755285263061523
loss_r:0.025704607367515564
loss_c:1.5162630081176758
loss_r:0.02770470455288887
loss_c:1.6657238006591797
loss_r:0.02681751921772957
loss_c:1.470855712890625
loss_r:0.029956454411149025
loss_c:1.7159194946289062
loss_r:0.027870768681168556
loss_c:1.704079031944275
loss_r:0.02859169989824295
loss_c:1.6320570707321167
loss_r:0.027381721884012222
loss_c:1.5498030185699463
loss_r:0.02926371619105339
loss_c:1.7398685216903687
loss_r:0.026755258440971375
loss_c:1.4823462963104248
loss_r:0.028939299285411835
loss_c:1.5772004127502441
loss_r:0.028643380850553513
loss_c:1.7658708095550537
loss_r:0.0285829808562994
loss_c:1.7272984981536865
loss_r:0.025129856541752815
loss_c:1.5543302297592163
loss_r:0.02739831618964672
loss_c:1.7040103673934937
loss_r:0.026817934587597847
loss_c:1.4815783500671387
loss_r:0.029017331078648567
loss_c:1.6466538906097412
loss_r:0.026424547657370567
loss_c:1.7076754570007324
loss_r:0.027082182466983795
loss_c:1.6488981246948242
loss_r:0.024347126483917236
loss_c:1.482924222946167
loss_r:0.02914806269109249
loss_c:1.704648733139038
loss_r:0.02750764600932598
loss_c:1.5085539817810059
loss_r:0.02843456156551838
loss_c:1.672316312789917
loss_r:0.027228033170104027
loss_c:1.6503804922103882
loss_r:0.02632412128150463
loss_c:1.575453519821167
loss_r:0.02600574679672718
loss_c:1.5425598621368408
loss_r:0.02910591848194599
loss_c:1.758559226989746
loss_r:0.026485253125429153
loss_c:1.4163917303085327
loss_r:0.030051639303565025
loss_c:1.614397406578064
loss_r:0.027341900393366814
loss_c:1.6674773693084717
loss_r:0.030894966796040535
loss_c:1.7726640701293945
loss_r:0.02668139711022377
loss_c:1.5712717771530151
loss_r:0.029108639806509018
loss_c:1.7070621252059937
loss_r:0.026776297017931938
loss_c:1.459560751914978
loss_r:0.030377134680747986
loss_c:1.6267917156219482
loss_r:0.02613215148448944
loss_c:1.5229610204696655
loss_r:0.02711224928498268
loss_c:1.6773908138275146
loss_r:0.024086853489279747
loss_c:1.5690147876739502
loss_r:0.027931679040193558
loss_c:1.720050573348999
loss_r:0.024161484092473984
loss_c:1.4152789115905762
loss_r:0.029326729476451874
loss_c:1.5635535717010498
loss_r:0.024144742637872696
loss_c:1.479112982749939
loss_r:0.025669937953352928
loss_c:1.6160545349121094
loss_r:0.024626433849334717
loss_c:1.597548007965088
loss_r:0.027859726920723915
loss_c:1.7026278972625732
loss_r:0.023975005373358727
loss_c:1.4127254486083984
loss_r:0.032598771154880524
loss_c:1.619950771331787
loss_r:0.025191470980644226
loss_c:1.4904636144638062
loss_r:0.028696445748209953
loss_c:1.6525914669036865
loss_r:0.026769651100039482
loss_c:1.6052554845809937
loss_r:0.031963057816028595
loss_c:1.7559678554534912
loss_r:0.030138405039906502
loss_c:1.4781036376953125
loss_r:0.038051772862672806
loss_c:1.6744916439056396
loss_r:0.029573414474725723
loss_c:1.5341567993164062
loss_r:0.031198127195239067
loss_c:1.7271708250045776
loss_r:0.029686911031603813
loss_c:1.6325782537460327
loss_r:0.029972316697239876
loss_c:1.64248788356781
loss_r:0.027471359819173813
loss_c:1.4241865873336792
loss_r:0.03693907707929611
loss_c:1.6593472957611084
loss_r:0.029553212225437164
loss_c:1.5695626735687256
loss_r:0.0303861852735281
loss_c:1.7061479091644287
loss_r:0.026053255423903465
loss_c:1.5825891494750977
loss_r:0.0330108180642128
loss_c:1.8018230199813843
loss_r:0.029391583055257797
loss_c:1.5056703090667725
loss_r:0.03774186968803406
loss_c:1.7659626007080078
loss_r:0.031332675367593765
loss_c:1.643819808959961
loss_r:0.033458732068538666
loss_c:1.7420462369918823
loss_r:0.029759490862488747
loss_c:1.6548346281051636
loss_r:0.03235834091901779
loss_c:1.7424156665802002
loss_r:0.029118603095412254
loss_c:1.545566439628601
loss_r:0.03546460345387459
loss_c:1.673006296157837
loss_r:0.02758633904159069
loss_c:1.5661687850952148
loss_r:0.036406826227903366
loss_c:1.909942388534546
loss_r:0.028412630781531334
loss_c:1.6450366973876953
loss_r:0.03317650407552719
loss_c:1.8033273220062256
loss_r:0.031509507447481155
loss_c:1.5928901433944702
loss_r:0.032212305814027786
loss_c:1.627907633781433
loss_r:0.02995801344513893
loss_c:1.6165612936019897
loss_r:0.033228177577257156
loss_c:1.777759313583374
loss_r:0.027859991416335106
loss_c:1.6628211736679077
loss_r:0.03509996831417084
loss_c:1.8364418745040894
loss_r:0.028502412140369415
loss_c:1.5274629592895508
loss_r:0.03249058872461319
loss_c:1.6203120946884155
loss_r:0.02958371676504612
loss_c:1.6116060018539429
loss_r:0.03564222902059555
loss_c:1.806594729423523
loss_r:0.026421504095196724
loss_c:1.6034505367279053
loss_r:0.032568082213401794
loss_c:1.7876085042953491
loss_r:0.02850574254989624
loss_c:1.502519965171814
loss_r:0.0313439704477787
loss_c:1.584243655204773
loss_r:0.02822512574493885
loss_c:1.5899291038513184
loss_r:0.03219013288617134
loss_c:1.7824962139129639
loss_r:0.025876525789499283
loss_c:1.61773681640625
loss_r:0.0341520681977272
loss_c:1.8519580364227295
loss_r:0.027107199653983116
loss_c:1.4788918495178223
loss_r:0.029295077547430992
loss_c:1.591094732284546
loss_r:0.028543582186102867
loss_c:1.6116703748703003
loss_r:0.03313811123371124
loss_c:1.800760269165039
loss_r:0.027258139103651047
loss_c:1.6388429403305054
loss_r:0.032794494181871414
loss_c:1.8005456924438477
loss_r:0.028122955933213234
loss_c:1.5315113067626953
loss_r:0.02897125668823719
loss_c:1.5806373357772827
loss_r:0.02647119015455246
loss_c:1.5642614364624023
loss_r:0.03341091424226761
loss_c:1.8311742544174194
loss_r:0.027258314192295074
loss_c:1.6725314855575562
loss_r:0.034816112369298935
loss_c:1.8978207111358643
loss_r:0.028051067143678665
loss_c:1.541948676109314
loss_r:0.026734724640846252
loss_c:1.5740150213241577
loss_r:0.027339624240994453
loss_c:1.6160295009613037
loss_r:0.032142605632543564
loss_c:1.7485673427581787
loss_r:0.02817058563232422
loss_c:1.6464636325836182
loss_r:0.033817414194345474
loss_c:1.8923735618591309
loss_r:0.030136214569211006
loss_c:1.5971956253051758
loss_r:0.029511163011193275
loss_c:1.5789101123809814
loss_r:0.030096150934696198
loss_c:1.61090886592865
loss_r:0.03790602460503578
loss_c:1.8412790298461914
loss_r:0.0277823805809021
loss_c:1.5953558683395386
loss_r:0.03403737396001816
loss_c:1.8041870594024658
loss_r:0.03045767731964588
loss_c:1.5509305000305176
loss_r:0.031130485236644745
loss_c:1.6141986846923828
loss_r:0.02968987263739109
loss_c:1.6184519529342651
loss_r:0.03513159602880478
loss_c:1.8323957920074463
loss_r:0.02587796188890934
loss_c:1.6407960653305054
loss_r:0.030143992975354195
loss_c:1.7574148178100586
loss_r:0.0284419022500515
loss_c:1.5707051753997803
loss_r:0.02741614356637001
loss_c:1.6102756261825562
loss_r:0.027834879234433174
loss_c:1.6253738403320312
loss_r:0.0341801680624485
loss_c:1.8203494548797607
loss_r:0.024242792278528214
loss_c:1.5436081886291504
loss_r:0.03086593747138977
loss_c:1.7856724262237549
loss_r:0.02757158689200878
loss_c:1.5751646757125854
loss_r:0.028180940076708794
loss_c:1.7495529651641846
loss_r:0.028328489512205124
loss_c:1.7186782360076904
loss_r:0.031413789838552475
loss_c:1.855596899986267
loss_r:0.022953912615776062
loss_c:1.6398496627807617
loss_r:0.029713062569499016
loss_c:1.793989896774292
loss_r:0.028787093237042427
loss_c:1.6772305965423584
loss_r:0.027002248913049698
loss_c:1.6607568264007568
loss_r:0.028176099061965942
loss_c:1.6523396968841553
loss_r:0.034003857523202896
loss_c:1.8804000616073608
loss_r:0.02642969973385334
loss_c:1.674104928970337
loss_r:0.0305341724306345
loss_c:1.7654225826263428
loss_r:0.028799137100577354
loss_c:1.6110124588012695
loss_r:0.029909305274486542
loss_c:1.7154021263122559
loss_r:0.027763254940509796
loss_c:1.6074600219726562
loss_r:0.032670460641384125
loss_c:1.8070647716522217
loss_r:0.02558186464011669
loss_c:1.6586774587631226
loss_r:0.03274139389395714
loss_c:1.8807381391525269
loss_r:0.03103676624596119
loss_c:1.7088474035263062
loss_r:0.029409129172563553
loss_c:1.7603864669799805
loss_r:0.029915176331996918
loss_c:1.6518852710723877
loss_r:0.032124098390340805
loss_c:1.7556869983673096
loss_r:0.025813747197389603
loss_c:1.668339729309082
loss_r:0.033595241606235504
loss_c:1.8977687358856201
loss_r:0.030455874279141426
loss_c:1.6511996984481812
loss_r:0.031821537762880325
loss_c:1.7549407482147217
loss_r:0.029532769694924355
loss_c:1.63802170753479
loss_r:0.033511824905872345
loss_c:1.8155937194824219
loss_r:0.02668541856110096
loss_c:1.6691386699676514
loss_r:0.03276617452502251
loss_c:1.7947964668273926
loss_r:0.030647549778223038
loss_c:1.5948410034179688
loss_r:0.03250522166490555
loss_c:1.7230113744735718
loss_r:0.031837183982133865
loss_c:1.5943686962127686
loss_r:0.030404923483729362
loss_c:1.6885383129119873
loss_r:0.02721051685512066
loss_c:1.6389052867889404
loss_r:0.03329549357295036
loss_c:1.7632932662963867
loss_r:0.0314585343003273
loss_c:1.6017036437988281
loss_r:0.03315911442041397
loss_c:1.66314697265625
loss_r:0.03288932517170906
loss_c:1.6464780569076538
loss_r:0.03338531032204628
loss_c:1.7476046085357666
loss_r:0.02821728214621544
loss_c:1.6350148916244507
loss_r:0.03437034413218498
loss_c:1.8215278387069702
loss_r:0.03265567868947983
loss_c:1.6466386318206787
loss_r:0.03499498963356018
loss_c:1.7773951292037964
loss_r:0.033682405948638916
loss_c:1.690371036529541
loss_r:0.03841855004429817
loss_c:1.8467156887054443
loss_r:0.030258556827902794
loss_c:1.6662172079086304
loss_r:0.032035376876592636
loss_c:1.6961984634399414
loss_r:0.032033029943704605
loss_c:1.6142339706420898
loss_r:0.037520576268434525
loss_c:1.7701867818832397
loss_r:0.03172468766570091
loss_c:1.665594458580017
loss_r:0.0363592728972435
loss_c:1.8031079769134521
loss_r:0.028532182797789574
loss_c:1.6717162132263184
loss_r:0.03501150757074356
loss_c:1.8165061473846436
loss_r:0.03251824527978897
loss_c:1.5726169347763062
loss_r:0.040309131145477295
loss_c:1.7412011623382568
loss_r:0.03348821401596069
loss_c:1.737260341644287
loss_r:0.03537135198712349
loss_c:1.804905891418457
loss_r:0.029155224561691284
loss_c:1.6441161632537842
loss_r:0.03389837592840195
loss_c:1.773902416229248
loss_r:0.03341710567474365
loss_c:1.5554277896881104
loss_r:0.03716898709535599
loss_c:1.6851266622543335
loss_r:0.03375417739152908
loss_c:1.7165091037750244
loss_r:0.034038808196783066
loss_c:1.7236683368682861
loss_r:0.02774806134402752
loss_c:1.563596487045288
loss_r:0.031100628897547722
loss_c:1.6711788177490234
loss_r:0.03164229169487953
loss_c:1.4990928173065186
loss_r:0.03756221756339073
loss_c:1.7263174057006836
loss_r:0.03192364051938057
loss_c:1.6649507284164429
loss_r:0.035452667623758316
loss_c:1.8084591627120972
loss_r:0.030283382162451744
loss_c:1.6058464050292969
loss_r:0.031347211450338364
loss_c:1.6447347402572632
loss_r:0.03542814403772354
loss_c:1.6277117729187012
loss_r:0.037160731852054596
loss_c:1.7568168640136719
loss_r:0.03277970477938652
loss_c:1.701168417930603
loss_r:0.03427676856517792
loss_c:1.721937656402588
loss_r:0.03172140568494797
loss_c:1.585272192955017
loss_r:0.03313980624079704
loss_c:1.72664475440979
loss_r:0.03519279509782791
loss_c:1.5847690105438232
loss_r:0.038107339292764664
loss_c:1.71466064453125
loss_r:0.03246593847870827
loss_c:1.6224043369293213
loss_r:0.035573963075876236
loss_c:1.712364912033081
loss_r:0.028890369459986687
loss_c:1.5682038068771362
loss_r:0.03386223688721657
loss_c:1.7133948802947998
loss_r:0.03314546123147011
loss_c:1.5088914632797241
loss_r:0.03720010444521904
loss_c:1.642148494720459
loss_r:0.03366554155945778
loss_c:1.6491305828094482
loss_r:0.03792716562747955
loss_c:1.748950481414795
loss_r:0.02894558571279049
loss_c:1.521667718887329
loss_r:0.030994027853012085
loss_c:1.6553974151611328
loss_r:0.03238042816519737
loss_c:1.5014910697937012
loss_r:0.03442288562655449
loss_c:1.670851707458496
loss_r:0.03164808079600334
loss_c:1.6231439113616943
loss_r:0.03806711733341217
loss_c:1.8137843608856201
loss_r:0.02843540534377098
loss_c:1.60807204246521
loss_r:0.030407743528485298
loss_c:1.6560657024383545
loss_r:0.03292819485068321
loss_c:1.5744712352752686
loss_r:0.03489580377936363
loss_c:1.704391360282898
loss_r:0.029483595862984657
loss_c:1.59892737865448
loss_r:0.03222295269370079
loss_c:1.6802198886871338
loss_r:0.028933485969901085
loss_c:1.6113622188568115
loss_r:0.03159284219145775
loss_c:1.7008273601531982
loss_r:0.03077629581093788
loss_c:1.5315895080566406
loss_r:0.03219398111104965
loss_c:1.6910594701766968
loss_r:0.03245371952652931
loss_c:1.655019760131836
loss_r:0.03183106705546379
loss_c:1.7430838346481323
loss_r:0.027673617005348206
loss_c:1.5746819972991943
loss_r:0.029610350728034973
loss_c:1.641905665397644
loss_r:0.027822835370898247
loss_c:1.4257185459136963
loss_r:0.03410205990076065
loss_c:1.7049903869628906
loss_r:0.030294720083475113
loss_c:1.665053129196167
loss_r:0.03153371810913086
loss_c:1.7854480743408203
loss_r:0.02826356515288353
loss_c:1.600273609161377
loss_r:0.033718209713697433
loss_c:1.7657697200775146
loss_r:0.03299989923834801
loss_c:1.6427628993988037
loss_r:0.03513166680932045
loss_c:1.7754411697387695
loss_r:0.038476064801216125
loss_c:1.8765524625778198
loss_r:0.0362616628408432
loss_c:1.9154832363128662
loss_r:0.030121607705950737
loss_c:1.6558774709701538
loss_r:0.029153816401958466
loss_c:1.8029760122299194
loss_r:0.028161898255348206
loss_c:1.6666593551635742
loss_r:0.031152017414569855
loss_c:1.812309980392456
loss_r:0.030900919809937477
loss_c:1.8798248767852783
loss_r:0.028307726606726646
loss_c:1.796726942062378
loss_r:0.024274684488773346
loss_c:1.66746187210083
loss_r:0.027924437075853348
loss_c:1.8216508626937866
loss_r:0.026565352454781532
loss_c:1.6645708084106445
loss_r:0.027749275788664818
loss_c:1.7740353345870972
loss_r:0.031048784032464027
loss_c:1.9443111419677734
loss_r:0.029027510434389114
loss_c:1.9762756824493408
loss_r:0.023845205083489418
loss_c:1.6992801427841187
loss_r:0.027758639305830002
loss_c:1.7827212810516357
loss_r:0.026366347447037697
loss_c:1.6951208114624023
loss_r:0.030961396172642708
loss_c:1.7553863525390625
loss_r:0.029471581801772118
loss_c:1.8186838626861572
loss_r:0.02862928993999958
loss_c:1.8624752759933472
loss_r:0.02434992976486683
loss_c:1.7083489894866943
loss_r:0.03000437095761299
loss_c:1.8394670486450195
loss_r:0.029183899983763695
loss_c:1.6601967811584473
loss_r:0.03086915612220764
loss_c:1.7411396503448486
loss_r:0.03134649619460106
loss_c:1.8126485347747803
loss_r:0.030354250222444534
loss_c:1.8791416883468628
loss_r:0.027356790378689766
loss_c:1.6745591163635254
loss_r:0.03197695314884186
loss_c:1.875547170639038
loss_r:0.026326412335038185
loss_c:1.673104166984558
loss_r:0.028680013492703438
loss_c:1.8188562393188477
loss_r:0.028972631320357323
loss_c:1.860421895980835
loss_r:0.028876926749944687
loss_c:1.9816679954528809
loss_r:0.027397090569138527
loss_c:1.8023732900619507
loss_r:0.029877226799726486
loss_c:1.8998459577560425
loss_r:0.026101311668753624
loss_c:1.712842345237732
loss_r:0.028127864003181458
loss_c:1.8477100133895874
loss_r:0.02710661292076111
loss_c:1.8504403829574585
loss_r:0.028670527040958405
loss_c:2.0128231048583984
loss_r:0.02478993870317936
loss_c:1.7706936597824097
loss_r:0.027637295424938202
loss_c:1.8570563793182373
loss_r:0.026207348331809044
loss_c:1.6720635890960693
loss_r:0.026352036744356155
loss_c:1.7388155460357666
loss_r:0.026589713990688324
loss_c:1.7713649272918701
loss_r:0.02766355499625206
loss_c:1.8345341682434082
loss_r:0.02596447989344597
loss_c:1.7375447750091553
loss_r:0.028057288378477097
loss_c:1.9610666036605835
loss_r:0.0248282290995121
loss_c:1.7675626277923584
loss_r:0.026045944541692734
loss_c:1.8174660205841064
loss_r:0.026417134329676628
loss_c:1.8832921981811523
loss_r:0.02702704258263111
loss_c:2.007544994354248
loss_r:0.023446008563041687
loss_c:1.7354549169540405
loss_r:0.027503982186317444
loss_c:1.879195213317871
loss_r:0.025486934930086136
loss_c:1.7576007843017578
loss_r:0.02865627408027649
loss_c:1.877608299255371
loss_r:0.027899011969566345
loss_c:1.8845555782318115
loss_r:0.029288122430443764
loss_c:2.0010485649108887
loss_r:0.024718180298805237
loss_c:1.755122184753418
loss_r:0.02898639254271984
loss_c:1.9040439128875732
loss_r:0.02699308656156063
loss_c:1.6819818019866943
loss_r:0.02886374481022358
loss_c:1.7758166790008545
loss_r:0.028084030374884605
loss_c:1.8036950826644897
loss_r:0.029295790940523148
loss_c:1.8698209524154663
loss_r:0.025469915941357613
loss_c:1.662883996963501
loss_r:0.02795305661857128
loss_c:1.8746235370635986
loss_r:0.025103889405727386
loss_c:1.7180149555206299
loss_r:0.02672186866402626
loss_c:1.7960450649261475
loss_r:0.026747429743409157
loss_c:1.9224603176116943
loss_r:0.027171345427632332
loss_c:1.923807144165039
loss_r:0.025620756670832634
loss_c:1.757585048675537
loss_r:0.029168615117669106
loss_c:1.9112024307250977
loss_r:0.027964483946561813
loss_c:1.7324683666229248
loss_r:0.033198971301317215
loss_c:1.9149130582809448
loss_r:0.030175698921084404
loss_c:1.9298404455184937
loss_r:0.031049655750393867
loss_c:1.9557794332504272
loss_r:0.025733716785907745
loss_c:1.698228120803833
loss_r:0.026313602924346924
loss_c:1.8572428226470947
loss_r:0.02537734992802143
loss_c:1.7839927673339844
loss_r:0.02795860357582569
loss_c:1.9294853210449219
loss_r:0.02769751101732254
loss_c:1.940540075302124
loss_r:0.024985607713460922
loss_c:1.941248893737793
loss_r:0.02369990572333336
loss_c:1.7655696868896484
loss_r:0.027083685621619225
loss_c:1.9118399620056152
loss_r:0.02597406692802906
loss_c:1.7690595388412476
loss_r:0.029218705371022224
loss_c:1.9008725881576538
loss_r:0.026128459721803665
loss_c:1.9663338661193848
loss_r:0.026131587103009224
loss_c:1.9584989547729492
loss_r:0.023645643144845963
loss_c:1.754029631614685
loss_r:0.026541823521256447
loss_c:1.883681058883667
loss_r:0.026698485016822815
loss_c:1.7301862239837646
loss_r:0.03025233931839466
loss_c:1.8101441860198975
loss_r:0.026903919875621796
loss_c:1.8331997394561768
loss_r:0.027280747890472412
loss_c:1.9340280294418335
loss_r:0.027945807203650475
loss_c:1.8507707118988037
loss_r:0.031205492094159126
loss_c:1.8992278575897217
loss_r:0.030315272510051727
loss_c:1.7233154773712158
loss_r:0.031311776489019394
loss_c:1.8012540340423584
loss_r:0.02893202006816864
loss_c:1.8074469566345215
loss_r:0.02354384772479534
loss_c:1.7399001121520996
loss_r:0.025085078552365303
loss_c:1.727081298828125
loss_r:0.027120105922222137
loss_c:1.8867181539535522
loss_r:0.026439694687724113
loss_c:1.6573386192321777
loss_r:0.028239425271749496
loss_c:1.8348281383514404
loss_r:0.026632186025381088
loss_c:1.8793786764144897
loss_r:0.02494710497558117
loss_c:1.7909400463104248
loss_r:0.02589099481701851
loss_c:1.7505401372909546
loss_r:0.02594398334622383
loss_c:1.8086684942245483
loss_r:0.025361446663737297
loss_c:1.608457326889038
loss_r:0.026661869138479233
loss_c:1.7986730337142944
loss_r:0.02424265444278717
loss_c:1.7937592267990112
loss_r:0.02353931963443756
loss_c:1.7637752294540405
loss_r:0.025209711864590645
loss_c:1.7391166687011719
loss_r:0.02596818469464779
loss_c:1.7806670665740967
loss_r:0.026657721027731895
loss_c:1.6178197860717773
loss_r:0.027530735358595848
loss_c:1.8284986019134521
loss_r:0.02520127408206463
loss_c:1.670395851135254
loss_r:0.0211479552090168
loss_c:1.5507855415344238
loss_r:0.02614685893058777
loss_c:1.6445420980453491
loss_r:0.02641790360212326
loss_c:1.7196701765060425
loss_r:0.02513037621974945
loss_c:1.5621675252914429
loss_r:0.025640591979026794
loss_c:1.6640536785125732
loss_r:0.026250436902046204
loss_c:1.7898273468017578
loss_r:0.026500817388296127
loss_c:1.8205708265304565
loss_r:0.0253274068236351
loss_c:1.616809606552124
loss_r:0.02486373856663704
loss_c:1.702906608581543
loss_r:0.024165503680706024
loss_c:1.5162490606307983
loss_r:0.02510249614715576
loss_c:1.6487443447113037
loss_r:0.02760455757379532
loss_c:1.837988257408142
loss_r:0.028497671708464622
loss_c:1.756040334701538
loss_r:0.027719853445887566
loss_c:1.6324312686920166
loss_r:0.026700152084231377
loss_c:1.7194442749023438
loss_r:0.022984672337770462
loss_c:1.4319432973861694
loss_r:0.023510470986366272
loss_c:1.6286678314208984
loss_r:0.026076501235365868
loss_c:1.8054816722869873
loss_r:0.023365512490272522
loss_c:1.648322582244873
loss_r:0.02480558678507805
loss_c:1.549990177154541
loss_r:0.027022309601306915
loss_c:1.76085364818573
loss_r:0.023720702156424522
loss_c:1.551877737045288
loss_r:0.02371661551296711
loss_c:1.6656146049499512
loss_r:0.02388625778257847
loss_c:1.750532865524292
loss_r:0.02431533671915531
loss_c:1.6960344314575195
loss_r:0.022764628753066063
loss_c:1.5387511253356934
loss_r:0.02598411589860916
loss_c:1.8083982467651367
loss_r:0.023090830072760582
loss_c:1.5624799728393555
loss_r:0.020453641191124916
loss_c:1.619909644126892
loss_r:0.024112453684210777
loss_c:1.8382976055145264
loss_r:0.02641095593571663
loss_c:1.7904832363128662
loss_r:0.02335580438375473
loss_c:1.580504298210144
loss_r:0.028857717290520668
loss_c:1.8002243041992188
loss_r:0.025025175884366035
loss_c:1.5444145202636719
loss_r:0.026194831356406212
loss_c:1.588037371635437
loss_r:0.028009166941046715
loss_c:1.7438777685165405
loss_r:0.02898588590323925
loss_c:1.779685378074646
loss_r:0.026059694588184357
loss_c:1.5021483898162842
loss_r:0.02753537893295288
loss_c:1.686614751815796
loss_r:0.02331315167248249
loss_c:1.5502699613571167
loss_r:0.026489797979593277
loss_c:1.612663984298706
loss_r:0.0312720350921154
loss_c:1.763849139213562
loss_r:0.028403159230947495
loss_c:1.6095346212387085
loss_r:0.029988989233970642
loss_c:1.520066261291504
loss_r:0.027419602498412132
loss_c:1.673581838607788
loss_r:0.028472309932112694
loss_c:1.486194372177124
loss_r:0.027866149321198463
loss_c:1.5269193649291992
loss_r:0.030609944835305214
loss_c:1.7378573417663574
loss_r:0.02929188497364521
loss_c:1.6541554927825928
loss_r:0.02820262312889099
loss_c:1.505887746810913
loss_r:0.02993566170334816
loss_c:1.7575483322143555
loss_r:0.029185697436332703
loss_c:1.5949351787567139
loss_r:0.024644216522574425
loss_c:1.5626158714294434
loss_r:0.030718497931957245
loss_c:1.9493331909179688
loss_r:0.029853031039237976
loss_c:1.6909370422363281
loss_r:0.02718205191195011
loss_c:1.509930968284607
loss_r:0.0292026586830616
loss_c:1.756170630455017
loss_r:0.027391232550144196
loss_c:1.5798534154891968
loss_r:0.026068463921546936
loss_c:1.5275071859359741
loss_r:0.02651062421500683
loss_c:1.620356559753418
loss_r:0.028209861367940903
loss_c:1.5430142879486084
loss_r:0.026978755369782448
loss_c:1.4665244817733765
loss_r:0.02962438017129898
loss_c:1.6844093799591064
loss_r:0.026719897985458374
loss_c:1.4298762083053589
loss_r:0.026748329401016235
loss_c:1.594824194908142
loss_r:0.024867882952094078
loss_c:1.7306671142578125
loss_r:0.02683994732797146
loss_c:1.6394785642623901
loss_r:0.02769496478140354
loss_c:1.5466349124908447
loss_r:0.028922099620103836
loss_c:1.763211727142334
loss_r:0.027994168922305107
loss_c:1.5548629760742188
loss_r:0.02537982538342476
loss_c:1.5254456996917725
loss_r:0.027658851817250252
loss_c:1.744654655456543
loss_r:0.024683834984898567
loss_c:1.5820072889328003
loss_r:0.02677261084318161
loss_c:1.4667613506317139
loss_r:0.02985856868326664
loss_c:1.7503762245178223
loss_r:0.025399770587682724
loss_c:1.460525393486023
loss_r:0.025865308940410614
loss_c:1.512943983078003
loss_r:0.026916280388832092
loss_c:1.7989156246185303
loss_r:0.024457009509205818
loss_c:1.5960206985473633
loss_r:0.026038821786642075
loss_c:1.5941157341003418
loss_r:0.028534654527902603
loss_c:1.8348078727722168
loss_r:0.028261469677090645
loss_c:1.662888526916504
loss_r:0.023487677797675133
loss_c:1.6529481410980225
loss_r:0.0279719028621912
loss_c:1.7961504459381104
loss_r:0.028895607218146324
loss_c:1.7111365795135498
loss_r:0.02796195074915886
loss_c:1.6246638298034668
loss_r:0.027903245761990547
loss_c:1.733741283416748
loss_r:0.028146808966994286
loss_c:1.4897875785827637
loss_r:0.027869904413819313
loss_c:1.6659834384918213
loss_r:0.02655213698744774
loss_c:1.7021749019622803
loss_r:0.024090953171253204
loss_c:1.6034345626831055
loss_r:0.024547461420297623
loss_c:1.5489263534545898
loss_r:0.023357277736067772
loss_c:1.6251046657562256
loss_r:0.020909061655402184
loss_c:1.4519329071044922
loss_r:0.022161798551678658
loss_c:1.609893798828125
loss_r:0.02144734561443329
loss_c:1.6961411237716675
loss_r:0.021324029192328453
loss_c:1.6192748546600342
loss_r:0.022506985813379288
loss_c:1.5848474502563477
loss_r:0.021842047572135925
loss_c:1.5428160429000854
loss_r:0.022360339760780334
loss_c:1.4748573303222656
loss_r:0.021669331938028336
loss_c:1.6309937238693237
loss_r:0.021649112924933434
loss_c:1.6252297163009644
loss_r:0.021166548132896423
loss_c:1.5870732069015503
loss_r:0.02062721736729145
loss_c:1.591719627380371
loss_r:0.022028736770153046
loss_c:1.6502593755722046
loss_r:0.02161889523267746
loss_c:1.5390256643295288
loss_r:0.02126312255859375
loss_c:1.5714077949523926
loss_r:0.02284427173435688
loss_c:1.6620612144470215
loss_r:0.022868992760777473
loss_c:1.6006830930709839
loss_r:0.024938585236668587
loss_c:1.6158469915390015
loss_r:0.02258436568081379
loss_c:1.638793706893921
loss_r:0.02332746610045433
loss_c:1.4994101524353027
loss_r:0.021665968000888824
loss_c:1.5363996028900146
loss_r:0.025996126234531403
loss_c:1.701927900314331
loss_r:0.024571184068918228
loss_c:1.644709825515747
loss_r:0.024869076907634735
loss_c:1.570746898651123
loss_r:0.02376604825258255
loss_c:1.5468052625656128
loss_r:0.024019364267587662
loss_c:1.5340094566345215
loss_r:0.023116309195756912
loss_c:1.5704212188720703
loss_r:0.023868663236498833
loss_c:1.5980428457260132
loss_r:0.02104053646326065
loss_c:1.625821828842163
loss_r:0.021141236647963524
loss_c:1.444570541381836
loss_r:0.021754296496510506
loss_c:1.6219911575317383
loss_r:0.020159250125288963
loss_c:1.5203795433044434
loss_r:0.018461020663380623
loss_c:1.534368872642517
loss_r:0.021625502035021782
loss_c:1.6758744716644287
loss_r:0.018764015287160873
loss_c:1.5322225093841553
loss_r:0.02114177867770195
loss_c:1.556394100189209
loss_r:0.02202684059739113
loss_c:1.6305774450302124
loss_r:0.021055765450000763
loss_c:1.5420281887054443
loss_r:0.017441943287849426
loss_c:1.5152578353881836
loss_r:0.02068324200809002
loss_c:1.68156898021698
loss_r:0.017333438619971275
loss_c:1.504399061203003
loss_r:0.01942617818713188
loss_c:1.5578246116638184
loss_r:0.019832978025078773
loss_c:1.563791036605835
loss_r:0.0187655258923769
loss_c:1.5021424293518066
loss_r:0.017596574500203133
loss_c:1.4942116737365723
loss_r:0.021048909053206444
loss_c:1.7138618230819702
loss_r:0.018193114548921585
loss_c:1.5247406959533691
loss_r:0.02001877874135971
loss_c:1.5314706563949585
loss_r:0.0214714165776968
loss_c:1.6264305114746094
loss_r:0.019313016906380653
loss_c:1.4844821691513062
loss_r:0.01976367086172104
loss_c:1.5146915912628174
loss_r:0.022242454811930656
loss_c:1.6712417602539062
loss_r:0.01883924938738346
loss_c:1.6531295776367188
loss_r:0.01934082992374897
loss_c:1.5445067882537842
loss_r:0.021838735789060593
loss_c:1.65655517578125
loss_r:0.02084892988204956
loss_c:1.5878747701644897
loss_r:0.017170105129480362
loss_c:1.5147316455841064
loss_r:0.021960902959108353
loss_c:1.6816699504852295
loss_r:0.019737323746085167
loss_c:1.6343196630477905
loss_r:0.018308455124497414
loss_c:1.4920213222503662
loss_r:0.02117539756000042
loss_c:1.6380915641784668
loss_r:0.019188305363059044
loss_c:1.5094431638717651
loss_r:0.01808318682014942
loss_c:1.5360848903656006
loss_r:0.023139355704188347
loss_c:1.6709010601043701
loss_r:0.018781956285238266
loss_c:1.6311039924621582
loss_r:0.019138367846608162
loss_c:1.5016248226165771
loss_r:0.023889323696494102
loss_c:1.6738336086273193
loss_r:0.021371478214859962
loss_c:1.532867431640625
loss_r:0.02105543203651905
loss_c:1.5402612686157227
loss_r:0.023259146139025688
loss_c:1.6920032501220703
loss_r:0.020233960822224617
loss_c:1.6765855550765991
loss_r:0.020002156496047974
loss_c:1.5501230955123901
loss_r:0.023295972496271133
loss_c:1.697392225265503
loss_r:0.022809693589806557
loss_c:1.6231683492660522
loss_r:0.019254006445407867
loss_c:1.543076515197754
loss_r:0.022427363321185112
loss_c:1.6406458616256714
loss_r:0.02059291861951351
loss_c:1.6001628637313843
loss_r:0.018918532878160477
loss_c:1.4813311100006104
loss_r:0.02427016571164131
loss_c:1.7172259092330933
loss_r:0.02356242761015892
loss_c:1.63596510887146
loss_r:0.018598634749650955
loss_c:1.5589250326156616
loss_r:0.02454063482582569
loss_c:1.742954969406128
loss_r:0.021700633689761162
loss_c:1.66563880443573
loss_r:0.022558409720659256
loss_c:1.5574681758880615
loss_r:0.02688714861869812
loss_c:1.7381404638290405
loss_r:0.02377323806285858
loss_c:1.5713613033294678
loss_r:0.022833475843071938
loss_c:1.5281312465667725
loss_r:0.02598792314529419
loss_c:1.6958612203598022
loss_r:0.025560809299349785
loss_c:1.7140579223632812
loss_r:0.02345433458685875
loss_c:1.5453310012817383
loss_r:0.02810022048652172
loss_c:1.7191798686981201
loss_r:0.027159756049513817
loss_c:1.6006190776824951
loss_r:0.023566456511616707
loss_c:1.4979350566864014
loss_r:0.025913823395967484
loss_c:1.630889654159546
loss_r:0.0259027611464262
loss_c:1.649418592453003
loss_r:0.02575763687491417
loss_c:1.5694020986557007
loss_r:0.028320003300905228
loss_c:1.7286250591278076
loss_r:0.02439914457499981
loss_c:1.5114434957504272
loss_r:0.024147655814886093
loss_c:1.5572004318237305
loss_r:0.026001721620559692
loss_c:1.7354943752288818
loss_r:0.023604707792401314
loss_c:1.6640863418579102
loss_r:0.024720797315239906
loss_c:1.6303911209106445
loss_r:0.027040915563702583
loss_c:1.7419923543930054
loss_r:0.024651166051626205
loss_c:1.497357726097107
loss_r:0.02662752754986286
loss_c:1.5513806343078613
loss_r:0.026411280035972595
loss_c:1.7090559005737305
loss_r:0.022669648751616478
loss_c:1.5584008693695068
loss_r:0.024675967171788216
loss_c:1.601057529449463
loss_r:0.026957722380757332
loss_c:1.7231848239898682
loss_r:0.02486160211265087
loss_c:1.5470426082611084
loss_r:0.023747412487864494
loss_c:1.5507186651229858
loss_r:0.02712642215192318
loss_c:1.77791166305542
loss_r:0.0221220925450325
loss_c:1.6468600034713745
loss_r:0.025227151811122894
loss_c:1.5897510051727295
loss_r:0.027792437002062798
loss_c:1.7344720363616943
loss_r:0.02477188967168331
loss_c:1.5574538707733154
loss_r:0.025932617485523224
loss_c:1.5913667678833008
loss_r:0.028622759506106377
loss_c:1.7955125570297241
loss_r:0.024183018133044243
loss_c:1.6382951736450195
loss_r:0.02631284110248089
loss_c:1.58782958984375
loss_r:0.028614861890673637
loss_c:1.7266161441802979
loss_r:0.02649788185954094
loss_c:1.537125587463379
loss_r:0.025980336591601372
loss_c:1.6441023349761963
loss_r:0.028414372354745865
loss_c:1.788039207458496
loss_r:0.023211728781461716
loss_c:1.6872260570526123
loss_r:0.024754676967859268
loss_c:1.5908427238464355
loss_r:0.029021963477134705
loss_c:1.7014966011047363
loss_r:0.02688327617943287
loss_c:1.5287666320800781
loss_r:0.026176873594522476
loss_c:1.6066639423370361
loss_r:0.029684608802199364
loss_c:1.7551860809326172
loss_r:0.02264760062098503
loss_c:1.56867253780365
loss_r:0.029575563967227936
loss_c:1.75986909866333
loss_r:0.03162884712219238
loss_c:1.800567626953125
loss_r:0.029426636174321175
loss_c:1.7051453590393066
loss_r:0.03108229488134384
loss_c:1.8169611692428589
loss_r:0.03000447154045105
loss_c:1.7857235670089722
loss_r:0.02775450423359871
loss_c:1.7367312908172607
loss_r:0.031760670244693756
loss_c:1.7731937170028687
loss_r:0.032280854880809784
loss_c:1.777279257774353
loss_r:0.032395318150520325
loss_c:1.6617354154586792
loss_r:0.03171376511454582
loss_c:1.800475835800171
loss_r:0.030007971450686455
loss_c:1.7761356830596924
loss_r:0.027981624007225037
loss_c:1.7410271167755127
loss_r:0.029539257287979126
loss_c:1.7718709707260132
loss_r:0.032823871821165085
loss_c:1.8375859260559082
loss_r:0.032047562301158905
loss_c:1.7074931859970093
loss_r:0.031094135716557503
loss_c:1.8139123916625977
loss_r:0.029637083411216736
loss_c:1.7974159717559814
loss_r:0.026544082909822464
loss_c:1.7019214630126953
loss_r:0.03338969126343727
loss_c:1.8444406986236572
loss_r:0.0351511687040329
loss_c:1.8919137716293335
loss_r:0.033955059945583344
loss_c:1.744739294052124
loss_r:0.035896822810173035
loss_c:1.8839654922485352
loss_r:0.03609026223421097
loss_c:1.8722057342529297
loss_r:0.032985199242830276
loss_c:1.776246428489685
loss_r:0.03472590819001198
loss_c:1.8810501098632812
loss_r:0.035601381212472916
loss_c:1.8396835327148438
loss_r:0.032797954976558685
loss_c:1.6950801610946655
loss_r:0.03277686610817909
loss_c:1.835966944694519
loss_r:0.033046118915081024
loss_c:1.8009541034698486
loss_r:0.03093014843761921
loss_c:1.7291781902313232
loss_r:0.032815124839544296
loss_c:1.8057074546813965
loss_r:0.03253655135631561
loss_c:1.8557052612304688
loss_r:0.0311549361795187
loss_c:1.7648379802703857
loss_r:0.03151271492242813
loss_c:1.8833305835723877
loss_r:0.031080741435289383
loss_c:1.8582795858383179
loss_r:0.030047675594687462
loss_c:1.7675451040267944
loss_r:0.03403975069522858
loss_c:1.8508257865905762
loss_r:0.03185754641890526
loss_c:1.8673274517059326
loss_r:0.03264822065830231
loss_c:1.6906700134277344
loss_r:0.03192177042365074
loss_c:1.8226888179779053
loss_r:0.029512226581573486
loss_c:1.799140214920044
loss_r:0.028414718806743622
loss_c:1.7224500179290771
loss_r:0.03237482160329819
loss_c:1.7878386974334717
loss_r:0.03112269937992096
loss_c:1.8385508060455322
loss_r:0.03232335299253464
loss_c:1.7024857997894287
total_val_loss:1.809531569480896
EarlyStopping counter: 2 out of 2
early_stopping
model:SimMTM
model=SimMTM enhance_decoding=True series_embed_len:1 data=ETTh2 input_len=336 encoder_depth=2 decoder_depth=1 enc_mask_rate=0.25 dec_mask_rate=0.75 lr=0.001 d_model=16 patch_size=336 train_shuffle:True 
 min_val_loss:1.7678864002227783
