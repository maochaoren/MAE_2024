nohup: ignoring input
Args in experiment:
Namespace(task_name='finetune', is_training=1, model_id='Weather', model='SimMTM', data='Weather', root_path='./dataset/weather/', data_path='weather.csv', features='M', target='OT', freq='h', checkpoints='./outputs/checkpoints/', pretrain_checkpoints='./outputs/pretrain_checkpoints/', transfer_checkpoints='ckpt_best.pth', load_checkpoints=None, select_channels=1, seq_len=384, label_len=48, pred_len=96, seasonal_patterns='Monthly', top_k=5, num_kernels=3, enc_in=21, dec_in=21, c_out=21, d_model=8, n_heads=8, e_layers=1, s_e_layers=2, t_e_layers=1, d_layers=1, d_ff=64, moving_avg=25, factor=1, distil=True, dropout=0.1, fc_dropout=0, head_dropout=0.1, embed='timeF', activation='gelu', output_attention=False, individual=0, pct_start=0.3, decomp=1, decomp_method='mov_avg', window_size=97, st_sep=5.0, top_k_fft=25, lpf=50, patching_s=0, patching_t=1, patch_len_s=24, patch_len_t=1, stride=8, num_workers=5, itr=1, train_epochs=40, batch_size=16, is_early_stop=1, patience=3, learning_rate=0.0001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0', lm=3, positive_nums=3, rbtp=1, temperature=0.2, masked_rule='geometric', mask_rate=0.5)
None
Use GPU: cuda:0
number of model params 594480
>>>>>>>start training : finetune_SimMTM_Weather_M_isdec1_decmetmov_avg_win97_sep5.0_topk25_sl384_ll48_pl96_dm8_df64_nh8_el1_dl1_fc1_dp0.1_hdp0.1_ep40_bs16_lr0.0001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36408 2275
val 5175 323
test 10444 10444
Epoch: 1, Steps: 2275, Time: 602.44s | Train Loss: 0.5829772 Vali Loss: 0.4617508 Test Loss: 0.1953722
Validation loss decreased (inf --> 0.461751).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2, Steps: 2275, Time: 603.73s | Train Loss: 0.4822579 Vali Loss: 0.4220396 Test Loss: 0.1739226
Validation loss decreased (0.461751 --> 0.422040).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3, Steps: 2275, Time: 603.08s | Train Loss: 0.4596738 Vali Loss: 0.4183508 Test Loss: 0.1707979
Validation loss decreased (0.422040 --> 0.418351).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4, Steps: 2275, Time: 602.10s | Train Loss: 0.4545301 Vali Loss: 0.4175227 Test Loss: 0.1698004
Validation loss decreased (0.418351 --> 0.417523).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5, Steps: 2275, Time: 599.62s | Train Loss: 0.4514701 Vali Loss: 0.4147705 Test Loss: 0.1683239
Validation loss decreased (0.417523 --> 0.414770).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6, Steps: 2275, Time: 600.29s | Train Loss: 0.4497994 Vali Loss: 0.4124951 Test Loss: 0.1676611
Validation loss decreased (0.414770 --> 0.412495).  Saving model ...
Updating learning rate to 3.125e-06
Epoch: 7, Steps: 2275, Time: 601.54s | Train Loss: 0.4491828 Vali Loss: 0.4103293 Test Loss: 0.1664424
Validation loss decreased (0.412495 --> 0.410329).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8, Steps: 2275, Time: 601.41s | Train Loss: 0.4489316 Vali Loss: 0.4110557 Test Loss: 0.1664399
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.8125e-07
Epoch: 9, Steps: 2275, Time: 600.27s | Train Loss: 0.4486720 Vali Loss: 0.4106064 Test Loss: 0.1662886
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.90625e-07
Epoch: 10, Steps: 2275, Time: 601.08s | Train Loss: 0.4485726 Vali Loss: 0.4107417 Test Loss: 0.1662959
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : finetune_SimMTM_Weather_M_isdec1_decmetmov_avg_win97_sep5.0_topk25_sl384_ll48_pl96_dm8_df64_nh8_el1_dl1_fc1_dp0.1_hdp0.1_ep40_bs16_lr0.0001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444 10444
384->96, mse:0.166, mae:0.217
Args in experiment:
Namespace(task_name='finetune', is_training=1, model_id='Weather', model='SimMTM', data='Weather', root_path='./dataset/weather/', data_path='weather.csv', features='M', target='OT', freq='h', checkpoints='./outputs/checkpoints/', pretrain_checkpoints='./outputs/pretrain_checkpoints/', transfer_checkpoints='ckpt_best.pth', load_checkpoints=None, select_channels=1, seq_len=384, label_len=48, pred_len=192, seasonal_patterns='Monthly', top_k=5, num_kernels=3, enc_in=21, dec_in=21, c_out=21, d_model=8, n_heads=8, e_layers=1, s_e_layers=2, t_e_layers=1, d_layers=1, d_ff=64, moving_avg=25, factor=1, distil=True, dropout=0.1, fc_dropout=0, head_dropout=0.1, embed='timeF', activation='gelu', output_attention=False, individual=0, pct_start=0.3, decomp=1, decomp_method='mov_avg', window_size=97, st_sep=5.0, top_k_fft=25, lpf=50, patching_s=0, patching_t=1, patch_len_s=24, patch_len_t=1, stride=8, num_workers=5, itr=1, train_epochs=40, batch_size=16, is_early_stop=1, patience=3, learning_rate=0.0001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0', lm=3, positive_nums=3, rbtp=1, temperature=0.2, masked_rule='geometric', mask_rate=0.5)
None
Use GPU: cuda:0
number of model params 1184496
>>>>>>>start training : finetune_SimMTM_Weather_M_isdec1_decmetmov_avg_win97_sep5.0_topk25_sl384_ll48_pl192_dm8_df64_nh8_el1_dl1_fc1_dp0.1_hdp0.1_ep40_bs16_lr0.0001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36312 2269
val 5079 317
test 10348 10348
Epoch: 1, Steps: 2269, Time: 597.00s | Train Loss: 0.6237220 Vali Loss: 0.5312133 Test Loss: 0.2358312
Validation loss decreased (inf --> 0.531213).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2, Steps: 2269, Time: 597.90s | Train Loss: 0.5312183 Vali Loss: 0.4952764 Test Loss: 0.2183124
Validation loss decreased (0.531213 --> 0.495276).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3, Steps: 2269, Time: 599.79s | Train Loss: 0.5120468 Vali Loss: 0.4933887 Test Loss: 0.2154935
Validation loss decreased (0.495276 --> 0.493389).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4, Steps: 2269, Time: 601.54s | Train Loss: 0.5074423 Vali Loss: 0.4897427 Test Loss: 0.2147934
Validation loss decreased (0.493389 --> 0.489743).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5, Steps: 2269, Time: 598.70s | Train Loss: 0.5052124 Vali Loss: 0.4875317 Test Loss: 0.2134103
Validation loss decreased (0.489743 --> 0.487532).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6, Steps: 2269, Time: 598.58s | Train Loss: 0.5040721 Vali Loss: 0.4877942 Test Loss: 0.2140916
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-06
Epoch: 7, Steps: 2269, Time: 599.08s | Train Loss: 0.5034390 Vali Loss: 0.4862180 Test Loss: 0.2137023
Validation loss decreased (0.487532 --> 0.486218).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8, Steps: 2269, Time: 599.66s | Train Loss: 0.5032448 Vali Loss: 0.4860637 Test Loss: 0.2133031
Validation loss decreased (0.486218 --> 0.486064).  Saving model ...
Updating learning rate to 7.8125e-07
Epoch: 9, Steps: 2269, Time: 599.86s | Train Loss: 0.5030510 Vali Loss: 0.4867468 Test Loss: 0.2134594
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.90625e-07
Epoch: 10, Steps: 2269, Time: 598.61s | Train Loss: 0.5029830 Vali Loss: 0.4862985 Test Loss: 0.2134962
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.953125e-07
Epoch: 11, Steps: 2269, Time: 599.29s | Train Loss: 0.5027561 Vali Loss: 0.4865775 Test Loss: 0.2133907
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : finetune_SimMTM_Weather_M_isdec1_decmetmov_avg_win97_sep5.0_topk25_sl384_ll48_pl192_dm8_df64_nh8_el1_dl1_fc1_dp0.1_hdp0.1_ep40_bs16_lr0.0001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10348 10348
384->192, mse:0.213, mae:0.258
Args in experiment:
Namespace(task_name='finetune', is_training=1, model_id='Weather', model='SimMTM', data='Weather', root_path='./dataset/weather/', data_path='weather.csv', features='M', target='OT', freq='h', checkpoints='./outputs/checkpoints/', pretrain_checkpoints='./outputs/pretrain_checkpoints/', transfer_checkpoints='ckpt_best.pth', load_checkpoints=None, select_channels=1, seq_len=384, label_len=48, pred_len=336, seasonal_patterns='Monthly', top_k=5, num_kernels=3, enc_in=21, dec_in=21, c_out=21, d_model=8, n_heads=8, e_layers=1, s_e_layers=2, t_e_layers=1, d_layers=1, d_ff=64, moving_avg=25, factor=1, distil=True, dropout=0.1, fc_dropout=0, head_dropout=0.1, embed='timeF', activation='gelu', output_attention=False, individual=0, pct_start=0.3, decomp=1, decomp_method='mov_avg', window_size=97, st_sep=5.0, top_k_fft=25, lpf=50, patching_s=0, patching_t=1, patch_len_s=24, patch_len_t=1, stride=8, num_workers=5, itr=1, train_epochs=40, batch_size=16, is_early_stop=1, patience=3, learning_rate=0.0001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0', lm=3, positive_nums=3, rbtp=1, temperature=0.2, masked_rule='geometric', mask_rate=0.5)
None
Use GPU: cuda:0
number of model params 2069520
>>>>>>>start training : finetune_SimMTM_Weather_M_isdec1_decmetmov_avg_win97_sep5.0_topk25_sl384_ll48_pl336_dm8_df64_nh8_el1_dl1_fc1_dp0.1_hdp0.1_ep40_bs16_lr0.0001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36168 2260
val 4935 308
test 10204 10204
Epoch: 1, Steps: 2260, Time: 596.70s | Train Loss: 0.6616709 Vali Loss: 0.5962319 Test Loss: 0.2777123
Validation loss decreased (inf --> 0.596232).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2, Steps: 2260, Time: 594.41s | Train Loss: 0.5789492 Vali Loss: 0.5648301 Test Loss: 0.2618088
Validation loss decreased (0.596232 --> 0.564830).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3, Steps: 2260, Time: 597.46s | Train Loss: 0.5609860 Vali Loss: 0.5614917 Test Loss: 0.2589214
Validation loss decreased (0.564830 --> 0.561492).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4, Steps: 2260, Time: 596.74s | Train Loss: 0.5569822 Vali Loss: 0.5587023 Test Loss: 0.2575880
Validation loss decreased (0.561492 --> 0.558702).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5, Steps: 2260, Time: 597.89s | Train Loss: 0.5550229 Vali Loss: 0.5612397 Test Loss: 0.2577075
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
Epoch: 6, Steps: 2260, Time: 598.16s | Train Loss: 0.5536208 Vali Loss: 0.5597432 Test Loss: 0.2573962
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-06
Epoch: 7, Steps: 2260, Time: 597.14s | Train Loss: 0.5532960 Vali Loss: 0.5592912 Test Loss: 0.2573957
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : finetune_SimMTM_Weather_M_isdec1_decmetmov_avg_win97_sep5.0_topk25_sl384_ll48_pl336_dm8_df64_nh8_el1_dl1_fc1_dp0.1_hdp0.1_ep40_bs16_lr0.0001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10204 10204
384->336, mse:0.258, mae:0.289
Args in experiment:
Namespace(task_name='finetune', is_training=1, model_id='Weather', model='SimMTM', data='Weather', root_path='./dataset/weather/', data_path='weather.csv', features='M', target='OT', freq='h', checkpoints='./outputs/checkpoints/', pretrain_checkpoints='./outputs/pretrain_checkpoints/', transfer_checkpoints='ckpt_best.pth', load_checkpoints=None, select_channels=1, seq_len=384, label_len=48, pred_len=720, seasonal_patterns='Monthly', top_k=5, num_kernels=3, enc_in=21, dec_in=21, c_out=21, d_model=8, n_heads=8, e_layers=1, s_e_layers=2, t_e_layers=1, d_layers=1, d_ff=64, moving_avg=25, factor=1, distil=True, dropout=0.1, fc_dropout=0, head_dropout=0.1, embed='timeF', activation='gelu', output_attention=False, individual=0, pct_start=0.3, decomp=1, decomp_method='mov_avg', window_size=97, st_sep=5.0, top_k_fft=25, lpf=50, patching_s=0, patching_t=1, patch_len_s=24, patch_len_t=1, stride=8, num_workers=5, itr=1, train_epochs=40, batch_size=16, is_early_stop=1, patience=3, learning_rate=0.0001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0', lm=3, positive_nums=3, rbtp=1, temperature=0.2, masked_rule='geometric', mask_rate=0.5)
None
Use GPU: cuda:0
number of model params 4429584
>>>>>>>start training : finetune_SimMTM_Weather_M_isdec1_decmetmov_avg_win97_sep5.0_topk25_sl384_ll48_pl720_dm8_df64_nh8_el1_dl1_fc1_dp0.1_hdp0.1_ep40_bs16_lr0.0001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 35784 2236
val 4551 284
test 9820 9820
Epoch: 1, Steps: 2236, Time: 588.32s | Train Loss: 0.7067839 Vali Loss: 0.6830520 Test Loss: 0.3396654
Validation loss decreased (inf --> 0.683052).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2, Steps: 2236, Time: 588.19s | Train Loss: 0.6415112 Vali Loss: 0.6667443 Test Loss: 0.3294293
Validation loss decreased (0.683052 --> 0.666744).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3, Steps: 2236, Time: 588.95s | Train Loss: 0.6261023 Vali Loss: 0.6610524 Test Loss: 0.3268712
Validation loss decreased (0.666744 --> 0.661052).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4, Steps: 2236, Time: 590.15s | Train Loss: 0.6222460 Vali Loss: 0.6615326 Test Loss: 0.3275100
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
Epoch: 5, Steps: 2236, Time: 590.24s | Train Loss: 0.6204882 Vali Loss: 0.6593643 Test Loss: 0.3273240
Validation loss decreased (0.661052 --> 0.659364).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6, Steps: 2236, Time: 588.72s | Train Loss: 0.6194696 Vali Loss: 0.6577064 Test Loss: 0.3262146
Validation loss decreased (0.659364 --> 0.657706).  Saving model ...
Updating learning rate to 3.125e-06
Epoch: 7, Steps: 2236, Time: 588.88s | Train Loss: 0.6189745 Vali Loss: 0.6579672 Test Loss: 0.3263038
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.5625e-06
Epoch: 8, Steps: 2236, Time: 588.76s | Train Loss: 0.6186498 Vali Loss: 0.6575941 Test Loss: 0.3265071
Validation loss decreased (0.657706 --> 0.657594).  Saving model ...
Updating learning rate to 7.8125e-07
Epoch: 9, Steps: 2236, Time: 586.80s | Train Loss: 0.6183836 Vali Loss: 0.6573817 Test Loss: 0.3262350
Validation loss decreased (0.657594 --> 0.657382).  Saving model ...
Updating learning rate to 3.90625e-07
Epoch: 10, Steps: 2236, Time: 587.94s | Train Loss: 0.6183671 Vali Loss: 0.6574055 Test Loss: 0.3262033
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.953125e-07
Epoch: 11, Steps: 2236, Time: 586.57s | Train Loss: 0.6184145 Vali Loss: 0.6576443 Test Loss: 0.3262401
EarlyStopping counter: 2 out of 3
Updating learning rate to 9.765625e-08
Epoch: 12, Steps: 2236, Time: 585.06s | Train Loss: 0.6183601 Vali Loss: 0.6575572 Test Loss: 0.3262801
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : finetune_SimMTM_Weather_M_isdec1_decmetmov_avg_win97_sep5.0_topk25_sl384_ll48_pl720_dm8_df64_nh8_el1_dl1_fc1_dp0.1_hdp0.1_ep40_bs16_lr0.0001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820 9820
384->720, mse:0.326, mae:0.339
